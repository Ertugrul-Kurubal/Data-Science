{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005970</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005971</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005972</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005973</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005974</th>\n",
       "      <td>her</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  frequency\n",
       "0                 bir   18835735\n",
       "1                  bu   11062659\n",
       "2                  ne    8025880\n",
       "3                  ve    7766036\n",
       "4                için    5484109\n",
       "...               ...        ...\n",
       "1005970       karnaya          5\n",
       "1005971   dörtlümüzün          5\n",
       "1005972  karnavalınız          5\n",
       "1005973      hurmanın          5\n",
       "1005974           her          5\n",
       "\n",
       "[1005975 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandone</td>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abanoz</td>\n",
       "      <td>ebony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdest</td>\n",
       "      <td>ablution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdesthane</td>\n",
       "      <td>ablution room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>zodyak</td>\n",
       "      <td>zodiac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>zooloji</td>\n",
       "      <td>zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>zoolojik</td>\n",
       "      <td>zoological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>zum</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main   english_word\n",
       "0             abaküs         abacus\n",
       "1           abandone        abandon\n",
       "2             abanoz          ebony\n",
       "3             abdest       ablution\n",
       "4         abdesthane  ablution room\n",
       "...              ...            ...\n",
       "2132          zodyak         zodiac\n",
       "2133           zombi         zombie\n",
       "2134         zooloji        zoology\n",
       "2135        zoolojik     zoological\n",
       "2136             zum           zoom\n",
       "\n",
       "[2137 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_pair_all = pd.read_excel(f\"{lang_pair_list[0]}\")\n",
    "df_pair_all = pd.read_excel(f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ekspres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elimine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enteresan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manüel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>leopar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>maksimum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>stratosfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>ombudsman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>greyder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2129 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main\n",
       "0            ekspres\n",
       "1            elimine\n",
       "2          enteresan\n",
       "3             detone\n",
       "4             manüel\n",
       "...              ...\n",
       "2124          leopar\n",
       "2125        maksimum\n",
       "2126      stratosfer\n",
       "2127       ombudsman\n",
       "2128         greyder\n",
       "\n",
       "[2129 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, word_thresh_num is an integer, column_list is list value\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop code block word and twogram pair\n",
    "word_thresh_num = 2  # want how many word sample \n",
    "word_start = 0  # 0\n",
    "word_end = 7  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1  # first output file extention\n",
    "\n",
    "twogram_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]  # must be include word and frequency column\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word \n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert twogram pair\n",
    "        try:\n",
    "            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                        freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_28_Word_Step_7_Result1.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result2.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result3.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result4.xlsx']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result*.xlsx\")\n",
    "part_result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read previous part result\n",
    "df_part_all = pd.DataFrame()\n",
    "for i in part_result_file:\n",
    "    df_var = pd.read_excel(f\"{i}\")\n",
    "    df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "# set_part_twogram_pair = set([])  # option for skip Condition 1\n",
    "\n",
    "# while loop code block\n",
    "\n",
    "word_thresh_num = 2\n",
    "twogram_thresh_minus = 0  # for optional twogram thresh number \n",
    "twogram_pair_thresh_minus = 0  # for optinal twogram pair thresh number.\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 28  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1\n",
    "\n",
    "twogram_num = word_thresh_num * step_num   # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_thresh_minus), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_pair_thresh_minus), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>evet doktor</td>\n",
       "      <td>1185</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>evet madam</td>\n",
       "      <td>1043</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>çok romantik</td>\n",
       "      <td>980</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>komik mi</td>\n",
       "      <td>822</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>parti mi</td>\n",
       "      <td>751</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>hayır değil</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>bir milyon</td>\n",
       "      <td>565</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>bu o</td>\n",
       "      <td>17682.0</td>\n",
       "      <td>dans mı</td>\n",
       "      <td>523</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>şans mı</td>\n",
       "      <td>510</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>bir bebek</td>\n",
       "      <td>509</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>evet var</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>problem ne</td>\n",
       "      <td>497</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>sen de</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>şifre ne</td>\n",
       "      <td>494</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>o kadar</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>plan bu</td>\n",
       "      <td>413</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>evet ama</td>\n",
       "      <td>6846.0</td>\n",
       "      <td>telefon yok</td>\n",
       "      <td>405</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>bir daha</td>\n",
       "      <td>5168.0</td>\n",
       "      <td>çok enteresan</td>\n",
       "      <td>405</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>ve sen</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>bu süper</td>\n",
       "      <td>360</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>bana mı</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>polis yok</td>\n",
       "      <td>323</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>bir şey</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>normal değil</td>\n",
       "      <td>239</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>bana da</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>hayır patron</td>\n",
       "      <td>238</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>hayır kaptan</td>\n",
       "      <td>211</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>daha çok</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>polis değil</td>\n",
       "      <td>174</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>ama yok</td>\n",
       "      <td>927.0</td>\n",
       "      <td>ve çek</td>\n",
       "      <td>169</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>bunu da</td>\n",
       "      <td>717.0</td>\n",
       "      <td>parti için</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>ve bunu</td>\n",
       "      <td>492.0</td>\n",
       "      <td>ben kaptan</td>\n",
       "      <td>113</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>çok yok</td>\n",
       "      <td>93.0</td>\n",
       "      <td>okul için</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>seni beni</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ben doktor</td>\n",
       "      <td>98</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>beni seni</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ama şef</td>\n",
       "      <td>91</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama patron</td>\n",
       "      <td>91</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanser gibi</td>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek var</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>makine gibi</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunu çek</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni moron</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>milyonlarca var</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o amerikalı</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve müzik</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni embesil</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o fransız</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şey pardon</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şey general</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>komik de</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tipik sen</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen amerikalı</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alo de</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pantolon da</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha romantik</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telefon da</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha şampanya</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bana kahve</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bana bira</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karavan kadar</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avokado kadar</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word      twogram freq_twogram twogram_pair_english  \\\n",
       "0     bir  18835735.0       ne var      62532.0          evet doktor   \n",
       "1      bu  11062659.0       ben de      59972.0           evet madam   \n",
       "2      ne   8025880.0     değil mi      58386.0         çok romantik   \n",
       "3      ve   7766036.0       ben mi      33652.0             komik mi   \n",
       "4    için   5484109.0      ne için      31857.0             parti mi   \n",
       "5      mi   5362714.0  hayır değil      18740.0           bir milyon   \n",
       "6       o   5013838.0         bu o      17682.0              dans mı   \n",
       "7     ben   4908913.0     hayır mı      15769.0              şans mı   \n",
       "8      de   4880315.0     bu kadar      15745.0            bir bebek   \n",
       "9     çok   4852169.0     evet var      11138.0           problem ne   \n",
       "10    ama   4661966.0       sen de      10089.0             şifre ne   \n",
       "11    var   4389551.0      o kadar       7040.0              plan bu   \n",
       "12   evet   4324786.0     evet ama       6846.0          telefon yok   \n",
       "13     mı   4001316.0     bir daha       5168.0        çok enteresan   \n",
       "14  değil   3883885.0       ve sen       4648.0             bu süper   \n",
       "15     da   3610161.0      bana mı       3593.0            polis yok   \n",
       "16    şey   3602024.0      bir şey       1611.0         normal değil   \n",
       "17  hayır   3406992.0      bana da       1498.0         hayır patron   \n",
       "18   daha   3317577.0     şey gibi       1314.0         hayır kaptan   \n",
       "19    sen   3283654.0     daha çok       1129.0          polis değil   \n",
       "20  kadar   2697900.0      ama yok        927.0               ve çek   \n",
       "21   bana   2659182.0      bunu da        717.0           parti için   \n",
       "22    yok   2491685.0      ve bunu        492.0           ben kaptan   \n",
       "23    onu   2486889.0      çok yok         93.0            okul için   \n",
       "24   seni   2454988.0    seni beni          7.0           ben doktor   \n",
       "25   beni   2446696.0    beni seni          4.0              ama şef   \n",
       "26   bunu   2445337.0          NaN          NaN           ama patron   \n",
       "27   gibi   2427957.0          NaN          NaN          kanser gibi   \n",
       "28    NaN         NaN          NaN          NaN            bebek var   \n",
       "29    NaN         NaN          NaN          NaN          makine gibi   \n",
       "30    NaN         NaN          NaN          NaN             bunu çek   \n",
       "31    NaN         NaN          NaN          NaN           seni moron   \n",
       "32    NaN         NaN          NaN          NaN      milyonlarca var   \n",
       "33    NaN         NaN          NaN          NaN          o amerikalı   \n",
       "34    NaN         NaN          NaN          NaN             ve müzik   \n",
       "35    NaN         NaN          NaN          NaN         seni embesil   \n",
       "36    NaN         NaN          NaN          NaN            o fransız   \n",
       "37    NaN         NaN          NaN          NaN           şey pardon   \n",
       "38    NaN         NaN          NaN          NaN          şey general   \n",
       "39    NaN         NaN          NaN          NaN             komik de   \n",
       "40    NaN         NaN          NaN          NaN            tipik sen   \n",
       "41    NaN         NaN          NaN          NaN        sen amerikalı   \n",
       "42    NaN         NaN          NaN          NaN               alo de   \n",
       "43    NaN         NaN          NaN          NaN          pantolon da   \n",
       "44    NaN         NaN          NaN          NaN        daha romantik   \n",
       "45    NaN         NaN          NaN          NaN           telefon da   \n",
       "46    NaN         NaN          NaN          NaN        daha şampanya   \n",
       "47    NaN         NaN          NaN          NaN           bana kahve   \n",
       "48    NaN         NaN          NaN          NaN            bana bira   \n",
       "49    NaN         NaN          NaN          NaN        karavan kadar   \n",
       "50    NaN         NaN          NaN          NaN        avokado kadar   \n",
       "51    NaN         NaN          NaN          NaN                  NaN   \n",
       "\n",
       "   freq_twogram_pair_english  word_count  \n",
       "0                       1185         4.0  \n",
       "1                       1043         4.0  \n",
       "2                        980         4.0  \n",
       "3                        822         4.0  \n",
       "4                        751         3.0  \n",
       "5                        565         4.0  \n",
       "6                        523         4.0  \n",
       "7                        510         4.0  \n",
       "8                        509         4.0  \n",
       "9                        497         4.0  \n",
       "10                       494         4.0  \n",
       "11                       413         4.0  \n",
       "12                       405         4.0  \n",
       "13                       405         4.0  \n",
       "14                       360         4.0  \n",
       "15                       323         4.0  \n",
       "16                       239         4.0  \n",
       "17                       238         4.0  \n",
       "18                       211         4.0  \n",
       "19                       174         4.0  \n",
       "20                       169         4.0  \n",
       "21                       114         4.0  \n",
       "22                       113         4.0  \n",
       "23                       107         NaN  \n",
       "24                        98         4.0  \n",
       "25                        91         2.0  \n",
       "26                        91         3.0  \n",
       "27                        82         3.0  \n",
       "28                        76         NaN  \n",
       "29                        76         NaN  \n",
       "30                        72         NaN  \n",
       "31                        71         NaN  \n",
       "32                        68         NaN  \n",
       "33                        65         NaN  \n",
       "34                        64         NaN  \n",
       "35                        63         NaN  \n",
       "36                        60         NaN  \n",
       "37                        30         NaN  \n",
       "38                        29         NaN  \n",
       "39                        20         NaN  \n",
       "40                        20         NaN  \n",
       "41                        18         NaN  \n",
       "42                        16         NaN  \n",
       "43                        14         NaN  \n",
       "44                        14         NaN  \n",
       "45                        13         NaN  \n",
       "46                        13         NaN  \n",
       "47                        10         NaN  \n",
       "48                         9         NaN  \n",
       "49                         4         NaN  \n",
       "50                         4         NaN  \n",
       "51                       NaN         NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>polis mi</td>\n",
       "      <td>2526</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>bir numara</td>\n",
       "      <td>1272</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>bu komik</td>\n",
       "      <td>994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>bebek mi</td>\n",
       "      <td>861</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>bu normal</td>\n",
       "      <td>828</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>ve motor</td>\n",
       "      <td>776</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>ne komik</td>\n",
       "      <td>685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plan ne</td>\n",
       "      <td>587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir polis</td>\n",
       "      <td>574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şans için</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron o</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve gol</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek için</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_english  freq_twogram_pair_english  \\\n",
       "0    bir  18835735.0             polis mi                       2526   \n",
       "1     bu  11062659.0           bir numara                       1272   \n",
       "2     ne   8025880.0             bu komik                        994   \n",
       "3     ve   7766036.0             bebek mi                        861   \n",
       "4   için   5484109.0            bu normal                        828   \n",
       "5     mi   5362714.0             ve motor                        776   \n",
       "6      o   5013838.0             ne komik                        685   \n",
       "7    NaN         NaN              plan ne                        587   \n",
       "8    NaN         NaN            bir polis                        574   \n",
       "9    NaN         NaN            şans için                        305   \n",
       "10   NaN         NaN             patron o                        251   \n",
       "11   NaN         NaN               ve gol                        203   \n",
       "12   NaN         NaN           bebek için                        173   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          1.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result1.xlsx\")\n",
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>çok komik</td>\n",
       "      <td>13097</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>evet patron</td>\n",
       "      <td>1476</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>çok şeker</td>\n",
       "      <td>1319</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>evet kaptan</td>\n",
       "      <td>1284</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>plan mı</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>bomba mı</td>\n",
       "      <td>541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>bomba var</td>\n",
       "      <td>326</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon ben</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telefon var</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ben ray</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon ama</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama doktor</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek de</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_english  freq_twogram_pair_english  \\\n",
       "0    ben  4908913.0            çok komik                      13097   \n",
       "1     de  4880315.0          evet patron                       1476   \n",
       "2    çok  4852169.0            çok şeker                       1319   \n",
       "3    ama  4661966.0          evet kaptan                       1284   \n",
       "4    var  4389551.0              plan mı                        556   \n",
       "5   evet  4324786.0             bomba mı                        541   \n",
       "6     mı  4001316.0            bomba var                        326   \n",
       "7    NaN        NaN           pardon ben                        200   \n",
       "8    NaN        NaN          telefon var                        187   \n",
       "9    NaN        NaN              ben ray                        139   \n",
       "10   NaN        NaN           pardon ama                        103   \n",
       "11   NaN        NaN           ama doktor                         94   \n",
       "12   NaN        NaN             bebek de                         30   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          1.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_12 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result2.xlsx\")\n",
    "df_part_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>komik değil</td>\n",
       "      <td>1785</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>problem değil</td>\n",
       "      <td>1678</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>hayır doktor</td>\n",
       "      <td>481</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>hayır madam</td>\n",
       "      <td>361</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>sen çek</td>\n",
       "      <td>97</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>komik şey</td>\n",
       "      <td>76</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>şeker şey</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha bebek</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon da</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roma da</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon sen</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha dramatik</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ahtapot kadar</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq_word twogram_pair_english  freq_twogram_pair_english  \\\n",
       "0   değil  3883885.0          komik değil                       1785   \n",
       "1      da  3610161.0        problem değil                       1678   \n",
       "2     şey  3602024.0         hayır doktor                        481   \n",
       "3   hayır  3406992.0          hayır madam                        361   \n",
       "4    daha  3317577.0              sen çek                         97   \n",
       "5     sen  3283654.0            komik şey                         76   \n",
       "6   kadar  2697900.0            şeker şey                         70   \n",
       "7     NaN        NaN           daha bebek                         44   \n",
       "8     NaN        NaN            pardon da                         43   \n",
       "9     NaN        NaN              roma da                         36   \n",
       "10    NaN        NaN           pardon sen                         21   \n",
       "11    NaN        NaN        daha dramatik                         15   \n",
       "12    NaN        NaN        ahtapot kadar                          6   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          1.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_13 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result3.xlsx\")\n",
    "df_part_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>problem yok</td>\n",
       "      <td>746</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>sinyal yok</td>\n",
       "      <td>742</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>çek onu</td>\n",
       "      <td>465</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>çek beni</td>\n",
       "      <td>316</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>seni manyak</td>\n",
       "      <td>279</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>bomba gibi</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>175</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni çakal</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as onu</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telefon bana</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vay bana</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_english  freq_twogram_pair_english  \\\n",
       "0   bana  2659182.0          problem yok                        746   \n",
       "1    yok  2491685.0           sinyal yok                        742   \n",
       "2    onu  2486889.0              çek onu                        465   \n",
       "3   seni  2454988.0             çek beni                        316   \n",
       "4   beni  2446696.0          seni manyak                        279   \n",
       "5   bunu  2445337.0           bomba gibi                        236   \n",
       "6   gibi  2427957.0           bebek gibi                        175   \n",
       "7    NaN        NaN           seni çakal                         89   \n",
       "8    NaN        NaN               as onu                         32   \n",
       "9    NaN        NaN         telefon bana                         28   \n",
       "10   NaN        NaN             vay bana                         12   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          1.0  \n",
       "5          NaN  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_14 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result4.xlsx\")\n",
    "df_part_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>evet doktor</td>\n",
       "      <td>1185</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>evet madam</td>\n",
       "      <td>1043</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>çok romantik</td>\n",
       "      <td>980</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>komik mi</td>\n",
       "      <td>822</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>parti mi</td>\n",
       "      <td>751</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>hayır değil</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>bir milyon</td>\n",
       "      <td>565</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>bu o</td>\n",
       "      <td>17682.0</td>\n",
       "      <td>dans mı</td>\n",
       "      <td>523</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>şans mı</td>\n",
       "      <td>510</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>bir bebek</td>\n",
       "      <td>509</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>evet var</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>problem ne</td>\n",
       "      <td>497</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>sen de</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>şifre ne</td>\n",
       "      <td>494</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>o kadar</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>plan bu</td>\n",
       "      <td>413</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>evet ama</td>\n",
       "      <td>6846.0</td>\n",
       "      <td>telefon yok</td>\n",
       "      <td>405</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>bir daha</td>\n",
       "      <td>5168.0</td>\n",
       "      <td>çok enteresan</td>\n",
       "      <td>405</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>ve sen</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>bu süper</td>\n",
       "      <td>360</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>bana mı</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>polis yok</td>\n",
       "      <td>323</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>bir şey</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>normal değil</td>\n",
       "      <td>239</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>bana da</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>hayır patron</td>\n",
       "      <td>238</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>hayır kaptan</td>\n",
       "      <td>211</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>daha çok</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>polis değil</td>\n",
       "      <td>174</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>ama yok</td>\n",
       "      <td>927.0</td>\n",
       "      <td>ve çek</td>\n",
       "      <td>169</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>bunu da</td>\n",
       "      <td>717.0</td>\n",
       "      <td>parti için</td>\n",
       "      <td>114</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>ve bunu</td>\n",
       "      <td>492.0</td>\n",
       "      <td>ben kaptan</td>\n",
       "      <td>113</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>çok yok</td>\n",
       "      <td>93.0</td>\n",
       "      <td>okul için</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>seni beni</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ben doktor</td>\n",
       "      <td>98</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>beni seni</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ama şef</td>\n",
       "      <td>91</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama patron</td>\n",
       "      <td>91</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanser gibi</td>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek var</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>makine gibi</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunu çek</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni moron</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>milyonlarca var</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o amerikalı</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve müzik</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni embesil</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o fransız</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şey pardon</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şey general</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>komik de</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tipik sen</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen amerikalı</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alo de</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pantolon da</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha romantik</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telefon da</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha şampanya</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bana kahve</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bana bira</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karavan kadar</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avokado kadar</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word      twogram  freq_twogram twogram_pair_english  \\\n",
       "0     bir  18835735.0       ne var       62532.0          evet doktor   \n",
       "1      bu  11062659.0       ben de       59972.0           evet madam   \n",
       "2      ne   8025880.0     değil mi       58386.0         çok romantik   \n",
       "3      ve   7766036.0       ben mi       33652.0             komik mi   \n",
       "4    için   5484109.0      ne için       31857.0             parti mi   \n",
       "5      mi   5362714.0  hayır değil       18740.0           bir milyon   \n",
       "6       o   5013838.0         bu o       17682.0              dans mı   \n",
       "7     ben   4908913.0     hayır mı       15769.0              şans mı   \n",
       "8      de   4880315.0     bu kadar       15745.0            bir bebek   \n",
       "9     çok   4852169.0     evet var       11138.0           problem ne   \n",
       "10    ama   4661966.0       sen de       10089.0             şifre ne   \n",
       "11    var   4389551.0      o kadar        7040.0              plan bu   \n",
       "12   evet   4324786.0     evet ama        6846.0          telefon yok   \n",
       "13     mı   4001316.0     bir daha        5168.0        çok enteresan   \n",
       "14  değil   3883885.0       ve sen        4648.0             bu süper   \n",
       "15     da   3610161.0      bana mı        3593.0            polis yok   \n",
       "16    şey   3602024.0      bir şey        1611.0         normal değil   \n",
       "17  hayır   3406992.0      bana da        1498.0         hayır patron   \n",
       "18   daha   3317577.0     şey gibi        1314.0         hayır kaptan   \n",
       "19    sen   3283654.0     daha çok        1129.0          polis değil   \n",
       "20  kadar   2697900.0      ama yok         927.0               ve çek   \n",
       "21   bana   2659182.0      bunu da         717.0           parti için   \n",
       "22    yok   2491685.0      ve bunu         492.0           ben kaptan   \n",
       "23    onu   2486889.0      çok yok          93.0            okul için   \n",
       "24   seni   2454988.0    seni beni           7.0           ben doktor   \n",
       "25   beni   2446696.0    beni seni           4.0              ama şef   \n",
       "26   bunu   2445337.0          NaN           NaN           ama patron   \n",
       "27   gibi   2427957.0          NaN           NaN          kanser gibi   \n",
       "28    NaN         NaN          NaN           NaN            bebek var   \n",
       "29    NaN         NaN          NaN           NaN          makine gibi   \n",
       "30    NaN         NaN          NaN           NaN             bunu çek   \n",
       "31    NaN         NaN          NaN           NaN           seni moron   \n",
       "32    NaN         NaN          NaN           NaN      milyonlarca var   \n",
       "33    NaN         NaN          NaN           NaN          o amerikalı   \n",
       "34    NaN         NaN          NaN           NaN             ve müzik   \n",
       "35    NaN         NaN          NaN           NaN         seni embesil   \n",
       "36    NaN         NaN          NaN           NaN            o fransız   \n",
       "37    NaN         NaN          NaN           NaN           şey pardon   \n",
       "38    NaN         NaN          NaN           NaN          şey general   \n",
       "39    NaN         NaN          NaN           NaN             komik de   \n",
       "40    NaN         NaN          NaN           NaN            tipik sen   \n",
       "41    NaN         NaN          NaN           NaN        sen amerikalı   \n",
       "42    NaN         NaN          NaN           NaN               alo de   \n",
       "43    NaN         NaN          NaN           NaN          pantolon da   \n",
       "44    NaN         NaN          NaN           NaN        daha romantik   \n",
       "45    NaN         NaN          NaN           NaN           telefon da   \n",
       "46    NaN         NaN          NaN           NaN        daha şampanya   \n",
       "47    NaN         NaN          NaN           NaN           bana kahve   \n",
       "48    NaN         NaN          NaN           NaN            bana bira   \n",
       "49    NaN         NaN          NaN           NaN        karavan kadar   \n",
       "50    NaN         NaN          NaN           NaN        avokado kadar   \n",
       "\n",
       "    freq_twogram_pair_english  word_count  \n",
       "0                        1185         4.0  \n",
       "1                        1043         4.0  \n",
       "2                         980         4.0  \n",
       "3                         822         4.0  \n",
       "4                         751         3.0  \n",
       "5                         565         4.0  \n",
       "6                         523         4.0  \n",
       "7                         510         4.0  \n",
       "8                         509         4.0  \n",
       "9                         497         4.0  \n",
       "10                        494         4.0  \n",
       "11                        413         4.0  \n",
       "12                        405         4.0  \n",
       "13                        405         4.0  \n",
       "14                        360         4.0  \n",
       "15                        323         4.0  \n",
       "16                        239         4.0  \n",
       "17                        238         4.0  \n",
       "18                        211         4.0  \n",
       "19                        174         4.0  \n",
       "20                        169         4.0  \n",
       "21                        114         4.0  \n",
       "22                        113         4.0  \n",
       "23                        107         NaN  \n",
       "24                         98         4.0  \n",
       "25                         91         2.0  \n",
       "26                         91         3.0  \n",
       "27                         82         3.0  \n",
       "28                         76         NaN  \n",
       "29                         76         NaN  \n",
       "30                         72         NaN  \n",
       "31                         71         NaN  \n",
       "32                         68         NaN  \n",
       "33                         65         NaN  \n",
       "34                         64         NaN  \n",
       "35                         63         NaN  \n",
       "36                         60         NaN  \n",
       "37                         30         NaN  \n",
       "38                         29         NaN  \n",
       "39                         20         NaN  \n",
       "40                         20         NaN  \n",
       "41                         18         NaN  \n",
       "42                         16         NaN  \n",
       "43                         14         NaN  \n",
       "44                         14         NaN  \n",
       "45                         13         NaN  \n",
       "46                         13         NaN  \n",
       "47                         10         NaN  \n",
       "48                          9         NaN  \n",
       "49                          4         NaN  \n",
       "50                          4         NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_21 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_28_Result1.xlsx\")\n",
    "df_part_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_11.to_excel(writer, sheet_name='Word_Part11', index=False)\n",
    "df_part_12.to_excel(writer, sheet_name='Word_Part12', index=False)\n",
    "df_part_13.to_excel(writer, sheet_name='Word_Part13', index=False)\n",
    "df_part_14.to_excel(writer, sheet_name='Word_Part14', index=False)\n",
    "df_part_21.to_excel(writer, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>polis mi</td>\n",
       "      <td>2526</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>bir numara</td>\n",
       "      <td>1272</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>bu komik</td>\n",
       "      <td>994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>bebek mi</td>\n",
       "      <td>861</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>bu normal</td>\n",
       "      <td>828</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>ve motor</td>\n",
       "      <td>776</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>ne komik</td>\n",
       "      <td>685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plan ne</td>\n",
       "      <td>587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir polis</td>\n",
       "      <td>574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şans için</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron o</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve gol</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek için</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_english  freq_twogram_pair_english  \\\n",
       "0    bir  18835735.0             polis mi                       2526   \n",
       "1     bu  11062659.0           bir numara                       1272   \n",
       "2     ne   8025880.0             bu komik                        994   \n",
       "3     ve   7766036.0             bebek mi                        861   \n",
       "4   için   5484109.0            bu normal                        828   \n",
       "5     mi   5362714.0             ve motor                        776   \n",
       "6      o   5013838.0             ne komik                        685   \n",
       "7    NaN         NaN              plan ne                        587   \n",
       "8    NaN         NaN            bir polis                        574   \n",
       "9    NaN         NaN            şans için                        305   \n",
       "10   NaN         NaN             patron o                        251   \n",
       "11   NaN         NaN               ve gol                        203   \n",
       "12   NaN         NaN           bebek için                        173   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          1.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir numara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir polis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu komik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne komik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ne</td>\n",
       "      <td>plan ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve gol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>için</td>\n",
       "      <td>şans için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>için</td>\n",
       "      <td>bebek için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mi</td>\n",
       "      <td>polis mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mi</td>\n",
       "      <td>bebek mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o</td>\n",
       "      <td>patron o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word twogram_pair_english\n",
       "0    bir           bir numara\n",
       "1    bir            bir polis\n",
       "2     bu             bu komik\n",
       "3     bu            bu normal\n",
       "4     ne             ne komik\n",
       "5     ne              plan ne\n",
       "6     ve             ve motor\n",
       "7     ve               ve gol\n",
       "8   için            şans için\n",
       "9   için           bebek için\n",
       "10    mi             polis mi\n",
       "11    mi             bebek mi\n",
       "12     o             patron o"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_11 = word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_12 = word_in_twogram(df_part_12, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_13 = word_in_twogram(df_part_13, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_14 = word_in_twogram(df_part_14, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_21 = word_in_twogram(df_part_21, \"word\", f\"twogram\") \n",
    "df_word_order_212 = word_in_twogram(df_part_21, \"word\", f\"twogram_pair_{lang_pair.lower()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11 = df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_12 = df_word_order_12.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_13 = df_word_order_13.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_14 = df_word_order_14.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>evet ama, ama yok</td>\n",
       "      <td>ama şef, ama patron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana mı, bana da</td>\n",
       "      <td>bana kahve, bana bira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben de, ben mi</td>\n",
       "      <td>ben kaptan, ben doktor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>seni beni, beni seni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir daha, bir şey</td>\n",
       "      <td>bir milyon, bir bebek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu o, bu kadar</td>\n",
       "      <td>plan bu, bu süper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bunu</td>\n",
       "      <td>bunu da, ve bunu</td>\n",
       "      <td>bunu çek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>da</td>\n",
       "      <td>bana da, bunu da</td>\n",
       "      <td>pantolon da, telefon da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daha</td>\n",
       "      <td>bir daha, daha çok</td>\n",
       "      <td>daha romantik, daha şampanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de</td>\n",
       "      <td>ben de, sen de</td>\n",
       "      <td>komik de, alo de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>değil</td>\n",
       "      <td>değil mi, hayır değil</td>\n",
       "      <td>normal değil, polis değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>evet var, evet ama</td>\n",
       "      <td>evet doktor, evet madam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gibi</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>kanser gibi, makine gibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hayır</td>\n",
       "      <td>hayır değil, hayır mı</td>\n",
       "      <td>hayır patron, hayır kaptan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>için</td>\n",
       "      <td>ne için</td>\n",
       "      <td>parti için, okul için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kadar</td>\n",
       "      <td>bu kadar, o kadar</td>\n",
       "      <td>karavan kadar, avokado kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mi</td>\n",
       "      <td>değil mi, ben mi</td>\n",
       "      <td>komik mi, parti mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mı</td>\n",
       "      <td>hayır mı, bana mı</td>\n",
       "      <td>dans mı, şans mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne var, ne için</td>\n",
       "      <td>problem ne, şifre ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>o</td>\n",
       "      <td>bu o, o kadar</td>\n",
       "      <td>o amerikalı, o fransız</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sen</td>\n",
       "      <td>sen de, ve sen</td>\n",
       "      <td>tipik sen, sen amerikalı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seni</td>\n",
       "      <td>seni beni, beni seni</td>\n",
       "      <td>seni moron, seni embesil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>var</td>\n",
       "      <td>ne var, evet var</td>\n",
       "      <td>bebek var, milyonlarca var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve sen, ve bunu</td>\n",
       "      <td>ve çek, ve müzik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yok</td>\n",
       "      <td>ama yok, çok yok</td>\n",
       "      <td>telefon yok, polis yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>çok</td>\n",
       "      <td>daha çok, çok yok</td>\n",
       "      <td>çok romantik, çok enteresan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>şey</td>\n",
       "      <td>bir şey, şey gibi</td>\n",
       "      <td>şey pardon, şey general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                twogram          twogram_pair_english\n",
       "0     ama      evet ama, ama yok           ama şef, ama patron\n",
       "1    bana       bana mı, bana da         bana kahve, bana bira\n",
       "2     ben         ben de, ben mi        ben kaptan, ben doktor\n",
       "3    beni   seni beni, beni seni                           NaN\n",
       "4     bir      bir daha, bir şey         bir milyon, bir bebek\n",
       "5      bu         bu o, bu kadar             plan bu, bu süper\n",
       "6    bunu       bunu da, ve bunu                      bunu çek\n",
       "7      da       bana da, bunu da       pantolon da, telefon da\n",
       "8    daha     bir daha, daha çok  daha romantik, daha şampanya\n",
       "9      de         ben de, sen de              komik de, alo de\n",
       "10  değil  değil mi, hayır değil     normal değil, polis değil\n",
       "11   evet     evet var, evet ama       evet doktor, evet madam\n",
       "12   gibi               şey gibi      kanser gibi, makine gibi\n",
       "13  hayır  hayır değil, hayır mı    hayır patron, hayır kaptan\n",
       "14   için                ne için         parti için, okul için\n",
       "15  kadar      bu kadar, o kadar  karavan kadar, avokado kadar\n",
       "16     mi       değil mi, ben mi            komik mi, parti mi\n",
       "17     mı      hayır mı, bana mı              dans mı, şans mı\n",
       "18     ne        ne var, ne için          problem ne, şifre ne\n",
       "19      o          bu o, o kadar        o amerikalı, o fransız\n",
       "20    sen         sen de, ve sen      tipik sen, sen amerikalı\n",
       "21   seni   seni beni, beni seni      seni moron, seni embesil\n",
       "22    var       ne var, evet var    bebek var, milyonlarca var\n",
       "23     ve        ve sen, ve bunu              ve çek, ve müzik\n",
       "24    yok       ama yok, çok yok        telefon yok, polis yok\n",
       "25    çok      daha çok, çok yok   çok romantik, çok enteresan\n",
       "26    şey      bir şey, şey gibi       şey pardon, şey general"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11.to_excel(writer2, sheet_name='Word_Part11', index=False)\n",
    "df_word_order_join_12.to_excel(writer2, sheet_name='Word_Part12', index=False)\n",
    "df_word_order_join_13.to_excel(writer2, sheet_name='Word_Part13', index=False)\n",
    "df_word_order_join_14.to_excel(writer2, sheet_name='Word_Part14', index=False)\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_28_Word_Step_7_Result1.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result2.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result3.xlsx',\n",
       " 'Turkish_English_28_Word_Step_7_Result4.xlsx',\n",
       " 'Turkish_English_28_Word_Step_28_Result1.xlsx',\n",
       " 'Turkish_English_28_Word_Result_With_Frequency.xlsx',\n",
       " 'Turkish_English_28_Word_Join_Result_Without_Frequency.xlsx']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
