{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Word Sentence And N Gram Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to merge ngram and ngram-sentence files into one merge file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat Axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_type = \"tengram\"  # twogram, threegram, fourgram, fivegram, sixgram, sevengram, eightgram, ninegram, tengram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram type and ngram files\n",
    "if ngram_type == \"twogram\":\n",
    "    files_name = \"Two_Gram\"\n",
    "elif ngram_type == \"threegram\":\n",
    "    files_name = \"Three_Gram\"\n",
    "elif ngram_type == \"fourgram\":\n",
    "    files_name = \"Four_Gram\"\n",
    "elif ngram_type == \"fivegram\":\n",
    "    files_name = \"Five_Gram\"\n",
    "elif ngram_type == \"sixgram\":\n",
    "    files_name = \"Six_Gram\"\n",
    "elif ngram_type == \"sevengram\":\n",
    "    files_name = \"Seven_Gram\"\n",
    "elif ngram_type == \"eightgram\":\n",
    "    files_name = \"Eight_Gram\"\n",
    "elif ngram_type == \"ninegram\":\n",
    "    files_name = \"Nine_Gram\"\n",
    "elif ngram_type == \"tengram\":\n",
    "    files_name = \"Ten_Gram\"\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_files_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Pyspark/Result/Sentence/Sentence Tokenize Data/{files_name}*.csv\")\n",
    "ngram_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data\n",
    "data_kind = f\"{ngram_type}\"\n",
    "df_all_result = pd.DataFrame()\n",
    "for i in ngram_files_list:\n",
    "#for i in range(1,8):\n",
    "    df_var = pd.read_csv(f'{i}')\n",
    "    #df_var = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Pyspark/Result/Clean_Spark_Sentence_Tokenize{i}.csv\")\n",
    "    df_all_result = pd.concat([df_var, df_all_result], axis=0)\n",
    "    df_all_result.dropna(inplace=True)\n",
    "    df_all_result.reset_index(drop=True, inplace=True)\n",
    "df_all_result = df_all_result[[f\"{data_kind}\", \"frequency\"]]\n",
    "df_all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_group = df_all_result.groupby([f\"{data_kind}\"])[\"frequency\"].sum().sort_values(ascending=False)\n",
    "df_all_group = df_all_group.reset_index()\n",
    "df_all_group.dropna(inplace=True)\n",
    "df_all_group.reset_index(drop=True, inplace=True)\n",
    "df_all_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_group = df_all_group[df_all_group.frequency >=5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_frequency = df_all_group.frequency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_group[\"ratio\"] = (df_all_group.frequency/total_frequency)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_group[\"cumul_ratio\"] = np.cumsum(df_all_group[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_group.to_csv(f\"{data_kind.capitalize()}_Merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('py39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
