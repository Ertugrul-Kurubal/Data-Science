{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Gram In N Gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 200  # 28  # native word end index\n",
    "\n",
    "# word all usage in sent\n",
    "word_use_num_min = 1\n",
    "word_use_num_max = 2\n",
    "\n",
    "# # adding native word to shared word\n",
    "# twogram_start = 0  # 0  # native word start index\n",
    "# twogram_end = 200  # 28  # native word end index\n",
    "\n",
    "# sentence check\n",
    "twogram_sentence_check = False  # True, False\n",
    "threegram_sentence_check = False\n",
    "fourgram_sentence_check = False\n",
    "fivegram_sentence_check = False\n",
    "\n",
    "# n gram sample\n",
    "threegram_sample = 6\n",
    "fourgram_sample = 4\n",
    "fivegram_sample = 2\n",
    "\n",
    "# n gram select\n",
    "twogram_select_start = 0\n",
    "twogram_select_end = 10000\n",
    "\n",
    "threegram_select_start = 0\n",
    "threegram_select_end = 10000\n",
    "\n",
    "fourgram_select_start = 0\n",
    "fourgram_select_end = 10000\n",
    "\n",
    "fivegram_select_start = 0\n",
    "fivegram_select_end = 10000\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # True for adding prefix suffix word\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = False  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Deployment2/Result/5-N Gram In N Gram Analysis/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(df):\n",
    "    for i in df.columns:\n",
    "        new_name = i.strip()\n",
    "        df.rename(columns={f\"{i}\":f\"{new_name}\"}, inplace=True)\n",
    "        df[f\"{new_name}\"] = df[f\"{new_name}\"].apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987924</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987925</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987926</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987927</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987928</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987929 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "987924     karneleme          5\n",
       "987925       karnaya          5\n",
       "987926   dörtlümüzün          5\n",
       "987927  karnavalınız          5\n",
       "987928      hurmanın          5\n",
       "\n",
       "[987929 rows x 2 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>saat</td>\n",
       "      <td>399989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>onunla</td>\n",
       "      <td>399330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>yapıyorsun</td>\n",
       "      <td>398274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>neler</td>\n",
       "      <td>397377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ister</td>\n",
       "      <td>396177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  frequency\n",
       "0           bir   18835735\n",
       "1            bu   11062659\n",
       "2            ne    8025880\n",
       "3            ve    7766036\n",
       "4          için    5484109\n",
       "..          ...        ...\n",
       "195        saat     399989\n",
       "196      onunla     399330\n",
       "197  yapıyorsun     398274\n",
       "198       neler     397377\n",
       "199       ister     396177\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "    df_word = df_word.loc[:,[\"word\",\"frequency\"]]\n",
    "    df_word = pd.concat([df_word,df_word_select], axis=0)\n",
    "    df_word.drop_duplicates(inplace=True)    \n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df_word = df_word_select\n",
    "\n",
    "if native_word:\n",
    "    df_word\n",
    "else:\n",
    "    df_word = df_word.head(0)\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sistematik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albüm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ekstrem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>ritüel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>enteresan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>yoğurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>burjuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>plastik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_entry_main\n",
       "0             robot\n",
       "1        sistematik\n",
       "2             prens\n",
       "3             albüm\n",
       "4           ekstrem\n",
       "..              ...\n",
       "594          ritüel\n",
       "595       enteresan\n",
       "596          yoğurt\n",
       "597         burjuva\n",
       "598         plastik\n",
       "\n",
       "[599 rows x 1 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "#df_pair = df_pair.head()\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dict_entry_main]\n",
       "Index: []"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair = pd.merge(df_pair,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair.drop_duplicates(inplace=True)\n",
    "    df_pair.reset_index(drop=True, inplace=True)\n",
    "    df_pair = df_pair.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if etymology_word:\n",
    "    df_pair\n",
    "else:\n",
    "    df_pair = df_pair.head(0)\n",
    "    \n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select = df_word[\"word\"].values.tolist()\n",
    "words = df_pair[\"dict_entry_main\"].values.tolist()\n",
    "word_select_set = set(word_select)\n",
    "disable_word_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = list((word_select_set.union(words_set)).difference(disable_word_set))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir şey</td>\n",
       "      <td>859944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>değil mi</td>\n",
       "      <td>585879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben de</td>\n",
       "      <td>377765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>370619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>322758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457029</th>\n",
       "      <td>fikret cibran</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457030</th>\n",
       "      <td>romalı fikret</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457031</th>\n",
       "      <td>fikret ciooney</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457032</th>\n",
       "      <td>fikret cisco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457033</th>\n",
       "      <td>seyretmeliyim fikret</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0                     bir şey     859944\n",
       "1                    değil mi     585879\n",
       "2                      ben de     377765\n",
       "3             teşekkür ederim     370619\n",
       "4                     ne oldu     322758\n",
       "...                       ...        ...\n",
       "4457029         fikret cibran          3\n",
       "4457030         romalı fikret          3\n",
       "4457031        fikret ciooney          3\n",
       "4457032          fikret cisco          3\n",
       "4457033  seyretmeliyim fikret          3\n",
       "\n",
       "[4457034 rows x 2 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if twogram_sentence_check:\n",
    "    df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_twogram = df_twogram_sent.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "else:\n",
    "    df_twogram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")  \n",
    "    df_twogram = df_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "\n",
    "df_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir şey</td>\n",
       "      <td>859944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>değil mi</td>\n",
       "      <td>585879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben de</td>\n",
       "      <td>377765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>370619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>322758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>olmak sanırım</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>olmak size</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>olmak vardı</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>olmak yani</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>iki size</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               twogram  frequency\n",
       "0              bir şey     859944\n",
       "1             değil mi     585879\n",
       "2               ben de     377765\n",
       "3      teşekkür ederim     370619\n",
       "4              ne oldu     322758\n",
       "...                ...        ...\n",
       "25473    olmak sanırım          6\n",
       "25474       olmak size          6\n",
       "25475      olmak vardı          6\n",
       "25476       olmak yani          6\n",
       "25477         iki size          6\n",
       "\n",
       "[25478 rows x 2 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list2  = df_twogram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist2 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist2 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list2):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list2.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist2.append(d_list2)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list2) # string_word liste\n",
    "\n",
    "result_list2 = list(resultlist2)\n",
    "df_result2 = pd.DataFrame(result_list2, columns=[0])  # add columns parameter for empty result\n",
    "df_result2 = df_result2.rename(columns = {0: \"twogram\"})\n",
    "df_merge2 = pd.merge(df_result2, df_twogram, how=\"left\", on=\"twogram\")\n",
    "df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result2.drop_duplicates(inplace=True)\n",
    "df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# all word should be used at least once\n",
    "#df_twogram_select = df_merge_result2.iloc[twogram_start:twogram_end,]\n",
    "\n",
    "df_merge_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max condition: False \n",
      "Min condition: True\n"
     ]
    }
   ],
   "source": [
    "# word usage condition\n",
    "word_num_dict = {}\n",
    "for i in word_list:\n",
    "    word_num_dict[f\"{i}\"] = 0\n",
    "\n",
    "result_list_select = []\n",
    "var_list = []\n",
    "for i in range(len(df_merge_result2)):\n",
    "    twogram = df_merge_result2.loc[i,\"twogram\"]\n",
    "    frequency = df_merge_result2.loc[i,\"frequency\"]\n",
    "    words = word_tokenize(twogram)   \n",
    "    temp_list = [word for word in words]\n",
    "    temp_list = temp_list + var_list\n",
    "    # word count for max\n",
    "    dict_list_count = Counter(temp_list)\n",
    "    count_list = list(dict_list_count.values())\n",
    "    # word count for min\n",
    "    count_list2 = list(word_num_dict.values())\n",
    "\n",
    "    if any([True if i>word_use_num_max else False for i in count_list]) or not(any([True if j<word_use_num_min else False for j in count_list2])):\n",
    "        pass\n",
    "    else:\n",
    "        var_list = temp_list\n",
    "        result_list_select.append([twogram,frequency]) \n",
    "\n",
    "        for item2 in dict_list_count.items(): \n",
    "            word_num_dict[item2[0]] = item2[1]        \n",
    "\n",
    "print(f\"Max condition: {any([True if i>word_use_num_max else False for i in count_list2])} \\nMin condition: {any([True if j<word_use_num_min else False for j in count_list2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zaten': 1,\n",
       " 'burada': 1,\n",
       " 'kötü': 1,\n",
       " 've': 1,\n",
       " 'sizi': 1,\n",
       " 'olmaz': 1,\n",
       " 'birkaç': 1,\n",
       " 'lütfen': 1,\n",
       " 'bizim': 1,\n",
       " 'et': 1,\n",
       " 'üzgünüm': 1,\n",
       " 'da': 1,\n",
       " 'tüm': 1,\n",
       " 'aynı': 1,\n",
       " 'işte': 1,\n",
       " 'sadece': 1,\n",
       " 'üç': 1,\n",
       " 'yok': 1,\n",
       " 'zaman': 1,\n",
       " 'olacak': 1,\n",
       " 'ki': 1,\n",
       " 'yeni': 1,\n",
       " 'neler': 1,\n",
       " 'hayır': 1,\n",
       " 'bile': 1,\n",
       " 'beni': 1,\n",
       " 'ile': 1,\n",
       " 'artık': 1,\n",
       " 'herkes': 1,\n",
       " 'hakkında': 1,\n",
       " 'fazla': 1,\n",
       " 'selam': 1,\n",
       " 'çok': 1,\n",
       " 'onunla': 1,\n",
       " 'para': 1,\n",
       " 'anne': 1,\n",
       " 'güzel': 1,\n",
       " 'diye': 1,\n",
       " 'ama': 1,\n",
       " 'mü': 1,\n",
       " 'ister': 1,\n",
       " 'ben': 1,\n",
       " 'biz': 1,\n",
       " 'o': 1,\n",
       " 'hiçbir': 1,\n",
       " 'neden': 1,\n",
       " 'yapıyorsun': 1,\n",
       " 'olduğunu': 1,\n",
       " 'son': 1,\n",
       " 'teşekkür': 1,\n",
       " 'kadar': 1,\n",
       " 'onun': 1,\n",
       " 'var': 1,\n",
       " 'kız': 1,\n",
       " 'tabii': 1,\n",
       " 'bizi': 1,\n",
       " 'hey': 1,\n",
       " 'ver': 1,\n",
       " 'biri': 1,\n",
       " 'mısın': 1,\n",
       " 'için': 1,\n",
       " 'hadi': 1,\n",
       " 'şeyi': 1,\n",
       " 'oluyor': 1,\n",
       " 'orada': 1,\n",
       " 'vardı': 1,\n",
       " 'git': 1,\n",
       " 'al': 1,\n",
       " 'yüzden': 1,\n",
       " 'olabilir': 0,\n",
       " 'dur': 1,\n",
       " 'ya': 1,\n",
       " 'evet': 1,\n",
       " 'içinde': 1,\n",
       " 'yine': 1,\n",
       " 'mı': 1,\n",
       " 'bize': 1,\n",
       " 'yoksa': 1,\n",
       " 'sorun': 1,\n",
       " 'sana': 1,\n",
       " 'peki': 1,\n",
       " 'ona': 1,\n",
       " 'doğru': 1,\n",
       " 'dostum': 1,\n",
       " 'siz': 1,\n",
       " 'olan': 1,\n",
       " 'senin': 1,\n",
       " 'demek': 1,\n",
       " 'dakika': 1,\n",
       " 'geri': 1,\n",
       " 'geldi': 1,\n",
       " 'değilim': 1,\n",
       " 'benim': 1,\n",
       " 'şey': 1,\n",
       " 'efendim': 1,\n",
       " 'en': 1,\n",
       " 'öyle': 1,\n",
       " 'çünkü': 1,\n",
       " 'göre': 1,\n",
       " 'bir': 1,\n",
       " 'harika': 1,\n",
       " 'aslında': 1,\n",
       " 'oh': 1,\n",
       " 'gerçek': 1,\n",
       " 'pekala': 1,\n",
       " 'mi': 1,\n",
       " 'tam': 1,\n",
       " 'bakalım': 1,\n",
       " 'olarak': 1,\n",
       " 'onlar': 1,\n",
       " 'buna': 1,\n",
       " 'sonra': 1,\n",
       " 'kimse': 1,\n",
       " 'kendi': 1,\n",
       " 'bana': 1,\n",
       " 'izin': 1,\n",
       " 'iş': 1,\n",
       " 'haydi': 1,\n",
       " 'her': 1,\n",
       " 'şekilde': 1,\n",
       " 'biliyorsun': 1,\n",
       " 'özür': 1,\n",
       " 'bunu': 1,\n",
       " 'bütün': 1,\n",
       " 'önemli': 1,\n",
       " 'lazım': 1,\n",
       " 'söyle': 1,\n",
       " 'saat': 1,\n",
       " 'hemen': 1,\n",
       " 'mu': 1,\n",
       " 'eğer': 1,\n",
       " 'gerek': 1,\n",
       " 'nerede': 1,\n",
       " 'tek': 1,\n",
       " 'hala': 1,\n",
       " 'benimle': 1,\n",
       " 'asla': 1,\n",
       " 'de': 1,\n",
       " 'gel': 1,\n",
       " 'buraya': 1,\n",
       " 'gece': 1,\n",
       " 'size': 1,\n",
       " 'sen': 1,\n",
       " 'şimdi': 1,\n",
       " 'önce': 1,\n",
       " 'küçük': 1,\n",
       " 'misin': 1,\n",
       " 'ol': 1,\n",
       " 'değil': 1,\n",
       " 'şunu': 0,\n",
       " 'tamam': 1,\n",
       " 'baba': 1,\n",
       " 'oldu': 1,\n",
       " 'hiç': 1,\n",
       " 'bak': 1,\n",
       " 'bence': 1,\n",
       " 'istiyorsun': 1,\n",
       " 'şeyler': 1,\n",
       " 'ilk': 1,\n",
       " 'yardım': 1,\n",
       " 'birlikte': 1,\n",
       " 'gibi': 1,\n",
       " 'iyi': 1,\n",
       " 'nasıl': 1,\n",
       " 'belki': 1,\n",
       " 'şu': 1,\n",
       " 'böyle': 1,\n",
       " 'sanırım': 1,\n",
       " 'istiyorum': 1,\n",
       " 'teşekkürler': 1,\n",
       " 'bugün': 1,\n",
       " 'bu': 1,\n",
       " 'seni': 1,\n",
       " 'büyük': 1,\n",
       " 'bilmiyorum': 1,\n",
       " 'olmak': 1,\n",
       " 'iki': 1,\n",
       " 'geliyor': 1,\n",
       " 'onları': 1,\n",
       " 'biliyor': 1,\n",
       " 'biliyorum': 1,\n",
       " 'merhaba': 1,\n",
       " 'olsun': 1,\n",
       " 'seninle': 1,\n",
       " 'tekrar': 1,\n",
       " 'yani': 1,\n",
       " 'uzun': 1,\n",
       " 'ne': 1,\n",
       " 'biraz': 1,\n",
       " 'gerçekten': 1,\n",
       " 'devam': 1,\n",
       " 'başka': 1,\n",
       " 'onu': 1,\n",
       " 'ederim': 1,\n",
       " 'musun': 1,\n",
       " 'daha': 1,\n",
       " 'olur': 1,\n",
       " 'gün': 1,\n",
       " 'adam': 1,\n",
       " 'bunun': 1}"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'teşekkürler': 1,\n",
       "         'özür': 1,\n",
       "         'ile': 1,\n",
       "         'tek': 1,\n",
       "         'yüzden': 1,\n",
       "         'kendi': 1,\n",
       "         'bence': 1,\n",
       "         'onunla': 1,\n",
       "         'yoksa': 1,\n",
       "         'yine': 1,\n",
       "         'bugün': 1,\n",
       "         'son': 1,\n",
       "         'sanırım': 1,\n",
       "         'hala': 1,\n",
       "         'aslında': 1,\n",
       "         'değilim': 1,\n",
       "         'belki': 1,\n",
       "         'bize': 1,\n",
       "         'onları': 1,\n",
       "         'hemen': 1,\n",
       "         'bizi': 1,\n",
       "         'asla': 1,\n",
       "         'pekala': 1,\n",
       "         'haydi': 1,\n",
       "         'zaten': 1,\n",
       "         'biliyorsun': 1,\n",
       "         'diye': 1,\n",
       "         'buna': 1,\n",
       "         'size': 1,\n",
       "         'göre': 1,\n",
       "         'yani': 1,\n",
       "         'eğer': 1,\n",
       "         'bunun': 1,\n",
       "         'seninle': 1,\n",
       "         'para': 1,\n",
       "         'lazım': 1,\n",
       "         'onlar': 1,\n",
       "         'bizim': 1,\n",
       "         'hiçbir': 1,\n",
       "         'sorun': 1,\n",
       "         'yeni': 1,\n",
       "         'geldi': 1,\n",
       "         'ilk': 1,\n",
       "         'iş': 1,\n",
       "         'şeyler': 1,\n",
       "         'işte': 1,\n",
       "         'hey': 1,\n",
       "         'siz': 1,\n",
       "         'çünkü': 1,\n",
       "         'biz': 1,\n",
       "         'adam': 1,\n",
       "         'vardı': 1,\n",
       "         'sizi': 1,\n",
       "         'tekrar': 1,\n",
       "         'fazla': 1,\n",
       "         'uzun': 1,\n",
       "         'tüm': 1,\n",
       "         'gece': 1,\n",
       "         'git': 1,\n",
       "         'artık': 1,\n",
       "         'doğru': 1,\n",
       "         'geliyor': 1,\n",
       "         'herkes': 1,\n",
       "         'nerede': 1,\n",
       "         'benimle': 1,\n",
       "         'birlikte': 1,\n",
       "         'gerçek': 1,\n",
       "         'şu': 1,\n",
       "         'küçük': 1,\n",
       "         'kız': 1,\n",
       "         'aynı': 1,\n",
       "         'şekilde': 1,\n",
       "         'dakika': 1,\n",
       "         'önce': 1,\n",
       "         'harika': 1,\n",
       "         'olacak': 1,\n",
       "         'selam': 1,\n",
       "         'baba': 1,\n",
       "         'bak': 1,\n",
       "         'sana': 1,\n",
       "         'söyle': 1,\n",
       "         'ona': 1,\n",
       "         'gerçekten': 1,\n",
       "         'üzgünüm': 1,\n",
       "         'başka': 1,\n",
       "         'biri': 1,\n",
       "         'bile': 1,\n",
       "         'bilmiyorum': 1,\n",
       "         'merhaba': 1,\n",
       "         'anne': 1,\n",
       "         'kötü': 1,\n",
       "         'mü': 1,\n",
       "         'sadece': 1,\n",
       "         'birkaç': 1,\n",
       "         'onun': 1,\n",
       "         'hakkında': 1,\n",
       "         'yapıyorsun': 1,\n",
       "         'burada': 1,\n",
       "         'ol': 1,\n",
       "         'dostum': 1,\n",
       "         'saat': 1,\n",
       "         'içinde': 1,\n",
       "         'seni': 1,\n",
       "         'sonra': 1,\n",
       "         'onu': 1,\n",
       "         'geri': 1,\n",
       "         'bütün': 1,\n",
       "         'gün': 1,\n",
       "         'peki': 1,\n",
       "         'tamam': 1,\n",
       "         'şimdi': 1,\n",
       "         'olmaz': 1,\n",
       "         'orada': 1,\n",
       "         'mısın': 1,\n",
       "         'olmak': 1,\n",
       "         'istiyorum': 1,\n",
       "         'önemli': 1,\n",
       "         'olan': 1,\n",
       "         'öyle': 1,\n",
       "         'olsun': 1,\n",
       "         'benim': 1,\n",
       "         'gibi': 1,\n",
       "         'lütfen': 1,\n",
       "         'beni': 1,\n",
       "         'dur': 1,\n",
       "         'biraz': 1,\n",
       "         'neden': 1,\n",
       "         'böyle': 1,\n",
       "         'oh': 1,\n",
       "         'hayır': 1,\n",
       "         'en': 1,\n",
       "         'büyük': 1,\n",
       "         'izin': 1,\n",
       "         'ver': 1,\n",
       "         'hiç': 1,\n",
       "         'kimse': 1,\n",
       "         'iki': 1,\n",
       "         'üç': 1,\n",
       "         'al': 1,\n",
       "         'bakalım': 1,\n",
       "         'sen': 1,\n",
       "         've': 1,\n",
       "         'bunu': 1,\n",
       "         'nasıl': 1,\n",
       "         'olur': 1,\n",
       "         'mu': 1,\n",
       "         'bana': 1,\n",
       "         'yardım': 1,\n",
       "         'olduğunu': 1,\n",
       "         'biliyorum': 1,\n",
       "         'tam': 1,\n",
       "         'olarak': 1,\n",
       "         'demek': 1,\n",
       "         'istiyorsun': 1,\n",
       "         'buraya': 1,\n",
       "         'gel': 1,\n",
       "         'hadi': 1,\n",
       "         'ama': 1,\n",
       "         'gerek': 1,\n",
       "         'yok': 1,\n",
       "         'evet': 1,\n",
       "         'efendim': 1,\n",
       "         'devam': 1,\n",
       "         'et': 1,\n",
       "         'senin': 1,\n",
       "         'için': 1,\n",
       "         'ya': 1,\n",
       "         'da': 1,\n",
       "         'tabii': 1,\n",
       "         'ki': 1,\n",
       "         'daha': 1,\n",
       "         'iyi': 1,\n",
       "         'her': 1,\n",
       "         'şeyi': 1,\n",
       "         'neler': 1,\n",
       "         'oluyor': 1,\n",
       "         'çok': 1,\n",
       "         'güzel': 1,\n",
       "         'ister': 1,\n",
       "         'misin': 1,\n",
       "         'biliyor': 1,\n",
       "         'musun': 1,\n",
       "         'o': 1,\n",
       "         'zaman': 1,\n",
       "         'bu': 1,\n",
       "         'kadar': 1,\n",
       "         'var': 1,\n",
       "         'mı': 1,\n",
       "         'ne': 1,\n",
       "         'oldu': 1,\n",
       "         'teşekkür': 1,\n",
       "         'ederim': 1,\n",
       "         'ben': 1,\n",
       "         'de': 1,\n",
       "         'değil': 1,\n",
       "         'mi': 1,\n",
       "         'bir': 1,\n",
       "         'şey': 1})"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counter(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir şey</td>\n",
       "      <td>859944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>değil mi</td>\n",
       "      <td>585879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben de</td>\n",
       "      <td>377765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>370619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>322758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>yoksa yine</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bence onunla</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>yüzden kendi</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ile tek</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>teşekkürler özür</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             twogram  frequency\n",
       "0            bir şey     859944\n",
       "1           değil mi     585879\n",
       "2             ben de     377765\n",
       "3    teşekkür ederim     370619\n",
       "4            ne oldu     322758\n",
       "..               ...        ...\n",
       "94        yoksa yine        243\n",
       "95      bence onunla        220\n",
       "96      yüzden kendi        178\n",
       "97           ile tek         61\n",
       "98  teşekkürler özür         10\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_select = pd.DataFrame(result_list_select, columns=[\"twogram\",\"frequency\"])\n",
    "df_twogram_select.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "df_twogram_select.reset_index(drop=True, inplace=True)\n",
    "df_twogram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threegram_sentence_check:\n",
    "    df_threegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Three_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_threegram_sent.rename(columns={\"three_gram\":\"threegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_threegram = df_threegram_sent.loc[:,[\"threegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_threegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")  \n",
    "    df_threegram = df_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "\n",
    "df_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list3  = df_threegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist3 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist3 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list3):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list3.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist3.append(d_list3)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list3) # string_word liste\n",
    "\n",
    "result_list3 = list(resultlist3)\n",
    "df_result3 = pd.DataFrame(result_list3, columns=[0])  # add columns parameter for empty result\n",
    "df_result3 = df_result3.rename(columns = {0: \"threegram\"})\n",
    "df_merge3 = pd.merge(df_result3, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_merge_result3 = df_merge3.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result3.drop_duplicates(inplace=True)\n",
    "df_merge_result3.reset_index(drop=True, inplace=True)\n",
    "df_threegram_select = df_merge_result3\n",
    "df_threegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fourgram_sentence_check:\n",
    "    df_fourgram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Four_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fourgram_sent.rename(columns={\"four_gram\":\"fourgram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fourgram = df_fourgram_sent.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fourgram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")  \n",
    "    df_fourgram = df_fourgram.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "\n",
    "df_fourgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list4  = df_fourgram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist4 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist4 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list4):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list4.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist4.append(d_list4)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list4) # string_word liste\n",
    "\n",
    "result_list4 = list(resultlist4)\n",
    "df_result4 = pd.DataFrame(result_list4, columns=[0])  # add columns parameter for empty result\n",
    "df_result4 = df_result4.rename(columns = {0: \"fourgram\"})\n",
    "df_merge4 = pd.merge(df_result4, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_merge_result4 = df_merge4.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result4.drop_duplicates(inplace=True)\n",
    "df_merge_result4.reset_index(drop=True, inplace=True)\n",
    "df_fourgram_select = df_merge_result4\n",
    "df_fourgram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fivegram_sentence_check:\n",
    "    df_fivegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Five_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fivegram_sent.rename(columns={\"five_gram\":\"fivegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fivegram = df_fivegram_sent.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fivegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")  \n",
    "    df_fivegram = df_fivegram.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "\n",
    "df_fivegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list5  = df_fivegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist5 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist5 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list5):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list5.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist5.append(d_list5)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list5) # string_word liste\n",
    "\n",
    "result_list5 = list(resultlist5)\n",
    "df_result5 = pd.DataFrame(result_list5, columns=[0])  # add columns parameter for empty result\n",
    "df_result5 = df_result5.rename(columns = {0: \"fivegram\"})\n",
    "df_merge5 = pd.merge(df_result5, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_merge_result5 = df_merge5.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result5.drop_duplicates(inplace=True)\n",
    "df_merge_result5.reset_index(drop=True, inplace=True)\n",
    "df_fivegram_select = df_merge_result5\n",
    "df_fivegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_concat = pd.concat([df_twogram_select, df_threegram_select, df_fourgram_select, df_fivegram_select], axis=1)\n",
    "df_ngram_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"threegram\",threegram_sample)\n",
    "df_two_in_four = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fourgram\",fourgram_sample)\n",
    "df_two_in_five = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fivegram\",fivegram_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_order_join_threegram = df_two_in_three.groupby([\"twogram\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fourgram = df_two_in_four.groupby([\"twogram\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fivegram = df_two_in_five.groupby([\"twogram\"])[\"fivegram\"].apply(\", \".join).reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_twogram_order_join_threegram, df_twogram_order_join_fourgram, df_twogram_order_join_fivegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = reduce(lambda  left,right: pd.merge(left,right, on=['twogram'], how='outer'), dfs)\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = pd.merge(df_ngram_sample_join_merge, df_twogram_select, how=\"left\", on=\"twogram\")\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge.rename(columns={\"frequency\":\"two_freq\"}, inplace=True)\n",
    "df_ngram_sample_join_merge.sort_values(by=\"two_freq\", ascending=False, inplace=True)\n",
    "df_ngram_sample_join_merge.reset_index(drop=True, inplace=True)\n",
    "df_ngram_sample_join_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge.to_excel(f\"{twogram_end}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Join_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Frequency For Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three_freq = pd.merge(df_two_in_three, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_two_in_three_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_three_freq.rename(columns={\"frequency\":\"three_freq\"}, inplace=True)\n",
    "df_two_in_three_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_three_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_four_freq = pd.merge(df_two_in_four, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_two_in_four_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_four_freq.rename(columns={\"frequency\":\"four_freq\"}, inplace=True)\n",
    "df_two_in_four_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_four_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_five_freq = pd.merge(df_two_in_five, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_two_in_five_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_five_freq.rename(columns={\"frequency\":\"five_freq\"}, inplace=True)\n",
    "df_two_in_five_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_five_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat = pd.concat([df_twogram_select,df_two_in_three_freq, df_two_in_four_freq, df_two_in_five_freq], axis=1)\n",
    "df_ngram_sample_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat.to_excel(f\"{twogram_end}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Frequency_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Result And Select Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_threegram_unique = df_ngram_sample_concat[[\"threegram\",\"three_freq\"]].drop_duplicates()\n",
    "df_ngram_fourgram_unique = df_ngram_sample_concat[[\"fourgram\",\"four_freq\"]].drop_duplicates()\n",
    "df_ngram_fivegram_unique = df_ngram_sample_concat[[\"fivegram\",\"five_freq\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_result_freq = df_twogram_select[\"frequency\"].sum()\n",
    "threegram_result_freq = df_ngram_threegram_unique[\"three_freq\"].sum()\n",
    "fourgram_result_freq = df_ngram_fourgram_unique[\"four_freq\"].sum()\n",
    "fivegram_result_freq = df_ngram_fivegram_unique[\"five_freq\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_select_freq = df_twogram.iloc[twogram_select_start:twogram_select_end,][\"frequency\"].sum()\n",
    "threegram_select_freq = df_threegram.iloc[threegram_select_start:threegram_select_end,][\"frequency\"].sum()\n",
    "fourgram_select_freq = df_fourgram.iloc[fourgram_select_start:fourgram_select_end,][\"frequency\"].sum()\n",
    "fivegram_select_freq = df_fivegram.iloc[fivegram_select_start:fivegram_select_end,][\"frequency\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(twogram_result_freq/twogram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(threegram_result_freq/threegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fourgram_result_freq/fourgram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fivegram_result_freq/fivegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{twogram_end}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_*_Result.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
