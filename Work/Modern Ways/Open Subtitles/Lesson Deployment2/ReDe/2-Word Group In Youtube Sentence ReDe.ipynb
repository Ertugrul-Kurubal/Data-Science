{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Group In Youtube Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 200  # 28  # native word end index\n",
    "\n",
    "# sentence ratio and time shift\n",
    "adjust_sent_word_ratio = 50\n",
    "adjust_text_word_ratio = 40\n",
    "shift = 0.3  # sentence time shift\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # True for adding prefix suffix word\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = False  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "\n",
    "print(f\"{file_ext}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Deployment2/Result/2-Word Group In Youtube Sentence/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_word_group(text, word_list):\n",
    "    '''\n",
    "    exract_word_group(text, word_list): \\n\n",
    "    text is a string sentence, word_list occurs words \n",
    "    '''\n",
    "    words = re.findall(r\"\\w+\", text, re.UNICODE)\n",
    "    index_list = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in word_list:\n",
    "            index_list.append(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    all_index_list = []\n",
    "    var_index_list = []\n",
    "    for j in range(len(index_list)):\n",
    "        try:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[j+1]\n",
    "        except:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[-1]\n",
    "        if var1 == var2:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "        else:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "            var4 = list(var_index_list)\n",
    "            all_index_list.append(var4)\n",
    "            var_index_list = []\n",
    "\n",
    "    text_list = []\n",
    "    for k in max(all_index_list, key=len):  # any error convert k to i\n",
    "        word = words[k]\n",
    "        text_list.append(word)\n",
    "    text = \" \".join(text_list)\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_time_loc(df, search, start_sent, end_sent, sent, sent_video_id):\n",
    "    '''\n",
    "    word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "    '''\n",
    "    word_time_loc_list = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,f\"{search}\"]\n",
    "        start_time = df.loc[i,f\"{start_sent}\"]\n",
    "        end_time = df.loc[i,f\"{end_sent}\"]\n",
    "        sentence = df.loc[i,f\"{sent}\"]\n",
    "        video_id = df.loc[i,f\"{sent_video_id}\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[f\"{search}\",f\"{start_sent}\",f\"{end_sent}\",f\"{sent}\",f\"{sent_video_id}\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988210</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988211</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988212</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988213</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988214</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "988210     karneleme          5\n",
       "988211       karnaya          5\n",
       "988212   dörtlümüzün          5\n",
       "988213  karnavalınız          5\n",
       "988214      hurmanın          5\n",
       "\n",
       "[988215 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>saat</td>\n",
       "      <td>399989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>onunla</td>\n",
       "      <td>399330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>yapıyorsun</td>\n",
       "      <td>398274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>neler</td>\n",
       "      <td>397377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ister</td>\n",
       "      <td>396177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  frequency\n",
       "0           bir   18835735\n",
       "1            bu   11062659\n",
       "2            ne    8025880\n",
       "3            ve    7766036\n",
       "4          için    5484109\n",
       "..          ...        ...\n",
       "195        saat     399989\n",
       "196      onunla     399330\n",
       "197  yapıyorsun     398274\n",
       "198       neler     397377\n",
       "199       ister     396177\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "    df_word = df_word.loc[:,[\"word\",\"frequency\"]]\n",
    "    df_word = pd.concat([df_word,df_word_select], axis=0)\n",
    "    df_word.drop_duplicates(inplace=True)    \n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df_word = df_word_select\n",
    "\n",
    "if native_word:\n",
    "    df_word\n",
    "else:\n",
    "    df_word = df_word.head(0)\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blockade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorbe</td>\n",
       "      <td>absorb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absürt</td>\n",
       "      <td>absurd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>açelya</td>\n",
       "      <td>azalea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zikzak</td>\n",
       "      <td>zigzag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zooloji</td>\n",
       "      <td>zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zum</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main english_word\n",
       "0             abaküs       abacus\n",
       "1             abluka     blockade\n",
       "2            absorbe       absorb\n",
       "3             absürt       absurd\n",
       "4             açelya       azalea\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zikzak       zigzag\n",
       "1775           zombi       zombie\n",
       "1776         zooloji      zoology\n",
       "1777             zum         zoom\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "#df_pair = df_pair.head()\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dict_entry_main, english_word]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair = pd.merge(df_pair,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair.drop_duplicates(inplace=True)\n",
    "    df_pair.reset_index(drop=True, inplace=True)\n",
    "    df_pair = df_pair.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if etymology_word:\n",
    "    df_pair\n",
    "else:\n",
    "    df_pair = df_pair.head(0)\n",
    "    \n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select = df_word[\"word\"].values.tolist()\n",
    "words = df_pair[\"dict_entry_main\"].values.tolist()\n",
    "word_select_set = set(word_select)\n",
    "disable_word_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_select_set.union(words_set.difference(disable_word_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Youtube Sentence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/{lang_folder.capitalize()}/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = pd.to_timedelta(df_youtube_sentence['start_time']) # data type converted timedelta for second \n",
    "df_youtube_sentence['end_time'] = pd.to_timedelta(df_youtube_sentence['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = df_youtube_sentence['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_youtube_sentence['end_time'] = df_youtube_sentence['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_youtube_sentence.reset_index(inplace=True)  # adding index column\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from multiprocessing import Process, Manager, Pool, Queue\n",
    "manager = multiprocessing.Manager()\n",
    "result_list = manager.list()\n",
    "word_set = set(word_list)\n",
    "index_num = list(range(len(df_youtube_sentence)))\n",
    "\n",
    "def sentence_word_ratio(index_num):\n",
    "    index = df_youtube_sentence.loc[index_num,\"index\"]\n",
    "    start = df_youtube_sentence.loc[index_num,\"start_time\"]\n",
    "    end = df_youtube_sentence.loc[index_num,\"end_time\"]\n",
    "    sentence = df_youtube_sentence.loc[index_num,\"sentence\"]\n",
    "    videoid = df_youtube_sentence.loc[index_num,\"video_id\"]\n",
    "\n",
    "    sent_word = re.findall(r\"\\w+\", sentence, re.UNICODE)\n",
    "    sent_word_set = set(sent_word)\n",
    "    intersect_word = list(word_set.intersection(sent_word_set))\n",
    "    different_word = list(sent_word_set.difference(word_set))\n",
    "    word_ratio = round(((len(intersect_word)/len(sent_word)+0.001)*100),1)\n",
    "    different = \", \".join(different_word)\n",
    "    intersect = \", \".join(intersect_word)\n",
    "\n",
    "    result_list.append([index,start,end,sentence,videoid,word_ratio,different,intersect])  \n",
    "    \n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(sentence_word_ratio, index_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_ratio_result = pd.DataFrame(list(result_list), columns=[\"index\",\"start_time\",\"end_time\",\"sentence\",\"video_id\",\"word_ratio\",\"different_word\",\"intersect_word\"])\n",
    "df_sentence_ratio_result.sort_values(by=\"index\", ascending=True, inplace=True)\n",
    "df_sentence_ratio_result.reset_index(drop=True, inplace=True)\n",
    "df_sentence_ratio_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_ratio_result[\"different_word\"] = df_sentence_ratio_result[\"different_word\"].apply(lambda x: np.nan if x == \"\" else x)\n",
    "df_sentence_ratio_result[\"intersect_word\"] = df_sentence_ratio_result[\"intersect_word\"].apply(lambda x: np.nan if x == \"\" else x)\n",
    "df_sentence_ratio_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_sentence_ratio = df_sentence_ratio_result[df_sentence_ratio_result[\"word_ratio\"] >= adjust_sent_word_ratio]\n",
    "df_adjust_sentence_ratio.reset_index(inplace=True, drop=True)\n",
    "df_adjust_sentence_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_sentence_ratio.loc[:,\"search_string\"] = df_adjust_sentence_ratio.loc[:,\"sentence\"].map(lambda x: exract_word_group(x, word_list))\n",
    "df_adjust_sentence_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_sent_result = word_group_time_loc(df_adjust_sentence_ratio, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_in_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_sent_result[\"start_time\"] = df_word_group_time_loc_in_sent_result[\"start_time\"].apply(lambda x: (x-shift))\n",
    "df_word_group_time_loc_in_sent_result[\"end_time\"] = df_word_group_time_loc_in_sent_result[\"end_time\"].apply(lambda x: (x+shift))\n",
    "df_word_group_time_loc_in_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_sent_result[\"start_time\"] = df_word_group_time_loc_in_sent_result[\"start_time\"].apply(lambda x: round(x))\n",
    "df_word_group_time_loc_in_sent_result[\"end_time\"] = df_word_group_time_loc_in_sent_result[\"end_time\"].apply(lambda x: round(x))\n",
    "df_word_group_time_loc_in_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_sent_result.sort_values(\"search_string\",key=lambda x:x.str.len(), inplace=True, ascending=False)\n",
    "df_word_group_time_loc_in_sent_result.reset_index(drop=True, inplace=True)\n",
    "df_word_group_time_loc_in_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_sent_result[\"video_url\"] = \"https://www.youtube.com/watch?v=\"+df_word_group_time_loc_in_sent_result['video_id'].map(str)+\"&t=\"+df_word_group_time_loc_in_sent_result['start_time'].map(str)+\"s\"\n",
    "df_word_group_time_loc_in_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_group_time_loc_in_sent_result.to_excel(\"Word_Group_In_Youtube_Sentence_Test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Youtube Videoid Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:02:51.948</td>\n",
       "      <td>00:02:58.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:03:00.956</td>\n",
       "      <td>00:03:04.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:03:13.434</td>\n",
       "      <td>00:03:16.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:03:17.235</td>\n",
       "      <td>00:03:21.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:03:27.806</td>\n",
       "      <td>00:03:33.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063204</th>\n",
       "      <td>00:11:07.990</td>\n",
       "      <td>00:11:14.560</td>\n",
       "      <td>oynatma listesi linkini videonun sağ üst köşes...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063205</th>\n",
       "      <td>00:11:14.560</td>\n",
       "      <td>00:11:21.040</td>\n",
       "      <td>kısmına ekledim dilediğiniz kenar deseni uyarl...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063206</th>\n",
       "      <td>00:11:21.040</td>\n",
       "      <td>00:11:27.880</td>\n",
       "      <td>ibaretti bir sonraki farklı bir elle örgü eğit...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063207</th>\n",
       "      <td>00:11:27.880</td>\n",
       "      <td>00:11:32.290</td>\n",
       "      <td>kanalıma abone olarak videomu beğenmeyi unutma...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063208</th>\n",
       "      <td>00:00:03.280</td>\n",
       "      <td>00:00:12.200</td>\n",
       "      <td>merhaba arkadaşlar sizler için tren yaptım vid...</td>\n",
       "      <td>L_ERx2ZNheU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3063209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time      end_time  \\\n",
       "0        00:02:51.948  00:02:58.829   \n",
       "1        00:03:00.956  00:03:04.236   \n",
       "2        00:03:13.434  00:03:16.327   \n",
       "3        00:03:17.235  00:03:21.338   \n",
       "4        00:03:27.806  00:03:33.383   \n",
       "...               ...           ...   \n",
       "3063204  00:11:07.990  00:11:14.560   \n",
       "3063205  00:11:14.560  00:11:21.040   \n",
       "3063206  00:11:21.040  00:11:27.880   \n",
       "3063207  00:11:27.880  00:11:32.290   \n",
       "3063208  00:00:03.280  00:00:12.200   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3063204  oynatma listesi linkini videonun sağ üst köşes...  MvWp9pWLihA  \n",
       "3063205  kısmına ekledim dilediğiniz kenar deseni uyarl...  MvWp9pWLihA  \n",
       "3063206  ibaretti bir sonraki farklı bir elle örgü eğit...  MvWp9pWLihA  \n",
       "3063207  kanalıma abone olarak videomu beğenmeyi unutma...  MvWp9pWLihA  \n",
       "3063208  merhaba arkadaşlar sizler için tren yaptım vid...  L_ERx2ZNheU  \n",
       "\n",
       "[3063209 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/{lang_folder.capitalize()}/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = pd.to_timedelta(df_youtube_sentence['start_time']) # data type converted timedelta for second \n",
    "df_youtube_sentence['end_time'] = pd.to_timedelta(df_youtube_sentence['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.948</td>\n",
       "      <td>178.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.956</td>\n",
       "      <td>184.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.434</td>\n",
       "      <td>196.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197.235</td>\n",
       "      <td>201.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207.806</td>\n",
       "      <td>213.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063204</th>\n",
       "      <td>667.990</td>\n",
       "      <td>674.560</td>\n",
       "      <td>oynatma listesi linkini videonun sağ üst köşes...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063205</th>\n",
       "      <td>674.560</td>\n",
       "      <td>681.040</td>\n",
       "      <td>kısmına ekledim dilediğiniz kenar deseni uyarl...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063206</th>\n",
       "      <td>681.040</td>\n",
       "      <td>687.880</td>\n",
       "      <td>ibaretti bir sonraki farklı bir elle örgü eğit...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063207</th>\n",
       "      <td>687.880</td>\n",
       "      <td>692.290</td>\n",
       "      <td>kanalıma abone olarak videomu beğenmeyi unutma...</td>\n",
       "      <td>MvWp9pWLihA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063208</th>\n",
       "      <td>3.280</td>\n",
       "      <td>12.200</td>\n",
       "      <td>merhaba arkadaşlar sizler için tren yaptım vid...</td>\n",
       "      <td>L_ERx2ZNheU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3063209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  \\\n",
       "0           171.948   178.829   \n",
       "1           180.956   184.236   \n",
       "2           193.434   196.327   \n",
       "3           197.235   201.338   \n",
       "4           207.806   213.383   \n",
       "...             ...       ...   \n",
       "3063204     667.990   674.560   \n",
       "3063205     674.560   681.040   \n",
       "3063206     681.040   687.880   \n",
       "3063207     687.880   692.290   \n",
       "3063208       3.280    12.200   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3063204  oynatma listesi linkini videonun sağ üst köşes...  MvWp9pWLihA  \n",
       "3063205  kısmına ekledim dilediğiniz kenar deseni uyarl...  MvWp9pWLihA  \n",
       "3063206  ibaretti bir sonraki farklı bir elle örgü eğit...  MvWp9pWLihA  \n",
       "3063207  kanalıma abone olarak videomu beğenmeyi unutma...  MvWp9pWLihA  \n",
       "3063208  merhaba arkadaşlar sizler için tren yaptım vid...  L_ERx2ZNheU  \n",
       "\n",
       "[3063209 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence['start_time'] = df_youtube_sentence['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_youtube_sentence['end_time'] = df_youtube_sentence['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>merhaba arkadaşlar bugün sizlere karadeniz yör...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>kontrol tamam galiba değil mi eee değerli bası...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>ioğluyla biraz vakit geçirsini ievlat bui idün...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>evleniyorsun kocam diyorsun aynı yastığa baş k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>bill gates and george soros developed a new co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>18361</td>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>hi kaye di yari merhaba arkadaşlar hikaye diya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>18362</td>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>bak baştan anlaşalım ya bu cinayete de diğer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>18363</td>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>ev avcısı kuşadası değirmendere de bugün örnek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>18364</td>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>ben arjantinli bir yapımcıyım ve taşınabilirli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>18365</td>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>herkese merhaba hoş geldiniz bugün üzerine sür...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     video_id                                           sentence\n",
       "0          0  007uL_OBtPE  merhaba arkadaşlar bugün sizlere karadeniz yör...\n",
       "1          1  00Dl6tNNlZ8  kontrol tamam galiba değil mi eee değerli bası...\n",
       "2          2  00QJHZSg0UE  ioğluyla biraz vakit geçirsini ievlat bui idün...\n",
       "3          3  00b3ov_NFSI  evleniyorsun kocam diyorsun aynı yastığa baş k...\n",
       "4          4  00fr8yyBQYo  bill gates and george soros developed a new co...\n",
       "...      ...          ...                                                ...\n",
       "18361  18361  zzOL9mRRU0c  hi kaye di yari merhaba arkadaşlar hikaye diya...\n",
       "18362  18362  zzWQXUKr9OA  bak baştan anlaşalım ya bu cinayete de diğer c...\n",
       "18363  18363  zzXTIIo7EvM  ev avcısı kuşadası değirmendere de bugün örnek...\n",
       "18364  18364  zzZfnY7Zjf0  ben arjantinli bir yapımcıyım ve taşınabilirli...\n",
       "18365  18365  zzlPmAUN8lM  herkese merhaba hoş geldiniz bugün üzerine sür...\n",
       "\n",
       "[18366 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videoid_sentence = df_youtube_sentence.groupby(\"video_id\")[\"sentence\"].apply(\" \".join).reset_index()\n",
    "df_videoid_sentence.reset_index(inplace=True)\n",
    "df_videoid_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>6.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>36.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>9.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>1.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>36.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>14.113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id  start_time\n",
       "0      007uL_OBtPE       6.680\n",
       "1      00Dl6tNNlZ8      36.803\n",
       "2      00QJHZSg0UE       0.440\n",
       "3      00b3ov_NFSI       0.000\n",
       "4      00fr8yyBQYo      18.000\n",
       "...            ...         ...\n",
       "18361  zzOL9mRRU0c       9.333\n",
       "18362  zzWQXUKr9OA       1.896\n",
       "18363  zzXTIIo7EvM      36.932\n",
       "18364  zzZfnY7Zjf0       0.000\n",
       "18365  zzlPmAUN8lM      14.113\n",
       "\n",
       "[18366 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videoid_start_time = df_youtube_sentence.groupby(\"video_id\")[[\"start_time\"]].min()\n",
    "df_videoid_start_time.reset_index(inplace=True)\n",
    "df_videoid_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>136.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>813.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>27.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>42.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>533.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>27.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>1591.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>531.949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id  end_time\n",
       "0      007uL_OBtPE   136.640\n",
       "1      00Dl6tNNlZ8   813.903\n",
       "2      00QJHZSg0UE    27.460\n",
       "3      00b3ov_NFSI    42.400\n",
       "4      00fr8yyBQYo   413.000\n",
       "...            ...       ...\n",
       "18361  zzOL9mRRU0c   533.254\n",
       "18362  zzWQXUKr9OA    27.969\n",
       "18363  zzXTIIo7EvM  1591.680\n",
       "18364  zzZfnY7Zjf0    15.000\n",
       "18365  zzlPmAUN8lM   531.949\n",
       "\n",
       "[18366 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videoid_end_time = df_youtube_sentence.groupby(\"video_id\")[[\"end_time\"]].max()\n",
    "df_videoid_end_time.reset_index(inplace=True)\n",
    "df_videoid_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>6.680</td>\n",
       "      <td>136.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>36.803</td>\n",
       "      <td>813.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>0.440</td>\n",
       "      <td>27.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>18.000</td>\n",
       "      <td>413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>9.333</td>\n",
       "      <td>533.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>1.896</td>\n",
       "      <td>27.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>36.932</td>\n",
       "      <td>1591.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>14.113</td>\n",
       "      <td>531.949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id  start_time  end_time\n",
       "0      007uL_OBtPE       6.680   136.640\n",
       "1      00Dl6tNNlZ8      36.803   813.903\n",
       "2      00QJHZSg0UE       0.440    27.460\n",
       "3      00b3ov_NFSI       0.000    42.400\n",
       "4      00fr8yyBQYo      18.000   413.000\n",
       "...            ...         ...       ...\n",
       "18361  zzOL9mRRU0c       9.333   533.254\n",
       "18362  zzWQXUKr9OA       1.896    27.969\n",
       "18363  zzXTIIo7EvM      36.932  1591.680\n",
       "18364  zzZfnY7Zjf0       0.000    15.000\n",
       "18365  zzlPmAUN8lM      14.113   531.949\n",
       "\n",
       "[18366 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_start_end_time = pd.merge(df_videoid_start_time, df_videoid_end_time, how=\"inner\", on=\"video_id\")\n",
    "df_merge_start_end_time.drop_duplicates(inplace=True)\n",
    "df_merge_start_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>merhaba arkadaşlar bugün sizlere karadeniz yör...</td>\n",
       "      <td>6.680</td>\n",
       "      <td>136.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>kontrol tamam galiba değil mi eee değerli bası...</td>\n",
       "      <td>36.803</td>\n",
       "      <td>813.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>ioğluyla biraz vakit geçirsini ievlat bui idün...</td>\n",
       "      <td>0.440</td>\n",
       "      <td>27.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>evleniyorsun kocam diyorsun aynı yastığa baş k...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>bill gates and george soros developed a new co...</td>\n",
       "      <td>18.000</td>\n",
       "      <td>413.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>18361</td>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>hi kaye di yari merhaba arkadaşlar hikaye diya...</td>\n",
       "      <td>9.333</td>\n",
       "      <td>533.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>18362</td>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>bak baştan anlaşalım ya bu cinayete de diğer c...</td>\n",
       "      <td>1.896</td>\n",
       "      <td>27.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>18363</td>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>ev avcısı kuşadası değirmendere de bugün örnek...</td>\n",
       "      <td>36.932</td>\n",
       "      <td>1591.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>18364</td>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>ben arjantinli bir yapımcıyım ve taşınabilirli...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>18365</td>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>herkese merhaba hoş geldiniz bugün üzerine sür...</td>\n",
       "      <td>14.113</td>\n",
       "      <td>531.949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     video_id                                           sentence  \\\n",
       "0          0  007uL_OBtPE  merhaba arkadaşlar bugün sizlere karadeniz yör...   \n",
       "1          1  00Dl6tNNlZ8  kontrol tamam galiba değil mi eee değerli bası...   \n",
       "2          2  00QJHZSg0UE  ioğluyla biraz vakit geçirsini ievlat bui idün...   \n",
       "3          3  00b3ov_NFSI  evleniyorsun kocam diyorsun aynı yastığa baş k...   \n",
       "4          4  00fr8yyBQYo  bill gates and george soros developed a new co...   \n",
       "...      ...          ...                                                ...   \n",
       "18361  18361  zzOL9mRRU0c  hi kaye di yari merhaba arkadaşlar hikaye diya...   \n",
       "18362  18362  zzWQXUKr9OA  bak baştan anlaşalım ya bu cinayete de diğer c...   \n",
       "18363  18363  zzXTIIo7EvM  ev avcısı kuşadası değirmendere de bugün örnek...   \n",
       "18364  18364  zzZfnY7Zjf0  ben arjantinli bir yapımcıyım ve taşınabilirli...   \n",
       "18365  18365  zzlPmAUN8lM  herkese merhaba hoş geldiniz bugün üzerine sür...   \n",
       "\n",
       "       start_time  end_time  \n",
       "0           6.680   136.640  \n",
       "1          36.803   813.903  \n",
       "2           0.440    27.460  \n",
       "3           0.000    42.400  \n",
       "4          18.000   413.000  \n",
       "...           ...       ...  \n",
       "18361       9.333   533.254  \n",
       "18362       1.896    27.969  \n",
       "18363      36.932  1591.680  \n",
       "18364       0.000    15.000  \n",
       "18365      14.113   531.949  \n",
       "\n",
       "[18366 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videoid_sentence = pd.merge(df_videoid_sentence, df_merge_start_end_time,how=\"inner\", on=\"video_id\")\n",
    "df_videoid_sentence.drop_duplicates(inplace=True)\n",
    "df_videoid_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from multiprocessing import Process, Manager, Pool, Queue\n",
    "manager = multiprocessing.Manager()\n",
    "result_list2 = manager.list()\n",
    "word_set = set(word_list)\n",
    "index_num = list(range(len(df_videoid_sentence)))\n",
    "\n",
    "def videoid_word_ratio(index_num):\n",
    "    index = df_videoid_sentence.loc[index_num,\"index\"]\n",
    "    videoid = df_videoid_sentence.loc[index_num,\"video_id\"]\n",
    "    sentence = df_videoid_sentence.loc[index_num,\"sentence\"]\n",
    "    \n",
    "\n",
    "    sent_word = re.findall(r\"\\w+\", sentence, re.UNICODE)\n",
    "    sent_word_set = set(sent_word)\n",
    "    intersect_word = list(word_set.intersection(sent_word_set))\n",
    "    different_word = list(sent_word_set.difference(word_set))\n",
    "    word_ratio = round(((len(intersect_word)/len(sent_word)+0.001)*100),1)\n",
    "    different = \", \".join(different_word)\n",
    "    intersect = \", \".join(intersect_word)\n",
    "\n",
    "    result_list2.append([index,videoid,sentence,word_ratio,different,intersect])  \n",
    "    \n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(videoid_word_ratio, index_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>different_word</th>\n",
       "      <th>intersect_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>merhaba arkadaşlar bugün sizlere karadeniz yör...</td>\n",
       "      <td>20.9</td>\n",
       "      <td>göstermek, sizlerde, üzerini, pişmeye, olmadığ...</td>\n",
       "      <td>saat, bu, istiyorum, olmaz, olacak, ister, siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>kontrol tamam galiba değil mi eee değerli bası...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>amacımız, kullanılsın, bugünkü, sonlandırması,...</td>\n",
       "      <td>çünkü, olacak, nasıl, eğer, büyük, şu, asla, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>ioğluyla biraz vakit geçirsini ievlat bui idün...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>bui, seviyorsunuzi, h, bahsetmedin, ömürlük, l...</td>\n",
       "      <td>yapıyorsun, dur, sen, ne, şu, ben, benim, de, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>evleniyorsun kocam diyorsun aynı yastığa baş k...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>masumu, ablam, birbirinden, terk, mehdi, yalnı...</td>\n",
       "      <td>bu, nasıl, mu, da, ama, bilmiyorum, o, var, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>bill gates and george soros developed a new co...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>something, guard, martyrs, a, along, performin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>hi kaye di yari merhaba arkadaşlar hikaye diya...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>gelirimbağışıklık, çıkmış, afrikaya, iyileşmes...</td>\n",
       "      <td>tüm, bu, haydi, tam, hadi, da, ama, merhaba, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>bak baştan anlaşalım ya bu cinayete de diğer c...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>kızınız, kurtaracak, bırak, kızı, dışında, bil...</td>\n",
       "      <td>bu, bana, en, sana, seni, ben, da, de, bak, ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>ev avcısı kuşadası değirmendere de bugün örnek...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>şubemiz, çeriye, veriyorlar, düşünürsek, ışıkl...</td>\n",
       "      <td>çünkü, harika, bence, eğer, büyük, vardı, şu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>ben arjantinli bir yapımcıyım ve taşınabilirli...</td>\n",
       "      <td>23.4</td>\n",
       "      <td>bakabileceğim, yelpazede, tablete, belgeseller...</td>\n",
       "      <td>bir, küçük, büyük, vardı, kadar, için, ben, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>herkese merhaba hoş geldiniz bugün üzerine sür...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>eşlik, tereyağı, üst, leziz, kızaracak, haşlam...</td>\n",
       "      <td>çünkü, bu, da, birlikte, merhaba, yine, ve, so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                                           sentence  \\\n",
       "0      007uL_OBtPE  merhaba arkadaşlar bugün sizlere karadeniz yör...   \n",
       "1      00Dl6tNNlZ8  kontrol tamam galiba değil mi eee değerli bası...   \n",
       "2      00QJHZSg0UE  ioğluyla biraz vakit geçirsini ievlat bui idün...   \n",
       "3      00b3ov_NFSI  evleniyorsun kocam diyorsun aynı yastığa baş k...   \n",
       "4      00fr8yyBQYo  bill gates and george soros developed a new co...   \n",
       "...            ...                                                ...   \n",
       "18361  zzOL9mRRU0c  hi kaye di yari merhaba arkadaşlar hikaye diya...   \n",
       "18362  zzWQXUKr9OA  bak baştan anlaşalım ya bu cinayete de diğer c...   \n",
       "18363  zzXTIIo7EvM  ev avcısı kuşadası değirmendere de bugün örnek...   \n",
       "18364  zzZfnY7Zjf0  ben arjantinli bir yapımcıyım ve taşınabilirli...   \n",
       "18365  zzlPmAUN8lM  herkese merhaba hoş geldiniz bugün üzerine sür...   \n",
       "\n",
       "       word_ratio                                     different_word  \\\n",
       "0            20.9  göstermek, sizlerde, üzerini, pişmeye, olmadığ...   \n",
       "1             5.9  amacımız, kullanılsın, bugünkü, sonlandırması,...   \n",
       "2            22.3  bui, seviyorsunuzi, h, bahsetmedin, ömürlük, l...   \n",
       "3            33.8  masumu, ablam, birbirinden, terk, mehdi, yalnı...   \n",
       "4             0.1  something, guard, martyrs, a, along, performin...   \n",
       "...           ...                                                ...   \n",
       "18361         6.9  gelirimbağışıklık, çıkmış, afrikaya, iyileşmes...   \n",
       "18362        27.4  kızınız, kurtaracak, bırak, kızı, dışında, bil...   \n",
       "18363         4.5  şubemiz, çeriye, veriyorlar, düşünürsek, ışıkl...   \n",
       "18364        23.4  bakabileceğim, yelpazede, tablete, belgeseller...   \n",
       "18365        12.3  eşlik, tereyağı, üst, leziz, kızaracak, haşlam...   \n",
       "\n",
       "                                          intersect_word  \n",
       "0      saat, bu, istiyorum, olmaz, olacak, ister, siz...  \n",
       "1      çünkü, olacak, nasıl, eğer, büyük, şu, asla, p...  \n",
       "2      yapıyorsun, dur, sen, ne, şu, ben, benim, de, ...  \n",
       "3      bu, nasıl, mu, da, ama, bilmiyorum, o, var, ge...  \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "18361  tüm, bu, haydi, tam, hadi, da, ama, merhaba, v...  \n",
       "18362  bu, bana, en, sana, seni, ben, da, de, bak, ya...  \n",
       "18363  çünkü, harika, bence, eğer, büyük, vardı, şu, ...  \n",
       "18364  bir, küçük, büyük, vardı, kadar, için, ben, bu...  \n",
       "18365  çünkü, bu, da, birlikte, merhaba, yine, ve, so...  \n",
       "\n",
       "[18366 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_ratio_result = pd.DataFrame(list(result_list2), columns=[\"index\",\"video_id\",\"sentence\",\"word_ratio\",\"different_word\",\"intersect_word\"])\n",
    "df_text_ratio_result.sort_values(by=\"index\", ascending=True, inplace=True)\n",
    "df_text_ratio_result.reset_index(drop=True, inplace=True)\n",
    "df_text_ratio_result.drop([\"index\"], axis=1, inplace=True)\n",
    "df_text_ratio_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>different_word</th>\n",
       "      <th>intersect_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007uL_OBtPE</td>\n",
       "      <td>merhaba arkadaşlar bugün sizlere karadeniz yör...</td>\n",
       "      <td>20.9</td>\n",
       "      <td>göstermek, sizlerde, üzerini, pişmeye, olmadığ...</td>\n",
       "      <td>saat, bu, istiyorum, olmaz, olacak, ister, siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Dl6tNNlZ8</td>\n",
       "      <td>kontrol tamam galiba değil mi eee değerli bası...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>amacımız, kullanılsın, bugünkü, sonlandırması,...</td>\n",
       "      <td>çünkü, olacak, nasıl, eğer, büyük, şu, asla, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00QJHZSg0UE</td>\n",
       "      <td>ioğluyla biraz vakit geçirsini ievlat bui idün...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>bui, seviyorsunuzi, h, bahsetmedin, ömürlük, l...</td>\n",
       "      <td>yapıyorsun, dur, sen, ne, şu, ben, benim, de, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00b3ov_NFSI</td>\n",
       "      <td>evleniyorsun kocam diyorsun aynı yastığa baş k...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>masumu, ablam, birbirinden, terk, mehdi, yalnı...</td>\n",
       "      <td>bu, nasıl, mu, da, ama, bilmiyorum, o, var, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00fr8yyBQYo</td>\n",
       "      <td>bill gates and george soros developed a new co...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>something, guard, martyrs, a, along, performin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>zzOL9mRRU0c</td>\n",
       "      <td>hi kaye di yari merhaba arkadaşlar hikaye diya...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>gelirimbağışıklık, çıkmış, afrikaya, iyileşmes...</td>\n",
       "      <td>tüm, bu, haydi, tam, hadi, da, ama, merhaba, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18362</th>\n",
       "      <td>zzWQXUKr9OA</td>\n",
       "      <td>bak baştan anlaşalım ya bu cinayete de diğer c...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>kızınız, kurtaracak, bırak, kızı, dışında, bil...</td>\n",
       "      <td>bu, bana, en, sana, seni, ben, da, de, bak, ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18363</th>\n",
       "      <td>zzXTIIo7EvM</td>\n",
       "      <td>ev avcısı kuşadası değirmendere de bugün örnek...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>şubemiz, çeriye, veriyorlar, düşünürsek, ışıkl...</td>\n",
       "      <td>çünkü, harika, bence, eğer, büyük, vardı, şu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18364</th>\n",
       "      <td>zzZfnY7Zjf0</td>\n",
       "      <td>ben arjantinli bir yapımcıyım ve taşınabilirli...</td>\n",
       "      <td>23.4</td>\n",
       "      <td>bakabileceğim, yelpazede, tablete, belgeseller...</td>\n",
       "      <td>bir, küçük, büyük, vardı, kadar, için, ben, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18365</th>\n",
       "      <td>zzlPmAUN8lM</td>\n",
       "      <td>herkese merhaba hoş geldiniz bugün üzerine sür...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>eşlik, tereyağı, üst, leziz, kızaracak, haşlam...</td>\n",
       "      <td>çünkü, bu, da, birlikte, merhaba, yine, ve, so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18366 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                                           sentence  \\\n",
       "0      007uL_OBtPE  merhaba arkadaşlar bugün sizlere karadeniz yör...   \n",
       "1      00Dl6tNNlZ8  kontrol tamam galiba değil mi eee değerli bası...   \n",
       "2      00QJHZSg0UE  ioğluyla biraz vakit geçirsini ievlat bui idün...   \n",
       "3      00b3ov_NFSI  evleniyorsun kocam diyorsun aynı yastığa baş k...   \n",
       "4      00fr8yyBQYo  bill gates and george soros developed a new co...   \n",
       "...            ...                                                ...   \n",
       "18361  zzOL9mRRU0c  hi kaye di yari merhaba arkadaşlar hikaye diya...   \n",
       "18362  zzWQXUKr9OA  bak baştan anlaşalım ya bu cinayete de diğer c...   \n",
       "18363  zzXTIIo7EvM  ev avcısı kuşadası değirmendere de bugün örnek...   \n",
       "18364  zzZfnY7Zjf0  ben arjantinli bir yapımcıyım ve taşınabilirli...   \n",
       "18365  zzlPmAUN8lM  herkese merhaba hoş geldiniz bugün üzerine sür...   \n",
       "\n",
       "       word_ratio                                     different_word  \\\n",
       "0            20.9  göstermek, sizlerde, üzerini, pişmeye, olmadığ...   \n",
       "1             5.9  amacımız, kullanılsın, bugünkü, sonlandırması,...   \n",
       "2            22.3  bui, seviyorsunuzi, h, bahsetmedin, ömürlük, l...   \n",
       "3            33.8  masumu, ablam, birbirinden, terk, mehdi, yalnı...   \n",
       "4             0.1  something, guard, martyrs, a, along, performin...   \n",
       "...           ...                                                ...   \n",
       "18361         6.9  gelirimbağışıklık, çıkmış, afrikaya, iyileşmes...   \n",
       "18362        27.4  kızınız, kurtaracak, bırak, kızı, dışında, bil...   \n",
       "18363         4.5  şubemiz, çeriye, veriyorlar, düşünürsek, ışıkl...   \n",
       "18364        23.4  bakabileceğim, yelpazede, tablete, belgeseller...   \n",
       "18365        12.3  eşlik, tereyağı, üst, leziz, kızaracak, haşlam...   \n",
       "\n",
       "                                          intersect_word  \n",
       "0      saat, bu, istiyorum, olmaz, olacak, ister, siz...  \n",
       "1      çünkü, olacak, nasıl, eğer, büyük, şu, asla, p...  \n",
       "2      yapıyorsun, dur, sen, ne, şu, ben, benim, de, ...  \n",
       "3      bu, nasıl, mu, da, ama, bilmiyorum, o, var, ge...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "18361  tüm, bu, haydi, tam, hadi, da, ama, merhaba, v...  \n",
       "18362  bu, bana, en, sana, seni, ben, da, de, bak, ya...  \n",
       "18363  çünkü, harika, bence, eğer, büyük, vardı, şu, ...  \n",
       "18364  bir, küçük, büyük, vardı, kadar, için, ben, bu...  \n",
       "18365  çünkü, bu, da, birlikte, merhaba, yine, ve, so...  \n",
       "\n",
       "[18366 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_ratio_result[\"different_word\"] = df_text_ratio_result[\"different_word\"].apply(lambda x: np.nan if x == \"\" else x)\n",
    "df_text_ratio_result[\"intersect_word\"] = df_text_ratio_result[\"intersect_word\"].apply(lambda x: np.nan if x == \"\" else x)\n",
    "df_text_ratio_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>different_word</th>\n",
       "      <th>intersect_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0RIp8JRHXXE</td>\n",
       "      <td>kimsin sen selvi yüreğimin tetiğini indiren ki...</td>\n",
       "      <td>45.9</td>\n",
       "      <td>söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...</td>\n",
       "      <td>bir, şey, bana, en, neden, sen, benim, da, çok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dAFdqL12F0</td>\n",
       "      <td>vazgeçmiyor kızım senden vazgeçmiyor fulya sen...</td>\n",
       "      <td>46.3</td>\n",
       "      <td>öylesine, hamileyim, diyorsun, bölümüyle, salı...</td>\n",
       "      <td>bu, da, lazım, mı, var, sana, hiç, sen, sonra,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1LMDmZNFyv8</td>\n",
       "      <td>heya son zamanlarda epey meşulmüşsün ha kötü s...</td>\n",
       "      <td>43.4</td>\n",
       "      <td>diyor, madem, meşulmüşsün, ha, very, i, zamanl...</td>\n",
       "      <td>bile, öyle, kötü, pekala, o, son, eğer, var, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a2_P8fAdmc</td>\n",
       "      <td>tamam efendim ustam bizim hesap ne kadar bir b...</td>\n",
       "      <td>44.5</td>\n",
       "      <td>e, ustam, tabi, yalnız, parasını, madem, fatur...</td>\n",
       "      <td>tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jrLF7RNI0k</td>\n",
       "      <td>size benim güzel bir haberim var artık anneniz...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...</td>\n",
       "      <td>çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>yWHodncIIqM</td>\n",
       "      <td>destek için abone ol beğen ve yorum yap lütfen</td>\n",
       "      <td>44.5</td>\n",
       "      <td>yorum, yap, destek, abone, beğen</td>\n",
       "      <td>ve, ol, lütfen, için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>yqERJ6yqYRw</td>\n",
       "      <td>abone olur musun</td>\n",
       "      <td>66.8</td>\n",
       "      <td>abone</td>\n",
       "      <td>musun, olur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ytqhB6dpsnw</td>\n",
       "      <td>resimli güzel ve anlamlı sözler</td>\n",
       "      <td>40.1</td>\n",
       "      <td>resimli, sözler, anlamlı</td>\n",
       "      <td>ve, güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>yvKCHSKRmbs</td>\n",
       "      <td>doğru nefes alıyor musun nefesini nerede hisse...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>nefes, nefesini, hissediyorsun, alıyor</td>\n",
       "      <td>musun, doğru, nerede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>zAbLCWRozxY</td>\n",
       "      <td>afiyet olsun</td>\n",
       "      <td>50.1</td>\n",
       "      <td>afiyet</td>\n",
       "      <td>olsun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                           sentence  \\\n",
       "0    0RIp8JRHXXE  kimsin sen selvi yüreğimin tetiğini indiren ki...   \n",
       "1    0dAFdqL12F0  vazgeçmiyor kızım senden vazgeçmiyor fulya sen...   \n",
       "2    1LMDmZNFyv8  heya son zamanlarda epey meşulmüşsün ha kötü s...   \n",
       "3    1a2_P8fAdmc  tamam efendim ustam bizim hesap ne kadar bir b...   \n",
       "4    1jrLF7RNI0k  size benim güzel bir haberim var artık anneniz...   \n",
       "..           ...                                                ...   \n",
       "299  yWHodncIIqM     destek için abone ol beğen ve yorum yap lütfen   \n",
       "300  yqERJ6yqYRw                                   abone olur musun   \n",
       "301  ytqhB6dpsnw                    resimli güzel ve anlamlı sözler   \n",
       "302  yvKCHSKRmbs  doğru nefes alıyor musun nefesini nerede hisse...   \n",
       "303  zAbLCWRozxY                                       afiyet olsun   \n",
       "\n",
       "     word_ratio                                     different_word  \\\n",
       "0          45.9  söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...   \n",
       "1          46.3  öylesine, hamileyim, diyorsun, bölümüyle, salı...   \n",
       "2          43.4  diyor, madem, meşulmüşsün, ha, very, i, zamanl...   \n",
       "3          44.5  e, ustam, tabi, yalnız, parasını, madem, fatur...   \n",
       "4          42.1  bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...   \n",
       "..          ...                                                ...   \n",
       "299        44.5                   yorum, yap, destek, abone, beğen   \n",
       "300        66.8                                              abone   \n",
       "301        40.1                           resimli, sözler, anlamlı   \n",
       "302        43.0             nefes, nefesini, hissediyorsun, alıyor   \n",
       "303        50.1                                             afiyet   \n",
       "\n",
       "                                        intersect_word  \n",
       "0    bir, şey, bana, en, neden, sen, benim, da, çok...  \n",
       "1    bu, da, lazım, mı, var, sana, hiç, sen, sonra,...  \n",
       "2    bile, öyle, kötü, pekala, o, son, eğer, var, b...  \n",
       "3    tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...  \n",
       "4    çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...  \n",
       "..                                                 ...  \n",
       "299                               ve, ol, lütfen, için  \n",
       "300                                        musun, olur  \n",
       "301                                          ve, güzel  \n",
       "302                               musun, doğru, nerede  \n",
       "303                                              olsun  \n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjust_text_ratio = df_text_ratio_result[df_text_ratio_result[\"word_ratio\"] >= adjust_text_word_ratio]\n",
    "df_adjust_text_ratio.reset_index(inplace=True, drop=True)\n",
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_text_ratio.loc[:,\"search_string\"] = df_adjust_text_ratio.loc[:,\"sentence\"].map(lambda x: exract_word_group(x, word_list))\n",
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_text_ratio = df_adjust_text_ratio[[\"search_string\",\"video_id\",\"sentence\",\"word_ratio\"]]\n",
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videoid_sentence = df_videoid_sentence[[\"video_id\",\"start_time\",\"end_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_text_ratio = pd.merge(df_adjust_text_ratio, df_videoid_sentence, how=\"inner\", on=\"video_id\")\n",
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result = word_group_time_loc(df_adjust_text_ratio, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_in_text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result[\"start_time\"] = df_word_group_time_loc_in_text_result[\"start_time\"].apply(lambda x: (x-shift))\n",
    "df_word_group_time_loc_in_text_result[\"end_time\"] = df_word_group_time_loc_in_text_result[\"end_time\"].apply(lambda x: (x+shift))\n",
    "df_word_group_time_loc_in_text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result[\"start_time\"] = df_word_group_time_loc_in_text_result[\"start_time\"].apply(lambda x: round(x))\n",
    "df_word_group_time_loc_in_text_result[\"end_time\"] = df_word_group_time_loc_in_text_result[\"end_time\"].apply(lambda x: round(x))\n",
    "df_word_group_time_loc_in_text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result.sort_values(\"search_string\",key=lambda x:x.str.len(), inplace=True, ascending=False)\n",
    "df_word_group_time_loc_in_text_result.reset_index(drop=True, inplace=True)\n",
    "df_word_group_time_loc_in_text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result[\"video_url\"] = \"https://www.youtube.com/watch?v=\"+df_word_group_time_loc_in_text_result['video_id'].map(str)+\"&t=\"+df_word_group_time_loc_in_text_result['start_time'].map(str)+\"s\"\n",
    "df_word_group_time_loc_in_text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_in_text_result.loc[0,\"search_string\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_word_group_time_loc_in_text_result.loc[13,\"sentence\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall(r\"\\w+\", text, re.UNICODE)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(len(words)):\n",
    "    if words[i] in word_list:\n",
    "        index_list.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index_list = []\n",
    "var_index_list = []\n",
    "for j in range(len(index_list)):\n",
    "    try:\n",
    "        var1 = index_list[j] + 1  \n",
    "        var2 = index_list[j+1]\n",
    "    except:\n",
    "        var1 = index_list[j] + 1  \n",
    "        var2 = index_list[-1]\n",
    "    if var1 == var2:\n",
    "        var3 = index_list[j]\n",
    "        var_index_list.append(var3)\n",
    "    else:\n",
    "        var3 = index_list[j]\n",
    "        var_index_list.append(var3)\n",
    "        var4 = list(var_index_list)\n",
    "        all_index_list.append(var4)\n",
    "        var_index_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_index_list, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(all_index_list, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for i in max(all_index_list, key=len):\n",
    "    word = words[i]\n",
    "    text_list.append(word)\n",
    "text = \" \".join(text_list)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>different_word</th>\n",
       "      <th>intersect_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0RIp8JRHXXE</td>\n",
       "      <td>kimsin sen selvi yüreğimin tetiğini indiren ki...</td>\n",
       "      <td>45.9</td>\n",
       "      <td>söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...</td>\n",
       "      <td>bir, şey, bana, en, neden, sen, benim, da, çok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dAFdqL12F0</td>\n",
       "      <td>vazgeçmiyor kızım senden vazgeçmiyor fulya sen...</td>\n",
       "      <td>46.3</td>\n",
       "      <td>öylesine, hamileyim, diyorsun, bölümüyle, salı...</td>\n",
       "      <td>bu, da, lazım, mı, var, sana, hiç, sen, sonra,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1LMDmZNFyv8</td>\n",
       "      <td>heya son zamanlarda epey meşulmüşsün ha kötü s...</td>\n",
       "      <td>43.4</td>\n",
       "      <td>diyor, madem, meşulmüşsün, ha, very, i, zamanl...</td>\n",
       "      <td>bile, öyle, kötü, pekala, o, son, eğer, var, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a2_P8fAdmc</td>\n",
       "      <td>tamam efendim ustam bizim hesap ne kadar bir b...</td>\n",
       "      <td>44.5</td>\n",
       "      <td>e, ustam, tabi, yalnız, parasını, madem, fatur...</td>\n",
       "      <td>tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jrLF7RNI0k</td>\n",
       "      <td>size benim güzel bir haberim var artık anneniz...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...</td>\n",
       "      <td>çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>yWHodncIIqM</td>\n",
       "      <td>destek için abone ol beğen ve yorum yap lütfen</td>\n",
       "      <td>44.5</td>\n",
       "      <td>yorum, yap, destek, abone, beğen</td>\n",
       "      <td>ve, ol, lütfen, için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>yqERJ6yqYRw</td>\n",
       "      <td>abone olur musun</td>\n",
       "      <td>66.8</td>\n",
       "      <td>abone</td>\n",
       "      <td>musun, olur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ytqhB6dpsnw</td>\n",
       "      <td>resimli güzel ve anlamlı sözler</td>\n",
       "      <td>40.1</td>\n",
       "      <td>resimli, sözler, anlamlı</td>\n",
       "      <td>ve, güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>yvKCHSKRmbs</td>\n",
       "      <td>doğru nefes alıyor musun nefesini nerede hisse...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>nefes, nefesini, hissediyorsun, alıyor</td>\n",
       "      <td>musun, doğru, nerede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>zAbLCWRozxY</td>\n",
       "      <td>afiyet olsun</td>\n",
       "      <td>50.1</td>\n",
       "      <td>afiyet</td>\n",
       "      <td>olsun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                           sentence  \\\n",
       "0    0RIp8JRHXXE  kimsin sen selvi yüreğimin tetiğini indiren ki...   \n",
       "1    0dAFdqL12F0  vazgeçmiyor kızım senden vazgeçmiyor fulya sen...   \n",
       "2    1LMDmZNFyv8  heya son zamanlarda epey meşulmüşsün ha kötü s...   \n",
       "3    1a2_P8fAdmc  tamam efendim ustam bizim hesap ne kadar bir b...   \n",
       "4    1jrLF7RNI0k  size benim güzel bir haberim var artık anneniz...   \n",
       "..           ...                                                ...   \n",
       "299  yWHodncIIqM     destek için abone ol beğen ve yorum yap lütfen   \n",
       "300  yqERJ6yqYRw                                   abone olur musun   \n",
       "301  ytqhB6dpsnw                    resimli güzel ve anlamlı sözler   \n",
       "302  yvKCHSKRmbs  doğru nefes alıyor musun nefesini nerede hisse...   \n",
       "303  zAbLCWRozxY                                       afiyet olsun   \n",
       "\n",
       "     word_ratio                                     different_word  \\\n",
       "0          45.9  söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...   \n",
       "1          46.3  öylesine, hamileyim, diyorsun, bölümüyle, salı...   \n",
       "2          43.4  diyor, madem, meşulmüşsün, ha, very, i, zamanl...   \n",
       "3          44.5  e, ustam, tabi, yalnız, parasını, madem, fatur...   \n",
       "4          42.1  bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...   \n",
       "..          ...                                                ...   \n",
       "299        44.5                   yorum, yap, destek, abone, beğen   \n",
       "300        66.8                                              abone   \n",
       "301        40.1                           resimli, sözler, anlamlı   \n",
       "302        43.0             nefes, nefesini, hissediyorsun, alıyor   \n",
       "303        50.1                                             afiyet   \n",
       "\n",
       "                                        intersect_word  \n",
       "0    bir, şey, bana, en, neden, sen, benim, da, çok...  \n",
       "1    bu, da, lazım, mı, var, sana, hiç, sen, sonra,...  \n",
       "2    bile, öyle, kötü, pekala, o, son, eğer, var, b...  \n",
       "3    tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...  \n",
       "4    çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...  \n",
       "..                                                 ...  \n",
       "299                               ve, ol, lütfen, için  \n",
       "300                                        musun, olur  \n",
       "301                                          ve, güzel  \n",
       "302                               musun, doğru, nerede  \n",
       "303                                              olsun  \n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_word_group(text, word_list):\n",
    "    '''\n",
    "    exract_word_group(text, word_list): \\n\n",
    "    text is a string sentence, word_list occurs words \n",
    "    '''\n",
    "    words = re.findall(r\"\\w+\", text, re.UNICODE)\n",
    "    index_list = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in word_list:\n",
    "            index_list.append(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    all_index_list = []\n",
    "    var_index_list = []\n",
    "    for j in range(len(index_list)):\n",
    "        try:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[j+1]\n",
    "        except:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[-1]\n",
    "        if var1 == var2:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "        else:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "            var4 = list(var_index_list)\n",
    "            all_index_list.append(var4)\n",
    "            var_index_list = []\n",
    "\n",
    "    text_list = []\n",
    "    for k in max(all_index_list, key=len):\n",
    "        word = words[k]\n",
    "        text_list.append(word)\n",
    "    text = \" \".join(text_list)\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will test\n",
    "def df_exract_word_group(df, source_text_column, opt_column, word_list, sent_len=False, sent_len_num=2):\n",
    "    '''\n",
    "    df_exract_word_group(df_adjust_text_ratio, sentence, video_id, word_list, sent_len=False, sent_len_num=2): \\n\n",
    "    df_adjust_text_ratio is a dataframe. sentence is a string sentence. \\n\n",
    "    video_id is optional column value. word_list occurs words \\n\n",
    "    sent_len is sentence length condition \\n\n",
    "    sent_len_num is sentence occurs how many word at least. \n",
    "    '''\n",
    "    df_new = pd.DataFrame()\n",
    "    for i in range(len(df)):\n",
    "        source_text = df.loc[i,f\"{source_text_column}\"]\n",
    "        opt_var = df.loc[i,f\"{opt_column}\"]\n",
    "        words = re.findall(r\"\\w+\", source_text, re.UNICODE)\n",
    "        index_list = []\n",
    "\n",
    "        for j in range(len(words)):\n",
    "            if words[j] in word_list:\n",
    "                index_list.append(j)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        all_index_list = []\n",
    "        var_index_list = []\n",
    "        for k in range(len(index_list)):\n",
    "            try:\n",
    "                var1 = index_list[k] + 1  \n",
    "                var2 = index_list[k+1]\n",
    "            except:\n",
    "                var1 = index_list[k] + 1  \n",
    "                var2 = index_list[-1]\n",
    "            if var1 == var2:\n",
    "                var3 = index_list[k]\n",
    "                var_index_list.append(var3)\n",
    "            else:\n",
    "                var3 = index_list[k]\n",
    "                var_index_list.append(var3)\n",
    "                var4 = list(var_index_list)\n",
    "                all_index_list.append(var4)\n",
    "                var_index_list = []\n",
    "\n",
    "        text_all_list = []\n",
    "        for m in all_index_list:\n",
    "            text_list = [] \n",
    "            for n in m:\n",
    "                word = words[n]\n",
    "                text_list.append(word)\n",
    "                if sent_len:\n",
    "                    if len(text_list) >= sent_len_num:\n",
    "                        text = \" \".join(text_list)\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                   text = \" \".join(text_list) \n",
    "            text_all_list.append(text)\n",
    "\n",
    "            df_var = pd.DataFrame()\n",
    "            for search_string in text_all_list:\n",
    "                df_var[\"index\"] = i\n",
    "                df_var[\"search_string\"] = search_string\n",
    "                df_var[\"sentence\"] = source_text\n",
    "                df_var[\"video_id\"] = opt_var\n",
    "                df_new = pd.concat([df_new, df_var], axis=0)\n",
    "\n",
    "    return df_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['çünkü',\n",
       " 'istiyorsun',\n",
       " 'misin',\n",
       " 'sanırım',\n",
       " 'olacak',\n",
       " 'ver',\n",
       " 'gerçek',\n",
       " 'biliyorsun',\n",
       " 'nasıl',\n",
       " 'harika',\n",
       " 'bence',\n",
       " 'eğer',\n",
       " 'dur',\n",
       " 'sizi',\n",
       " 'büyük',\n",
       " 'vardı',\n",
       " 'git',\n",
       " 'şu',\n",
       " 'neler',\n",
       " 'oluyor',\n",
       " 'asla',\n",
       " 'biraz',\n",
       " 'peki',\n",
       " 'gerek',\n",
       " 'olarak',\n",
       " 'geri',\n",
       " 'en',\n",
       " 'yüzden',\n",
       " 'burada',\n",
       " 'işte',\n",
       " 'aynı',\n",
       " 'de',\n",
       " 'yani',\n",
       " 'aslında',\n",
       " 'mısın',\n",
       " 'ilk',\n",
       " 'değilim',\n",
       " 'olmak',\n",
       " 'hala',\n",
       " 'adam',\n",
       " 'küçük',\n",
       " 'teşekkür',\n",
       " 'et',\n",
       " 'oh',\n",
       " 'artık',\n",
       " 'için',\n",
       " 'bunun',\n",
       " 'biliyor',\n",
       " 'yoksa',\n",
       " 'teşekkürler',\n",
       " 'önemli',\n",
       " 'bizim',\n",
       " 'al',\n",
       " 'onlar',\n",
       " 'tüm',\n",
       " 'saat',\n",
       " 'haydi',\n",
       " 'istiyorum',\n",
       " 'benimle',\n",
       " 'tam',\n",
       " 'neden',\n",
       " 'yok',\n",
       " 'şeyi',\n",
       " 'mu',\n",
       " 'da',\n",
       " 'ama',\n",
       " 'bilmiyorum',\n",
       " 'mı',\n",
       " 'üzgünüm',\n",
       " 'şey',\n",
       " 'onun',\n",
       " 'biri',\n",
       " 'evet',\n",
       " 'sana',\n",
       " 'nerede',\n",
       " 'onu',\n",
       " 'izin',\n",
       " 'senin',\n",
       " 'hakkında',\n",
       " 'geldi',\n",
       " 'efendim',\n",
       " 'kadar',\n",
       " 'para',\n",
       " 'bizi',\n",
       " 'böyle',\n",
       " 'şekilde',\n",
       " 'her',\n",
       " 'biliyorum',\n",
       " 'onunla',\n",
       " 'mi',\n",
       " 'bugün',\n",
       " 'içinde',\n",
       " 'güzel',\n",
       " 'seni',\n",
       " 'şimdi',\n",
       " 'selam',\n",
       " 'sadece',\n",
       " 'dakika',\n",
       " 'olur',\n",
       " 'çok',\n",
       " 'kimse',\n",
       " 'oldu',\n",
       " 'baba',\n",
       " 'göre',\n",
       " 'bile',\n",
       " 'hayır',\n",
       " 'bütün',\n",
       " 'öyle',\n",
       " 'tekrar',\n",
       " 'kötü',\n",
       " 'siz',\n",
       " 'ister',\n",
       " 'pekala',\n",
       " 'orada',\n",
       " 'yine',\n",
       " 've',\n",
       " 'o',\n",
       " 'son',\n",
       " 'seninle',\n",
       " 'var',\n",
       " 'ile',\n",
       " 'bize',\n",
       " 'sen',\n",
       " 'beni',\n",
       " 'gece',\n",
       " 'iki',\n",
       " 'zaman',\n",
       " 'olduğunu',\n",
       " 'bak',\n",
       " 'başka',\n",
       " 'özür',\n",
       " 'tamam',\n",
       " 'gün',\n",
       " 'bir',\n",
       " 'musun',\n",
       " 'anne',\n",
       " 'ol',\n",
       " 'kendi',\n",
       " 'demek',\n",
       " 'birkaç',\n",
       " 'olan',\n",
       " 'şunu',\n",
       " 'lütfen',\n",
       " 'geliyor',\n",
       " 'hey',\n",
       " 'değil',\n",
       " 'ben',\n",
       " 'gibi',\n",
       " 'gel',\n",
       " 'bu',\n",
       " 'olmaz',\n",
       " 'hiçbir',\n",
       " 'üç',\n",
       " 'hadi',\n",
       " 'birlikte',\n",
       " 'lazım',\n",
       " 'merhaba',\n",
       " 'hemen',\n",
       " 'buraya',\n",
       " 'yapıyorsun',\n",
       " 'tabii',\n",
       " 'hiç',\n",
       " 'devam',\n",
       " 'olsun',\n",
       " 'sonra',\n",
       " 'benim',\n",
       " 'sorun',\n",
       " 'iş',\n",
       " 'yardım',\n",
       " 'onları',\n",
       " 'şeyler',\n",
       " 'iyi',\n",
       " 'tek',\n",
       " 'bana',\n",
       " 'buna',\n",
       " 'yeni',\n",
       " 'bakalım',\n",
       " 'ne',\n",
       " 'belki',\n",
       " 'size',\n",
       " 'ya',\n",
       " 'bunu',\n",
       " 'gerçekten',\n",
       " 'uzun',\n",
       " 'söyle',\n",
       " 'önce',\n",
       " 'biz',\n",
       " 'diye',\n",
       " 'zaten',\n",
       " 'daha',\n",
       " 'ederim',\n",
       " 'ona',\n",
       " 'fazla',\n",
       " 'olabilir',\n",
       " 'kız',\n",
       " 'ki',\n",
       " 'mü',\n",
       " 'doğru',\n",
       " 'dostum',\n",
       " 'herkes']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_ratio</th>\n",
       "      <th>different_word</th>\n",
       "      <th>intersect_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0RIp8JRHXXE</td>\n",
       "      <td>kimsin sen selvi yüreğimin tetiğini indiren ki...</td>\n",
       "      <td>45.9</td>\n",
       "      <td>söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...</td>\n",
       "      <td>bir, şey, bana, en, neden, sen, benim, da, çok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dAFdqL12F0</td>\n",
       "      <td>vazgeçmiyor kızım senden vazgeçmiyor fulya sen...</td>\n",
       "      <td>46.3</td>\n",
       "      <td>öylesine, hamileyim, diyorsun, bölümüyle, salı...</td>\n",
       "      <td>bu, da, lazım, mı, var, sana, hiç, sen, sonra,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1LMDmZNFyv8</td>\n",
       "      <td>heya son zamanlarda epey meşulmüşsün ha kötü s...</td>\n",
       "      <td>43.4</td>\n",
       "      <td>diyor, madem, meşulmüşsün, ha, very, i, zamanl...</td>\n",
       "      <td>bile, öyle, kötü, pekala, o, son, eğer, var, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a2_P8fAdmc</td>\n",
       "      <td>tamam efendim ustam bizim hesap ne kadar bir b...</td>\n",
       "      <td>44.5</td>\n",
       "      <td>e, ustam, tabi, yalnız, parasını, madem, fatur...</td>\n",
       "      <td>tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jrLF7RNI0k</td>\n",
       "      <td>size benim güzel bir haberim var artık anneniz...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...</td>\n",
       "      <td>çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>yWHodncIIqM</td>\n",
       "      <td>destek için abone ol beğen ve yorum yap lütfen</td>\n",
       "      <td>44.5</td>\n",
       "      <td>yorum, yap, destek, abone, beğen</td>\n",
       "      <td>ve, ol, lütfen, için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>yqERJ6yqYRw</td>\n",
       "      <td>abone olur musun</td>\n",
       "      <td>66.8</td>\n",
       "      <td>abone</td>\n",
       "      <td>musun, olur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ytqhB6dpsnw</td>\n",
       "      <td>resimli güzel ve anlamlı sözler</td>\n",
       "      <td>40.1</td>\n",
       "      <td>resimli, sözler, anlamlı</td>\n",
       "      <td>ve, güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>yvKCHSKRmbs</td>\n",
       "      <td>doğru nefes alıyor musun nefesini nerede hisse...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>nefes, nefesini, hissediyorsun, alıyor</td>\n",
       "      <td>musun, doğru, nerede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>zAbLCWRozxY</td>\n",
       "      <td>afiyet olsun</td>\n",
       "      <td>50.1</td>\n",
       "      <td>afiyet</td>\n",
       "      <td>olsun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                           sentence  \\\n",
       "0    0RIp8JRHXXE  kimsin sen selvi yüreğimin tetiğini indiren ki...   \n",
       "1    0dAFdqL12F0  vazgeçmiyor kızım senden vazgeçmiyor fulya sen...   \n",
       "2    1LMDmZNFyv8  heya son zamanlarda epey meşulmüşsün ha kötü s...   \n",
       "3    1a2_P8fAdmc  tamam efendim ustam bizim hesap ne kadar bir b...   \n",
       "4    1jrLF7RNI0k  size benim güzel bir haberim var artık anneniz...   \n",
       "..           ...                                                ...   \n",
       "299  yWHodncIIqM     destek için abone ol beğen ve yorum yap lütfen   \n",
       "300  yqERJ6yqYRw                                   abone olur musun   \n",
       "301  ytqhB6dpsnw                    resimli güzel ve anlamlı sözler   \n",
       "302  yvKCHSKRmbs  doğru nefes alıyor musun nefesini nerede hisse...   \n",
       "303  zAbLCWRozxY                                       afiyet olsun   \n",
       "\n",
       "     word_ratio                                     different_word  \\\n",
       "0          45.9  söylemiyorsun, tetiğini, yanıyor, yüreğimin, i...   \n",
       "1          46.3  öylesine, hamileyim, diyorsun, bölümüyle, salı...   \n",
       "2          43.4  diyor, madem, meşulmüşsün, ha, very, i, zamanl...   \n",
       "3          44.5  e, ustam, tabi, yalnız, parasını, madem, fatur...   \n",
       "4          42.1  bulmanın, çıkarma, anneniz, hanımı, salı, yaşa...   \n",
       "..          ...                                                ...   \n",
       "299        44.5                   yorum, yap, destek, abone, beğen   \n",
       "300        66.8                                              abone   \n",
       "301        40.1                           resimli, sözler, anlamlı   \n",
       "302        43.0             nefes, nefesini, hissediyorsun, alıyor   \n",
       "303        50.1                                             afiyet   \n",
       "\n",
       "                                        intersect_word  \n",
       "0    bir, şey, bana, en, neden, sen, benim, da, çok...  \n",
       "1    bu, da, lazım, mı, var, sana, hiç, sen, sonra,...  \n",
       "2    bile, öyle, kötü, pekala, o, son, eğer, var, b...  \n",
       "3    tüm, bu, olmaz, ve, var, tamam, bir, buna, efe...  \n",
       "4    çünkü, öyle, yok, siz, mu, ama, mı, var, ile, ...  \n",
       "..                                                 ...  \n",
       "299                               ve, ol, lütfen, için  \n",
       "300                                        musun, olur  \n",
       "301                                          ve, güzel  \n",
       "302                               musun, doğru, nerede  \n",
       "303                                              olsun  \n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjust_text_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>search_string</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, search_string, sentence, video_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exract_word_group(df_adjust_text_ratio, \"sentence\", \"video_id\", word_list, sent_len=False, sent_len_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all_list = []\n",
    "for i in all_index_list:\n",
    "    text_list = [] \n",
    "    for j in i:\n",
    "        word = words[j]\n",
    "        text_list.append(word)\n",
    "        text = \" \".join(text_list)\n",
    "    text_all_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_videoid_sentence.loc[0,\"sentence\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"burcu biraz daha devam et devam et istanbul burcu burcu tamam oldu et izmir devam et devam et burcu burcu daha devam et burcu burcu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall(r\"\\w+\", text, re.UNICODE)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[1] in word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(len(words)):\n",
    "    if words[i] in word_list:\n",
    "        index_list.append(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index_list = []\n",
    "var_index_list = []\n",
    "for j in range(len(index_list)):\n",
    "    try:\n",
    "        var1 = index_list[j] + 1  \n",
    "        var2 = index_list[j+1]\n",
    "    except:\n",
    "        var1 = index_list[j] + 1  \n",
    "        var2 = index_list[-1]\n",
    "    if var1 == var2:\n",
    "        var3 = index_list[j]\n",
    "        var_index_list.append(var3)\n",
    "    else:\n",
    "        var3 = index_list[j]\n",
    "        var_index_list.append(var3)\n",
    "        var4 = list(var_index_list)\n",
    "        all_index_list.append(var4)\n",
    "        var_index_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(all_index_list, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for i in max(all_index_list, key=len):\n",
    "    word = words[i]\n",
    "    text_list.append(word)\n",
    "text = \" \".join(text_list)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_word_group(text, word_list):\n",
    "    words = re.findall(r\"\\w+\", text, re.UNICODE)\n",
    "    index_list = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in word_list:\n",
    "            index_list.append(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    all_index_list = []\n",
    "    var_index_list = []\n",
    "    for j in range(len(index_list)):\n",
    "        try:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[j+1]\n",
    "        except:\n",
    "            var1 = index_list[j] + 1  \n",
    "            var2 = index_list[-1]\n",
    "        if var1 == var2:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "        else:\n",
    "            var3 = index_list[j]\n",
    "            var_index_list.append(var3)\n",
    "            var4 = list(var_index_list)\n",
    "            all_index_list.append(var4)\n",
    "            var_index_list = []\n",
    "\n",
    "    text_list = []\n",
    "    for i in max(all_index_list, key=len):\n",
    "        word = words[i]\n",
    "        text_list.append(word)\n",
    "    text = \" \".join(text_list)\n",
    "    \n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"burcu biraz daha devam et devam et istanbul burcu burcu tamam oldu et izmir devam et devam et burcu burcu daha devam et burcu burcu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exract_word_group(text, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_sentence_ratio_test = df_adjust_sentence_ratio.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjust_sentence_ratio_test.loc[:,\"search_string\"] = df_adjust_sentence_ratio_test.loc[:,\"sentence\"].map(lambda x: exract_word_group(x, word_list))\n",
    "df_adjust_sentence_ratio_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_time_loc(df, search, start_sent, end_sent, sent, sent_video_id):\n",
    "    '''\n",
    "    word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "    '''\n",
    "    word_time_loc_list = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,f\"{search}\"]\n",
    "        start_time = df.loc[i,f\"{start_sent}\"]\n",
    "        end_time = df.loc[i,f\"{end_sent}\"]\n",
    "        sentence = df.loc[i,f\"{sent}\"]\n",
    "        video_id = df.loc[i,f\"{sent_video_id}\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[f\"{search}\",f\"{start_sent}\",f\"{end_sent}\",f\"{sent}\",f\"{sent_video_id}\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_result = word_group_time_loc(df_adjust_sentence_ratio_test, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
