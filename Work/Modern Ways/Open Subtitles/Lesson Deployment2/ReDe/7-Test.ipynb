{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Arabic\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# source path\n",
    "source_path = \"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Deployment2/Result/Deploy2 Result Manuel/Turkish\"\n",
    "\n",
    "# parameter\n",
    "file = \"Basics Cover the Most Master File\"  # file without extention\n",
    "sheets = \"85 Sentence\"  # 2 gram target, 2 gram hybrid\n",
    "file_ext = \"85 Sentence\"\n",
    "first_column = 2  # start column location number\n",
    "end_column = 3\n",
    "\n",
    "# native word select for Part 2 \n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 200 # 28  # native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]\n",
    "df_word_select.reset_index(inplace=True)\n",
    "df_word_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = pd.read_excel(f\"{source_path}/{file}.xlsx\", sheet_name=f\"{sheets}\")\n",
    "#df_file.sort_values(\"search_string\",key=lambda x:x.str.len(), inplace=True, ascending=True)\n",
    "df_file.reset_index(drop=True, inplace=True)\n",
    "df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_count = word_count_result(df_file, df_file.columns[0:1])  # \"search_string\" column\n",
    "df_check = df_file_count[df_file_count[\"word_count\"] > 1]\n",
    "check_list = df_check[\"word\"].to_list()\n",
    "remove_list = []\n",
    "df_file_var = df_file\n",
    "for var_sent in df_file[\"search_string\"]:\n",
    "    result_list = []\n",
    "    words = re.findall(r\"\\w+\",var_sent, re.UNICODE)\n",
    "    for word in words:\n",
    "        if word in check_list:\n",
    "            result_list.append(True)\n",
    "        else:\n",
    "            result_list.append(False)\n",
    "    if all(result_list):\n",
    "        df_file_var = df_file_var[df_file_var[\"search_string\"] != f\"{var_sent}\"]\n",
    "        df_file_var_count = word_count_result(df_file_var, df_file_var.columns[0:1])\n",
    "        df_check = df_file_var_count[df_file_var_count[\"word_count\"] > 1]\n",
    "        check_list = df_check[\"word\"].to_list()\n",
    "        remove_list.append(var_sent)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "df_file_var.reset_index(drop=True, inplace=True)\n",
    "df_file_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_word_count = word_count_result(df_file_var, df_file.columns[0:1])\n",
    "df_result_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_var.to_excel(f\"{lang_folder.capitalize()}_{word_end}_Word_Group_In_Youtube_Sentence_Word_Index_List_Sample_Selected.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_count = word_count_result(df_file, df_file.columns[0:1])\n",
    "df_file_count.sort_values(by=\"word_count\", ascending=False)\n",
    "df_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_file_count[df_file_count[\"word_count\"] > 2]\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = df_check[\"word\"].to_list()\n",
    "check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_count = word_count_result(df_file, df_file.columns[0:1])  # \"search_string\" column\n",
    "df_check = df_file_count[df_file_count[\"word_count\"] > 2]\n",
    "check_list = df_check[\"word\"].to_list()\n",
    "remove_list = []\n",
    "for var_sent in df_file[\"search_string\"]:\n",
    "    result_list = []\n",
    "    words = re.findall(r\"\\w+\",var_sent, re.UNICODE)\n",
    "    for word in words:\n",
    "        if word in check_list:\n",
    "            result_list.append(True)\n",
    "        else:\n",
    "            result_list.append(False)\n",
    "    if all(result_list):\n",
    "        df_file = df_file[df_file[\"search_string\"] != f\"{var_sent}\"]\n",
    "        df_file_count = word_count_result(df_file, df_file.columns[0:1])\n",
    "        df_check = df_file_count[df_file_count[\"word_count\"] > 2]\n",
    "        check_list = df_check[\"word\"].to_list()\n",
    "        remove_list.append(var_sent)\n",
    "    else:\n",
    "        df_file = df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_result(df_file, df_file.columns[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"aet\",\"Ã¶nce\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test in check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_count = word_count_result(df_file, df_file.columns[0:1])  # \"search_string\" column\n",
    "df_check = df_file_count[df_file_count[\"word_count\"] > 2]\n",
    "check_list = df_check[\"word\"].to_list()\n",
    "i = 0\n",
    "while i < len(df_file):\n",
    "    var_sent in df_file.loc[i,\"search_string\"]\n",
    "    result_list = []\n",
    "    words = re.findall(r\"\\w+\",var_sent, re.UNICODE)\n",
    "    for word in words:\n",
    "        if word in check_list:\n",
    "            result_list.append(True)\n",
    "        else:\n",
    "            result_list.append(False)\n",
    "    if all(result_list):\n",
    "        df_file = df_file[df_file[\"search_string\"] != f\"{var_sent}\"]\n",
    "        df_file_count = word_count_result(df_file, df_file.columns[0:1])\n",
    "        df_check = df_file_count[df_file_count[\"word_count\"] > 1]\n",
    "        check_list = df_check[\"word\"].to_list()\n",
    "    else:\n",
    "        df_file = df_file\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while var_sent in df_file[\"search_string\"]:\n",
    "    print(var_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "for var_sent in df_file[\"search_string\"]:\n",
    "    result_list = []\n",
    "    words = re.findall(r\"\\w+\",var_sent, re.UNICODE)\n",
    "    for word in words:\n",
    "        if word in check_list:\n",
    "            result_list.append(True)\n",
    "        else:\n",
    "            result_list.append(False)\n",
    "    all_list.append(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for j in all_list:\n",
    "    if all(j):\n",
    "        test_list.append(j)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
