{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# native word select for Part 2 \n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 200 # 28  # native word end index\n",
    "\n",
    "# data file parameter\n",
    "file = \"200 Classification\"  # must be excel file\n",
    "sheets = \"Sheet3\"  # \"Sheet3\"\n",
    "start_first_column = 0  # start column location number\n",
    "\n",
    "# classification for Part 1\n",
    "threshold_num = 1\n",
    "\n",
    "# word all usage in sent\n",
    "word_use_num_max = 3\n",
    "word_use_num_min = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Deployment2/Result/6-Youtube Sentence Pos Tag Analysis/{lang_folder.capitalize()}\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(df_word, word_column, sentence):\n",
    "    word_index_list = []\n",
    "    word_index_dict = {var2:var1 for (var1, var2) in enumerate(df_word[f\"{word_column}\"])}\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        value = word_index_dict[f\"{word}\"]\n",
    "        word_index_list.append(value)\n",
    "    return word_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]\n",
    "df_word_select.reset_index(inplace=True)\n",
    "df_word_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sent_result = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment2/Result/\\\n",
    "6-Youtube Sentence Pos Tag Analysis/Deploy Result Manuel/{lang_folder.capitalize()}_200_Word_Group_In_Youtube_Sentence_Word_Index_List_Sample Revised.xlsx\")\n",
    "df_youtube_sent_result.sort_values(by=\"search_string\", key=lambda x:x.str.len(), ascending=True, inplace=True)\n",
    "df_youtube_sent_result.drop([\"word_index\"], axis=1, inplace=True)\n",
    "#df_youtube_sent_result = df_youtube_sent_result.sample(107)\n",
    "df_youtube_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sent_result[\"word_index_list\"] = df_youtube_sent_result[\"search_string\"].apply(lambda sent: word_index(df_word_select, \"word\", sent))\n",
    "df_youtube_sent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sent_select = df_youtube_sent_result[df_youtube_sent_result[\"start_time\"] <= 700]\n",
    "df_youtube_sent_select.reset_index(drop=True, inplace=True)\n",
    "df_youtube_sent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word usage in min max condition\n",
    "word_num_index_dict = {}\n",
    "for i in df_word_select[\"index\"]:\n",
    "    word_num_index_dict[i] = 0\n",
    "\n",
    "result_list = []\n",
    "index_list = []\n",
    "for i in range(len(df_youtube_sent_select)):\n",
    "    search = df_youtube_sent_select.loc[i,\"search_string\"]\n",
    "    start=df_youtube_sent_select.loc[i,\"start_time\"]\n",
    "    end=df_youtube_sent_select.loc[i,\"end_time\"]\n",
    "    sent=df_youtube_sent_select.loc[i,\"sentence\"]\n",
    "    id = df_youtube_sent_select.loc[i,\"video_id\"]\n",
    "    id_url = df_youtube_sent_select.loc[i,\"video_url\"]\n",
    "    word_index = df_youtube_sent_select.loc[i,\"word_index_list\"]\n",
    "    list_var = index_list + word_index\n",
    "    #list_var = index_list + [x for x in word_index]\n",
    "    # word count for max\n",
    "    dict_list_count = Counter(list_var)\n",
    "    count_list = list(dict_list_count.values())\n",
    "     # word count for min\n",
    "    count_list2 = list(word_num_index_dict.values())   \n",
    "\n",
    "    if any([True if i>word_use_num_max else False for i in count_list]) or not(any([True if j<word_use_num_min else False for j in count_list2])):\n",
    "        index_list = index_list\n",
    "    else:\n",
    "        index_list = index_list + word_index\n",
    "        result_list.append([search,start,end,sent,id,id_url,word_index])\n",
    "\n",
    "        for item2 in dict_list_count.items(): \n",
    "            word_num_index_dict[item2[0]] = item2[1]\n",
    "\n",
    "print(f\"Max condition: {any([True if i>word_use_num_max else False for i in count_list2])} \\nMin condition: {any([True if j<word_use_num_min else False for j in count_list2])}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_index = set(index_list)\n",
    "set_all_index = set([x for x in df_word_select[\"index\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_sent = set_all_index.difference(set_index)\n",
    "not_in_sent = list(not_in_sent)\n",
    "not_in_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sent_sample = pd.DataFrame(result_list, columns=[\"search_string\",\"start_time\",\"end_time\",\"sentence\",\"video_id\",\"video_url\",\"word_index_list\"])\n",
    "df_youtube_sent_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_word(index_list, df_word, word_column, reverse=True):\n",
    "    '''\n",
    "    index_to_word(not_in_sent, df_word_select, \"word\", reverse=True)\\n\n",
    "    not in sent is index list as numeric\\n\n",
    "    df_word_select is a dataframe that includes word colunm (\"word\" is a column)\\n\n",
    "    reverse is used for string index list convert numeric.\n",
    "    '''\n",
    "    if reverse:\n",
    "        word_index_dict = {var1:var2 for (var1, var2) in enumerate(df_word[f\"{word_column}\"])}\n",
    "    else:\n",
    "        word_index_dict = {var2:var1 for (var1, var2) in enumerate(df_word[f\"{word_column}\"])}\n",
    "\n",
    "    convert_word_list = []\n",
    "    for index in index_list:\n",
    "        convert_word = word_index_dict[index]\n",
    "        convert_word_list.append(convert_word)\n",
    "    return convert_word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_sent_word = index_to_word(not_in_sent, df_word_select, \"word\", reverse=True)\n",
    "not_in_sent_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_in_sent_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(source_word_list, df_target, target_column, word_sample_num, simple=False):\n",
    "\n",
    "    '''word_in_wordgroup(not_in_sent_word_list, df_youtube_sent_select, \"search_string\", 5, simple=False)\\n\n",
    "       source_word_list is searching word list\\n\n",
    "       df_target is dataframe, target_column are dataframe column string name\\n\n",
    "       word_sample_num is searching sample number.\n",
    "       simple use for all column result or only target column result \n",
    "    '''\n",
    "    if simple:\n",
    "        df_select = df_target[[f\"{target_column}\"]].dropna()\n",
    "    else:\n",
    "        df_select = df_target\n",
    "        \n",
    "    df_result = pd.DataFrame()\n",
    "    for i in source_word_list:\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,\"word\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_sent_selected_word_list_result = word_in_wordgroup(not_in_sent_word, df_youtube_sent_select, \"search_string\", 1, simple=False)\n",
    "not_in_sent_selected_word_list_result = not_in_sent_selected_word_list_result.drop([\"word\"], axis=1)\n",
    "not_in_sent_selected_word_list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_concat = pd.concat([df_youtube_sent_sample, not_in_sent_selected_word_list_result], axis=0)\n",
    "df_result_concat.reset_index(drop=True, inplace=True)\n",
    "df_result_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_word_manuel_count = word_count_result(df_result_concat, df_result_concat.columns[0:1])\n",
    "df_shared_word_manuel_count.sort_values(by=\"word_count\", inplace=True, ascending=False)\n",
    "df_shared_word_manuel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_word = set(df_word_select[\"word\"])\n",
    "set_select_word = set(df_shared_word_manuel_count[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_not_in_select = set_word.difference(set_select_word)\n",
    "set_not_in_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result_concat.to_excel(f\"{lang_folder.capitalize()}_{word_end}_Word_Group_In_Youtube_Sentence_Word_Index_List_Sample.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
