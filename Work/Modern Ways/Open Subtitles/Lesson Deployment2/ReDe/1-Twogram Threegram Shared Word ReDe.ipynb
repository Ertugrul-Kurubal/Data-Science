{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 200  # 28  # native word end index\n",
    "\n",
    "# word sample\n",
    "word_sample = True  # True, False\n",
    "word_sample_num = 20\n",
    "\n",
    "# sentence check\n",
    "sentence_check = True  # True, False\n",
    "#twogram_sentence_check = False  # True, False\n",
    "#threegram_sentence_check = False\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # True for adding prefix suffix word\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = False  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Deployment2/Result/1-Twogram Threegram Shared Analysis/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    '''\n",
    "    remove_repetition(word_group): detect word repetion in word group \n",
    "    '''\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "    df_word = df_word.loc[:,[\"word\",\"frequency\"]]\n",
    "    df_word = pd.concat([df_word,df_word_select], axis=0)\n",
    "    df_word.drop_duplicates(inplace=True)    \n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df_word = df_word_select\n",
    "\n",
    "if native_word:\n",
    "    df_word\n",
    "else:\n",
    "    df_word = df_word.head(0)\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair = pd.read_excel(f\"{lang_pair_list[0]}\")\n",
    "df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "#df_pair = df_pair.head()\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair = pd.merge(df_pair,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair.drop_duplicates(inplace=True)\n",
    "    df_pair.reset_index(drop=True, inplace=True)\n",
    "    df_pair = df_pair.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if etymology_word:\n",
    "    df_pair\n",
    "else:\n",
    "    df_pair = df_pair.head(0)\n",
    "    \n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select = df_word[\"word\"].values.tolist()\n",
    "words = df_pair[\"dict_entry_main\"].values.tolist()\n",
    "word_select_set = set(word_select)\n",
    "disable_word_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_select_set.union(words_set.difference(disable_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 way  Not: 1 way is long and in Shared Word ReDe part \n",
    "data_kind_list = [\"Two\", \"Three\"]\n",
    "for i in data_kind_list:\n",
    "    sent_ngram_file = f\"{i}\" # Two, Three, Four, Five, Sentence\n",
    " \n",
    "    if sent_ngram_file.lower() != \"sentence\":\n",
    "        data_kind = f\"{sent_ngram_file}gram\"  # Twogram, Threegram, Fourgram, Fivegram\n",
    "        folder_path = \"N Gram\"\n",
    "    else:\n",
    "        data_kind = \"sentence\"\n",
    "        folder_path = \"Sentence\"\n",
    "\n",
    "    df = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/{folder_path.capitalize()}/Merge/{data_kind.capitalize()}_Merge.csv\")\n",
    "    d_list  = df.iloc[:,0].values.tolist()\n",
    "\n",
    "    resultlist = []\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup(d_list):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = d_list.split()\n",
    "        except:\n",
    "            word = []\n",
    "            #pass  disabled for non split value\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist.append(d_list)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup, d_list) # string_word liste\n",
    "\n",
    "    result_list = list(resultlist)\n",
    "    df_result = pd.DataFrame(result_list, columns=[0])  # add columns parameter for empty result\n",
    "    df_result = df_result.rename(columns = {0: f\"{data_kind.lower()}\"})\n",
    "    df_merge = pd.merge(df_result, df, how=\"left\", on=f\"{data_kind.lower()}\")\n",
    "    df_merge_result = df_merge.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result.drop_duplicates(inplace=True)\n",
    "    df_merge_result[f\"{data_kind.lower()}\"] = df_merge_result[f\"{data_kind.lower()}\"].apply(lambda x: remove_repetition(x))  # added remove_repetition \n",
    "    df_merge_result = df_merge_result[df_merge_result[f\"{data_kind.lower()}\"] != \"repetitive_word_group\"]  # remove_repetition part\n",
    "    df_merge_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_merge_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_{data_kind.capitalize()}_Result{file_ext}.xlsx\", index=False)\n",
    "\n",
    "    #if sentence_check:\n",
    "    #    df_merge_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_{data_kind.capitalize()}_Sentence{file_ext}.xlsx\", index=False)\n",
    "    #else:\n",
    "    #    df_merge_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_{data_kind.capitalize()}_All{file_ext}.xlsx\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Frequency\n",
    "if shared_word_frequency:\n",
    "    #df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "    df_word = pd.merge(df_word,df_word_all, how=\"inner\", on=\"word\")\n",
    "    df_word.drop_duplicates(inplace=True)\n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_twogram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Result{file_ext}.xlsx\")\n",
    "df_shared_twogram = df_shared_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "df_shared_twogram.rename(columns={\"frequency\":\"freq_twogram\"}, inplace=True)\n",
    "\n",
    "#if sentence_check:\n",
    "#    df_shared_twogram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Sentence{file_ext}.xlsx\")\n",
    "#    df_shared_twogram = df_shared_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "#    df_shared_twogram.rename(columns={\"frequency\":\"freq_twogram\"}, inplace=True)\n",
    "#else:\n",
    "#    df_shared_twogram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_All{file_ext}.xlsx\")\n",
    "#    df_shared_twogram = df_shared_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "#    df_shared_twogram.rename(columns={\"frequency\":\"freq_twogram\"}, inplace=True)\n",
    "\n",
    "df_shared_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Twogram Sentence\n",
    "#if twogram_sentence_check:\n",
    "if sentence_check:\n",
    "    df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_twogram_sent = df_twogram_sent.loc[:,[\"twogram\"]]\n",
    "    df_shared_twogram = pd.merge(df_shared_twogram, df_twogram_sent, how=\"inner\", on=\"twogram\")\n",
    "    df_shared_twogram.drop_duplicates(inplace=True)\n",
    "    df_shared_twogram.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_shared_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_threegram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_Result{file_ext}.xlsx\")\n",
    "df_shared_threegram = df_shared_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "df_shared_threegram.rename(columns={\"frequency\":\"freq_threegram\"}, inplace=True)\n",
    "\n",
    "\n",
    "#if sentence_check:\n",
    "#    df_shared_threegram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_Sentence{file_ext}.xlsx\")\n",
    "#    df_shared_threegram = df_shared_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "#    df_shared_threegram.rename(columns={\"frequency\":\"freq_threegram\"}, inplace=True)\n",
    "#else:\n",
    "#    df_shared_threegram = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_All{file_ext}.xlsx\")\n",
    "#    df_shared_threegram = df_shared_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "#    df_shared_threegram.rename(columns={\"frequency\":\"freq_threegram\"}, inplace=True)\n",
    "\n",
    "df_shared_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Threegram Sentence\n",
    "#if threegram_sentence_check:\n",
    "if sentence_check:\n",
    "    df_threegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Three_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_threegram_sent.rename(columns={\"three_gram\":\"threegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_threegram_sent = df_threegram_sent.loc[:,[\"threegram\"]]\n",
    "    df_shared_threegram = pd.merge(df_shared_threegram, df_threegram_sent, how=\"inner\", on=\"threegram\")\n",
    "    df_shared_threegram.drop_duplicates(inplace=True)\n",
    "    df_shared_threegram.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_shared_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_all = pd.concat([df_word, df_shared_twogram, df_shared_threegram], axis=1)\n",
    "df_shared_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Output\n",
    "#if sentence_check:\n",
    "#    df_shared_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_Sentence_Result_With_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_shared_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Sentence_Result_With_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_shared_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_Sentence_Result_With_Frequency{file_ext}.xlsx\", index=False)\n",
    "#else:\n",
    "#    df_shared_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_All_Result_With_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_shared_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_All_Result_With_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_shared_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_All_Result_With_Frequency{file_ext}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concat Result With Comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\******\n",
    "df_word_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "df_word_prefix_suffix = df_word_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_word_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ety_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "df_ety_prefix_suffix = df_ety_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_ety_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_ext == \"1\":\n",
    "    df_word_not_prefix_suffix = df_word_all\n",
    "    df_word_not_prefix_suffix[\"search_word\"] = df_word_all[\"word\"]\n",
    "    df_word_not_prefix_suffix = df_word_not_prefix_suffix[\"search_word\",\"word\"]\n",
    "    \n",
    "    df_ety_not_prefix_suffix = df_pair\n",
    "    df_ety_not_prefix_suffix = df_ety_not_prefix_suffix.rename(columns={\"dict_entry_main\":\"word\"})\n",
    "    df_ety_not_prefix_suffix[\"search_word\"] = df_ety_not_prefix_suffix[\"word\"]\n",
    "    df_ety_not_prefix_suffix = df_ety_not_prefix_suffix[\"search_word\",\"word\"]\n",
    "    \n",
    "    df_all_word = pd.concat([df_word_not_prefix_suffix,df_ety_not_prefix_suffix],axis=0)\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"2\":\n",
    "    df_ety_not_prefix_suffix = df_pair\n",
    "    df_ety_not_prefix_suffix = df_ety_not_prefix_suffix.rename(columns={\"dict_entry_main\":\"word\"})\n",
    "    df_ety_not_prefix_suffix[\"search_word\"] = df_ety_not_prefix_suffix[\"word\"]\n",
    "    df_ety_not_prefix_suffix = df_ety_not_prefix_suffix[\"search_word\",\"word\"]\n",
    "\n",
    "    df_all_word = df_ety_not_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"3\":\n",
    "    df_all_word = pd.concat([df_word_prefix_suffix,df_ety_prefix_suffix],axis=0)\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"4\":\n",
    "    df_all_word = df_ety_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"5\":\n",
    "    df_all_word = df_word_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"6\":\n",
    "    df_word_not_prefix_suffix = df_word_all\n",
    "    df_word_not_prefix_suffix[\"search_word\"] = df_word_all[\"word\"]\n",
    "    df_word_not_prefix_suffix = df_word_not_prefix_suffix[\"search_word\",\"word\"]\n",
    "\n",
    "    df_all_word = df_word_not_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "df_all_word\n",
    "# /******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, source_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            if word_sample:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)  # Option\n",
    "            else:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_all, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_all, \"word\", \"threegram\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\*****\n",
    "df_word_order_twogram = pd.merge(df_word_order_twogram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_threegram = pd.merge(df_word_order_threegram,df_all_word, how=\"inner\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"search_word\"])[\"twogram\"].apply(\", \".join).reset_index()  \n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"search_word\"])[\"threegram\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['search_word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all.rename(columns={\"search_word\":\"word\"}, inplace=True)\n",
    "df_word_order_join_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option For Word Frequency\n",
    "#if shared_word_frequency:\n",
    "#    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "#    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "#    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\"]]\n",
    "#    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "#    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "#else:\n",
    "#    pass\n",
    "#\n",
    "#df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\"]]\n",
    "df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip_func(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = df_word_all.loc[:,[\"word\",\"frequency\"]]\n",
    "df_word_all[\"word\"] = df_word_all[\"word\"].apply(lambda x: lower_strip_func(x))\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_all = df_twogram_all.loc[:,[\"twogram\",\"frequency\"]]\n",
    "df_twogram_all[\"twogram\"] = df_twogram_all[\"twogram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_twogram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")\n",
    "df_threegram_all = df_threegram_all.loc[:,[\"threegram\",\"frequency\"]]\n",
    "df_threegram_all[\"threegram\"] = df_threegram_all[\"threegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_threegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all = df_word_order_join_all\n",
    "for i in range(len(df_shared_process_all)):\n",
    "    # column result\n",
    "    try:\n",
    "        # column result\n",
    "        df_two_var = pd.DataFrame(df_shared_process_all.loc[i,\"twogram\"].split(\", \"), columns=[\"twogram\"])\n",
    "        # merge with all\n",
    "        df_two_var_merge = pd.merge(df_two_var, df_twogram_all, how=\"left\", on=\"twogram\")\n",
    "        df_two_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_two_var_merge_select = df_two_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_two_var_list = df_two_var_merge_select[\"twogram\"].to_list()\n",
    "        # list join\n",
    "        df_two_var_list_join = \", \".join(df_two_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"twogram\"] = df_two_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_three_var = pd.DataFrame(df_shared_process_all.loc[i,\"threegram\"].split(\", \"), columns=[\"threegram\"])\n",
    "        # merge with all\n",
    "        df_three_var_merge = pd.merge(df_three_var, df_threegram_all, how=\"left\", on=\"threegram\")\n",
    "        df_three_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_three_var_merge_select = df_three_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_three_var_list = df_three_var_merge_select[\"threegram\"].to_list()\n",
    "        # list join\n",
    "        df_three_var_list_join = \", \".join(df_three_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"threegram\"] = df_three_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_shared_process_all\n",
    "# /****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_shared_process_all[[\"word\",\"frequency\",\"twogram\"]]\n",
    "df_word_order_join_threegram = df_shared_process_all[[\"word\",\"frequency\",\"threegram\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sentence_check:\n",
    "    df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "    df_word_order_join_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "    df_word_order_join_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "else:\n",
    "    df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "    df_word_order_join_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "    df_word_order_join_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_order_join_twogram = df_word_order_twogram.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "#df_word_order_join_threegram = df_word_order_threegram.groupby([\"word\"])[\"threegram\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [df_word_order_join_twogram,df_word_order_join_threegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "##df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "#df_word_order_join_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option For Word Frequency\n",
    "#if shared_word_frequency:\n",
    "#    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "#    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "#    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\"]]\n",
    "#    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "#    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "#\n",
    "#    df_word_order_join_twogram = pd.merge(df_word_order_join_twogram,df_word_all, how=\"inner\", on=\"word\")\n",
    "#    df_word_order_join_twogram.drop_duplicates(inplace=True)\n",
    "#    df_word_order_join_twogram = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\"]]\n",
    "#    df_word_order_join_twogram.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "#    df_word_order_join_twogram.reset_index(drop=True, inplace=True)\n",
    "#\n",
    "#    df_word_order_join_threegram = pd.merge(df_word_order_join_threegram,df_word_all, how=\"inner\", on=\"word\")\n",
    "#    df_word_order_join_threegram.drop_duplicates(inplace=True)\n",
    "#    df_word_order_join_threegram = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"threegram\"]]\n",
    "#    df_word_order_join_threegram.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "#    df_word_order_join_threegram.reset_index(drop=True, inplace=True)\n",
    "#else:\n",
    "#    pass\n",
    "#\n",
    "#df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_order_join_all.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if sentence_check:\n",
    "#    df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_word_order_join_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_word_order_join_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_Sentence_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "#else:\n",
    "#    df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_Threegram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_word_order_join_twogram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Twogram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)\n",
    "#    df_word_order_join_threegram.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Threegram_All_Join_Result_Without_Frequency{file_ext}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    #destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
