{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Word File Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# language pair\n",
    "lang_folder = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # always must be False in this part\n",
    "native_word = True # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twogram In Threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552149</th>\n",
       "      <td>fruitcocktail</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552150</th>\n",
       "      <td>andthesunlightshining</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552151</th>\n",
       "      <td>upravo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552152</th>\n",
       "      <td>yagawa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552153</th>\n",
       "      <td>foxtrotoscar</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552154 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  frequency\n",
       "0                         you  102069964\n",
       "1                           i   94447074\n",
       "2                         the   77481215\n",
       "3                          to   58281119\n",
       "4                          is   50852895\n",
       "...                       ...        ...\n",
       "552149          fruitcocktail          6\n",
       "552150  andthesunlightshining          6\n",
       "552151                 upravo          6\n",
       "552152                 yagawa          6\n",
       "552153           foxtrotoscar          6\n",
       "\n",
       "[552154 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0    i am    10494331.0             i do not   \n",
       "1         i   94447074.0  do not     8972296.0             i am not   \n",
       "2       the   77481215.0    i do     4179914.0          what do you   \n",
       "3        to   58281119.0  i will     3706224.0           you do not   \n",
       "4        is   50852895.0  do you     3358227.0           do not you   \n",
       "...     ...          ...     ...           ...                  ...   \n",
       "206638  NaN          NaN     NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN     NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN     NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN     NaN           NaN         cup will not   \n",
       "206642  NaN          NaN     NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence  \n",
       "0            107450.0   of course       266277.0  \n",
       "1             34568.0  what is it       251203.0  \n",
       "2             21572.0     stop it       152280.0  \n",
       "3             21499.0        i am       136931.0  \n",
       "4             18564.0        i do       114801.0  \n",
       "...               ...         ...            ...  \n",
       "206638            NaN         NaN            NaN  \n",
       "206639            NaN         NaN            NaN  \n",
       "206640            NaN         NaN            NaN  \n",
       "206641            NaN         NaN            NaN  \n",
       "206642            NaN         NaN            NaN  \n",
       "\n",
       "[206643 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_file = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            #word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(10)  # Option\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(100) \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{list_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_count = word_count_result(df_shared_file,[\"threegram\"])\n",
    "#df_shared_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_file[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am</td>\n",
       "      <td>no i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am</td>\n",
       "      <td>what i am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am</td>\n",
       "      <td>i am the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334913</th>\n",
       "      <td>champion puzzle</td>\n",
       "      <td>a champion puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334914</th>\n",
       "      <td>quality material</td>\n",
       "      <td>was quality material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334915</th>\n",
       "      <td>quality mask</td>\n",
       "      <td>a quality mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334916</th>\n",
       "      <td>quality index</td>\n",
       "      <td>quality index is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334917</th>\n",
       "      <td>classical department</td>\n",
       "      <td>the classical department</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334918 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     twogram                 threegram\n",
       "0                       i am                  i am not\n",
       "1                       i am                    i am a\n",
       "2                       i am                   no i am\n",
       "3                       i am                 what i am\n",
       "4                       i am                  i am the\n",
       "...                      ...                       ...\n",
       "334913       champion puzzle         a champion puzzle\n",
       "334914      quality material      was quality material\n",
       "334915          quality mask            a quality mask\n",
       "334916         quality index          quality index is\n",
       "334917  classical department  the classical department\n",
       "\n",
       "[334918 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three = word_in_wordgroup(df_shared_file, \"twogram\", \"threegram\")\n",
    "df_two_in_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60870"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three[\"twogram\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       twogram  freq_twogram\n",
       "0         i am    10494331.0\n",
       "1       do not     8972296.0\n",
       "2         i do     4179914.0\n",
       "3       i will     3706224.0\n",
       "4       do you     3358227.0\n",
       "...        ...           ...\n",
       "206638     NaN           NaN\n",
       "206639     NaN           NaN\n",
       "206640     NaN           NaN\n",
       "206641     NaN           NaN\n",
       "206642     NaN           NaN\n",
       "\n",
       "[206643 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_select_twogram = df_shared_file.loc[:,[\"twogram\",\"freq_twogram\"]]\n",
    "df_shared_select_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_shared_twogram = set(df_shared_select_twogram[\"twogram\"])\n",
    "set_two_three = set(df_two_in_three[\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hologram is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realism do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corner depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>social plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>bouquet the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>cafe we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>training baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>unit hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                twogram\n",
       "0           your screen\n",
       "1           hologram is\n",
       "2         action august\n",
       "3            realism do\n",
       "4      corner depressed\n",
       "...                 ...\n",
       "60865       social plan\n",
       "60866       bouquet the\n",
       "60867           cafe we\n",
       "60868     training baby\n",
       "60869          unit hit\n",
       "\n",
       "[60870 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram = pd.DataFrame(set_two_three, columns=[\"twogram\"])  # columns=[\"twogram_in_threegram\"]\n",
    "df_twogram_in_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60865</th>\n",
       "      <td>lift music</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60866</th>\n",
       "      <td>counter no</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60867</th>\n",
       "      <td>system design</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60868</th>\n",
       "      <td>have champion</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60869</th>\n",
       "      <td>frequency active</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twogram_in_threegram  freq_two_in_three\n",
       "0                     i am         10494331.0\n",
       "1                   do not          8972296.0\n",
       "2                     i do          4179914.0\n",
       "3                   i will          3706224.0\n",
       "4                   do you          3358227.0\n",
       "...                    ...                ...\n",
       "60865           lift music                4.0\n",
       "60866           counter no                4.0\n",
       "60867        system design                4.0\n",
       "60868        have champion                4.0\n",
       "60869     frequency active                4.0\n",
       "\n",
       "[60870 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_in_threegram_freq = pd.merge(df_twogram_in_threegram, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_in_threegram_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_in_threegram_freq.rename(columns={\"twogram\":\"twogram_in_threegram\",\"freq_twogram\":\"freq_two_in_three\"}, inplace=True)\n",
    "df_twogram_in_threegram_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_in_threegram_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anonymous sponsor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diet chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>subsidy to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>shot type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17487</th>\n",
       "      <td>captain post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17488</th>\n",
       "      <td>it initiative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>miniature control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17490 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 twogram\n",
       "0                    NaN\n",
       "1      anonymous sponsor\n",
       "2             diet chips\n",
       "3       complete protein\n",
       "4        university hall\n",
       "...                  ...\n",
       "17485         subsidy to\n",
       "17486          shot type\n",
       "17487       captain post\n",
       "17488      it initiative\n",
       "17489  miniature control\n",
       "\n",
       "[17490 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff = pd.DataFrame(set_shared_twogram.difference(set_two_three), columns=[\"twogram\"])\n",
    "df_twogram_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145768</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145773 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               twogram  freq_twogram\n",
       "0          media group        4604.0\n",
       "1        hello sheriff         501.0\n",
       "2           hello mark         457.0\n",
       "3       hello princess         433.0\n",
       "4        hello general         398.0\n",
       "...                ...           ...\n",
       "145768             NaN           NaN\n",
       "145769             NaN           NaN\n",
       "145770             NaN           NaN\n",
       "145771             NaN           NaN\n",
       "145772             NaN           NaN\n",
       "\n",
       "[145773 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_diff_freq = pd.merge(df_twogram_diff, df_shared_select_twogram, how=\"left\", on=\"twogram\")\n",
    "df_twogram_diff_freq.sort_values(by=\"freq_twogram\", ascending=False, inplace=True)\n",
    "df_twogram_diff_freq.reset_index(drop=True, inplace=True)\n",
    "df_twogram_diff_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_file[\"twogram\"] = df_twogram_diff_freq[\"twogram\"]\n",
    "df_shared_file[\"freq_twogram\"] = df_twogram_diff_freq[\"freq_twogram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>freq_threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>freq_fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>freq_fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>freq_sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "      <th>freq_two_in_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>media group</td>\n",
       "      <td>4604.0</td>\n",
       "      <td>i do not</td>\n",
       "      <td>3520257</td>\n",
       "      <td>you do not have</td>\n",
       "      <td>160426.0</td>\n",
       "      <td>you do not have to</td>\n",
       "      <td>107450.0</td>\n",
       "      <td>of course</td>\n",
       "      <td>266277.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>10494331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>hello sheriff</td>\n",
       "      <td>501.0</td>\n",
       "      <td>i am not</td>\n",
       "      <td>1262941</td>\n",
       "      <td>i do not have</td>\n",
       "      <td>158788.0</td>\n",
       "      <td>i do not have a</td>\n",
       "      <td>34568.0</td>\n",
       "      <td>what is it</td>\n",
       "      <td>251203.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>8972296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>hello mark</td>\n",
       "      <td>457.0</td>\n",
       "      <td>what do you</td>\n",
       "      <td>1120086</td>\n",
       "      <td>do not have to</td>\n",
       "      <td>150328.0</td>\n",
       "      <td>do not have to do</td>\n",
       "      <td>21572.0</td>\n",
       "      <td>stop it</td>\n",
       "      <td>152280.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>4179914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>hello princess</td>\n",
       "      <td>433.0</td>\n",
       "      <td>you do not</td>\n",
       "      <td>1010676</td>\n",
       "      <td>no i do not</td>\n",
       "      <td>105374.0</td>\n",
       "      <td>i do not have to</td>\n",
       "      <td>21499.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "      <td>i will</td>\n",
       "      <td>3706224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>hello general</td>\n",
       "      <td>398.0</td>\n",
       "      <td>do not you</td>\n",
       "      <td>644488</td>\n",
       "      <td>i do not like</td>\n",
       "      <td>99318.0</td>\n",
       "      <td>i do not like it</td>\n",
       "      <td>18564.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "      <td>do you</td>\n",
       "      <td>3358227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i control radiation</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the antibiotic i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my radar screen</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cup will not</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop on no</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206643 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    frequency         twogram  freq_twogram            threegram  \\\n",
       "0       you  102069964.0     media group        4604.0             i do not   \n",
       "1         i   94447074.0   hello sheriff         501.0             i am not   \n",
       "2       the   77481215.0      hello mark         457.0          what do you   \n",
       "3        to   58281119.0  hello princess         433.0           you do not   \n",
       "4        is   50852895.0   hello general         398.0           do not you   \n",
       "...     ...          ...             ...           ...                  ...   \n",
       "206638  NaN          NaN             NaN           NaN  i control radiation   \n",
       "206639  NaN          NaN             NaN           NaN     the antibiotic i   \n",
       "206640  NaN          NaN             NaN           NaN      my radar screen   \n",
       "206641  NaN          NaN             NaN           NaN         cup will not   \n",
       "206642  NaN          NaN             NaN           NaN           stop on no   \n",
       "\n",
       "        freq_threegram         fourgram  freq_fourgram            fivegram  \\\n",
       "0              3520257  you do not have       160426.0  you do not have to   \n",
       "1              1262941    i do not have       158788.0     i do not have a   \n",
       "2              1120086   do not have to       150328.0   do not have to do   \n",
       "3              1010676      no i do not       105374.0    i do not have to   \n",
       "4               644488    i do not like        99318.0    i do not like it   \n",
       "...                ...              ...            ...                 ...   \n",
       "206638               4              NaN            NaN                 NaN   \n",
       "206639               4              NaN            NaN                 NaN   \n",
       "206640               4              NaN            NaN                 NaN   \n",
       "206641               4              NaN            NaN                 NaN   \n",
       "206642               4              NaN            NaN                 NaN   \n",
       "\n",
       "        freq_fivegram    sentence  freq_sentence twogram_in_threegram  \\\n",
       "0            107450.0   of course       266277.0                 i am   \n",
       "1             34568.0  what is it       251203.0               do not   \n",
       "2             21572.0     stop it       152280.0                 i do   \n",
       "3             21499.0        i am       136931.0               i will   \n",
       "4             18564.0        i do       114801.0               do you   \n",
       "...               ...         ...            ...                  ...   \n",
       "206638            NaN         NaN            NaN                  NaN   \n",
       "206639            NaN         NaN            NaN                  NaN   \n",
       "206640            NaN         NaN            NaN                  NaN   \n",
       "206641            NaN         NaN            NaN                  NaN   \n",
       "206642            NaN         NaN            NaN                  NaN   \n",
       "\n",
       "        freq_two_in_three  \n",
       "0              10494331.0  \n",
       "1               8972296.0  \n",
       "2               4179914.0  \n",
       "3               3706224.0  \n",
       "4               3358227.0  \n",
       "...                   ...  \n",
       "206638                NaN  \n",
       "206639                NaN  \n",
       "206640                NaN  \n",
       "206641                NaN  \n",
       "206642                NaN  \n",
       "\n",
       "[206643 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shared_twogram_process = pd.concat([df_shared_file,df_twogram_in_threegram_freq], axis=1)\n",
    "df_shared_twogram_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_twogram_process.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concat Result With Comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_twogram_process, \"word\", \"sentence\")\n",
    "df_word_order_twogram_threegram = word_in_wordgroup(df_shared_twogram_process, \"word\", \"twogram_in_threegram\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"word\"])[\"sentence\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_twogram_threegram = df_word_order_twogram_threegram.groupby([\"word\"])[\"twogram_in_threegram\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence,df_word_order_join_twogram_threegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>agent a, a terrorism, solo a, a tribune, mummy...</td>\n",
       "      <td>i am a, i have a, this is a, you have a, it wa...</td>\n",
       "      <td>i am not a, do not have a, do you have a, this...</td>\n",
       "      <td>i do not have a, you do not have a, we do not ...</td>\n",
       "      <td>a what, not a chance, what a surprise, i am a ...</td>\n",
       "      <td>have a, is a, was a, for a, in a, not a, like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>your abacus, abacus and, abacus of, my abacus</td>\n",
       "      <td>like the abacus, abacus to the, and the abacus...</td>\n",
       "      <td>i like the abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and the abacus, my abacus</td>\n",
       "      <td>the abacus, abacus to, abacus is, abacus you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>on abnormal, this abnormal, for abnormal, you ...</td>\n",
       "      <td>i am abnormal, in the abnormal, am i abnormal,...</td>\n",
       "      <td>contact in the abnormal, and you have abnormal...</td>\n",
       "      <td>we have on the abnormal, the reaction to the a...</td>\n",
       "      <td>abnormal psychology, i am abnormal, am i abnor...</td>\n",
       "      <td>the abnormal, no abnormal, abnormal psychology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absorb</td>\n",
       "      <td>i absorb, absorb shock</td>\n",
       "      <td>to absorb the, will absorb the, and absorb it,...</td>\n",
       "      <td>it and absorb it, will absorb the radiation, t...</td>\n",
       "      <td>that will absorb the radiation, the ocean will...</td>\n",
       "      <td>absorb it, to absorb, i absorb, absorb this in...</td>\n",
       "      <td>to absorb, absorb the, absorb it, will absorb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>absurd it, absurd you, what absurd, you absurd...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>absurd is not it, absurd your position is, you...</td>\n",
       "      <td>is it not absurd to, absurd name for a cricket...</td>\n",
       "      <td>this is absurd, that is absurd, it is absurd, ...</td>\n",
       "      <td>is absurd, absurd to, the absurd, this absurd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>provoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not provoke, not provoke me, to provoke me,...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not yo...</td>\n",
       "      <td>you do do not provoke, do not you provoke me, ...</td>\n",
       "      <td>do not provoke me, i do not provoke, do not pr...</td>\n",
       "      <td>to provoke, not provoke, provoke me, you provo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>quadrillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion electron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a quadrillion</td>\n",
       "      <td>a quadrillion, quadrillion electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>retouch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do not retouch, will retouch it, to retouch it...</td>\n",
       "      <td>we do not retouch, we will retouch it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retouch it, not retouch, will retouch, to retouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>sympathizer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>me a sympathizer, a communist sympathizer, is ...</td>\n",
       "      <td>am a communist sympathizer, brother was a symp...</td>\n",
       "      <td>i am a communist sympathizer, your brother was...</td>\n",
       "      <td>communist sympathizer, a sympathizer, i am a c...</td>\n",
       "      <td>a sympathizer, communist sympathizer, sympathi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex toilet, you have unisex, it was unise...</td>\n",
       "      <td>me it was unisex, this is a unisex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a unisex, a unisex toilet</td>\n",
       "      <td>a unisex, unisex toilet, have unisex, was unis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                            twogram  \\\n",
       "0               a  agent a, a terrorism, solo a, a tribune, mummy...   \n",
       "1          abacus      your abacus, abacus and, abacus of, my abacus   \n",
       "2        abnormal  on abnormal, this abnormal, for abnormal, you ...   \n",
       "3          absorb                             i absorb, absorb shock   \n",
       "4          absurd  absurd it, absurd you, what absurd, you absurd...   \n",
       "...           ...                                                ...   \n",
       "1695      provoke                                                NaN   \n",
       "1696  quadrillion                                                NaN   \n",
       "1697      retouch                                                NaN   \n",
       "1698  sympathizer                                                NaN   \n",
       "1699       unisex                                                NaN   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     i am a, i have a, this is a, you have a, it wa...   \n",
       "1     like the abacus, abacus to the, and the abacus...   \n",
       "2     i am abnormal, in the abnormal, am i abnormal,...   \n",
       "3     to absorb the, will absorb the, and absorb it,...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke, not provoke me, to provoke me,...   \n",
       "1696                             a quadrillion electron   \n",
       "1697  do not retouch, will retouch it, to retouch it...   \n",
       "1698  me a sympathizer, a communist sympathizer, is ...   \n",
       "1699  a unisex toilet, you have unisex, it was unise...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     i am not a, do not have a, do you have a, this...   \n",
       "1                                     i like the abacus   \n",
       "2     contact in the abnormal, and you have abnormal...   \n",
       "3     it and absorb it, will absorb the radiation, t...   \n",
       "4     absurd is not it, absurd your position is, you...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not yo...   \n",
       "1696                                                NaN   \n",
       "1697              we do not retouch, we will retouch it   \n",
       "1698  am a communist sympathizer, brother was a symp...   \n",
       "1699                 me it was unisex, this is a unisex   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     i do not have a, you do not have a, we do not ...   \n",
       "1                                                   NaN   \n",
       "2     we have on the abnormal, the reaction to the a...   \n",
       "3     that will absorb the radiation, the ocean will...   \n",
       "4     is it not absurd to, absurd name for a cricket...   \n",
       "...                                                 ...   \n",
       "1695  you do do not provoke, do not you provoke me, ...   \n",
       "1696                                                NaN   \n",
       "1697                                                NaN   \n",
       "1698  i am a communist sympathizer, your brother was...   \n",
       "1699                                                NaN   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     a what, not a chance, what a surprise, i am a ...   \n",
       "1                             and the abacus, my abacus   \n",
       "2     abnormal psychology, i am abnormal, am i abnor...   \n",
       "3     absorb it, to absorb, i absorb, absorb this in...   \n",
       "4     this is absurd, that is absurd, it is absurd, ...   \n",
       "...                                                 ...   \n",
       "1695  do not provoke me, i do not provoke, do not pr...   \n",
       "1696                                      a quadrillion   \n",
       "1697                                                NaN   \n",
       "1698  communist sympathizer, a sympathizer, i am a c...   \n",
       "1699                          a unisex, a unisex toilet   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     have a, is a, was a, for a, in a, not a, like ...  \n",
       "1     the abacus, abacus to, abacus is, abacus you, ...  \n",
       "2     the abnormal, no abnormal, abnormal psychology...  \n",
       "3     to absorb, absorb the, absorb it, will absorb,...  \n",
       "4     is absurd, absurd to, the absurd, this absurd,...  \n",
       "...                                                 ...  \n",
       "1695  to provoke, not provoke, provoke me, you provo...  \n",
       "1696                a quadrillion, quadrillion electron  \n",
       "1697  retouch it, not retouch, will retouch, to retouch  \n",
       "1698  a sympathizer, communist sympathizer, sympathi...  \n",
       "1699  a unisex, unisex toilet, have unisex, was unis...  \n",
       "\n",
       "[1700 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "      <th>fourgram</th>\n",
       "      <th>fivegram</th>\n",
       "      <th>sentence</th>\n",
       "      <th>twogram_in_threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "      <td>you korean, specific you, cypher you, you comm...</td>\n",
       "      <td>what do you, you do not, do not you, you have ...</td>\n",
       "      <td>you do not have, do you have a, no you do not,...</td>\n",
       "      <td>you do not have to, you do not have a, you do ...</td>\n",
       "      <td>and you, do you, you do, no you do not, you do...</td>\n",
       "      <td>do you, you have, you do, not you, you will, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "      <td>anonymous i, i absorb, i contract, i wow, dies...</td>\n",
       "      <td>i do not, i am not, i am a, i have to, i will ...</td>\n",
       "      <td>i do not have, no i do not, i do not like, i a...</td>\n",
       "      <td>i do not have a, i do not have to, i do not li...</td>\n",
       "      <td>i am, i do, i will, i do not, i am not, no i d...</td>\n",
       "      <td>i am, i do, i will, i have, i was, and i, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "      <td>the idealist, fantastic the, sophisticated the...</td>\n",
       "      <td>this is the, i am the, out of the, it was the,...</td>\n",
       "      <td>i am in the, i am not the, this is not the, do...</td>\n",
       "      <td>i do not have the, i do not like the, i am not...</td>\n",
       "      <td>what the, the what, the police, the baby, the ...</td>\n",
       "      <td>in the, to the, on the, of the, what the, for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "      <td>to booster, to princess, to formula, to capaci...</td>\n",
       "      <td>i have to, you have to, we have to, not have t...</td>\n",
       "      <td>do not have to, you will have to, do i have to...</td>\n",
       "      <td>you do not have to, do not have to do, i do no...</td>\n",
       "      <td>i have to, you do not have to, you have to, to...</td>\n",
       "      <td>have to, to the, to me, to do, to you, you to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "      <td>is simultaneous, is feminine, is bourgeois, tu...</td>\n",
       "      <td>what is it, this is not, this is a, this is th...</td>\n",
       "      <td>this is not a, is that what you, this is not t...</td>\n",
       "      <td>you have to do is, is not that what you, is th...</td>\n",
       "      <td>what is it, what is this, what is that, it is,...</td>\n",
       "      <td>this is, is not, is it, what is, is that, it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>camp</td>\n",
       "      <td>6</td>\n",
       "      <td>captain camp, camp zombie, camp doctor, camp e...</td>\n",
       "      <td>in the camp, to the camp, we will camp, in thi...</td>\n",
       "      <td>this is base camp, me to the camp, the camp wa...</td>\n",
       "      <td>this for a band camp, this is a training camp,...</td>\n",
       "      <td>the camp, base camp, what camp, a camp, in the...</td>\n",
       "      <td>the camp, to camp, base camp, this camp, camp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>session</td>\n",
       "      <td>6</td>\n",
       "      <td>practice session, detector session, session a,...</td>\n",
       "      <td>is in session, the session is, have a session,...</td>\n",
       "      <td>a group therapy session, congress is in sessio...</td>\n",
       "      <td>the meeting is in session, in a group therapy ...</td>\n",
       "      <td>i am in session, school is in session, this is...</td>\n",
       "      <td>in session, a session, the session, this sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>captain</td>\n",
       "      <td>6</td>\n",
       "      <td>captain axis, captain camp, control captain, c...</td>\n",
       "      <td>this is captain, i am captain, is the captain,...</td>\n",
       "      <td>this is the captain, i am the captain, this is...</td>\n",
       "      <td>i am the captain of, captain of the football t...</td>\n",
       "      <td>this is the captain, the captain, no captain, ...</td>\n",
       "      <td>the captain, you captain, captain i, is captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>have</td>\n",
       "      <td>6</td>\n",
       "      <td>have name, have depressed, have tank, caps hav...</td>\n",
       "      <td>do not have, i have to, you have to, i have a,...</td>\n",
       "      <td>you do not have, i do not have, do not have to...</td>\n",
       "      <td>you do not have to, i do not have a, do not ha...</td>\n",
       "      <td>i have, have you, i have to, you do not have t...</td>\n",
       "      <td>i have, you have, have to, we have, have a, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>point</td>\n",
       "      <td>6</td>\n",
       "      <td>point bar, million point, out point, point cap...</td>\n",
       "      <td>not the point, the point is, to the point, the...</td>\n",
       "      <td>what is the point, you have a point, is not th...</td>\n",
       "      <td>that is not the point, what is the point of, i...</td>\n",
       "      <td>the point is, no point, your point, what is th...</td>\n",
       "      <td>the point, a point, your point, point is, poin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency                                            twogram  \\\n",
       "0         you  102069964  you korean, specific you, cypher you, you comm...   \n",
       "1           i   94447074  anonymous i, i absorb, i contract, i wow, dies...   \n",
       "2         the   77481215  the idealist, fantastic the, sophisticated the...   \n",
       "3          to   58281119  to booster, to princess, to formula, to capaci...   \n",
       "4          is   50852895  is simultaneous, is feminine, is bourgeois, tu...   \n",
       "...       ...        ...                                                ...   \n",
       "2299     camp          6  captain camp, camp zombie, camp doctor, camp e...   \n",
       "2300  session          6  practice session, detector session, session a,...   \n",
       "2301  captain          6  captain axis, captain camp, control captain, c...   \n",
       "2302     have          6  have name, have depressed, have tank, caps hav...   \n",
       "2303    point          6  point bar, million point, out point, point cap...   \n",
       "\n",
       "                                              threegram  \\\n",
       "0     what do you, you do not, do not you, you have ...   \n",
       "1     i do not, i am not, i am a, i have to, i will ...   \n",
       "2     this is the, i am the, out of the, it was the,...   \n",
       "3     i have to, you have to, we have to, not have t...   \n",
       "4     what is it, this is not, this is a, this is th...   \n",
       "...                                                 ...   \n",
       "2299  in the camp, to the camp, we will camp, in thi...   \n",
       "2300  is in session, the session is, have a session,...   \n",
       "2301  this is captain, i am captain, is the captain,...   \n",
       "2302  do not have, i have to, you have to, i have a,...   \n",
       "2303  not the point, the point is, to the point, the...   \n",
       "\n",
       "                                               fourgram  \\\n",
       "0     you do not have, do you have a, no you do not,...   \n",
       "1     i do not have, no i do not, i do not like, i a...   \n",
       "2     i am in the, i am not the, this is not the, do...   \n",
       "3     do not have to, you will have to, do i have to...   \n",
       "4     this is not a, is that what you, this is not t...   \n",
       "...                                                 ...   \n",
       "2299  this is base camp, me to the camp, the camp wa...   \n",
       "2300  a group therapy session, congress is in sessio...   \n",
       "2301  this is the captain, i am the captain, this is...   \n",
       "2302  you do not have, i do not have, do not have to...   \n",
       "2303  what is the point, you have a point, is not th...   \n",
       "\n",
       "                                               fivegram  \\\n",
       "0     you do not have to, you do not have a, you do ...   \n",
       "1     i do not have a, i do not have to, i do not li...   \n",
       "2     i do not have the, i do not like the, i am not...   \n",
       "3     you do not have to, do not have to do, i do no...   \n",
       "4     you have to do is, is not that what you, is th...   \n",
       "...                                                 ...   \n",
       "2299  this for a band camp, this is a training camp,...   \n",
       "2300  the meeting is in session, in a group therapy ...   \n",
       "2301  i am the captain of, captain of the football t...   \n",
       "2302  you do not have to, i do not have a, do not ha...   \n",
       "2303  that is not the point, what is the point of, i...   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     and you, do you, you do, no you do not, you do...   \n",
       "1     i am, i do, i will, i do not, i am not, no i d...   \n",
       "2     what the, the what, the police, the baby, the ...   \n",
       "3     i have to, you do not have to, you have to, to...   \n",
       "4     what is it, what is this, what is that, it is,...   \n",
       "...                                                 ...   \n",
       "2299  the camp, base camp, what camp, a camp, in the...   \n",
       "2300  i am in session, school is in session, this is...   \n",
       "2301  this is the captain, the captain, no captain, ...   \n",
       "2302  i have, have you, i have to, you do not have t...   \n",
       "2303  the point is, no point, your point, what is th...   \n",
       "\n",
       "                                   twogram_in_threegram  \n",
       "0     do you, you have, you do, not you, you will, f...  \n",
       "1     i am, i do, i will, i have, i was, and i, what...  \n",
       "2     in the, to the, on the, of the, what the, for ...  \n",
       "3     have to, to the, to me, to do, to you, you to,...  \n",
       "4     this is, is not, is it, what is, is that, it i...  \n",
       "...                                                 ...  \n",
       "2299  the camp, to camp, base camp, this camp, camp ...  \n",
       "2300  in session, a session, the session, this sessi...  \n",
       "2301  the captain, you captain, captain i, is captai...  \n",
       "2302  i have, you have, have to, we have, have a, no...  \n",
       "2303  the point, a point, your point, point is, poin...  \n",
       "\n",
       "[2304 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"inner\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\",\"twogram_in_threegram\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English_Turkish_Shared_Result_With_Frequency12.xlsx',\n",
       " 'English_Turkish_Shared_Join_Result_Without_Frequency12.xlsx']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}2.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Italian\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0  # native word start index\n",
    "word_end = 28  # 28  # native word end index\n",
    "\n",
    "# word sample\n",
    "word_sample = True  # True, False\n",
    "word_sample_num = 20\n",
    "\n",
    "# shared word frequency\n",
    "shared_word_frequency = True  # True, False\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # always must be True in this part\n",
    "native_word = False # True for adding native word\n",
    "etymology_word = True  # True for adding etymology word\n",
    "\n",
    "# adding output file extention\n",
    "if (not prefix_suffix) & etymology_word & native_word:\n",
    "    file_ext = \"1\"\n",
    "elif (not prefix_suffix) & etymology_word & (not native_word):\n",
    "    file_ext = \"2\"\n",
    "elif prefix_suffix & etymology_word & native_word:\n",
    "    file_ext = \"3\"\n",
    "elif prefix_suffix & etymology_word & (not native_word):\n",
    "    file_ext = \"4\"\n",
    "elif prefix_suffix & (not etymology_word) & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & (not etymology_word) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "# 1 => for native word and etymology word without prefix suffix. \n",
    "# 2 => for only etymology word without prefix suffix. \n",
    "# 3 => for native word and etymology word with prefix suffix. prefix_suffix, native_word and etymology_word must be True. \n",
    "# 4 => for only etymology word with prefix suffix.\n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup(df, source_column, target_column):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            if word_sample:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)  # Option\n",
    "            else:\n",
    "                word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_word_cluster], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "df_word_prefix_suffix = df_word_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_word_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ety_prefix_suffix = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "df_ety_prefix_suffix = df_ety_prefix_suffix[[\"search_word\",\"word\"]]\n",
    "df_ety_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_ext == \"3\":\n",
    "    df_all_word = pd.concat([df_word_prefix_suffix,df_ety_prefix_suffix],axis=0)\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"4\":\n",
    "    df_all_word = df_ety_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "elif file_ext == \"5\":\n",
    "    df_all_word = df_word_prefix_suffix\n",
    "    df_all_word.drop_duplicates(inplace=True)\n",
    "    df_all_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/4-Shared Word/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency{file_ext}.xlsx\")\n",
    "#df_shared_all = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Result_With_Frequency.xlsx\")\n",
    "df_shared_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = word_in_wordgroup(df_shared_all, \"word\", \"twogram\")\n",
    "df_word_order_threegram = word_in_wordgroup(df_shared_all, \"word\", \"threegram\") \n",
    "df_word_order_fourgram = word_in_wordgroup(df_shared_all, \"word\", \"fourgram\") \n",
    "df_word_order_fivegram = word_in_wordgroup(df_shared_all, \"word\", \"fivegram\")\n",
    "df_word_order_sentence = word_in_wordgroup(df_shared_all, \"word\", \"sentence\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_twogram = pd.merge(df_word_order_twogram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_threegram = pd.merge(df_word_order_threegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fourgram = pd.merge(df_word_order_fourgram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_fivegram = pd.merge(df_word_order_fivegram,df_all_word, how=\"inner\", on=\"word\")\n",
    "df_word_order_sentence = pd.merge(df_word_order_sentence,df_all_word, how=\"inner\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_twogram = df_word_order_twogram.groupby([\"search_word\"])[\"twogram\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_threegram = df_word_order_threegram.groupby([\"search_word\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fourgram = df_word_order_fourgram.groupby([\"search_word\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_fivegram = df_word_order_fivegram.groupby([\"search_word\"])[\"fivegram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_sentence = df_word_order_sentence.groupby([\"search_word\"])[\"sentence\"].apply(\", \".join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_word_order_join_twogram,df_word_order_join_threegram,df_word_order_join_fourgram,df_word_order_join_fivegram,df_word_order_join_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all = reduce(lambda  left,right: pd.merge(left,right, on=['search_word'], how='outer'), dfs)  # left,right make left to right merge\n",
    "#df_word_order_join_all = reduce(lambda  right,left: pd.merge(left,right, on=['word'], how='outer'), dfs)  # right,left make right to left merge\n",
    "df_word_order_join_all.rename(columns={\"search_word\":\"word\"}, inplace=True)\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option For Word Frequency\n",
    "if shared_word_frequency:\n",
    "    df_word_order_join_all = pd.merge(df_word_order_join_all,df_word_all, how=\"left\", on=\"word\")\n",
    "    df_word_order_join_all.drop_duplicates(inplace=True)\n",
    "    df_word_order_join_all = df_word_order_join_all.loc[:,[\"word\",\"frequency\",\"twogram\",\"threegram\",\"fourgram\",\"fivegram\",\"sentence\"]]\n",
    "    df_word_order_join_all.sort_values(by=\"frequency\", inplace=True, ascending=False)\n",
    "    df_word_order_join_all.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "df_word_order_join_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file2 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*{file_ext}3.xlsx\")\n",
    "output_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file2:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file2:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Shared File Word Result Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## language pair (same previous part parameter)\n",
    "#lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"French\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# word sample\n",
    "word_sample_num = 20\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip_func(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Result_Without_Frequency{file_ext}3.xlsx\")\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all = df_word_all.loc[:,[\"word\",\"frequency\"]]\n",
    "df_word_all[\"word\"] = df_word_all[\"word\"].apply(lambda x: lower_strip_func(x))\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_all = df_twogram_all.loc[:,[\"twogram\",\"frequency\"]]\n",
    "df_twogram_all[\"twogram\"] = df_twogram_all[\"twogram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_twogram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")\n",
    "df_threegram_all = df_threegram_all.loc[:,[\"threegram\",\"frequency\"]]\n",
    "df_threegram_all[\"threegram\"] = df_threegram_all[\"threegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_threegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")\n",
    "df_fourgram_all = df_fourgram_all.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "df_fourgram_all[\"fourgram\"] = df_fourgram_all[\"fourgram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fourgram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")\n",
    "df_fivegram_all = df_fivegram_all.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "df_fivegram_all[\"fivegram\"] = df_fivegram_all[\"fivegram\"].apply(lambda x: lower_strip_func(x))\n",
    "df_fivegram_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_all = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/Sentence/Merge/Sentence_Merge.csv\")\n",
    "df_sentence_all = df_sentence_all.loc[:,[\"sentence\",\"frequency\"]]\n",
    "df_sentence_all[\"sentence\"] = df_sentence_all[\"sentence\"].apply(lambda x: lower_strip_func(x))\n",
    "df_sentence_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_shared_process_all)):\n",
    "    # column result\n",
    "    try:\n",
    "        # column result\n",
    "        df_two_var = pd.DataFrame(df_shared_process_all.loc[i,\"twogram\"].split(\", \"), columns=[\"twogram\"])\n",
    "        # merge with all\n",
    "        df_two_var_merge = pd.merge(df_two_var, df_twogram_all, how=\"left\", on=\"twogram\")\n",
    "        df_two_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_two_var_merge_select = df_two_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_two_var_list = df_two_var_merge_select[\"twogram\"].to_list()\n",
    "        # list join\n",
    "        df_two_var_list_join = \", \".join(df_two_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"twogram\"] = df_two_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_three_var = pd.DataFrame(df_shared_process_all.loc[i,\"threegram\"].split(\", \"), columns=[\"threegram\"])\n",
    "        # merge with all\n",
    "        df_three_var_merge = pd.merge(df_three_var, df_threegram_all, how=\"left\", on=\"threegram\")\n",
    "        df_three_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_three_var_merge_select = df_three_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_three_var_list = df_three_var_merge_select[\"threegram\"].to_list()\n",
    "        # list join\n",
    "        df_three_var_list_join = \", \".join(df_three_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"threegram\"] = df_three_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_four_var = pd.DataFrame(df_shared_process_all.loc[i,\"fourgram\"].split(\", \"), columns=[\"fourgram\"])\n",
    "        # merge with all\n",
    "        df_four_var_merge = pd.merge(df_four_var, df_fourgram_all, how=\"left\", on=\"fourgram\")\n",
    "        df_four_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_four_var_merge_select = df_four_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_four_var_list = df_four_var_merge_select[\"fourgram\"].to_list()\n",
    "        # list join\n",
    "        df_four_var_list_join = \", \".join(df_four_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fourgram\"] = df_four_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_five_var = pd.DataFrame(df_shared_process_all.loc[i,\"fivegram\"].split(\", \"), columns=[\"fivegram\"])\n",
    "        # merge with all\n",
    "        df_five_var_merge = pd.merge(df_five_var, df_fivegram_all, how=\"left\", on=\"fivegram\")\n",
    "        df_five_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_five_var_merge_select = df_five_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_five_var_list = df_five_var_merge_select[\"fivegram\"].to_list()\n",
    "        # list join\n",
    "        df_five_var_list_join = \", \".join(df_five_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"fivegram\"] = df_five_var_list_join\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # column result\n",
    "        df_sentence_var = pd.DataFrame(df_shared_process_all.loc[i,\"sentence\"].split(\", \"), columns=[\"sentence\"])\n",
    "        # merge with all\n",
    "        df_sentence_var_merge = pd.merge(df_sentence_var, df_sentence_all, how=\"left\", on=\"sentence\")\n",
    "        df_sentence_var_merge.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "        df_sentence_var_merge_select = df_sentence_var_merge.head(word_sample_num)\n",
    "        # to list value\n",
    "        df_sentence_var_list = df_sentence_var_merge_select[\"sentence\"].to_list()\n",
    "        # list join\n",
    "        df_sentence_var_list_join = \", \".join(df_sentence_var_list)\n",
    "        # change value\n",
    "        df_shared_process_all.loc[i,\"sentence\"] = df_sentence_var_list_join\n",
    "    except:\n",
    "        pass      \n",
    "\n",
    "df_shared_process_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shared_process_all.sort_values(by=\"frequency\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_process_all.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Join_Select_Result_Without_Frequency{file_ext}4.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file3 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared*_Select_*{file_ext}4.xlsx\")\n",
    "output_file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file3:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file3:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram hybrid\")\n",
    "df_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count = word_count_result(df_hybrid, [\"twogram_pair1\",\"twogram_pair2\",\"twogram_pair3\",\"twogram_pair4\"])\n",
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge = pd.merge(df_hybrid,df_hybrid_count,how=\"left\",on=\"word\")\n",
    "df_hybrid_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge2 = pd.merge(df_hybrid,df_hybrid_count,how=\"outer\",on=\"word\")\n",
    "df_hybrid_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Hybrid_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count_merge.to_excel(writer, sheet_name='28_Hybrid_Word_Count', index=False)\n",
    "df_hybrid_count_merge2.to_excel(writer, sheet_name='All_Hybrid_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_excel(\"Turkish English manual selected 2 gram hybrids 3.xlsx\", sheet_name=\"2 gram target\")\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count = word_count_result(df_target, [\"twogram_1\",\"twogram_2\",\"twogram_3\",\"twogram_4\"])\n",
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge = pd.merge(df_target,df_target_count,how=\"left\",on=\"word\")\n",
    "df_target_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge2 = pd.merge(df_target,df_target_count,how=\"outer\",on=\"word\")\n",
    "df_target_count_merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_Target_Word_Count.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count_merge.to_excel(writer2, sheet_name='28_Target_Word_Count', index=False)\n",
    "df_target_count_merge2.to_excel(writer2, sheet_name='All_Target_Word_Count', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Target Hybrid Word Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybrid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word = pd.concat([df_target_count, df_hybrid_count], axis=0)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.groupby(\"word\")[[\"word_count\"]].sum().reset_index(inplace=True)\n",
    "df_all_word.sort_values(by=\"word_count\", ascending=False, inplace=True)\n",
    "df_all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_word.to_excel(f\"{lang_folder}_{lang_pair}_Target_Hybrid_Word_Count.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file4 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Word_Count.xlsx\")\n",
    "output_file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in output_file4:\n",
    "    source = o # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in output_file4:\n",
    "    try:\n",
    "        os.remove(p)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Prefix Suffix Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_word = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shared_word_count = word_count_result(df_shared_word, [\"twogram_1\",\"twogram_2\",\"twogram_3\",\"twogram_4\"])\n",
    "df_shared_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# parameter\n",
    "sheets = \"2 gram hybrid\"  # 2 gram target, 2 gram hybrid\n",
    "time_shift = 0.6\n",
    "sample_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:02:51.948</td>\n",
       "      <td>00:02:58.829</td>\n",
       "      <td>Ã¶zgÃ¼r bunlar normalde kamyon daha bÃ¼yÃ¼k araÃ§la...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:03:00.956</td>\n",
       "      <td>00:03:04.236</td>\n",
       "      <td>burcu arka tarafÄ± baÄŸlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:03:13.434</td>\n",
       "      <td>00:03:16.327</td>\n",
       "      <td>Ã¶zgÃ¼r arabaya yarÄ±m tur attÄ±racaÄŸÄ±m</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:03:17.235</td>\n",
       "      <td>00:03:21.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:03:27.806</td>\n",
       "      <td>00:03:33.383</td>\n",
       "      <td>burcu ÅŸimdilik iki tekere takacaÄŸÄ±z ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>00:07:51.970</td>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>umarÄ±z ki bu bÃ¼yÃ¼k ve gÃ¼Ã§lÃ¼ teknoloji yanlÄ±ÅŸ e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>00:08:02.304</td>\n",
       "      <td>daha faydalÄ± ve Ã¶zgÃ¼n kurumlarda herkesin eÅŸit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>00:08:02.498</td>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>i zlediÄŸiniz iÃ§in teÅŸekkÃ¼rler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>yararlandÄ±ÄŸÄ±m kaynaklarÄ± aÃ§Ä±klamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>00:08:11.770</td>\n",
       "      <td>i leri dÃ¼zey okuma ve araÅŸtÄ±rma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time      end_time  \\\n",
       "0        00:02:51.948  00:02:58.829   \n",
       "1        00:03:00.956  00:03:04.236   \n",
       "2        00:03:13.434  00:03:16.327   \n",
       "3        00:03:17.235  00:03:21.338   \n",
       "4        00:03:27.806  00:03:33.383   \n",
       "...               ...           ...   \n",
       "3036932  00:07:51.970  00:07:52.470   \n",
       "3036933  00:07:52.470  00:08:02.304   \n",
       "3036934  00:08:02.498  00:08:04.178   \n",
       "3036935  00:08:04.178  00:08:08.089   \n",
       "3036936  00:08:08.089  00:08:11.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        Ã¶zgÃ¼r bunlar normalde kamyon daha bÃ¼yÃ¼k araÃ§la...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafÄ± baÄŸlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      Ã¶zgÃ¼r arabaya yarÄ±m tur attÄ±racaÄŸÄ±m  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu ÅŸimdilik iki tekere takacaÄŸÄ±z ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarÄ±z ki bu bÃ¼yÃ¼k ve gÃ¼Ã§lÃ¼ teknoloji yanlÄ±ÅŸ e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalÄ± ve Ã¶zgÃ¼n kurumlarda herkesin eÅŸit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediÄŸiniz iÃ§in teÅŸekkÃ¼rler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandÄ±ÄŸÄ±m kaynaklarÄ± aÃ§Ä±klamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri dÃ¼zey okuma ve araÅŸtÄ±rma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/{lang_folder.capitalize()}/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtube_sentence['start_time'] = pd.to_timedelta(df_youtube_sentence['start_time']) # data type converted timedelta for second \n",
    "df_youtube_sentence['end_time'] = pd.to_timedelta(df_youtube_sentence['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.948</td>\n",
       "      <td>178.829</td>\n",
       "      <td>Ã¶zgÃ¼r bunlar normalde kamyon daha bÃ¼yÃ¼k araÃ§la...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.956</td>\n",
       "      <td>184.236</td>\n",
       "      <td>burcu arka tarafÄ± baÄŸlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.434</td>\n",
       "      <td>196.327</td>\n",
       "      <td>Ã¶zgÃ¼r arabaya yarÄ±m tur attÄ±racaÄŸÄ±m</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197.235</td>\n",
       "      <td>201.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207.806</td>\n",
       "      <td>213.383</td>\n",
       "      <td>burcu ÅŸimdilik iki tekere takacaÄŸÄ±z ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>471.970</td>\n",
       "      <td>472.470</td>\n",
       "      <td>umarÄ±z ki bu bÃ¼yÃ¼k ve gÃ¼Ã§lÃ¼ teknoloji yanlÄ±ÅŸ e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>472.470</td>\n",
       "      <td>482.304</td>\n",
       "      <td>daha faydalÄ± ve Ã¶zgÃ¼n kurumlarda herkesin eÅŸit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>482.498</td>\n",
       "      <td>484.178</td>\n",
       "      <td>i zlediÄŸiniz iÃ§in teÅŸekkÃ¼rler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>484.178</td>\n",
       "      <td>488.089</td>\n",
       "      <td>yararlandÄ±ÄŸÄ±m kaynaklarÄ± aÃ§Ä±klamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>488.089</td>\n",
       "      <td>491.770</td>\n",
       "      <td>i leri dÃ¼zey okuma ve araÅŸtÄ±rma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  \\\n",
       "0           171.948   178.829   \n",
       "1           180.956   184.236   \n",
       "2           193.434   196.327   \n",
       "3           197.235   201.338   \n",
       "4           207.806   213.383   \n",
       "...             ...       ...   \n",
       "3036932     471.970   472.470   \n",
       "3036933     472.470   482.304   \n",
       "3036934     482.498   484.178   \n",
       "3036935     484.178   488.089   \n",
       "3036936     488.089   491.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        Ã¶zgÃ¼r bunlar normalde kamyon daha bÃ¼yÃ¼k araÃ§la...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafÄ± baÄŸlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      Ã¶zgÃ¼r arabaya yarÄ±m tur attÄ±racaÄŸÄ±m  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu ÅŸimdilik iki tekere takacaÄŸÄ±z ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarÄ±z ki bu bÃ¼yÃ¼k ve gÃ¼Ã§lÃ¼ teknoloji yanlÄ±ÅŸ e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalÄ± ve Ã¶zgÃ¼n kurumlarda herkesin eÅŸit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediÄŸiniz iÃ§in teÅŸekkÃ¼rler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandÄ±ÄŸÄ±m kaynaklarÄ± aÃ§Ä±klamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri dÃ¼zey okuma ve araÅŸtÄ±rma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_youtube_sentence['start_time'] = df_youtube_sentence['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_youtube_sentence['end_time'] = df_youtube_sentence['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_youtube_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_group_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/Deploy Result Manuel/\\\n",
    "#{lang_folder.capitalize()} {lang_pair.capitalize()} Manual Selected 2 Gram Hybrids.xlsx\", sheet_name= f\"{sheets}\")\n",
    "#df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair1</th>\n",
       "      <th>twogram_pair2</th>\n",
       "      <th>twogram_pair3</th>\n",
       "      <th>twogram_pair4</th>\n",
       "      <th>twogram_pair5</th>\n",
       "      <th>twogram_pair6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kontrol</td>\n",
       "      <td>trafik kontrol</td>\n",
       "      <td>kontrol paneli</td>\n",
       "      <td>sistem kontrolÃ¼</td>\n",
       "      <td>trafik kontrolÃ¼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doktor</td>\n",
       "      <td>doktor raporu</td>\n",
       "      <td>doktorun numarasÄ±</td>\n",
       "      <td>doktorun telefonu</td>\n",
       "      <td>doktorun ofisine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polis</td>\n",
       "      <td>polis ÅŸefi</td>\n",
       "      <td>trafik polisi</td>\n",
       "      <td>sivil polis</td>\n",
       "      <td>polis raporu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dolar</td>\n",
       "      <td>milyon dolar</td>\n",
       "      <td>milyon dolarlÄ±k</td>\n",
       "      <td>milyonlarca dolar</td>\n",
       "      <td>amerikan dolarÄ±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>komik</td>\n",
       "      <td>komik film</td>\n",
       "      <td>komik videolarÄ±</td>\n",
       "      <td>komik tipler</td>\n",
       "      <td>komik karakter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>alarm</td>\n",
       "      <td>genel alarm</td>\n",
       "      <td>alarm sistemi</td>\n",
       "      <td>alarm ÅŸifresi</td>\n",
       "      <td>kriz alarmÄ±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>motor</td>\n",
       "      <td>jet motoru</td>\n",
       "      <td>motorlar stop</td>\n",
       "      <td>motor kontrol</td>\n",
       "      <td>turbo motor</td>\n",
       "      <td>elektrik motorlarÄ±</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>otobÃ¼s</td>\n",
       "      <td>okul otobÃ¼sÃ¼</td>\n",
       "      <td>takÄ±m otobÃ¼se</td>\n",
       "      <td>otobÃ¼s terminali</td>\n",
       "      <td>turist otobÃ¼sÃ¼</td>\n",
       "      <td>tur otobÃ¼sÃ¼</td>\n",
       "      <td>otobÃ¼s turu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>manyak</td>\n",
       "      <td>psikopat manyak</td>\n",
       "      <td>manyak film</td>\n",
       "      <td>manyak numara</td>\n",
       "      <td>manyak parti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>makine</td>\n",
       "      <td>fotoÄŸraf makinesi</td>\n",
       "      <td>kahve makinesi</td>\n",
       "      <td>tost makinesi</td>\n",
       "      <td>fotokopi makinesi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      twogram_pair1        twogram_pair2       twogram_pair3  \\\n",
       "0   kontrol     trafik kontrol       kontrol paneli     sistem kontrolÃ¼   \n",
       "1    doktor      doktor raporu    doktorun numarasÄ±   doktorun telefonu   \n",
       "2     polis         polis ÅŸefi        trafik polisi         sivil polis   \n",
       "3     dolar       milyon dolar      milyon dolarlÄ±k   milyonlarca dolar   \n",
       "4     komik         komik film      komik videolarÄ±        komik tipler   \n",
       "..      ...                ...                  ...                 ...   \n",
       "71    alarm        genel alarm        alarm sistemi       alarm ÅŸifresi   \n",
       "72    motor         jet motoru        motorlar stop       motor kontrol   \n",
       "73   otobÃ¼s       okul otobÃ¼sÃ¼        takÄ±m otobÃ¼se    otobÃ¼s terminali   \n",
       "74   manyak    psikopat manyak          manyak film       manyak numara   \n",
       "75   makine  fotoÄŸraf makinesi       kahve makinesi       tost makinesi   \n",
       "\n",
       "         twogram_pair4        twogram_pair5 twogram_pair6  \n",
       "0      trafik kontrolÃ¼                  NaN           NaN  \n",
       "1     doktorun ofisine                  NaN           NaN  \n",
       "2         polis raporu                  NaN           NaN  \n",
       "3      amerikan dolarÄ±                  NaN           NaN  \n",
       "4       komik karakter                  NaN           NaN  \n",
       "..                 ...                  ...           ...  \n",
       "71         kriz alarmÄ±                  NaN           NaN  \n",
       "72         turbo motor   elektrik motorlarÄ±           NaN  \n",
       "73      turist otobÃ¼sÃ¼          tur otobÃ¼sÃ¼   otobÃ¼s turu  \n",
       "74        manyak parti                  NaN           NaN  \n",
       "75   fotokopi makinesi                  NaN           NaN  \n",
       "\n",
       "[76 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp\n",
    "df_word_group_select = pd.read_excel(\"Turkish English manual selected 2 gram hybrids.xlsx\", sheet_name=\"2 gram SV\")\n",
    "df_word_group_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_select.loc[74,\"twogram_pair5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2588e2916b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ali\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "math.isnan(\"ali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trafik kontrol',\n",
       " 'kontrol paneli',\n",
       " 'sistem kontrolÃ¼',\n",
       " 'trafik kontrolÃ¼',\n",
       " 'doktor raporu',\n",
       " 'doktorun numarasÄ±',\n",
       " 'doktorun telefonu',\n",
       " 'doktorun ofisine',\n",
       " 'polis ÅŸefi',\n",
       " 'trafik polisi',\n",
       " 'sivil polis',\n",
       " 'polis raporu',\n",
       " 'milyon dolar',\n",
       " 'milyon dolarlÄ±k',\n",
       " 'milyonlarca dolar',\n",
       " 'amerikan dolarÄ±',\n",
       " 'komik film',\n",
       " 'komik videolarÄ±',\n",
       " 'komik tipler',\n",
       " 'komik karakter',\n",
       " 'telefon numarasÄ±',\n",
       " 'telefon kartÄ±',\n",
       " 'telefonun ÅŸarjÄ±',\n",
       " 'doktorun telefonu',\n",
       " 'tÃ¼p bebek',\n",
       " 'bebek penguenler',\n",
       " 'bebek pudrasÄ±',\n",
       " 'sÃ¼per bebek',\n",
       " 'dans partisi',\n",
       " 'dans okuluna',\n",
       " 'diskoda dans',\n",
       " 'modern dans',\n",
       " '',\n",
       " 'milyon dolar',\n",
       " 'milyon dolarlÄ±k',\n",
       " 'milyon kilometre',\n",
       " 'milyon ton',\n",
       " 'takÄ±m kaptanÄ±',\n",
       " 'kaptan pilot',\n",
       " 'kaptan amerika',\n",
       " 'kaptan barÄ±',\n",
       " 'sistemler normal',\n",
       " 'normal kahve',\n",
       " 'fonksiyonlar normal',\n",
       " 'testleri normal',\n",
       " 'ÅŸans kÃ¼pÃ¼',\n",
       " 'ÅŸanslÄ± numara',\n",
       " 'ÅŸans faktÃ¶rÃ¼',\n",
       " 'ÅŸans perisi',\n",
       " 'kahve makinesi',\n",
       " 'kahve servisi',\n",
       " 'kafeinsiz kahve',\n",
       " 'kremalÄ± kahve',\n",
       " 'narkotik ajanÄ±',\n",
       " 'ÅŸef ajan',\n",
       " 'sÃ¼per ajan',\n",
       " 'siber ajan',\n",
       " 'ÅŸifreli mesaj',\n",
       " 'video mesajÄ±',\n",
       " 'telefon mesajlarÄ±',\n",
       " 'mesaj panosu',\n",
       " 'telefon numarasÄ±',\n",
       " 'plaka numarasÄ±',\n",
       " 'rozet numarasÄ±',\n",
       " 'kart numarasÄ±',\n",
       " 'kovboy filmi',\n",
       " 'aksiyon filmi',\n",
       " 'sinema filmi',\n",
       " 'film karakteri',\n",
       " 'komedi filmi',\n",
       " 'pijama partisi',\n",
       " 'sÃ¼rpriz parti',\n",
       " 'dans partisi',\n",
       " 'parti lideri',\n",
       " 'futbol takÄ±mÄ±',\n",
       " 'takÄ±m kaptanÄ±',\n",
       " 'beyzbol takÄ±mÄ±',\n",
       " 'okul takÄ±mÄ±',\n",
       " 'sÃ¼per star',\n",
       " 'sÃ¼per kupa',\n",
       " 'sÃ¼per market',\n",
       " 'sÃ¼per model',\n",
       " 'enstrÃ¼mantal mÃ¼zik',\n",
       " 'klasik mÃ¼zik',\n",
       " 'pop mÃ¼zik',\n",
       " 'mÃ¼zik festivali',\n",
       " 'okul otobÃ¼sÃ¼',\n",
       " 'okul projesi',\n",
       " 'okul takÄ±mÄ±',\n",
       " 'okul Ã¼niformasÄ±',\n",
       " 'polis ÅŸefi',\n",
       " 'orkestra ÅŸefi',\n",
       " 'personel ÅŸefi',\n",
       " 'bÃ¼ro ÅŸefi',\n",
       " 'karavan parkÄ±',\n",
       " 'park metre',\n",
       " 'park personeli',\n",
       " 'paralel park',\n",
       " 'karantina planÄ±',\n",
       " 'finansal planlar',\n",
       " 'planlama ofisi',\n",
       " 'stratejik planlama',\n",
       " 'grup lideri',\n",
       " 'grup terapisi',\n",
       " 'grup ÅŸemasÄ±',\n",
       " 'park metre',\n",
       " 'milyonlarca metre',\n",
       " 'metre kÃ¼p',\n",
       " 'kilo metre',\n",
       " 'fizik profesÃ¶rÃ¼',\n",
       " 'psikoloji profesÃ¶rÃ¼',\n",
       " 'matematik profesÃ¶rÃ¼',\n",
       " 'arkeoloji profesÃ¶rÃ¼',\n",
       " 'test pozitif',\n",
       " 'alkol testi',\n",
       " 'test negatif',\n",
       " 'alerji testi',\n",
       " 'fiziksel test',\n",
       " 'sÃ¼rpriz parti',\n",
       " 'Ã§ikolata sÃ¼rprizi',\n",
       " 'sÃ¼rpriz bebek',\n",
       " 'sÃ¼rpriz atak',\n",
       " 'atom bombasÄ±',\n",
       " 'nÃ¼kleer bomba',\n",
       " 'bomba aktif',\n",
       " 'gaz bombasÄ±',\n",
       " 'avukatlÄ±k bÃ¼rosu',\n",
       " 'avukatlar ofisi',\n",
       " 'firmanÄ±n avukatÄ±',\n",
       " 'avukatÄ±n numarasÄ±',\n",
       " 'bazÄ± notlar',\n",
       " 'kredi notu',\n",
       " 'ÅŸifreli not',\n",
       " 'laboratuvar notlarÄ±',\n",
       " 'rafine ÅŸeker',\n",
       " 'kÃ¼p ÅŸeker',\n",
       " 'ÅŸekerli kahve',\n",
       " 'ÅŸekerli krema',\n",
       " 'ekstra ÅŸekerli',\n",
       " 'balistik raporu',\n",
       " 'polis raporu',\n",
       " 'otopsi raporu',\n",
       " 'doktor raporu',\n",
       " 'fotoÄŸraf makinesi',\n",
       " 'fotoÄŸraf albÃ¼mÃ¼',\n",
       " 'grup fotoÄŸrafÄ±',\n",
       " 'fotoÄŸraf stÃ¼dyosu',\n",
       " 'prenses kostÃ¼mÃ¼',\n",
       " 'japon prensesin',\n",
       " 'balonun prensesi',\n",
       " 'prenses kalesi',\n",
       " 'negatif enerji',\n",
       " 'pozitif enerji',\n",
       " 'enerji santralÄ±',\n",
       " 'nÃ¼kleer enerji',\n",
       " 'elektrik enerjisi',\n",
       " 'spor kanalÄ±',\n",
       " 'takÄ±m sproru',\n",
       " 'spor akademisine',\n",
       " 'profesyonel sporcu',\n",
       " 'spor programÄ±',\n",
       " 'psikolojik problemler',\n",
       " 'kilo problemi',\n",
       " 'vize problemi',\n",
       " 'matematik problemi',\n",
       " 'banka kredisi',\n",
       " 'banka Ã§eki',\n",
       " 'telefonla bankacÄ±lÄ±ÄŸÄ±',\n",
       " 'banka kartÄ±',\n",
       " 'kilo problemi',\n",
       " 'kilo somon',\n",
       " 'kilo ÅŸeker',\n",
       " 'tren istasyonu',\n",
       " 'tren rayÄ±',\n",
       " 'ekspres tren',\n",
       " 'metro treni',\n",
       " 'elektrik santrali',\n",
       " 'elektrik sistemi',\n",
       " 'statik elektrik',\n",
       " 'elektrik kablosu',\n",
       " 'taksi limuzin',\n",
       " 'taksinin bagajÄ±',\n",
       " 'taksinin markasÄ±',\n",
       " 'taksi numarasÄ±',\n",
       " 'televizyon programÄ±',\n",
       " 'kablolu televizyon',\n",
       " 'televizyon stÃ¼dyosu',\n",
       " 'teknik servis',\n",
       " 'teknik detaylar',\n",
       " 'teknik direktÃ¶r',\n",
       " 'teknik ekipman',\n",
       " 'kredi kartÄ±',\n",
       " 'banka kredisi',\n",
       " 'kredi limiti',\n",
       " 'okul kredisi',\n",
       " 'plaza otel',\n",
       " 'otel telefonu',\n",
       " 'otelin barÄ±',\n",
       " 'lÃ¼ks otel',\n",
       " 'genel sekreter',\n",
       " 'genel anestezi',\n",
       " 'genel karantina',\n",
       " 'genel kÃ¼ltÃ¼r',\n",
       " 'onur madalyasÄ±',\n",
       " 'onur listesi',\n",
       " 'onur rozeti',\n",
       " 'gaz maskesi',\n",
       " 'biber gazÄ±',\n",
       " 'gaz bombasÄ±',\n",
       " 'karbondioksit gazÄ±',\n",
       " 'sosyalist parti',\n",
       " 'sosyal psikoloji',\n",
       " 'sosyal medya',\n",
       " 'sosyal aktivite',\n",
       " 'futbol takÄ±mÄ±',\n",
       " 'futbol maÃ§Ä±',\n",
       " 'profesyonel futbol',\n",
       " 'futbol antrenmanÄ±',\n",
       " 'futbol ligi',\n",
       " 'profesyonel futbol',\n",
       " 'profesyonel lig',\n",
       " 'profesyonel basketbol',\n",
       " 'profesyonel boks',\n",
       " 'entelektÃ¼el tipler',\n",
       " 'psikopat tipi',\n",
       " 'polis tipli',\n",
       " 'komik tipi',\n",
       " 'filmde rol',\n",
       " 'doktor rolÃ¼',\n",
       " 'rol model',\n",
       " 'aktif rol',\n",
       " 'teknik servis',\n",
       " 'servis asansÃ¶rÃ¼',\n",
       " 'kahve servisi',\n",
       " 'okul servisi',\n",
       " 'nÃ¼kleer bomba',\n",
       " 'nÃ¼kleer enerji',\n",
       " 'nÃ¼kleer santral',\n",
       " 'nÃ¼kleer fizik',\n",
       " 'fiziksel temas',\n",
       " 'fiziksel test',\n",
       " 'fiziksel aktivite',\n",
       " 'fiziksel form',\n",
       " 'radyo sinyali',\n",
       " 'telefon sinyali',\n",
       " 'radar sinyali',\n",
       " 'orijinal sinyal',\n",
       " 'sezon finali',\n",
       " 'beyzbol sezonu',\n",
       " 'hokey sezonu',\n",
       " 'sezon ÅŸampiyonu',\n",
       " 'senatÃ¶rÃ¼n kampanyasÄ±',\n",
       " 'senatÃ¶rÃ¼n asistanÄ±',\n",
       " 'senatÃ¶rÃ¼n planÄ±',\n",
       " 'romantik restoran',\n",
       " 'romantik komedi',\n",
       " 'romantik atmosfer',\n",
       " 'romantik mÃ¼zik',\n",
       " 'boks maÃ§Ä±',\n",
       " 'futbol maÃ§Ä±',\n",
       " 'final maÃ§Ä±',\n",
       " 'ÅŸampiyonluk maÃ§Ä±',\n",
       " 'doktora tezi',\n",
       " 'akdemik doktora',\n",
       " 'doktora komitesi',\n",
       " 'fizik doktorasÄ±',\n",
       " 'elektrik ÅŸoku',\n",
       " 'ÅŸok terapisi',\n",
       " 'alerjik ÅŸoka',\n",
       " 'ÅŸok video',\n",
       " 'video Ã¼nitesi',\n",
       " 'video filmi',\n",
       " 'video klip',\n",
       " 'video konferans',\n",
       " 'kredi kartÄ±',\n",
       " 'telefon kartÄ±',\n",
       " 'kart numarasÄ±',\n",
       " 'banka kartÄ±',\n",
       " 'posta kartÄ±',\n",
       " 'vampir filmi',\n",
       " 'vampir rolÃ¼ne',\n",
       " 'mutant vampir',\n",
       " 'vampir antijeni',\n",
       " 'trafik polisi',\n",
       " 'trafik kontrolÃ¼',\n",
       " 'trafik lambasÄ±',\n",
       " 'trafik raporu',\n",
       " 'genel alarm',\n",
       " 'alarm sistemi',\n",
       " 'alarm ÅŸifresi',\n",
       " 'kriz alarmÄ±',\n",
       " 'jet motoru',\n",
       " 'motorlar stop',\n",
       " 'motor kontrol',\n",
       " 'turbo motor',\n",
       " 'elektrik motorlarÄ±',\n",
       " 'okul otobÃ¼sÃ¼',\n",
       " 'takÄ±m otobÃ¼se',\n",
       " 'otobÃ¼s terminali',\n",
       " 'turist otobÃ¼sÃ¼',\n",
       " 'tur otobÃ¼sÃ¼',\n",
       " 'otobÃ¼s turu',\n",
       " 'psikopat manyak',\n",
       " 'manyak film',\n",
       " 'manyak numara',\n",
       " 'manyak parti',\n",
       " 'fotoÄŸraf makinesi',\n",
       " 'kahve makinesi',\n",
       " 'tost makinesi',\n",
       " 'fotokopi makinesi']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_list = []\n",
    "for i in range(len(df_word_group_select)):\n",
    "    for j in df_word_group_select.columns[1:]:\n",
    "        string = df_word_group_select.loc[i,j]\n",
    "        \n",
    "        if pd.isnull(string) == False and string != 'nan':\n",
    "            search_list.append(string.strip())\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #search_list.append(string.strip())\n",
    "        #search_list = [x for x in search_list if np.isnan(x) == False]\n",
    "search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_youtube(df, search_list, target_column, sample_num): \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        try:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].sample(sample_num)\n",
    "        except:\n",
    "            df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)].head(sample_num)\n",
    "        #df_result = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=True)]  # sentence length part\n",
    "        #df_result.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        #df_select = df_result.head(sample_num)\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_search_result = pd.DataFrame()\n",
    "#for i in range(len(df_english_select)):\n",
    "#    for j in df_english_select.columns[1:]:\n",
    "#        string = df_english_select.loc[i,j]\n",
    "#        df_result = df_youtube_sent[df_youtube_sent.sentence.str.contains(fr\"(?:\\s|^){string}(?:\\s|$)\", na=True)]\n",
    "#        df_result.sort_values(\"sentence\",key=lambda x:x.str.len(), inplace=True)\n",
    "#        df_select = df_result.head(6)\n",
    "#        df_select.insert(0,\"search_string\",string)\n",
    "#        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "#df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7303.594</td>\n",
       "      <td>7306.376</td>\n",
       "      <td>tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3657.882</td>\n",
       "      <td>3662.884</td>\n",
       "      <td>hocam yani biz eski kuÅŸak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>32.980</td>\n",
       "      <td>35.840</td>\n",
       "      <td>havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2895.962</td>\n",
       "      <td>2897.712</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>812.656</td>\n",
       "      <td>822.328</td>\n",
       "      <td>descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1080.799</td>\n",
       "      <td>1085.049</td>\n",
       "      <td>ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3681.081</td>\n",
       "      <td>3683.858</td>\n",
       "      <td>aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.153</td>\n",
       "      <td>3617.830</td>\n",
       "      <td>Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>36.000</td>\n",
       "      <td>43.080</td>\n",
       "      <td>bu nedenle performansÄ±m bir dans gibi deÄŸil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>104.587</td>\n",
       "      <td>112.883</td>\n",
       "      <td>peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor    7303.594  7306.376   \n",
       "1      bir doktor    3657.882  3662.884   \n",
       "2      bir doktor      32.980    35.840   \n",
       "3      bir doktor    2895.962  2897.712   \n",
       "4      bir doktor     812.656   822.328   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi    1080.799  1085.049   \n",
       "437    bebek gibi    3681.081  3683.858   \n",
       "438    bebek gibi    3616.153  3617.830   \n",
       "439     dans gibi      36.000    43.080   \n",
       "440     dans gibi     104.587   112.883   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuÅŸak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...  KHMNiXYbdaU  \n",
       "437  aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...  metH403loSY  \n",
       "438    Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansÄ±m bir dans gibi deÄŸil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_result = word_group_youtube(df_youtube_sentence, search_list, \"sentence\", 6)\n",
    "df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_time_loc(df, search, start_sent, end_sent, sent, sent_video_id):\n",
    "    word_time_loc_list = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,f\"{search}\"]\n",
    "        start_time = df.loc[i,f\"{start_sent}\"]\n",
    "        end_time = df.loc[i,f\"{end_sent}\"]\n",
    "        sentence = df.loc[i,f\"{sent}\"]\n",
    "        video_id = df.loc[i,f\"{sent_video_id}\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[f\"{search}\",f\"{start_sent}\",f\"{end_sent}\",f\"{sent}\",f\"{sent_video_id}\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7305.071937</td>\n",
       "      <td>7306.115188</td>\n",
       "      <td>tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659.595014</td>\n",
       "      <td>3660.417260</td>\n",
       "      <td>hocam yani biz eski kuÅŸak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33.666400</td>\n",
       "      <td>34.352800</td>\n",
       "      <td>havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896.342435</td>\n",
       "      <td>2897.255478</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818.893739</td>\n",
       "      <td>819.734783</td>\n",
       "      <td>descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081.994312</td>\n",
       "      <td>1082.525562</td>\n",
       "      <td>ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682.149077</td>\n",
       "      <td>3682.789923</td>\n",
       "      <td>aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.652532</td>\n",
       "      <td>3617.080702</td>\n",
       "      <td>Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38.331220</td>\n",
       "      <td>39.280976</td>\n",
       "      <td>bu nedenle performansÄ±m bir dans gibi deÄŸil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108.453097</td>\n",
       "      <td>109.339078</td>\n",
       "      <td>peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string   start_time     end_time  \\\n",
       "0      bir doktor  7305.071937  7306.115188   \n",
       "1      bir doktor  3659.595014  3660.417260   \n",
       "2      bir doktor    33.666400    34.352800   \n",
       "3      bir doktor  2896.342435  2897.255478   \n",
       "4      bir doktor   818.893739   819.734783   \n",
       "..            ...          ...          ...   \n",
       "436    bebek gibi  1081.994312  1082.525562   \n",
       "437    bebek gibi  3682.149077  3682.789923   \n",
       "438    bebek gibi  3616.652532  3617.080702   \n",
       "439     dans gibi    38.331220    39.280976   \n",
       "440     dans gibi   108.453097   109.339078   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuÅŸak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...  KHMNiXYbdaU  \n",
       "437  aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...  metH403loSY  \n",
       "438    Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansÄ±m bir dans gibi deÄŸil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result = word_group_time_loc(df_search_result, \"search_string\", \"start_time\", \"end_time\", \"sentence\", \"video_id\")\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304.471937</td>\n",
       "      <td>7306.715188</td>\n",
       "      <td>tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3658.995014</td>\n",
       "      <td>3661.017260</td>\n",
       "      <td>hocam yani biz eski kuÅŸak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33.066400</td>\n",
       "      <td>34.952800</td>\n",
       "      <td>havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2895.742435</td>\n",
       "      <td>2897.855478</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818.293739</td>\n",
       "      <td>820.334783</td>\n",
       "      <td>descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081.394313</td>\n",
       "      <td>1083.125562</td>\n",
       "      <td>ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3681.549077</td>\n",
       "      <td>3683.389923</td>\n",
       "      <td>aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616.052532</td>\n",
       "      <td>3617.680702</td>\n",
       "      <td>Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>37.731220</td>\n",
       "      <td>39.880976</td>\n",
       "      <td>bu nedenle performansÄ±m bir dans gibi deÄŸil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>107.853097</td>\n",
       "      <td>109.939078</td>\n",
       "      <td>peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string   start_time     end_time  \\\n",
       "0      bir doktor  7304.471937  7306.715188   \n",
       "1      bir doktor  3658.995014  3661.017260   \n",
       "2      bir doktor    33.066400    34.952800   \n",
       "3      bir doktor  2895.742435  2897.855478   \n",
       "4      bir doktor   818.293739   820.334783   \n",
       "..            ...          ...          ...   \n",
       "436    bebek gibi  1081.394313  1083.125562   \n",
       "437    bebek gibi  3681.549077  3683.389923   \n",
       "438    bebek gibi  3616.052532  3617.680702   \n",
       "439     dans gibi    37.731220    39.880976   \n",
       "440     dans gibi   107.853097   109.939078   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuÅŸak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...  KHMNiXYbdaU  \n",
       "437  aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...  metH403loSY  \n",
       "438    Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansÄ±m bir dans gibi deÄŸil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time_shift = 0.3\n",
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: (x-time_shift))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: (x+time_shift))\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304</td>\n",
       "      <td>7307</td>\n",
       "      <td>tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659</td>\n",
       "      <td>3661</td>\n",
       "      <td>hocam yani biz eski kuÅŸak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896</td>\n",
       "      <td>2898</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818</td>\n",
       "      <td>820</td>\n",
       "      <td>descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081</td>\n",
       "      <td>1083</td>\n",
       "      <td>ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682</td>\n",
       "      <td>3683</td>\n",
       "      <td>aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616</td>\n",
       "      <td>3618</td>\n",
       "      <td>Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>bu nedenle performansÄ±m bir dans gibi deÄŸil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor        7304      7307   \n",
       "1      bir doktor        3659      3661   \n",
       "2      bir doktor          33        35   \n",
       "3      bir doktor        2896      2898   \n",
       "4      bir doktor         818       820   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi        1081      1083   \n",
       "437    bebek gibi        3682      3683   \n",
       "438    bebek gibi        3616      3618   \n",
       "439     dans gibi          38        40   \n",
       "440     dans gibi         108       110   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                     tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var  6ip1mqRyI5M  \n",
       "1    hocam yani biz eski kuÅŸak bir doktor bekliyord...  BWSxerD3LDc  \n",
       "2    havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...  yLJbfglM_tY  \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg  \n",
       "4    descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...  dSrXG27FnBY  \n",
       "..                                                 ...          ...  \n",
       "436  ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...  KHMNiXYbdaU  \n",
       "437  aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...  metH403loSY  \n",
       "438    Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan  riiIV32FEuM  \n",
       "439  bu nedenle performansÄ±m bir dans gibi deÄŸil da...  JOGsTT3hDRo  \n",
       "440  peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...  4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result.start_time = df_word_group_time_loc_result.start_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result.end_time = df_word_group_time_loc_result.end_time.apply(lambda x: round(x))\n",
    "df_word_group_time_loc_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_string</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>7304</td>\n",
       "      <td>7307</td>\n",
       "      <td>tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var</td>\n",
       "      <td>6ip1mqRyI5M</td>\n",
       "      <td>https://www.youtube.com/watch?v=6ip1mqRyI5M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>3659</td>\n",
       "      <td>3661</td>\n",
       "      <td>hocam yani biz eski kuÅŸak bir doktor bekliyord...</td>\n",
       "      <td>BWSxerD3LDc</td>\n",
       "      <td>https://www.youtube.com/watch?v=BWSxerD3LDc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...</td>\n",
       "      <td>yLJbfglM_tY</td>\n",
       "      <td>https://www.youtube.com/watch?v=yLJbfglM_tY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>2896</td>\n",
       "      <td>2898</td>\n",
       "      <td>sonra bir doktor bulduk</td>\n",
       "      <td>GJyk2ANh7mg</td>\n",
       "      <td>https://www.youtube.com/watch?v=GJyk2ANh7mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir doktor</td>\n",
       "      <td>818</td>\n",
       "      <td>820</td>\n",
       "      <td>descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...</td>\n",
       "      <td>dSrXG27FnBY</td>\n",
       "      <td>https://www.youtube.com/watch?v=dSrXG27FnBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>1081</td>\n",
       "      <td>1083</td>\n",
       "      <td>ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...</td>\n",
       "      <td>KHMNiXYbdaU</td>\n",
       "      <td>https://www.youtube.com/watch?v=KHMNiXYbdaU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3682</td>\n",
       "      <td>3683</td>\n",
       "      <td>aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...</td>\n",
       "      <td>metH403loSY</td>\n",
       "      <td>https://www.youtube.com/watch?v=metH403loSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>3616</td>\n",
       "      <td>3618</td>\n",
       "      <td>Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan</td>\n",
       "      <td>riiIV32FEuM</td>\n",
       "      <td>https://www.youtube.com/watch?v=riiIV32FEuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>bu nedenle performansÄ±m bir dans gibi deÄŸil da...</td>\n",
       "      <td>JOGsTT3hDRo</td>\n",
       "      <td>https://www.youtube.com/watch?v=JOGsTT3hDRo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>dans gibi</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...</td>\n",
       "      <td>4aN0e5dOzh0</td>\n",
       "      <td>https://www.youtube.com/watch?v=4aN0e5dOzh0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_string  start_time  end_time  \\\n",
       "0      bir doktor        7304      7307   \n",
       "1      bir doktor        3659      3661   \n",
       "2      bir doktor          33        35   \n",
       "3      bir doktor        2896      2898   \n",
       "4      bir doktor         818       820   \n",
       "..            ...         ...       ...   \n",
       "436    bebek gibi        1081      1083   \n",
       "437    bebek gibi        3682      3683   \n",
       "438    bebek gibi        3616      3618   \n",
       "439     dans gibi          38        40   \n",
       "440     dans gibi         108       110   \n",
       "\n",
       "                                              sentence     video_id  \\\n",
       "0                     tanÄ±dÄ±ÄŸÄ±m Ã§ok iyi bir doktor var  6ip1mqRyI5M   \n",
       "1    hocam yani biz eski kuÅŸak bir doktor bekliyord...  BWSxerD3LDc   \n",
       "2    havaalanÄ±nda bir doktor bir Ã§ocuÄŸu mu kurtarmÄ±...  yLJbfglM_tY   \n",
       "3                              sonra bir doktor bulduk  GJyk2ANh7mg   \n",
       "4    descendants of the sun kÄ±saca birleÅŸmiÅŸ millet...  dSrXG27FnBY   \n",
       "..                                                 ...          ...   \n",
       "436  ya onlar bana bu gÃ¼ne kadar bebek gibi baktÄ± b...  KHMNiXYbdaU   \n",
       "437  aradÄ±m vallahi hedoÅŸ bebek gibi bakÄ±yormuÅŸ gay...  metH403loSY   \n",
       "438    Ã§iÅŸin var diye bebek gibi zÄ±rladÄ±n iki saat lan  riiIV32FEuM   \n",
       "439  bu nedenle performansÄ±m bir dans gibi deÄŸil da...  JOGsTT3hDRo   \n",
       "440  peki sen gerÃ§ek anlamda bÃ¶yle beden eÄŸitimi gi...  4aN0e5dOzh0   \n",
       "\n",
       "                                       video_url  \n",
       "0    https://www.youtube.com/watch?v=6ip1mqRyI5M  \n",
       "1    https://www.youtube.com/watch?v=BWSxerD3LDc  \n",
       "2    https://www.youtube.com/watch?v=yLJbfglM_tY  \n",
       "3    https://www.youtube.com/watch?v=GJyk2ANh7mg  \n",
       "4    https://www.youtube.com/watch?v=dSrXG27FnBY  \n",
       "..                                           ...  \n",
       "436  https://www.youtube.com/watch?v=KHMNiXYbdaU  \n",
       "437  https://www.youtube.com/watch?v=metH403loSY  \n",
       "438  https://www.youtube.com/watch?v=riiIV32FEuM  \n",
       "439  https://www.youtube.com/watch?v=JOGsTT3hDRo  \n",
       "440  https://www.youtube.com/watch?v=4aN0e5dOzh0  \n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_group_time_loc_result[\"video_url\"] = \"https://www.youtube.com/watch?v=\"+df_word_group_time_loc_result['video_id'].map(str)\n",
    "df_word_group_time_loc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_result.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{sheets.capitalize()}_\\\n",
    "{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_2 gram hybrid_6_Youtube_0.6s_Timeshift_Result.xlsx',\n",
       " 'Turkish_English_2 gram target_6_Youtube_0.6s_Timeshift_Result.xlsx']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file5 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_{sample_num}_Youtube_{time_shift}s_Timeshift_Result.xlsx\")\n",
    "output_file5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in output_file5:\n",
    "    source = y # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/5-Shared Word File/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in output_file5:\n",
    "    try:\n",
    "        os.remove(z)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
