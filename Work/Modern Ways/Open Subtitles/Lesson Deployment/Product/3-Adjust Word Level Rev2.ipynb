{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Arabic\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # True for adding prefix suffix word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988212</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988213</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988214</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988215</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988216</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "988212     karneleme          5\n",
       "988213       karnaya          5\n",
       "988214   dörtlümüzün          5\n",
       "988215  karnavalınız          5\n",
       "988216      hurmanın          5\n",
       "\n",
       "[988217 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>arabic_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba</td>\n",
       "      <td>abāˀ أباء/قباء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abes</td>\n",
       "      <td>ˁabas̠ عبث</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abide</td>\n",
       "      <td>ābidat آبد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablak</td>\n",
       "      <td>ablaḳ أبلق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acaba</td>\n",
       "      <td>ˁacab عجب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>ziyade</td>\n",
       "      <td>ziyādat زيادة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>ziyafet</td>\n",
       "      <td>ḍiyāfat ضيافة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>ziyaret</td>\n",
       "      <td>aynı anlama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>zulüm</td>\n",
       "      <td>aynı anlama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>zürafa</td>\n",
       "      <td>zurāfat زرافة</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main        arabic_word\n",
       "0                aba   abāˀ أباء/قباء  \n",
       "1               abes       ˁabas̠ عبث  \n",
       "2              abide       ābidat آبد  \n",
       "3              ablak      ablaḳ أبلق  \n",
       "4              acaba        ˁacab عجب  \n",
       "...              ...                ...\n",
       "1436          ziyade    ziyādat زيادة  \n",
       "1437         ziyafet   ḍiyāfat ضيافة  \n",
       "1438         ziyaret       aynı anlama \n",
       "1439           zulüm       aynı anlama \n",
       "1440          zürafa    zurāfat زرافة  \n",
       "\n",
       "[1441 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_pair_ety = pd.read_excel(f\"{lang_pair_list[0]}\")  # need only dict_entry_main column\n",
    "df_pair_ety = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair_ety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>arabic_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba</td>\n",
       "      <td>abāˀ أباء/قباء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aban</td>\n",
       "      <td>abāˀ أباء/قباء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abayı</td>\n",
       "      <td>abāˀ أباء/قباء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaza</td>\n",
       "      <td>abāˀ أباء/قباء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abes</td>\n",
       "      <td>ˁabas̠ عبث</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>zulüm</td>\n",
       "      <td>aynı anlama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>zulümden</td>\n",
       "      <td>aynı anlama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>zürafa</td>\n",
       "      <td>zurāfat زرافة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>zürafalar</td>\n",
       "      <td>zurāfat زرافة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>zürafayı</td>\n",
       "      <td>zurāfat زرافة</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main        arabic_word\n",
       "0                aba   abāˀ أباء/قباء  \n",
       "1               aban   abāˀ أباء/قباء  \n",
       "2              abayı   abāˀ أباء/قباء  \n",
       "3              abaza   abāˀ أباء/قباء  \n",
       "4               abes       ˁabas̠ عبث  \n",
       "...              ...                ...\n",
       "5953           zulüm       aynı anlama \n",
       "5954        zulümden       aynı anlama \n",
       "5955          zürafa    zurāfat زرافة  \n",
       "5956       zürafalar    zurāfat زرافة  \n",
       "5957        zürafayı    zurāfat زرافة  \n",
       "\n",
       "[5958 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_merge = pd.merge(df_pair_ety,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair_merge.drop_duplicates(inplace=True)\n",
    "    df_pair_merge.reset_index(drop=True, inplace=True)\n",
    "    df_pair_merge = df_pair_merge.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair_merge.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_all = df_pair_merge\n",
    "else:\n",
    "    df_pair_all = df_pair_ety\n",
    "\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()\n",
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cemiyetine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hatırlayın</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>askerlerin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hissetti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>istifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>şükür</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>ziyaretime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>cepheyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>cesetten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>kederini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main\n",
       "0         cemiyetine\n",
       "1         hatırlayın\n",
       "2         askerlerin\n",
       "3           hissetti\n",
       "4             istifa\n",
       "...              ...\n",
       "5792           şükür\n",
       "5793      ziyaretime\n",
       "5794         cepheyi\n",
       "5795        cesetten\n",
       "5796        kederini\n",
       "\n",
       "[5797 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    '''\n",
    "    remove_repetition(word_group): detect word repetion in word group \n",
    "    '''\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, word_thresh_num is an integer, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, word_thresh_num, column_list):\\n\n",
    "    df is a dataframe, word_thresh_num is an integer, column_list is df column names\\n\n",
    "    word_count_bool(df, 7, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4):\n",
    "    '''\n",
    "    default parameter:\\n    \n",
    "    condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4) \\n\n",
    "    word_end 28/4 = 7 word group\n",
    "    '''\n",
    "\n",
    "    # while loop code block word and twogram pair\n",
    "    word_thresh_num = thresh_num  # want how many word sample \n",
    "    word_start = word_start_num  # 0\n",
    "    word_end = int((word_limit_num-word_start_num)/total_part_num)  \n",
    "    step_num = word_end  \n",
    "    word_limit = word_limit_num   \n",
    "    part_num = 1  # first output file extention\n",
    "    \n",
    "    #twogram_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "    twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "    \n",
    "    while word_end <= word_limit:\n",
    "        df_word = df_word_all.iloc[word_start:word_end,]  # must be include word and frequency column\n",
    "        df_word.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        # language pair twogram\n",
    "        word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "        word_list = df_word[\"word\"].to_list()  # *****    \n",
    "        ngram_list = []\n",
    "        for i in word_pair_list:\n",
    "            for j in word_tokenize(i):\n",
    "                for k in word_list:\n",
    "                    twogram_1_2 = f\"{j} {k}\"\n",
    "                    ngram_list.append(twogram_1_2)\n",
    "                    twogram_2_1 = f\"{k} {j}\"\n",
    "                    ngram_list.append(twogram_2_1)\n",
    "        df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "        #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # ******\n",
    "        df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "        df_pair_ngram.drop_duplicates(inplace=True)\n",
    "        df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "        df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "        df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "        df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "        #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    \n",
    "        # output\n",
    "        df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "    \n",
    "        df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "        a = 0\n",
    "        #for i in range(0,110):\n",
    "        for i in range(len(df_output_result)):  # *****\n",
    "            # Insert words and their count \n",
    "            try:\n",
    "                word = df_output_result.iloc[i,0]  # word \n",
    "                freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "                df_lesson_result.loc[i,\"word\"] = word\n",
    "                df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Insert twogram pair\n",
    "            try:\n",
    "                var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    try:\n",
    "                        while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                            a += 1\n",
    "                            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                            df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                            df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            a += 1\n",
    "    \n",
    "        df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "        df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "        df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "        df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "    \n",
    "        word_start += step_num\n",
    "        word_end += step_num\n",
    "        part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameter Part ---\n",
    "\n",
    "# condition 1\n",
    "condition1_word_start = 0\n",
    "condition1_word_limit = 28\n",
    "condition1_word_thresh_num = 2\n",
    "condition1_total_part_num = 4  # 28/4 = 7 word group\n",
    "\n",
    "# condition 2\n",
    "condition1_dependency = True  # True, False\n",
    "word_thresh_num = 2\n",
    "twogram_thresh_minus = 0  # for optional twogram thresh number \n",
    "twogram_pair_thresh_minus = 0  # for optinal twogram pair thresh number.\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = condition1_word_limit  # condition1_word_limit must be equal word_end (condition2 parameter)\n",
    "step_num = word_end  # 10\n",
    "word_limit = word_end  # 200\n",
    "part_num = 1\n",
    "    \n",
    "if condition1_dependency:        \n",
    "    # Read previous part result\n",
    "    condition1(word_start_num = condition1_word_start, word_limit_num = condition1_word_limit, thresh_num = condition1_word_thresh_num, total_part_num = condition1_total_part_num)  # word_end 28/4 = 7 word group. Condition 1 parameters \n",
    "    df_part_all = pd.DataFrame()\n",
    "    part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_*_Word_Step_*_Result*.xlsx\")\n",
    "    for i in part_result_file:\n",
    "        df_var = pd.read_excel(f\"{i}\")\n",
    "        df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "    df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "    df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "    set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "else:\n",
    "    set_part_twogram_pair = set([])  # option for skip Condition 1\n",
    "# --- Parameter End ---\n",
    "\n",
    "# while loop code block\n",
    "\n",
    "twogram_num = word_thresh_num * step_num   # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "    word_list = df_word[\"word\"].to_list()  # ***** \n",
    "    ngram_list = []\n",
    "    for i in word_pair_list:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in word_list:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "    #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # *****\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = pd.DataFrame(result_list2, columns=[f\"{data_kind}\"])  # *****\n",
    "    #df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})  # *****\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(len(df_output_result)):  # *****\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_thresh_minus), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_pair_thresh_minus), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_arabic</th>\n",
       "      <th>freq_twogram_pair_arabic</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>ne dersin</td>\n",
       "      <td>14566</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>evet tamam</td>\n",
       "      <td>10250</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>hatırladın mı</td>\n",
       "      <td>10114</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>hayır değil</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>evet haklısın</td>\n",
       "      <td>8844</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>bu o</td>\n",
       "      <td>17682.0</td>\n",
       "      <td>mümkün değil</td>\n",
       "      <td>8812</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>bu delilik</td>\n",
       "      <td>6370</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>beni dinleyin</td>\n",
       "      <td>5228</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>evet var</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>çok tuhaf</td>\n",
       "      <td>5127</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>sen de</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>ne haber</td>\n",
       "      <td>4951</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>o kadar</td>\n",
       "      <td>7040.0</td>\n",
       "      <td>çok basit</td>\n",
       "      <td>4669</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>evet ama</td>\n",
       "      <td>6846.0</td>\n",
       "      <td>elbette hayır</td>\n",
       "      <td>4595</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>bir daha</td>\n",
       "      <td>5168.0</td>\n",
       "      <td>o haklı</td>\n",
       "      <td>3719</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>ve sen</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>ben hazırım</td>\n",
       "      <td>3699</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>bana mı</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>ve ben</td>\n",
       "      <td>2970</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>bir şey</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>zamanımız yok</td>\n",
       "      <td>2552</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>bana da</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>ver bana</td>\n",
       "      <td>2121</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>elimde değil</td>\n",
       "      <td>2007</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>daha çok</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>bir kazaydı</td>\n",
       "      <td>1933</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>ama yok</td>\n",
       "      <td>927.0</td>\n",
       "      <td>o halde</td>\n",
       "      <td>1767</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>bunu da</td>\n",
       "      <td>717.0</td>\n",
       "      <td>acelem var</td>\n",
       "      <td>1714</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>ve bunu</td>\n",
       "      <td>492.0</td>\n",
       "      <td>zaman yok</td>\n",
       "      <td>1693</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>çok yok</td>\n",
       "      <td>93.0</td>\n",
       "      <td>bir hediye</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>seni beni</td>\n",
       "      <td>7.0</td>\n",
       "      <td>dinleyin beni</td>\n",
       "      <td>1129</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>beni seni</td>\n",
       "      <td>4.0</td>\n",
       "      <td>misafirimiz var</td>\n",
       "      <td>990</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen hariç</td>\n",
       "      <td>947</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen harikasın</td>\n",
       "      <td>923</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama anne</td>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hediye mi</td>\n",
       "      <td>819</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tamam ama</td>\n",
       "      <td>709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni şerefsiz</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tehlikeli mi</td>\n",
       "      <td>687</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hakla onu</td>\n",
       "      <td>668</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onu dinle</td>\n",
       "      <td>491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lanet şey</td>\n",
       "      <td>482</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bana ait</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seni hain</td>\n",
       "      <td>464</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rüya gibi</td>\n",
       "      <td>386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve şey</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunu anlarım</td>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunu hatırla</td>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aşk için</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fıstık gibi</td>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tabiki de</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha fazlasını</td>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha kuvvetli</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haklı da</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zafer için</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tam da</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elveda de</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zerre kadar</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word      twogram freq_twogram twogram_pair_arabic  \\\n",
       "0     bir  18835735.0       ne var      62532.0            hayır mı   \n",
       "1      bu  11062659.0       ben de      59972.0            bu kadar   \n",
       "2      ne   8025880.0     değil mi      58386.0           ne dersin   \n",
       "3      ve   7766036.0       ben mi      33652.0          evet tamam   \n",
       "4    için   5484109.0      ne için      31857.0       hatırladın mı   \n",
       "5      mi   5362714.0  hayır değil      18740.0       evet haklısın   \n",
       "6       o   5013838.0         bu o      17682.0        mümkün değil   \n",
       "7     ben   4908913.0     hayır mı      15769.0          bu delilik   \n",
       "8      de   4880315.0     bu kadar      15745.0       beni dinleyin   \n",
       "9     çok   4852169.0     evet var      11138.0           çok tuhaf   \n",
       "10    ama   4661966.0       sen de      10089.0            ne haber   \n",
       "11    var   4389551.0      o kadar       7040.0           çok basit   \n",
       "12   evet   4324786.0     evet ama       6846.0       elbette hayır   \n",
       "13     mı   4001316.0     bir daha       5168.0             o haklı   \n",
       "14  değil   3883885.0       ve sen       4648.0         ben hazırım   \n",
       "15     da   3610161.0      bana mı       3593.0              ve ben   \n",
       "16    şey   3602024.0      bir şey       1611.0       zamanımız yok   \n",
       "17  hayır   3406992.0      bana da       1498.0            ver bana   \n",
       "18   daha   3317577.0     şey gibi       1314.0        elimde değil   \n",
       "19    sen   3283654.0     daha çok       1129.0         bir kazaydı   \n",
       "20  kadar   2697900.0      ama yok        927.0             o halde   \n",
       "21   bana   2659182.0      bunu da        717.0          acelem var   \n",
       "22    yok   2491685.0      ve bunu        492.0           zaman yok   \n",
       "23    onu   2486889.0      çok yok         93.0          bir hediye   \n",
       "24   seni   2454988.0    seni beni          7.0       dinleyin beni   \n",
       "25   beni   2446696.0    beni seni          4.0     misafirimiz var   \n",
       "26   bunu   2445337.0          NaN          NaN           sen hariç   \n",
       "27   gibi   2427957.0          NaN          NaN       sen harikasın   \n",
       "28    NaN         NaN          NaN          NaN            ama anne   \n",
       "29    NaN         NaN          NaN          NaN           hediye mi   \n",
       "30    NaN         NaN          NaN          NaN           tamam ama   \n",
       "31    NaN         NaN          NaN          NaN       seni şerefsiz   \n",
       "32    NaN         NaN          NaN          NaN        tehlikeli mi   \n",
       "33    NaN         NaN          NaN          NaN           hakla onu   \n",
       "34    NaN         NaN          NaN          NaN           onu dinle   \n",
       "35    NaN         NaN          NaN          NaN           lanet şey   \n",
       "36    NaN         NaN          NaN          NaN            bana ait   \n",
       "37    NaN         NaN          NaN          NaN           seni hain   \n",
       "38    NaN         NaN          NaN          NaN           rüya gibi   \n",
       "39    NaN         NaN          NaN          NaN              ve şey   \n",
       "40    NaN         NaN          NaN          NaN        bunu anlarım   \n",
       "41    NaN         NaN          NaN          NaN        bunu hatırla   \n",
       "42    NaN         NaN          NaN          NaN            aşk için   \n",
       "43    NaN         NaN          NaN          NaN         fıstık gibi   \n",
       "44    NaN         NaN          NaN          NaN           tabiki de   \n",
       "45    NaN         NaN          NaN          NaN      daha fazlasını   \n",
       "46    NaN         NaN          NaN          NaN       daha kuvvetli   \n",
       "47    NaN         NaN          NaN          NaN            haklı da   \n",
       "48    NaN         NaN          NaN          NaN          zafer için   \n",
       "49    NaN         NaN          NaN          NaN              tam da   \n",
       "50    NaN         NaN          NaN          NaN           elveda de   \n",
       "51    NaN         NaN          NaN          NaN         zerre kadar   \n",
       "52    NaN         NaN          NaN          NaN                 NaN   \n",
       "\n",
       "   freq_twogram_pair_arabic  word_count  \n",
       "0                     15769         4.0  \n",
       "1                     15745         4.0  \n",
       "2                     14566         4.0  \n",
       "3                     10250         4.0  \n",
       "4                     10114         3.0  \n",
       "5                      8844         4.0  \n",
       "6                      8812         4.0  \n",
       "7                      6370         4.0  \n",
       "8                      5228         4.0  \n",
       "9                      5127         4.0  \n",
       "10                     4951         4.0  \n",
       "11                     4669         4.0  \n",
       "12                     4595         4.0  \n",
       "13                     3719         4.0  \n",
       "14                     3699         4.0  \n",
       "15                     2970         4.0  \n",
       "16                     2552         4.0  \n",
       "17                     2121         4.0  \n",
       "18                     2007         4.0  \n",
       "19                     1933         4.0  \n",
       "20                     1767         4.0  \n",
       "21                     1714         4.0  \n",
       "22                     1693         4.0  \n",
       "23                     1225         2.0  \n",
       "24                     1129         4.0  \n",
       "25                      990         4.0  \n",
       "26                      947         4.0  \n",
       "27                      923         3.0  \n",
       "28                      894         NaN  \n",
       "29                      819         NaN  \n",
       "30                      709         NaN  \n",
       "31                      700         NaN  \n",
       "32                      687         NaN  \n",
       "33                      668         NaN  \n",
       "34                      491         NaN  \n",
       "35                      482         NaN  \n",
       "36                      476         NaN  \n",
       "37                      464         NaN  \n",
       "38                      386         NaN  \n",
       "39                      326         NaN  \n",
       "40                      322         NaN  \n",
       "41                      238         NaN  \n",
       "42                      198         NaN  \n",
       "43                      191         NaN  \n",
       "44                      185         NaN  \n",
       "45                      172         NaN  \n",
       "46                      161         NaN  \n",
       "47                      153         NaN  \n",
       "48                      132         NaN  \n",
       "49                      128         NaN  \n",
       "50                       60         NaN  \n",
       "51                       36         NaN  \n",
       "52                      NaN         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var.to_excel(writer, sheet_name=f'Word_Part1{i}', index=False)            \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_part_var2.to_excel(writer, sheet_name=f'Word_Part21', index=False)        \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var_order = word_in_twogram(df_part_var, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "            df_part_var_order_join = df_part_var_order.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "            df_part_var_order_join.to_excel(writer2, sheet_name=f'Word_Part1{i}', index=False)          \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_word_order_21 = word_in_twogram(df_part_var2, \"word\", f\"twogram\")\n",
    "df_word_order_212 = word_in_twogram(df_part_var2, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)        \n",
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_Arabic_28_Word_Step_7_Result1.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result2.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result3.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result4.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_28_Result1.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Result_With_Frequency.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Join_Result_Without_Frequency.xlsx']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
