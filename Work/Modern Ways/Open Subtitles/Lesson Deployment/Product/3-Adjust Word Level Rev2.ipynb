{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # True for adding prefix suffix word\n",
    "\n",
    "# word frequency\n",
    "word_frequency = True  # True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988212</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988213</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988214</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988215</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988216</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "988212     karneleme          5\n",
       "988213       karnaya          5\n",
       "988214   dörtlümüzün          5\n",
       "988215  karnavalınız          5\n",
       "988216      hurmanın          5\n",
       "\n",
       "[988217 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blockade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorbe</td>\n",
       "      <td>absorb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absürt</td>\n",
       "      <td>absurd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>açelya</td>\n",
       "      <td>azalea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zikzak</td>\n",
       "      <td>zigzag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zooloji</td>\n",
       "      <td>zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zum</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main english_word\n",
       "0             abaküs       abacus\n",
       "1             abluka     blockade\n",
       "2            absorbe       absorb\n",
       "3             absürt       absurd\n",
       "4             açelya       azalea\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zikzak       zigzag\n",
       "1775           zombi       zombie\n",
       "1776         zooloji      zoology\n",
       "1777             zum         zoom\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_pair_ety = pd.read_excel(f\"{lang_pair_list[0]}\")  # need only dict_entry_main column\n",
    "df_pair_ety = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair_ety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blockade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorbe</td>\n",
       "      <td>absorb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absürt</td>\n",
       "      <td>absurd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>açelya</td>\n",
       "      <td>azalea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zikzak</td>\n",
       "      <td>zigzag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zooloji</td>\n",
       "      <td>zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zum</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main english_word\n",
       "0             abaküs       abacus\n",
       "1             abluka     blockade\n",
       "2            absorbe       absorb\n",
       "3             absürt       absurd\n",
       "4             açelya       azalea\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zikzak       zigzag\n",
       "1775           zombi       zombie\n",
       "1776         zooloji      zoology\n",
       "1777             zum         zoom\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_merge = pd.merge(df_pair_ety,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair_merge.drop_duplicates(inplace=True)\n",
    "    df_pair_merge.reset_index(drop=True, inplace=True)\n",
    "    df_pair_merge = df_pair_merge.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair_merge.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_all = df_pair_merge\n",
    "else:\n",
    "    df_pair_all = df_pair_ety\n",
    "\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()\n",
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hokus pokus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>totaliter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dolar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dinamit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>printer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>mobil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>bisküvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>hemoroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>hangar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main\n",
       "0        hokus pokus\n",
       "1          totaliter\n",
       "2              dolar\n",
       "3               repo\n",
       "4            dinamit\n",
       "...              ...\n",
       "1771         printer\n",
       "1772           mobil\n",
       "1773         bisküvi\n",
       "1774        hemoroid\n",
       "1775          hangar\n",
       "\n",
       "[1776 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    '''\n",
    "    remove_repetition(word_group): detect word repetion in word group \n",
    "    '''\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, word_thresh_num is an integer, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, word_thresh_num, column_list):\\n\n",
    "    df is a dataframe, word_thresh_num is an integer, column_list is df column names\\n\n",
    "    word_count_bool(df, 7, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4):\n",
    "    '''\n",
    "    default parameter:\\n    \n",
    "    condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4) \\n\n",
    "    word_end 28/4 = 7 word group\n",
    "    '''\n",
    "\n",
    "    # while loop code block word and twogram pair\n",
    "    word_thresh_num = thresh_num  # want how many word sample \n",
    "    word_start = word_start_num  # 0\n",
    "    word_end = int((word_limit_num-word_start_num)/total_part_num)  \n",
    "    step_num = word_end  \n",
    "    word_limit = word_limit_num   \n",
    "    part_num = 1  # first output file extention\n",
    "    \n",
    "    #twogram_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "    twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "    \n",
    "    while word_end <= word_limit:\n",
    "        df_word = df_word_all.iloc[word_start:word_end,]  # must be include word and frequency column\n",
    "        df_word.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        # language pair twogram\n",
    "        word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "        word_list = df_word[\"word\"].to_list()  # *****    \n",
    "        ngram_list = []\n",
    "        for i in word_pair_list:\n",
    "            for j in word_tokenize(i):\n",
    "                for k in word_list:\n",
    "                    twogram_1_2 = f\"{j} {k}\"\n",
    "                    ngram_list.append(twogram_1_2)\n",
    "                    twogram_2_1 = f\"{k} {j}\"\n",
    "                    ngram_list.append(twogram_2_1)\n",
    "        df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "        #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # ******\n",
    "        df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "        df_pair_ngram.drop_duplicates(inplace=True)\n",
    "        df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "        df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "        df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "        df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "        #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    \n",
    "        # output\n",
    "        df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "    \n",
    "        df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "        a = 0\n",
    "        #for i in range(0,110):\n",
    "        for i in range(len(df_output_result)):  # *****\n",
    "            # Insert words and their count \n",
    "            try:\n",
    "                word = df_output_result.iloc[i,0]  # word \n",
    "                freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "                df_lesson_result.loc[i,\"word\"] = word\n",
    "                df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Insert twogram pair\n",
    "            try:\n",
    "                var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    try:\n",
    "                        while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                            a += 1\n",
    "                            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                            df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                            df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            a += 1\n",
    "    \n",
    "        df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "        df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "        df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "        df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "    \n",
    "        word_start += step_num\n",
    "        word_end += step_num\n",
    "        part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameter Part ---\n",
    "\n",
    "# condition 1\n",
    "condition1_word_start = 0\n",
    "condition1_word_limit = 28\n",
    "condition1_word_thresh_num = 2\n",
    "condition1_total_part_num = 4  # 28/4 = 7 word group\n",
    "\n",
    "# condition 2\n",
    "condition1_dependency = True  # True, False\n",
    "word_thresh_num = 20\n",
    "twogram_thresh_minus = 0  # for optional twogram thresh number \n",
    "twogram_pair_thresh_minus = 0  # for optinal twogram pair thresh number.\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = condition1_word_limit  # condition1_word_limit must be equal word_end (condition2 parameter)\n",
    "step_num = word_end  # 10\n",
    "word_limit = word_end  # 200\n",
    "part_num = 1\n",
    "    \n",
    "if condition1_dependency:        \n",
    "    # Read previous part result\n",
    "    condition1(word_start_num = condition1_word_start, word_limit_num = condition1_word_limit, thresh_num = condition1_word_thresh_num, total_part_num = condition1_total_part_num)  # word_end 28/4 = 7 word group. Condition 1 parameters \n",
    "    df_part_all = pd.DataFrame()\n",
    "    part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_*_Word_Step_*_Result*.xlsx\")\n",
    "    for i in part_result_file:\n",
    "        df_var = pd.read_excel(f\"{i}\")\n",
    "        df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "    df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "    df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "    set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "else:\n",
    "    set_part_twogram_pair = set([])  # option for skip Condition 1\n",
    "# --- Parameter End ---\n",
    "\n",
    "# while loop code block\n",
    "\n",
    "twogram_num = word_thresh_num * step_num   # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "    word_list = df_word[\"word\"].to_list()  # ***** \n",
    "    ngram_list = []\n",
    "    for i in word_pair_list:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in word_list:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "    #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # *****\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = pd.DataFrame(result_list2, columns=[f\"{data_kind}\"])  # *****\n",
    "    #df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})  # *****\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(len(df_output_result)):  # *****\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_thresh_minus), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_pair_thresh_minus), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "      <th>freq_twogram_pair_english</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>çok komik</td>\n",
       "      <td>13097</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>polis mi</td>\n",
       "      <td>2526</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>komik değil</td>\n",
       "      <td>1785</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>problem değil</td>\n",
       "      <td>1678</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>evet patron</td>\n",
       "      <td>1476</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politika da</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen maestro</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sen doktora</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sauna da</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word   twogram freq_twogram twogram_pair_english  \\\n",
       "0     bir  18835735.0    ne var      62532.0            çok komik   \n",
       "1      bu  11062659.0    ben de      59972.0             polis mi   \n",
       "2      ne   8025880.0  değil mi      58386.0          komik değil   \n",
       "3      ve   7766036.0    ben mi      33652.0        problem değil   \n",
       "4    için   5484109.0   ne için      31857.0          evet patron   \n",
       "..    ...         ...       ...          ...                  ...   \n",
       "470   NaN         NaN       NaN          NaN          politika da   \n",
       "471   NaN         NaN       NaN          NaN          sen maestro   \n",
       "472   NaN         NaN       NaN          NaN          sen doktora   \n",
       "473   NaN         NaN       NaN          NaN             sauna da   \n",
       "474   NaN         NaN       NaN          NaN                  NaN   \n",
       "\n",
       "    freq_twogram_pair_english  word_count  \n",
       "0                       13097        40.0  \n",
       "1                        2526        40.0  \n",
       "2                        1785        40.0  \n",
       "3                        1678        40.0  \n",
       "4                        1476        25.0  \n",
       "..                        ...         ...  \n",
       "470                         3         NaN  \n",
       "471                         3         NaN  \n",
       "472                         3         NaN  \n",
       "473                         3         NaN  \n",
       "474                       NaN         NaN  \n",
       "\n",
       "[475 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var.to_excel(writer, sheet_name=f'Word_Part1{i}', index=False)            \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_part_var2.to_excel(writer, sheet_name=f'Word_Part21', index=False)        \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if word_frequency:\n",
    "        writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_With_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    else:\n",
    "        writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var_order = word_in_twogram(df_part_var, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "            df_part_var_order_join = df_part_var_order.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "            df_part_var_order_join.to_excel(writer2, sheet_name=f'Word_Part1{i}', index=False)          \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_word_order_21 = word_in_twogram(df_part_var2, \"word\", f\"twogram\")\n",
    "df_word_order_212 = word_in_twogram(df_part_var2, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)        \n",
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>evet ama, ama ben, ama ne, ama bu, ama sen, ha...</td>\n",
       "      <td>pardon ama, ama doktor, ama şef, ama patron, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana mı, bana ne, bana da, bana değil, bu bana...</td>\n",
       "      <td>telefon bana, vay bana, bana kahve, bana bira,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben de, ben mi, hayır ben, ama ben, ben değil,...</td>\n",
       "      <td>pardon ben, ben ray, ben kaptan, ben doktor, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>beni mi, beni de, beni değil, ve beni, sen ben...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir daha, bir ne, bu bir, bir şey, bir de, o b...</td>\n",
       "      <td>bir numara, bir polis, bir milyon, bir bebek, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...</td>\n",
       "      <td>bu komik, bu normal, plan bu, bu süper, bu müz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bunu</td>\n",
       "      <td>bunu da, ve bunu, ben bunu, bunu değil, bunu i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>da</td>\n",
       "      <td>bu da, bana da, o da, bunu da, onu da, daha da...</td>\n",
       "      <td>pardon da, pantolon da, telefon da, kanal da, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daha</td>\n",
       "      <td>daha değil, bir daha, daha çok, daha var, daha...</td>\n",
       "      <td>daha bebek, daha dramatik, daha romantik, daha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de</td>\n",
       "      <td>ben de, sen de, seni de, bir de, evet de, beni...</td>\n",
       "      <td>bebek de, komik de, alo de, patates de, polis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>değil</td>\n",
       "      <td>değil mi, hayır değil, daha değil, ben değil, ...</td>\n",
       "      <td>komik değil, problem değil, normal değil, poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>evet var, evet ama, evet o, evet mi, evet ben,...</td>\n",
       "      <td>evet patron, evet kaptan, evet doktor, evet ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gibi</td>\n",
       "      <td>ne gibi, şey gibi, gibi mi, yok gibi, var gibi...</td>\n",
       "      <td>bomba gibi, bebek gibi, kanser gibi, makine gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hayır</td>\n",
       "      <td>hayır değil, hayır mı, hayır yok, hayır ben, y...</td>\n",
       "      <td>hayır doktor, hayır madam, hayır patron, hayır...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>için</td>\n",
       "      <td>ne için, şey için, bunu için, için mi, yok için</td>\n",
       "      <td>şans için, bebek için, parti için, okul için, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kadar</td>\n",
       "      <td>ne kadar, bu kadar, o kadar, kadar mı</td>\n",
       "      <td>ahtapot kadar, karavan kadar, avokado kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mi</td>\n",
       "      <td>değil mi, ben mi, sen mi, evet mi, beni mi, ne...</td>\n",
       "      <td>polis mi, bebek mi, komik mi, parti mi, kahve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mı</td>\n",
       "      <td>hayır mı, bana mı, var mı, daha mı, ama mı, ka...</td>\n",
       "      <td>plan mı, bomba mı, dans mı, şans mı, avukat mı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne var, ne için, bu ne, ne kadar, ne gibi, o n...</td>\n",
       "      <td>ne komik, plan ne, problem ne, şifre ne, ne şa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>o</td>\n",
       "      <td>bu o, o ne, o kadar, evet o, ne o, o değil, am...</td>\n",
       "      <td>patron o, o polis, o doktor, kaptan o, o norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>onu</td>\n",
       "      <td>onu değil, onu da, ben onu, ve onu, sen onu, o...</td>\n",
       "      <td>as onu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sen</td>\n",
       "      <td>sen de, sen mi, ve sen, evet sen, sen ne, sen ...</td>\n",
       "      <td>pardon sen, tipik sen, sen doktor, bar sen, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>seni</td>\n",
       "      <td>seni de, seni mi, seni değil, ben seni, seni o...</td>\n",
       "      <td>seni manyak, seni çakal, seni moron, seni embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>var</td>\n",
       "      <td>ne var, evet var, var mı, hayır var, ama var, ...</td>\n",
       "      <td>bomba var, telefon var, parti var, bebek var, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve sen, ve ben, ve bu, ve ne, ve o, ve evet, v...</td>\n",
       "      <td>ve motor, ve gol, ve bebek, ve müzik, ve komik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yok</td>\n",
       "      <td>hayır yok, yok hayır, ama yok, evet yok, yok b...</td>\n",
       "      <td>problem yok, sinyal yok, telefon yok, polis yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>çok</td>\n",
       "      <td>bu çok, çok değil, daha çok, evet çok, sen çok...</td>\n",
       "      <td>çok komik, çok şeker, çok romantik, çok entere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>şey</td>\n",
       "      <td>şey ben, şey evet, evet şey, ben şey, bir şey,...</td>\n",
       "      <td>komik şey, şeker şey, şey pardon, şey general,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                                            twogram  \\\n",
       "0     ama  evet ama, ama ben, ama ne, ama bu, ama sen, ha...   \n",
       "1    bana  bana mı, bana ne, bana da, bana değil, bu bana...   \n",
       "2     ben  ben de, ben mi, hayır ben, ama ben, ben değil,...   \n",
       "3    beni  beni mi, beni de, beni değil, ve beni, sen ben...   \n",
       "4     bir  bir daha, bir ne, bu bir, bir şey, bir de, o b...   \n",
       "5      bu  bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...   \n",
       "6    bunu  bunu da, ve bunu, ben bunu, bunu değil, bunu i...   \n",
       "7      da  bu da, bana da, o da, bunu da, onu da, daha da...   \n",
       "8    daha  daha değil, bir daha, daha çok, daha var, daha...   \n",
       "9      de  ben de, sen de, seni de, bir de, evet de, beni...   \n",
       "10  değil  değil mi, hayır değil, daha değil, ben değil, ...   \n",
       "11   evet  evet var, evet ama, evet o, evet mi, evet ben,...   \n",
       "12   gibi  ne gibi, şey gibi, gibi mi, yok gibi, var gibi...   \n",
       "13  hayır  hayır değil, hayır mı, hayır yok, hayır ben, y...   \n",
       "14   için    ne için, şey için, bunu için, için mi, yok için   \n",
       "15  kadar              ne kadar, bu kadar, o kadar, kadar mı   \n",
       "16     mi  değil mi, ben mi, sen mi, evet mi, beni mi, ne...   \n",
       "17     mı  hayır mı, bana mı, var mı, daha mı, ama mı, ka...   \n",
       "18     ne  ne var, ne için, bu ne, ne kadar, ne gibi, o n...   \n",
       "19      o  bu o, o ne, o kadar, evet o, ne o, o değil, am...   \n",
       "20    onu  onu değil, onu da, ben onu, ve onu, sen onu, o...   \n",
       "21    sen  sen de, sen mi, ve sen, evet sen, sen ne, sen ...   \n",
       "22   seni  seni de, seni mi, seni değil, ben seni, seni o...   \n",
       "23    var  ne var, evet var, var mı, hayır var, ama var, ...   \n",
       "24     ve  ve sen, ve ben, ve bu, ve ne, ve o, ve evet, v...   \n",
       "25    yok  hayır yok, yok hayır, ama yok, evet yok, yok b...   \n",
       "26    çok  bu çok, çok değil, daha çok, evet çok, sen çok...   \n",
       "27    şey  şey ben, şey evet, evet şey, ben şey, bir şey,...   \n",
       "\n",
       "                                 twogram_pair_english  \n",
       "0   pardon ama, ama doktor, ama şef, ama patron, k...  \n",
       "1   telefon bana, vay bana, bana kahve, bana bira,...  \n",
       "2   pardon ben, ben ray, ben kaptan, ben doktor, k...  \n",
       "3                                                 NaN  \n",
       "4   bir numara, bir polis, bir milyon, bir bebek, ...  \n",
       "5   bu komik, bu normal, plan bu, bu süper, bu müz...  \n",
       "6                                                 NaN  \n",
       "7   pardon da, pantolon da, telefon da, kanal da, ...  \n",
       "8   daha bebek, daha dramatik, daha romantik, daha...  \n",
       "9   bebek de, komik de, alo de, patates de, polis ...  \n",
       "10  komik değil, problem değil, normal değil, poli...  \n",
       "11  evet patron, evet kaptan, evet doktor, evet ma...  \n",
       "12  bomba gibi, bebek gibi, kanser gibi, makine gi...  \n",
       "13  hayır doktor, hayır madam, hayır patron, hayır...  \n",
       "14  şans için, bebek için, parti için, okul için, ...  \n",
       "15        ahtapot kadar, karavan kadar, avokado kadar  \n",
       "16  polis mi, bebek mi, komik mi, parti mi, kahve ...  \n",
       "17  plan mı, bomba mı, dans mı, şans mı, avukat mı...  \n",
       "18  ne komik, plan ne, problem ne, şifre ne, ne şa...  \n",
       "19  patron o, o polis, o doktor, kaptan o, o norma...  \n",
       "20                                             as onu  \n",
       "21  pardon sen, tipik sen, sen doktor, bar sen, se...  \n",
       "22  seni manyak, seni çakal, seni moron, seni embe...  \n",
       "23  bomba var, telefon var, parti var, bebek var, ...  \n",
       "24  ve motor, ve gol, ve bebek, ve müzik, ve komik...  \n",
       "25  problem yok, sinyal yok, telefon yok, polis yo...  \n",
       "26  çok komik, çok şeker, çok romantik, çok entere...  \n",
       "27  komik şey, şeker şey, şey pardon, şey general,...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "      <td>bir daha, bir ne, bu bir, bir şey, bir de, o b...</td>\n",
       "      <td>bir numara, bir polis, bir milyon, bir bebek, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "      <td>bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...</td>\n",
       "      <td>bu komik, bu normal, plan bu, bu süper, bu müz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "      <td>ne var, ne için, bu ne, ne kadar, ne gibi, o n...</td>\n",
       "      <td>ne komik, plan ne, problem ne, şifre ne, ne şa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "      <td>ve sen, ve ben, ve bu, ve ne, ve o, ve evet, v...</td>\n",
       "      <td>ve motor, ve gol, ve bebek, ve müzik, ve komik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "      <td>ne için, şey için, bunu için, için mi, yok için</td>\n",
       "      <td>şans için, bebek için, parti için, okul için, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714</td>\n",
       "      <td>değil mi, ben mi, sen mi, evet mi, beni mi, ne...</td>\n",
       "      <td>polis mi, bebek mi, komik mi, parti mi, kahve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838</td>\n",
       "      <td>bu o, o ne, o kadar, evet o, ne o, o değil, am...</td>\n",
       "      <td>patron o, o polis, o doktor, kaptan o, o norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913</td>\n",
       "      <td>ben de, ben mi, hayır ben, ama ben, ben değil,...</td>\n",
       "      <td>pardon ben, ben ray, ben kaptan, ben doktor, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315</td>\n",
       "      <td>ben de, sen de, seni de, bir de, evet de, beni...</td>\n",
       "      <td>bebek de, komik de, alo de, patates de, polis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169</td>\n",
       "      <td>bu çok, çok değil, daha çok, evet çok, sen çok...</td>\n",
       "      <td>çok komik, çok şeker, çok romantik, çok entere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966</td>\n",
       "      <td>evet ama, ama ben, ama ne, ama bu, ama sen, ha...</td>\n",
       "      <td>pardon ama, ama doktor, ama şef, ama patron, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551</td>\n",
       "      <td>ne var, evet var, var mı, hayır var, ama var, ...</td>\n",
       "      <td>bomba var, telefon var, parti var, bebek var, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786</td>\n",
       "      <td>evet var, evet ama, evet o, evet mi, evet ben,...</td>\n",
       "      <td>evet patron, evet kaptan, evet doktor, evet ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316</td>\n",
       "      <td>hayır mı, bana mı, var mı, daha mı, ama mı, ka...</td>\n",
       "      <td>plan mı, bomba mı, dans mı, şans mı, avukat mı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885</td>\n",
       "      <td>değil mi, hayır değil, daha değil, ben değil, ...</td>\n",
       "      <td>komik değil, problem değil, normal değil, poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161</td>\n",
       "      <td>bu da, bana da, o da, bunu da, onu da, daha da...</td>\n",
       "      <td>pardon da, pantolon da, telefon da, kanal da, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024</td>\n",
       "      <td>şey ben, şey evet, evet şey, ben şey, bir şey,...</td>\n",
       "      <td>komik şey, şeker şey, şey pardon, şey general,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992</td>\n",
       "      <td>hayır değil, hayır mı, hayır yok, hayır ben, y...</td>\n",
       "      <td>hayır doktor, hayır madam, hayır patron, hayır...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577</td>\n",
       "      <td>daha değil, bir daha, daha çok, daha var, daha...</td>\n",
       "      <td>daha bebek, daha dramatik, daha romantik, daha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654</td>\n",
       "      <td>sen de, sen mi, ve sen, evet sen, sen ne, sen ...</td>\n",
       "      <td>pardon sen, tipik sen, sen doktor, bar sen, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900</td>\n",
       "      <td>ne kadar, bu kadar, o kadar, kadar mı</td>\n",
       "      <td>ahtapot kadar, karavan kadar, avokado kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182</td>\n",
       "      <td>bana mı, bana ne, bana da, bana değil, bu bana...</td>\n",
       "      <td>telefon bana, vay bana, bana kahve, bana bira,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685</td>\n",
       "      <td>hayır yok, yok hayır, ama yok, evet yok, yok b...</td>\n",
       "      <td>problem yok, sinyal yok, telefon yok, polis yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889</td>\n",
       "      <td>onu değil, onu da, ben onu, ve onu, sen onu, o...</td>\n",
       "      <td>as onu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988</td>\n",
       "      <td>seni de, seni mi, seni değil, ben seni, seni o...</td>\n",
       "      <td>seni manyak, seni çakal, seni moron, seni embe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696</td>\n",
       "      <td>beni mi, beni de, beni değil, ve beni, sen ben...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337</td>\n",
       "      <td>bunu da, ve bunu, ben bunu, bunu değil, bunu i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957</td>\n",
       "      <td>ne gibi, şey gibi, gibi mi, yok gibi, var gibi...</td>\n",
       "      <td>bomba gibi, bebek gibi, kanser gibi, makine gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency                                            twogram  \\\n",
       "4     bir   18835735  bir daha, bir ne, bu bir, bir şey, bir de, o b...   \n",
       "5      bu   11062659  bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...   \n",
       "18     ne    8025880  ne var, ne için, bu ne, ne kadar, ne gibi, o n...   \n",
       "24     ve    7766036  ve sen, ve ben, ve bu, ve ne, ve o, ve evet, v...   \n",
       "14   için    5484109    ne için, şey için, bunu için, için mi, yok için   \n",
       "16     mi    5362714  değil mi, ben mi, sen mi, evet mi, beni mi, ne...   \n",
       "19      o    5013838  bu o, o ne, o kadar, evet o, ne o, o değil, am...   \n",
       "2     ben    4908913  ben de, ben mi, hayır ben, ama ben, ben değil,...   \n",
       "9      de    4880315  ben de, sen de, seni de, bir de, evet de, beni...   \n",
       "26    çok    4852169  bu çok, çok değil, daha çok, evet çok, sen çok...   \n",
       "0     ama    4661966  evet ama, ama ben, ama ne, ama bu, ama sen, ha...   \n",
       "23    var    4389551  ne var, evet var, var mı, hayır var, ama var, ...   \n",
       "11   evet    4324786  evet var, evet ama, evet o, evet mi, evet ben,...   \n",
       "17     mı    4001316  hayır mı, bana mı, var mı, daha mı, ama mı, ka...   \n",
       "10  değil    3883885  değil mi, hayır değil, daha değil, ben değil, ...   \n",
       "7      da    3610161  bu da, bana da, o da, bunu da, onu da, daha da...   \n",
       "27    şey    3602024  şey ben, şey evet, evet şey, ben şey, bir şey,...   \n",
       "13  hayır    3406992  hayır değil, hayır mı, hayır yok, hayır ben, y...   \n",
       "8    daha    3317577  daha değil, bir daha, daha çok, daha var, daha...   \n",
       "21    sen    3283654  sen de, sen mi, ve sen, evet sen, sen ne, sen ...   \n",
       "15  kadar    2697900              ne kadar, bu kadar, o kadar, kadar mı   \n",
       "1    bana    2659182  bana mı, bana ne, bana da, bana değil, bu bana...   \n",
       "25    yok    2491685  hayır yok, yok hayır, ama yok, evet yok, yok b...   \n",
       "20    onu    2486889  onu değil, onu da, ben onu, ve onu, sen onu, o...   \n",
       "22   seni    2454988  seni de, seni mi, seni değil, ben seni, seni o...   \n",
       "3    beni    2446696  beni mi, beni de, beni değil, ve beni, sen ben...   \n",
       "6    bunu    2445337  bunu da, ve bunu, ben bunu, bunu değil, bunu i...   \n",
       "12   gibi    2427957  ne gibi, şey gibi, gibi mi, yok gibi, var gibi...   \n",
       "\n",
       "                                 twogram_pair_english  \n",
       "4   bir numara, bir polis, bir milyon, bir bebek, ...  \n",
       "5   bu komik, bu normal, plan bu, bu süper, bu müz...  \n",
       "18  ne komik, plan ne, problem ne, şifre ne, ne şa...  \n",
       "24  ve motor, ve gol, ve bebek, ve müzik, ve komik...  \n",
       "14  şans için, bebek için, parti için, okul için, ...  \n",
       "16  polis mi, bebek mi, komik mi, parti mi, kahve ...  \n",
       "19  patron o, o polis, o doktor, kaptan o, o norma...  \n",
       "2   pardon ben, ben ray, ben kaptan, ben doktor, k...  \n",
       "9   bebek de, komik de, alo de, patates de, polis ...  \n",
       "26  çok komik, çok şeker, çok romantik, çok entere...  \n",
       "0   pardon ama, ama doktor, ama şef, ama patron, k...  \n",
       "23  bomba var, telefon var, parti var, bebek var, ...  \n",
       "11  evet patron, evet kaptan, evet doktor, evet ma...  \n",
       "17  plan mı, bomba mı, dans mı, şans mı, avukat mı...  \n",
       "10  komik değil, problem değil, normal değil, poli...  \n",
       "7   pardon da, pantolon da, telefon da, kanal da, ...  \n",
       "27  komik şey, şeker şey, şey pardon, şey general,...  \n",
       "13  hayır doktor, hayır madam, hayır patron, hayır...  \n",
       "8   daha bebek, daha dramatik, daha romantik, daha...  \n",
       "21  pardon sen, tipik sen, sen doktor, bar sen, se...  \n",
       "15        ahtapot kadar, karavan kadar, avokado kadar  \n",
       "1   telefon bana, vay bana, bana kahve, bana bira,...  \n",
       "25  problem yok, sinyal yok, telefon yok, polis yo...  \n",
       "20                                             as onu  \n",
       "22  seni manyak, seni çakal, seni moron, seni embe...  \n",
       "3                                                 NaN  \n",
       "6                                                 NaN  \n",
       "12  bomba gibi, bebek gibi, kanser gibi, makine gi...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21 = pd.merge(df_word_order_join_21, df_word_all, how=\"left\", on=\"word\")\n",
    "df_word_order_join_21.drop_duplicates(inplace=True)\n",
    "df_word_order_join_21 = df_word_order_join_21.iloc[:,[0,3,1,2]]\n",
    "df_word_order_join_21.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_21.to_excel(\"Turkish_English_28_Word_Join_Result_With_Frequency.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_28_Word_Step_28_Result1.xlsx',\n",
       " 'Turkish_English_28_Word_Result_With_Frequency.xlsx',\n",
       " 'Turkish_English_28_Word_Join_Result_Without_Frequency.xlsx']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
