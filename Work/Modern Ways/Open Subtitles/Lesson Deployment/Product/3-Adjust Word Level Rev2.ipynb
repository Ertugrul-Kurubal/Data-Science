{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False  # True for adding prefix suffix word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552149</th>\n",
       "      <td>fruitcocktail</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552150</th>\n",
       "      <td>andthesunlightshining</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552151</th>\n",
       "      <td>upravo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552152</th>\n",
       "      <td>yagawa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552153</th>\n",
       "      <td>foxtrotoscar</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  frequency\n",
       "0                         you  102069964\n",
       "1                           i   94447074\n",
       "2                         the   77481215\n",
       "3                          to   58281119\n",
       "4                          is   50852895\n",
       "...                       ...        ...\n",
       "552149          fruitcocktail          6\n",
       "552150  andthesunlightshining          6\n",
       "552151                 upravo          6\n",
       "552152                 yagawa          6\n",
       "552153           foxtrotoscar          6\n",
       "\n",
       "[552154 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>come on</td>\n",
       "      <td>1347415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank you</td>\n",
       "      <td>1222974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all right</td>\n",
       "      <td>946314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know</td>\n",
       "      <td>459647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excuse me</td>\n",
       "      <td>385487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726241</th>\n",
       "      <td>gwen turning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726242</th>\n",
       "      <td>gwen wait</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726243</th>\n",
       "      <td>fucking xactos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726244</th>\n",
       "      <td>fucking yellow</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726245</th>\n",
       "      <td>savio please</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>726246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               twogram  frequency\n",
       "0              come on    1347415\n",
       "1            thank you    1222974\n",
       "2            all right     946314\n",
       "3               i know     459647\n",
       "4            excuse me     385487\n",
       "...                ...        ...\n",
       "726241    gwen turning          4\n",
       "726242       gwen wait          4\n",
       "726243  fucking xactos          4\n",
       "726244  fucking yellow          4\n",
       "726245    savio please          4\n",
       "\n",
       "[726246 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>turkish_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abaküs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blockade</td>\n",
       "      <td>abluka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorb</td>\n",
       "      <td>absorbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absurd</td>\n",
       "      <td>absürt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>azalea</td>\n",
       "      <td>açelya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>zikzak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombie</td>\n",
       "      <td>zombi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zoology</td>\n",
       "      <td>zooloji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zoom</td>\n",
       "      <td>zum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main turkish_word\n",
       "0             abacus       abaküs\n",
       "1           blockade       abluka\n",
       "2             absorb      absorbe\n",
       "3             absurd       absürt\n",
       "4             azalea       açelya\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zigzag       zikzak\n",
       "1775          zombie        zombi\n",
       "1776         zoology      zooloji\n",
       "1777            zoom          zum\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_pair_ety = pd.read_excel(f\"{lang_pair_list[0]}\")  # need only dict_entry_main column\n",
    "df_pair_ety = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair_ety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>turkish_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abacus</td>\n",
       "      <td>abaküs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blockade</td>\n",
       "      <td>abluka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorb</td>\n",
       "      <td>absorbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absurd</td>\n",
       "      <td>absürt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>azalea</td>\n",
       "      <td>açelya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>zikzak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombie</td>\n",
       "      <td>zombi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zoology</td>\n",
       "      <td>zooloji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zoom</td>\n",
       "      <td>zum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main turkish_word\n",
       "0             abacus       abaküs\n",
       "1           blockade       abluka\n",
       "2             absorb      absorbe\n",
       "3             absurd       absürt\n",
       "4             azalea       açelya\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zigzag       zikzak\n",
       "1775          zombie        zombi\n",
       "1776         zoology      zooloji\n",
       "1777            zoom          zum\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_merge = pd.merge(df_pair_ety,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair_merge.drop_duplicates(inplace=True)\n",
    "    df_pair_merge.reset_index(drop=True, inplace=True)\n",
    "    df_pair_merge = df_pair_merge.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair_merge.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_all = df_pair_merge\n",
    "else:\n",
    "    df_pair_all = df_pair_ety\n",
    "\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()\n",
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manipulate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lavender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>ace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>disinfectant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>route</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>tanker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main\n",
       "0             anemia\n",
       "1         manipulate\n",
       "2            offside\n",
       "3           lavender\n",
       "4            station\n",
       "...              ...\n",
       "1735             ace\n",
       "1736        solution\n",
       "1737    disinfectant\n",
       "1738           route\n",
       "1739          tanker\n",
       "\n",
       "[1740 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    '''\n",
    "    remove_repetition(word_group): detect word repetion in word group \n",
    "    '''\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, word_thresh_num is an integer, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, word_thresh_num, column_list):\\n\n",
    "    df is a dataframe, word_thresh_num is an integer, column_list is df column names\\n\n",
    "    word_count_bool(df, 7, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4):\n",
    "    '''\n",
    "    default parameter:\\n    \n",
    "    condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4) \\n\n",
    "    word_end 28/4 = 7 word group\n",
    "    '''\n",
    "\n",
    "    # while loop code block word and twogram pair\n",
    "    word_thresh_num = thresh_num  # want how many word sample \n",
    "    word_start = word_start_num  # 0\n",
    "    word_end = int((word_limit_num-word_start_num)/total_part_num)  \n",
    "    step_num = word_end  \n",
    "    word_limit = word_limit_num   \n",
    "    part_num = 1  # first output file extention\n",
    "    \n",
    "    #twogram_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "    twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "    \n",
    "    while word_end <= word_limit:\n",
    "        df_word = df_word_all.iloc[word_start:word_end,]  # must be include word and frequency column\n",
    "        df_word.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        # language pair twogram\n",
    "        word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "        word_list = df_word[\"word\"].to_list()  # *****    \n",
    "        ngram_list = []\n",
    "        for i in word_pair_list:\n",
    "            for j in word_tokenize(i):\n",
    "                for k in word_list:\n",
    "                    twogram_1_2 = f\"{j} {k}\"\n",
    "                    ngram_list.append(twogram_1_2)\n",
    "                    twogram_2_1 = f\"{k} {j}\"\n",
    "                    ngram_list.append(twogram_2_1)\n",
    "        df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "        #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # ******\n",
    "        df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "        df_pair_ngram.drop_duplicates(inplace=True)\n",
    "        df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "        df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "        df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "        df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "        #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    \n",
    "        # output\n",
    "        df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "    \n",
    "        df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "        a = 0\n",
    "        #for i in range(0,110):\n",
    "        for i in range(len(df_output_result)):  # *****\n",
    "            # Insert words and their count \n",
    "            try:\n",
    "                word = df_output_result.iloc[i,0]  # word \n",
    "                freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "                df_lesson_result.loc[i,\"word\"] = word\n",
    "                df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Insert twogram pair\n",
    "            try:\n",
    "                var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    try:\n",
    "                        while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                            a += 1\n",
    "                            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                            df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                            df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            a += 1\n",
    "    \n",
    "        df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "        df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "        df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "        df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "    \n",
    "        word_start += step_num\n",
    "        word_end += step_num\n",
    "        part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameter Part ---\n",
    "\n",
    "# condition 1\n",
    "condition1_word_start = 0\n",
    "condition1_word_limit = 28\n",
    "condition1_word_thresh_num = 2\n",
    "condition1_total_part_num = 4  # 28/4 = 7 word group\n",
    "\n",
    "# condition 2\n",
    "condition1_dependency = True  # True, False\n",
    "word_thresh_num = 2\n",
    "twogram_thresh_minus = 0  # for optional twogram thresh number \n",
    "twogram_pair_thresh_minus = 0  # for optinal twogram pair thresh number.\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = condition1_word_limit  # condition1_word_limit must be equal word_end (condition2 parameter)\n",
    "step_num = word_end  # 10\n",
    "word_limit = word_end  # 200\n",
    "part_num = 1\n",
    "    \n",
    "if condition1_dependency:        \n",
    "    # Read previous part result\n",
    "    condition1(word_start_num = condition1_word_start, word_limit_num = condition1_word_limit, thresh_num = condition1_word_thresh_num, total_part_num = condition1_total_part_num)  # word_end 28/4 = 7 word group. Condition 1 parameters \n",
    "    df_part_all = pd.DataFrame()\n",
    "    part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_*_Word_Step_*_Result*.xlsx\")\n",
    "    for i in part_result_file:\n",
    "        df_var = pd.read_excel(f\"{i}\")\n",
    "        df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "    df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "    df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "    set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "else:\n",
    "    set_part_twogram_pair = set([])  # option for skip Condition 1\n",
    "# --- Parameter End ---\n",
    "\n",
    "# while loop code block\n",
    "\n",
    "twogram_num = word_thresh_num * step_num   # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "    word_list = df_word[\"word\"].to_list()  # ***** \n",
    "    ngram_list = []\n",
    "    for i in word_pair_list:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in word_list:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "    #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # *****\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = pd.DataFrame(result_list2, columns=[f\"{data_kind}\"])  # *****\n",
    "    #df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})  # *****\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(len(df_output_result)):  # *****\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_thresh_minus), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_pair_thresh_minus), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>102069964.0</td>\n",
       "      <td>i am</td>\n",
       "      <td>136931.0</td>\n",
       "      <td>like that</td>\n",
       "      <td>12872</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>94447074.0</td>\n",
       "      <td>i do</td>\n",
       "      <td>114801.0</td>\n",
       "      <td>hit me</td>\n",
       "      <td>9163</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>77481215.0</td>\n",
       "      <td>do not</td>\n",
       "      <td>102558.0</td>\n",
       "      <td>my brother</td>\n",
       "      <td>6974</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>58281119.0</td>\n",
       "      <td>and you</td>\n",
       "      <td>53582.0</td>\n",
       "      <td>my lady</td>\n",
       "      <td>6354</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>50852895.0</td>\n",
       "      <td>for what</td>\n",
       "      <td>53302.0</td>\n",
       "      <td>what time</td>\n",
       "      <td>5992</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>49726799.0</td>\n",
       "      <td>it is</td>\n",
       "      <td>49111.0</td>\n",
       "      <td>like me</td>\n",
       "      <td>5643</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>not</td>\n",
       "      <td>48510772.0</td>\n",
       "      <td>what for</td>\n",
       "      <td>47522.0</td>\n",
       "      <td>no time</td>\n",
       "      <td>3976</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>47050281.0</td>\n",
       "      <td>is it</td>\n",
       "      <td>31032.0</td>\n",
       "      <td>your brother</td>\n",
       "      <td>3897</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>35204210.0</td>\n",
       "      <td>not me</td>\n",
       "      <td>23708.0</td>\n",
       "      <td>no chance</td>\n",
       "      <td>3118</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and</td>\n",
       "      <td>34806253.0</td>\n",
       "      <td>you will</td>\n",
       "      <td>13353.0</td>\n",
       "      <td>fix it</td>\n",
       "      <td>2727</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>of</td>\n",
       "      <td>30136270.0</td>\n",
       "      <td>we will</td>\n",
       "      <td>11199.0</td>\n",
       "      <td>the doctor</td>\n",
       "      <td>2611</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>do</td>\n",
       "      <td>29872416.0</td>\n",
       "      <td>and this</td>\n",
       "      <td>10327.0</td>\n",
       "      <td>stop what</td>\n",
       "      <td>2310</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is</td>\n",
       "      <td>26450040.0</td>\n",
       "      <td>he was</td>\n",
       "      <td>9001.0</td>\n",
       "      <td>name it</td>\n",
       "      <td>2278</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>24816414.0</td>\n",
       "      <td>to me</td>\n",
       "      <td>6410.0</td>\n",
       "      <td>a doctor</td>\n",
       "      <td>2188</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what</td>\n",
       "      <td>24517922.0</td>\n",
       "      <td>that was</td>\n",
       "      <td>4722.0</td>\n",
       "      <td>you may</td>\n",
       "      <td>1780</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>we</td>\n",
       "      <td>24095762.0</td>\n",
       "      <td>we have</td>\n",
       "      <td>3974.0</td>\n",
       "      <td>your family</td>\n",
       "      <td>1770</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>have</td>\n",
       "      <td>23810016.0</td>\n",
       "      <td>no that</td>\n",
       "      <td>810.0</td>\n",
       "      <td>a party</td>\n",
       "      <td>1751</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>me</td>\n",
       "      <td>22790878.0</td>\n",
       "      <td>no this</td>\n",
       "      <td>645.0</td>\n",
       "      <td>i refuse</td>\n",
       "      <td>1475</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>this</td>\n",
       "      <td>20203389.0</td>\n",
       "      <td>in the</td>\n",
       "      <td>490.0</td>\n",
       "      <td>you moron</td>\n",
       "      <td>1382</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>he</td>\n",
       "      <td>19072522.0</td>\n",
       "      <td>have to</td>\n",
       "      <td>453.0</td>\n",
       "      <td>in position</td>\n",
       "      <td>1149</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>am</td>\n",
       "      <td>18783155.0</td>\n",
       "      <td>in a</td>\n",
       "      <td>283.0</td>\n",
       "      <td>not fair</td>\n",
       "      <td>1109</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>will</td>\n",
       "      <td>18133892.0</td>\n",
       "      <td>on the</td>\n",
       "      <td>274.0</td>\n",
       "      <td>the name</td>\n",
       "      <td>993</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>for</td>\n",
       "      <td>17512777.0</td>\n",
       "      <td>on a</td>\n",
       "      <td>114.0</td>\n",
       "      <td>and stop</td>\n",
       "      <td>808</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>on</td>\n",
       "      <td>17154831.0</td>\n",
       "      <td>of your</td>\n",
       "      <td>26.0</td>\n",
       "      <td>in theory</td>\n",
       "      <td>752</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>my</td>\n",
       "      <td>17062911.0</td>\n",
       "      <td>of my</td>\n",
       "      <td>17.0</td>\n",
       "      <td>i protest</td>\n",
       "      <td>681</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>your</td>\n",
       "      <td>16504266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and out</td>\n",
       "      <td>591</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>no</td>\n",
       "      <td>15774417.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not real</td>\n",
       "      <td>486</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>was</td>\n",
       "      <td>15728284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on guard</td>\n",
       "      <td>483</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may we</td>\n",
       "      <td>397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fix this</td>\n",
       "      <td>389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stand to</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to school</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on radio</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that music</td>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>for school</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we out</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>for revenge</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bye will</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this part</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is mine</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>point is</td>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>of mine</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>have tea</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>he shot</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>of music</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>he hello</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>have coffee</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>was real</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>director do</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>traffic was</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>do start</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>will pass</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>am engaged</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>am free</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word    freq_word   twogram freq_twogram twogram_pair_turkish  \\\n",
       "0    you  102069964.0      i am     136931.0            like that   \n",
       "1      i   94447074.0      i do     114801.0               hit me   \n",
       "2    the   77481215.0    do not     102558.0           my brother   \n",
       "3     to   58281119.0   and you      53582.0              my lady   \n",
       "4     is   50852895.0  for what      53302.0            what time   \n",
       "5      a   49726799.0     it is      49111.0              like me   \n",
       "6    not   48510772.0  what for      47522.0              no time   \n",
       "7     it   47050281.0     is it      31032.0         your brother   \n",
       "8   that   35204210.0    not me      23708.0            no chance   \n",
       "9    and   34806253.0  you will      13353.0               fix it   \n",
       "10    of   30136270.0   we will      11199.0           the doctor   \n",
       "11    do   29872416.0  and this      10327.0            stop what   \n",
       "12    is   26450040.0    he was       9001.0              name it   \n",
       "13    in   24816414.0     to me       6410.0             a doctor   \n",
       "14  what   24517922.0  that was       4722.0              you may   \n",
       "15    we   24095762.0   we have       3974.0          your family   \n",
       "16  have   23810016.0   no that        810.0              a party   \n",
       "17    me   22790878.0   no this        645.0             i refuse   \n",
       "18  this   20203389.0    in the        490.0            you moron   \n",
       "19    he   19072522.0   have to        453.0          in position   \n",
       "20    am   18783155.0      in a        283.0             not fair   \n",
       "21  will   18133892.0    on the        274.0             the name   \n",
       "22   for   17512777.0      on a        114.0             and stop   \n",
       "23    on   17154831.0   of your         26.0            in theory   \n",
       "24    my   17062911.0     of my         17.0            i protest   \n",
       "25  your   16504266.0       NaN          NaN              and out   \n",
       "26    no   15774417.0       NaN          NaN             not real   \n",
       "27   was   15728284.0       NaN          NaN             on guard   \n",
       "28   NaN          NaN       NaN          NaN               may we   \n",
       "29   NaN          NaN       NaN          NaN             fix this   \n",
       "30   NaN          NaN       NaN          NaN             stand to   \n",
       "31   NaN          NaN       NaN          NaN            to school   \n",
       "32   NaN          NaN       NaN          NaN             on radio   \n",
       "33   NaN          NaN       NaN          NaN           that music   \n",
       "34   NaN          NaN       NaN          NaN           for school   \n",
       "35   NaN          NaN       NaN          NaN               we out   \n",
       "36   NaN          NaN       NaN          NaN          for revenge   \n",
       "37   NaN          NaN       NaN          NaN             bye will   \n",
       "38   NaN          NaN       NaN          NaN            this part   \n",
       "39   NaN          NaN       NaN          NaN              is mine   \n",
       "40   NaN          NaN       NaN          NaN             point is   \n",
       "41   NaN          NaN       NaN          NaN              of mine   \n",
       "42   NaN          NaN       NaN          NaN             have tea   \n",
       "43   NaN          NaN       NaN          NaN              he shot   \n",
       "44   NaN          NaN       NaN          NaN             of music   \n",
       "45   NaN          NaN       NaN          NaN             he hello   \n",
       "46   NaN          NaN       NaN          NaN          have coffee   \n",
       "47   NaN          NaN       NaN          NaN             was real   \n",
       "48   NaN          NaN       NaN          NaN          director do   \n",
       "49   NaN          NaN       NaN          NaN          traffic was   \n",
       "50   NaN          NaN       NaN          NaN             do start   \n",
       "51   NaN          NaN       NaN          NaN            will pass   \n",
       "52   NaN          NaN       NaN          NaN           am engaged   \n",
       "53   NaN          NaN       NaN          NaN              am free   \n",
       "54   NaN          NaN       NaN          NaN                  NaN   \n",
       "\n",
       "   freq_twogram_pair_turkish  word_count  \n",
       "0                      12872         4.0  \n",
       "1                       9163         4.0  \n",
       "2                       6974         4.0  \n",
       "3                       6354         4.0  \n",
       "4                       5992         4.0  \n",
       "5                       5643         4.0  \n",
       "6                       3976         4.0  \n",
       "7                       3897         4.0  \n",
       "8                       3118         4.0  \n",
       "9                       2727         4.0  \n",
       "10                      2611         4.0  \n",
       "11                      2310         4.0  \n",
       "12                      2278         4.0  \n",
       "13                      2188         4.0  \n",
       "14                      1780         4.0  \n",
       "15                      1770         4.0  \n",
       "16                      1751         4.0  \n",
       "17                      1475         4.0  \n",
       "18                      1382         4.0  \n",
       "19                      1149         3.0  \n",
       "20                      1109         3.0  \n",
       "21                       993         4.0  \n",
       "22                       808         4.0  \n",
       "23                       752         4.0  \n",
       "24                       681         3.0  \n",
       "25                       591         3.0  \n",
       "26                       486         4.0  \n",
       "27                       483         4.0  \n",
       "28                       397         NaN  \n",
       "29                       389         NaN  \n",
       "30                       326         NaN  \n",
       "31                       299         NaN  \n",
       "32                       260         NaN  \n",
       "33                       233         NaN  \n",
       "34                       216         NaN  \n",
       "35                       199         NaN  \n",
       "36                       168         NaN  \n",
       "37                       154         NaN  \n",
       "38                       147         NaN  \n",
       "39                       140         NaN  \n",
       "40                       118         NaN  \n",
       "41                       115         NaN  \n",
       "42                       115         NaN  \n",
       "43                       106         NaN  \n",
       "44                        51         NaN  \n",
       "45                        46         NaN  \n",
       "46                        45         NaN  \n",
       "47                        30         NaN  \n",
       "48                        27         NaN  \n",
       "49                        18         NaN  \n",
       "50                        15         NaN  \n",
       "51                        12         NaN  \n",
       "52                         7         NaN  \n",
       "53                         5         NaN  \n",
       "54                       NaN         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var.to_excel(writer, sheet_name=f'Word_Part1{i}', index=False)            \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_part_var2.to_excel(writer, sheet_name=f'Word_Part21', index=False)        \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var_order = word_in_twogram(df_part_var, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "            df_part_var_order_join = df_part_var_order.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "            df_part_var_order_join.to_excel(writer2, sheet_name=f'Word_Part1{i}', index=False)          \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_word_order_21 = word_in_twogram(df_part_var2, \"word\", f\"twogram\")\n",
    "df_word_order_212 = word_in_twogram(df_part_var2, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)        \n",
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English_Turkish_28_Word_Step_7_Result1.xlsx',\n",
       " 'English_Turkish_28_Word_Step_7_Result2.xlsx',\n",
       " 'English_Turkish_28_Word_Step_7_Result3.xlsx',\n",
       " 'English_Turkish_28_Word_Step_7_Result4.xlsx',\n",
       " 'English_Turkish_28_Word_Step_28_Result1.xlsx',\n",
       " 'English_Turkish_28_Word_Result_With_Frequency.xlsx',\n",
       " 'English_Turkish_28_Word_Join_Result_Without_Frequency.xlsx']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
