{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_folder = \"French\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language\n",
    "lang_pair = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>16588988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>16386475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas</td>\n",
       "      <td>11547876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>10592792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>9939090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320426</th>\n",
       "      <td>perpetuel</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320427</th>\n",
       "      <td>fifis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320428</th>\n",
       "      <td>fifteenth</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320429</th>\n",
       "      <td>perouse</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320430</th>\n",
       "      <td>escuses</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320431 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  frequency\n",
       "0              de   16588988\n",
       "1              je   16386475\n",
       "2             pas   11547876\n",
       "3              le   10592792\n",
       "4              la    9939090\n",
       "...           ...        ...\n",
       "320426  perpetuel          5\n",
       "320427      fifis          5\n",
       "320428  fifteenth          5\n",
       "320429    perouse          5\n",
       "320430    escuses          5\n",
       "\n",
       "[320431 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bien sûr</td>\n",
       "      <td>132006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je sais</td>\n",
       "      <td>130876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ça va</td>\n",
       "      <td>120098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>très bien</td>\n",
       "      <td>107245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cest vrai</td>\n",
       "      <td>98435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468839</th>\n",
       "      <td>salut chicago</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468840</th>\n",
       "      <td>salut chickamaw</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468841</th>\n",
       "      <td>salut ching</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468842</th>\n",
       "      <td>salut chienpo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468843</th>\n",
       "      <td>cette trottinette</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468844 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  twogram  frequency\n",
       "0                bien sûr     132006\n",
       "1                 je sais     130876\n",
       "2                   ça va     120098\n",
       "3               très bien     107245\n",
       "4               cest vrai      98435\n",
       "...                   ...        ...\n",
       "468839      salut chicago          2\n",
       "468840    salut chickamaw          2\n",
       "468841        salut ching          2\n",
       "468842      salut chienpo          2\n",
       "468843  cette trottinette          2\n",
       "\n",
       "[468844 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/French/French_And_Turkish (tur)_Etymologeek_Result_All.xlsx']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>turkish_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perruque</td>\n",
       "      <td>peruk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>palabre</td>\n",
       "      <td>palavra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parloir</td>\n",
       "      <td>salon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salon</td>\n",
       "      <td>salon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraboler</td>\n",
       "      <td>parabol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>équinoxe</td>\n",
       "      <td>ekinoks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>érotique</td>\n",
       "      <td>erotik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>éthique</td>\n",
       "      <td>etik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>étiquette</td>\n",
       "      <td>etiket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>étymologie</td>\n",
       "      <td>etimoloji</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_entry_main turkish_word\n",
       "0          perruque        peruk\n",
       "1           palabre      palavra\n",
       "2           parloir        salon\n",
       "3             salon        salon\n",
       "4         paraboler      parabol\n",
       "..              ...          ...\n",
       "825        équinoxe      ekinoks\n",
       "826        érotique       erotik\n",
       "827         éthique         etik\n",
       "828       étiquette       etiket\n",
       "829      étymologie    etimoloji\n",
       "\n",
       "[830 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair_all = pd.read_excel(f\"{lang_pair_list[0]}\")\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtuose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emmagasiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dualisme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>modèle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>banquer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>raquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>aorte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>antioxydant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dict_entry_main\n",
       "0          virtuose\n",
       "1            cation\n",
       "2             salon\n",
       "3       emmagasiner\n",
       "4          dualisme\n",
       "..              ...\n",
       "805          modèle\n",
       "806         banquer\n",
       "807        raquette\n",
       "808           aorte\n",
       "809     antioxydant\n",
       "\n",
       "[810 rows x 1 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, bigger_than is integer\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, bigger_than is an integer\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop code block word and twogram pair\n",
    "twogram_num = 100  # 2*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = 100  # 2*step_num minimum: for each word takes two twogram pair\n",
    "word_thresh_num = 2\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 7  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word \n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert twogram pair\n",
    "        try:\n",
    "            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                        freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French_Turkish_28_Word_Step_7_Result1.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result2.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result3.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result4.xlsx']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result*.xlsx\")\n",
    "part_result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read previous part result\n",
    "df_part_all = pd.DataFrame()\n",
    "for i in part_result_file:\n",
    "    df_var = pd.read_excel(f\"{i}\")\n",
    "    df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "\n",
    "# while loop code block\n",
    "twogram_num = 100  # 2*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = 100  # 2*step_num minimum: for each word takes two twogram pair\n",
    "word_thresh_num = 7\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 28  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>16588988.0</td>\n",
       "      <td>cest ça</td>\n",
       "      <td>58819.0</td>\n",
       "      <td>cest intéressant</td>\n",
       "      <td>2580</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>16386475.0</td>\n",
       "      <td>et vous</td>\n",
       "      <td>18817.0</td>\n",
       "      <td>cest personnel</td>\n",
       "      <td>1728</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas</td>\n",
       "      <td>11547876.0</td>\n",
       "      <td>cest qui</td>\n",
       "      <td>11327.0</td>\n",
       "      <td>en partie</td>\n",
       "      <td>695</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>10592792.0</td>\n",
       "      <td>qui ça</td>\n",
       "      <td>9732.0</td>\n",
       "      <td>une surprise</td>\n",
       "      <td>545</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>9939090.0</td>\n",
       "      <td>je ne</td>\n",
       "      <td>5078.0</td>\n",
       "      <td>un whisky</td>\n",
       "      <td>540</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>que</td>\n",
       "      <td>9858145.0</td>\n",
       "      <td>pas vous</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>un message</td>\n",
       "      <td>508</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vous</td>\n",
       "      <td>8980559.0</td>\n",
       "      <td>il est</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>en théorie</td>\n",
       "      <td>507</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tu</td>\n",
       "      <td>8776452.0</td>\n",
       "      <td>mais je</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>une carte</td>\n",
       "      <td>417</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>et</td>\n",
       "      <td>8039570.0</td>\n",
       "      <td>on la</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>la bombe</td>\n",
       "      <td>397</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>un</td>\n",
       "      <td>7421102.0</td>\n",
       "      <td>tu les</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>le film</td>\n",
       "      <td>382</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cest</td>\n",
       "      <td>7378985.0</td>\n",
       "      <td>et nous</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>le garçon</td>\n",
       "      <td>377</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ne</td>\n",
       "      <td>6522193.0</td>\n",
       "      <td>pas nous</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>la carte</td>\n",
       "      <td>297</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>il</td>\n",
       "      <td>6113702.0</td>\n",
       "      <td>on est</td>\n",
       "      <td>495.0</td>\n",
       "      <td>merci je</td>\n",
       "      <td>111</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>les</td>\n",
       "      <td>6088090.0</td>\n",
       "      <td>il la</td>\n",
       "      <td>390.0</td>\n",
       "      <td>mais madame</td>\n",
       "      <td>103</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ça</td>\n",
       "      <td>5453443.0</td>\n",
       "      <td>mais que</td>\n",
       "      <td>368.0</td>\n",
       "      <td>pour noël</td>\n",
       "      <td>77</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ce</td>\n",
       "      <td>4975690.0</td>\n",
       "      <td>tu ne</td>\n",
       "      <td>307.0</td>\n",
       "      <td>mais chef</td>\n",
       "      <td>72</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>une</td>\n",
       "      <td>4859112.0</td>\n",
       "      <td>jai un</td>\n",
       "      <td>192.0</td>\n",
       "      <td>merci de</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pour</td>\n",
       "      <td>4831957.0</td>\n",
       "      <td>jai une</td>\n",
       "      <td>97.0</td>\n",
       "      <td>madame je</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>est</td>\n",
       "      <td>4749944.0</td>\n",
       "      <td>dans le</td>\n",
       "      <td>71.0</td>\n",
       "      <td>les archives</td>\n",
       "      <td>60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>on</td>\n",
       "      <td>4700594.0</td>\n",
       "      <td>ce que</td>\n",
       "      <td>66.0</td>\n",
       "      <td>pas intéressant</td>\n",
       "      <td>58</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en</td>\n",
       "      <td>4433573.0</td>\n",
       "      <td>pour le</td>\n",
       "      <td>34.0</td>\n",
       "      <td>on fait</td>\n",
       "      <td>55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>des</td>\n",
       "      <td>3795364.0</td>\n",
       "      <td>dans un</td>\n",
       "      <td>25.0</td>\n",
       "      <td>ce symbole</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qui</td>\n",
       "      <td>3292758.0</td>\n",
       "      <td>de ce</td>\n",
       "      <td>14.0</td>\n",
       "      <td>pour information</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jai</td>\n",
       "      <td>3239656.0</td>\n",
       "      <td>pour les</td>\n",
       "      <td>12.0</td>\n",
       "      <td>il téléphone</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mais</td>\n",
       "      <td>3176885.0</td>\n",
       "      <td>en une</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ce message</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dans</td>\n",
       "      <td>2977115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de biologie</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nous</td>\n",
       "      <td>2961551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ça fond</td>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>me</td>\n",
       "      <td>2890264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maître qui</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qui enquête</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>et surprise</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pas rouge</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des japonais</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous docteur</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>et noël</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fait ça</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>les lire</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des as</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on téléphone</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>docteur jai</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous amiral</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>est partie</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il enquête</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gene est</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jai sport</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron que</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>japonais dans</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word   twogram freq_twogram twogram_pair_turkish  \\\n",
       "0     de  16588988.0   cest ça      58819.0     cest intéressant   \n",
       "1     je  16386475.0   et vous      18817.0       cest personnel   \n",
       "2    pas  11547876.0  cest qui      11327.0            en partie   \n",
       "3     le  10592792.0    qui ça       9732.0         une surprise   \n",
       "4     la   9939090.0     je ne       5078.0            un whisky   \n",
       "5    que   9858145.0  pas vous       3847.0           un message   \n",
       "6   vous   8980559.0    il est       2312.0           en théorie   \n",
       "7     tu   8776452.0   mais je       2154.0            une carte   \n",
       "8     et   8039570.0     on la       1604.0             la bombe   \n",
       "9     un   7421102.0    tu les       1411.0              le film   \n",
       "10  cest   7378985.0   et nous       1368.0            le garçon   \n",
       "11    ne   6522193.0  pas nous       1227.0             la carte   \n",
       "12    il   6113702.0    on est        495.0             merci je   \n",
       "13   les   6088090.0     il la        390.0          mais madame   \n",
       "14    ça   5453443.0  mais que        368.0            pour noël   \n",
       "15    ce   4975690.0     tu ne        307.0            mais chef   \n",
       "16   une   4859112.0    jai un        192.0             merci de   \n",
       "17  pour   4831957.0   jai une         97.0            madame je   \n",
       "18   est   4749944.0   dans le         71.0         les archives   \n",
       "19    on   4700594.0    ce que         66.0      pas intéressant   \n",
       "20    en   4433573.0   pour le         34.0              on fait   \n",
       "21   des   3795364.0   dans un         25.0           ce symbole   \n",
       "22   qui   3292758.0     de ce         14.0     pour information   \n",
       "23   jai   3239656.0  pour les         12.0         il téléphone   \n",
       "24  mais   3176885.0    en une         10.0           ce message   \n",
       "25  dans   2977115.0       NaN          NaN          de biologie   \n",
       "26  nous   2961551.0       NaN          NaN              ça fond   \n",
       "27    me   2890264.0       NaN          NaN           maître qui   \n",
       "28   NaN         NaN       NaN          NaN          qui enquête   \n",
       "29   NaN         NaN       NaN          NaN          et surprise   \n",
       "30   NaN         NaN       NaN          NaN            pas rouge   \n",
       "31   NaN         NaN       NaN          NaN         des japonais   \n",
       "32   NaN         NaN       NaN          NaN         vous docteur   \n",
       "33   NaN         NaN       NaN          NaN              et noël   \n",
       "34   NaN         NaN       NaN          NaN              fait ça   \n",
       "35   NaN         NaN       NaN          NaN             les lire   \n",
       "36   NaN         NaN       NaN          NaN               des as   \n",
       "37   NaN         NaN       NaN          NaN         on téléphone   \n",
       "38   NaN         NaN       NaN          NaN          docteur jai   \n",
       "39   NaN         NaN       NaN          NaN          vous amiral   \n",
       "40   NaN         NaN       NaN          NaN           est partie   \n",
       "41   NaN         NaN       NaN          NaN           il enquête   \n",
       "42   NaN         NaN       NaN          NaN             gene est   \n",
       "43   NaN         NaN       NaN          NaN            jai sport   \n",
       "44   NaN         NaN       NaN          NaN           patron que   \n",
       "45   NaN         NaN       NaN          NaN        japonais dans   \n",
       "46   NaN         NaN       NaN          NaN                  NaN   \n",
       "\n",
       "   freq_twogram_pair_turkish  word_count  \n",
       "0                       2580         3.0  \n",
       "1                       1728         4.0  \n",
       "2                        695         4.0  \n",
       "3                        545         4.0  \n",
       "4                        540         4.0  \n",
       "5                        508         3.0  \n",
       "6                        507         4.0  \n",
       "7                        417         2.0  \n",
       "8                        397         4.0  \n",
       "9                        382         4.0  \n",
       "10                       377         4.0  \n",
       "11                       297         2.0  \n",
       "12                       111         4.0  \n",
       "13                       103         4.0  \n",
       "14                        77         4.0  \n",
       "15                        72         4.0  \n",
       "16                        70         4.0  \n",
       "17                        61         4.0  \n",
       "18                        60         4.0  \n",
       "19                        58         4.0  \n",
       "20                        55         3.0  \n",
       "21                        50         2.0  \n",
       "22                        47         4.0  \n",
       "23                        45         4.0  \n",
       "24                        44         4.0  \n",
       "25                        43         3.0  \n",
       "26                        39         2.0  \n",
       "27                        36         NaN  \n",
       "28                        26         NaN  \n",
       "29                        26         NaN  \n",
       "30                        22         NaN  \n",
       "31                        22         NaN  \n",
       "32                        20         NaN  \n",
       "33                        19         NaN  \n",
       "34                        16         NaN  \n",
       "35                        14         NaN  \n",
       "36                        13         NaN  \n",
       "37                        12         NaN  \n",
       "38                        12         NaN  \n",
       "39                        10         NaN  \n",
       "40                         7         NaN  \n",
       "41                         7         NaN  \n",
       "42                         4         NaN  \n",
       "43                         3         NaN  \n",
       "44                         3         NaN  \n",
       "45                         2         NaN  \n",
       "46                       NaN         NaN  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>16588988.0</td>\n",
       "      <td>la police</td>\n",
       "      <td>3194</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>16386475.0</td>\n",
       "      <td>le téléphone</td>\n",
       "      <td>978</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas</td>\n",
       "      <td>11547876.0</td>\n",
       "      <td>le docteur</td>\n",
       "      <td>674</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>10592792.0</td>\n",
       "      <td>la musique</td>\n",
       "      <td>589</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>9939090.0</td>\n",
       "      <td>de vous</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>que</td>\n",
       "      <td>9858145.0</td>\n",
       "      <td>je danse</td>\n",
       "      <td>261</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vous</td>\n",
       "      <td>8980559.0</td>\n",
       "      <td>pas super</td>\n",
       "      <td>147</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pas de</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>je téléphone</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous madame</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fait que</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>que fait</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_turkish  freq_twogram_pair_turkish  \\\n",
       "0     de  16588988.0            la police                       3194   \n",
       "1     je  16386475.0         le téléphone                        978   \n",
       "2    pas  11547876.0           le docteur                        674   \n",
       "3     le  10592792.0           la musique                        589   \n",
       "4     la   9939090.0              de vous                        514   \n",
       "5    que   9858145.0             je danse                        261   \n",
       "6   vous   8980559.0            pas super                        147   \n",
       "7    NaN         NaN               pas de                        140   \n",
       "8    NaN         NaN         je téléphone                        123   \n",
       "9    NaN         NaN          vous madame                         58   \n",
       "10   NaN         NaN             fait que                         33   \n",
       "11   NaN         NaN             que fait                          4   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result1.xlsx\")\n",
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tu</td>\n",
       "      <td>8776452.0</td>\n",
       "      <td>cest super</td>\n",
       "      <td>10475</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et</td>\n",
       "      <td>8039570.0</td>\n",
       "      <td>cest fait</td>\n",
       "      <td>9439</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>un</td>\n",
       "      <td>7421102.0</td>\n",
       "      <td>un café</td>\n",
       "      <td>2171</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cest</td>\n",
       "      <td>7378985.0</td>\n",
       "      <td>un garçon</td>\n",
       "      <td>1309</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne</td>\n",
       "      <td>6522193.0</td>\n",
       "      <td>et merci</td>\n",
       "      <td>860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>il</td>\n",
       "      <td>6113702.0</td>\n",
       "      <td>tu as</td>\n",
       "      <td>634</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>les</td>\n",
       "      <td>6088090.0</td>\n",
       "      <td>les chinois</td>\n",
       "      <td>125</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>les japonais</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>et madame</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il danse</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il fait</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as tu</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ne point</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_turkish  freq_twogram_pair_turkish  \\\n",
       "0     tu  8776452.0           cest super                      10475   \n",
       "1     et  8039570.0            cest fait                       9439   \n",
       "2     un  7421102.0              un café                       2171   \n",
       "3   cest  7378985.0            un garçon                       1309   \n",
       "4     ne  6522193.0             et merci                        860   \n",
       "5     il  6113702.0                tu as                        634   \n",
       "6    les  6088090.0          les chinois                        125   \n",
       "7    NaN        NaN         les japonais                        105   \n",
       "8    NaN        NaN            et madame                        103   \n",
       "9    NaN        NaN             il danse                        102   \n",
       "10   NaN        NaN              il fait                         69   \n",
       "11   NaN        NaN                as tu                         33   \n",
       "12   NaN        NaN             ne point                          4   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          1.0  \n",
       "5          2.0  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_12 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result2.xlsx\")\n",
    "df_part_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ça</td>\n",
       "      <td>5453443.0</td>\n",
       "      <td>en fait</td>\n",
       "      <td>4479</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce</td>\n",
       "      <td>4975690.0</td>\n",
       "      <td>en position</td>\n",
       "      <td>1435</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>une</td>\n",
       "      <td>4859112.0</td>\n",
       "      <td>une bombe</td>\n",
       "      <td>758</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pour</td>\n",
       "      <td>4831957.0</td>\n",
       "      <td>on danse</td>\n",
       "      <td>732</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>est</td>\n",
       "      <td>4749944.0</td>\n",
       "      <td>une ambulance</td>\n",
       "      <td>674</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>4700594.0</td>\n",
       "      <td>de ça</td>\n",
       "      <td>357</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en</td>\n",
       "      <td>4433573.0</td>\n",
       "      <td>ça fait</td>\n",
       "      <td>307</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ce garçon</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merci pour</td>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on enquête</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pour lire</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ce film</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>est figurant</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>madame est</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_turkish  freq_twogram_pair_turkish  \\\n",
       "0     ça  5453443.0              en fait                       4479   \n",
       "1     ce  4975690.0          en position                       1435   \n",
       "2    une  4859112.0            une bombe                        758   \n",
       "3   pour  4831957.0             on danse                        732   \n",
       "4    est  4749944.0        une ambulance                        674   \n",
       "5     on  4700594.0                de ça                        357   \n",
       "6     en  4433573.0              ça fait                        307   \n",
       "7    NaN        NaN            ce garçon                        189   \n",
       "8    NaN        NaN           merci pour                        171   \n",
       "9    NaN        NaN           on enquête                         93   \n",
       "10   NaN        NaN            pour lire                         88   \n",
       "11   NaN        NaN              ce film                         78   \n",
       "12   NaN        NaN         est figurant                         10   \n",
       "13   NaN        NaN           madame est                          8   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13         NaN  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_13 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result3.xlsx\")\n",
    "df_part_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>des</td>\n",
       "      <td>3795364.0</td>\n",
       "      <td>de qui</td>\n",
       "      <td>2683</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qui</td>\n",
       "      <td>3292758.0</td>\n",
       "      <td>mais merci</td>\n",
       "      <td>1097</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jai</td>\n",
       "      <td>3239656.0</td>\n",
       "      <td>de nous</td>\n",
       "      <td>430</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mais</td>\n",
       "      <td>3176885.0</td>\n",
       "      <td>merci mais</td>\n",
       "      <td>311</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dans</td>\n",
       "      <td>2977115.0</td>\n",
       "      <td>jai fait</td>\n",
       "      <td>284</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nous</td>\n",
       "      <td>2961551.0</td>\n",
       "      <td>docteur qui</td>\n",
       "      <td>64</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>me</td>\n",
       "      <td>2890264.0</td>\n",
       "      <td>des chinois</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des spaghetti</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jai école</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dans chrome</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avantage nous</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dans ascenseur</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_turkish  freq_twogram_pair_turkish  \\\n",
       "0    des  3795364.0               de qui                       2683   \n",
       "1    qui  3292758.0           mais merci                       1097   \n",
       "2    jai  3239656.0              de nous                        430   \n",
       "3   mais  3176885.0           merci mais                        311   \n",
       "4   dans  2977115.0             jai fait                        284   \n",
       "5   nous  2961551.0          docteur qui                         64   \n",
       "6     me  2890264.0          des chinois                         55   \n",
       "7    NaN        NaN        des spaghetti                         35   \n",
       "8    NaN        NaN            jai école                         16   \n",
       "9    NaN        NaN          dans chrome                          8   \n",
       "10   NaN        NaN        avantage nous                          5   \n",
       "11   NaN        NaN       dans ascenseur                          4   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_14 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result4.xlsx\")\n",
    "df_part_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>16588988.0</td>\n",
       "      <td>cest ça</td>\n",
       "      <td>58819.0</td>\n",
       "      <td>cest intéressant</td>\n",
       "      <td>2580</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>16386475.0</td>\n",
       "      <td>et vous</td>\n",
       "      <td>18817.0</td>\n",
       "      <td>cest personnel</td>\n",
       "      <td>1728</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas</td>\n",
       "      <td>11547876.0</td>\n",
       "      <td>cest qui</td>\n",
       "      <td>11327.0</td>\n",
       "      <td>en partie</td>\n",
       "      <td>695</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>10592792.0</td>\n",
       "      <td>qui ça</td>\n",
       "      <td>9732.0</td>\n",
       "      <td>une surprise</td>\n",
       "      <td>545</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>9939090.0</td>\n",
       "      <td>je ne</td>\n",
       "      <td>5078.0</td>\n",
       "      <td>un whisky</td>\n",
       "      <td>540</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>que</td>\n",
       "      <td>9858145.0</td>\n",
       "      <td>pas vous</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>un message</td>\n",
       "      <td>508</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vous</td>\n",
       "      <td>8980559.0</td>\n",
       "      <td>il est</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>en théorie</td>\n",
       "      <td>507</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tu</td>\n",
       "      <td>8776452.0</td>\n",
       "      <td>mais je</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>une carte</td>\n",
       "      <td>417</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>et</td>\n",
       "      <td>8039570.0</td>\n",
       "      <td>on la</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>la bombe</td>\n",
       "      <td>397</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>un</td>\n",
       "      <td>7421102.0</td>\n",
       "      <td>tu les</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>le film</td>\n",
       "      <td>382</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cest</td>\n",
       "      <td>7378985.0</td>\n",
       "      <td>et nous</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>le garçon</td>\n",
       "      <td>377</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ne</td>\n",
       "      <td>6522193.0</td>\n",
       "      <td>pas nous</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>la carte</td>\n",
       "      <td>297</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>il</td>\n",
       "      <td>6113702.0</td>\n",
       "      <td>on est</td>\n",
       "      <td>495.0</td>\n",
       "      <td>merci je</td>\n",
       "      <td>111</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>les</td>\n",
       "      <td>6088090.0</td>\n",
       "      <td>il la</td>\n",
       "      <td>390.0</td>\n",
       "      <td>mais madame</td>\n",
       "      <td>103</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ça</td>\n",
       "      <td>5453443.0</td>\n",
       "      <td>mais que</td>\n",
       "      <td>368.0</td>\n",
       "      <td>pour noël</td>\n",
       "      <td>77</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ce</td>\n",
       "      <td>4975690.0</td>\n",
       "      <td>tu ne</td>\n",
       "      <td>307.0</td>\n",
       "      <td>mais chef</td>\n",
       "      <td>72</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>une</td>\n",
       "      <td>4859112.0</td>\n",
       "      <td>jai un</td>\n",
       "      <td>192.0</td>\n",
       "      <td>merci de</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pour</td>\n",
       "      <td>4831957.0</td>\n",
       "      <td>jai une</td>\n",
       "      <td>97.0</td>\n",
       "      <td>madame je</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>est</td>\n",
       "      <td>4749944.0</td>\n",
       "      <td>dans le</td>\n",
       "      <td>71.0</td>\n",
       "      <td>les archives</td>\n",
       "      <td>60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>on</td>\n",
       "      <td>4700594.0</td>\n",
       "      <td>ce que</td>\n",
       "      <td>66.0</td>\n",
       "      <td>pas intéressant</td>\n",
       "      <td>58</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en</td>\n",
       "      <td>4433573.0</td>\n",
       "      <td>pour le</td>\n",
       "      <td>34.0</td>\n",
       "      <td>on fait</td>\n",
       "      <td>55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>des</td>\n",
       "      <td>3795364.0</td>\n",
       "      <td>dans un</td>\n",
       "      <td>25.0</td>\n",
       "      <td>ce symbole</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qui</td>\n",
       "      <td>3292758.0</td>\n",
       "      <td>de ce</td>\n",
       "      <td>14.0</td>\n",
       "      <td>pour information</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jai</td>\n",
       "      <td>3239656.0</td>\n",
       "      <td>pour les</td>\n",
       "      <td>12.0</td>\n",
       "      <td>il téléphone</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mais</td>\n",
       "      <td>3176885.0</td>\n",
       "      <td>en une</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ce message</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dans</td>\n",
       "      <td>2977115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de biologie</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nous</td>\n",
       "      <td>2961551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ça fond</td>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>me</td>\n",
       "      <td>2890264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maître qui</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qui enquête</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>et surprise</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pas rouge</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des japonais</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous docteur</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>et noël</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fait ça</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>les lire</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des as</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on téléphone</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>docteur jai</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous amiral</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>est partie</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>il enquête</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gene est</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jai sport</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron que</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>japonais dans</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word   twogram  freq_twogram twogram_pair_turkish  \\\n",
       "0     de  16588988.0   cest ça       58819.0     cest intéressant   \n",
       "1     je  16386475.0   et vous       18817.0       cest personnel   \n",
       "2    pas  11547876.0  cest qui       11327.0            en partie   \n",
       "3     le  10592792.0    qui ça        9732.0         une surprise   \n",
       "4     la   9939090.0     je ne        5078.0            un whisky   \n",
       "5    que   9858145.0  pas vous        3847.0           un message   \n",
       "6   vous   8980559.0    il est        2312.0           en théorie   \n",
       "7     tu   8776452.0   mais je        2154.0            une carte   \n",
       "8     et   8039570.0     on la        1604.0             la bombe   \n",
       "9     un   7421102.0    tu les        1411.0              le film   \n",
       "10  cest   7378985.0   et nous        1368.0            le garçon   \n",
       "11    ne   6522193.0  pas nous        1227.0             la carte   \n",
       "12    il   6113702.0    on est         495.0             merci je   \n",
       "13   les   6088090.0     il la         390.0          mais madame   \n",
       "14    ça   5453443.0  mais que         368.0            pour noël   \n",
       "15    ce   4975690.0     tu ne         307.0            mais chef   \n",
       "16   une   4859112.0    jai un         192.0             merci de   \n",
       "17  pour   4831957.0   jai une          97.0            madame je   \n",
       "18   est   4749944.0   dans le          71.0         les archives   \n",
       "19    on   4700594.0    ce que          66.0      pas intéressant   \n",
       "20    en   4433573.0   pour le          34.0              on fait   \n",
       "21   des   3795364.0   dans un          25.0           ce symbole   \n",
       "22   qui   3292758.0     de ce          14.0     pour information   \n",
       "23   jai   3239656.0  pour les          12.0         il téléphone   \n",
       "24  mais   3176885.0    en une          10.0           ce message   \n",
       "25  dans   2977115.0       NaN           NaN          de biologie   \n",
       "26  nous   2961551.0       NaN           NaN              ça fond   \n",
       "27    me   2890264.0       NaN           NaN           maître qui   \n",
       "28   NaN         NaN       NaN           NaN          qui enquête   \n",
       "29   NaN         NaN       NaN           NaN          et surprise   \n",
       "30   NaN         NaN       NaN           NaN            pas rouge   \n",
       "31   NaN         NaN       NaN           NaN         des japonais   \n",
       "32   NaN         NaN       NaN           NaN         vous docteur   \n",
       "33   NaN         NaN       NaN           NaN              et noël   \n",
       "34   NaN         NaN       NaN           NaN              fait ça   \n",
       "35   NaN         NaN       NaN           NaN             les lire   \n",
       "36   NaN         NaN       NaN           NaN               des as   \n",
       "37   NaN         NaN       NaN           NaN         on téléphone   \n",
       "38   NaN         NaN       NaN           NaN          docteur jai   \n",
       "39   NaN         NaN       NaN           NaN          vous amiral   \n",
       "40   NaN         NaN       NaN           NaN           est partie   \n",
       "41   NaN         NaN       NaN           NaN           il enquête   \n",
       "42   NaN         NaN       NaN           NaN             gene est   \n",
       "43   NaN         NaN       NaN           NaN            jai sport   \n",
       "44   NaN         NaN       NaN           NaN           patron que   \n",
       "45   NaN         NaN       NaN           NaN        japonais dans   \n",
       "\n",
       "    freq_twogram_pair_turkish  word_count  \n",
       "0                        2580         3.0  \n",
       "1                        1728         4.0  \n",
       "2                         695         4.0  \n",
       "3                         545         4.0  \n",
       "4                         540         4.0  \n",
       "5                         508         3.0  \n",
       "6                         507         4.0  \n",
       "7                         417         2.0  \n",
       "8                         397         4.0  \n",
       "9                         382         4.0  \n",
       "10                        377         4.0  \n",
       "11                        297         2.0  \n",
       "12                        111         4.0  \n",
       "13                        103         4.0  \n",
       "14                         77         4.0  \n",
       "15                         72         4.0  \n",
       "16                         70         4.0  \n",
       "17                         61         4.0  \n",
       "18                         60         4.0  \n",
       "19                         58         4.0  \n",
       "20                         55         3.0  \n",
       "21                         50         2.0  \n",
       "22                         47         4.0  \n",
       "23                         45         4.0  \n",
       "24                         44         4.0  \n",
       "25                         43         3.0  \n",
       "26                         39         2.0  \n",
       "27                         36         NaN  \n",
       "28                         26         NaN  \n",
       "29                         26         NaN  \n",
       "30                         22         NaN  \n",
       "31                         22         NaN  \n",
       "32                         20         NaN  \n",
       "33                         19         NaN  \n",
       "34                         16         NaN  \n",
       "35                         14         NaN  \n",
       "36                         13         NaN  \n",
       "37                         12         NaN  \n",
       "38                         12         NaN  \n",
       "39                         10         NaN  \n",
       "40                          7         NaN  \n",
       "41                          7         NaN  \n",
       "42                          4         NaN  \n",
       "43                          3         NaN  \n",
       "44                          3         NaN  \n",
       "45                          2         NaN  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_21 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_28_Result1.xlsx\")\n",
    "df_part_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_11.to_excel(writer, sheet_name='Word_Part11', index=False)\n",
    "df_part_12.to_excel(writer, sheet_name='Word_Part12', index=False)\n",
    "df_part_13.to_excel(writer, sheet_name='Word_Part13', index=False)\n",
    "df_part_14.to_excel(writer, sheet_name='Word_Part14', index=False)\n",
    "df_part_21.to_excel(writer, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "      <th>freq_twogram_pair_turkish</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>16588988.0</td>\n",
       "      <td>la police</td>\n",
       "      <td>3194</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>je</td>\n",
       "      <td>16386475.0</td>\n",
       "      <td>le téléphone</td>\n",
       "      <td>978</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas</td>\n",
       "      <td>11547876.0</td>\n",
       "      <td>le docteur</td>\n",
       "      <td>674</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>10592792.0</td>\n",
       "      <td>la musique</td>\n",
       "      <td>589</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la</td>\n",
       "      <td>9939090.0</td>\n",
       "      <td>de vous</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>que</td>\n",
       "      <td>9858145.0</td>\n",
       "      <td>je danse</td>\n",
       "      <td>261</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vous</td>\n",
       "      <td>8980559.0</td>\n",
       "      <td>pas super</td>\n",
       "      <td>147</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pas de</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>je téléphone</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vous madame</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fait que</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>que fait</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_turkish  freq_twogram_pair_turkish  \\\n",
       "0     de  16588988.0            la police                       3194   \n",
       "1     je  16386475.0         le téléphone                        978   \n",
       "2    pas  11547876.0           le docteur                        674   \n",
       "3     le  10592792.0           la musique                        589   \n",
       "4     la   9939090.0              de vous                        514   \n",
       "5    que   9858145.0             je danse                        261   \n",
       "6   vous   8980559.0            pas super                        147   \n",
       "7    NaN         NaN               pas de                        140   \n",
       "8    NaN         NaN         je téléphone                        123   \n",
       "9    NaN         NaN          vous madame                         58   \n",
       "10   NaN         NaN             fait que                         33   \n",
       "11   NaN         NaN             que fait                          4   \n",
       "\n",
       "    word_count  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  \n",
       "5          2.0  \n",
       "6          2.0  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>de vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>pas de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je</td>\n",
       "      <td>je danse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>je</td>\n",
       "      <td>je téléphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pas</td>\n",
       "      <td>pas super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pas</td>\n",
       "      <td>pas de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>le</td>\n",
       "      <td>le téléphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>le</td>\n",
       "      <td>le docteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>la</td>\n",
       "      <td>la police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>la</td>\n",
       "      <td>la musique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>que</td>\n",
       "      <td>fait que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>que</td>\n",
       "      <td>que fait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vous</td>\n",
       "      <td>de vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vous</td>\n",
       "      <td>vous madame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word twogram_pair_turkish\n",
       "0     de              de vous\n",
       "1     de               pas de\n",
       "2     je             je danse\n",
       "3     je         je téléphone\n",
       "4    pas            pas super\n",
       "5    pas               pas de\n",
       "6     le         le téléphone\n",
       "7     le           le docteur\n",
       "8     la            la police\n",
       "9     la           la musique\n",
       "10   que             fait que\n",
       "11   que             que fait\n",
       "12  vous              de vous\n",
       "13  vous          vous madame"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_11 = word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_12 = word_in_twogram(df_part_12, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_13 = word_in_twogram(df_part_13, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_14 = word_in_twogram(df_part_14, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_21 = word_in_twogram(df_part_21, \"word\", f\"twogram\") \n",
    "df_word_order_212 = word_in_twogram(df_part_21, \"word\", f\"twogram_pair_{lang_pair.lower()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11 = df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_12 = df_word_order_12.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_13 = df_word_order_13.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_14 = df_word_order_14.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ce</td>\n",
       "      <td>ce que, de ce</td>\n",
       "      <td>ce symbole, ce message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cest</td>\n",
       "      <td>cest ça, cest qui</td>\n",
       "      <td>cest intéressant, cest personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dans</td>\n",
       "      <td>dans le, dans un</td>\n",
       "      <td>japonais dans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de ce</td>\n",
       "      <td>merci de, de biologie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>en une</td>\n",
       "      <td>en partie, en théorie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>est</td>\n",
       "      <td>il est, on est</td>\n",
       "      <td>est partie, gene est</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>et</td>\n",
       "      <td>et vous, et nous</td>\n",
       "      <td>et surprise, et noël</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>il</td>\n",
       "      <td>il est, il la</td>\n",
       "      <td>il téléphone, il enquête</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jai</td>\n",
       "      <td>jai un, jai une</td>\n",
       "      <td>docteur jai, jai sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>je</td>\n",
       "      <td>je ne, mais je</td>\n",
       "      <td>merci je, madame je</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>la</td>\n",
       "      <td>on la, il la</td>\n",
       "      <td>la bombe, la carte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>le</td>\n",
       "      <td>dans le, pour le</td>\n",
       "      <td>le film, le garçon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>les</td>\n",
       "      <td>tu les, pour les</td>\n",
       "      <td>les archives, les lire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mais</td>\n",
       "      <td>mais je, mais que</td>\n",
       "      <td>mais madame, mais chef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ne</td>\n",
       "      <td>je ne, tu ne</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nous</td>\n",
       "      <td>et nous, pas nous</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>on</td>\n",
       "      <td>on la, on est</td>\n",
       "      <td>on fait, on téléphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pas</td>\n",
       "      <td>pas vous, pas nous</td>\n",
       "      <td>pas intéressant, pas rouge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pour</td>\n",
       "      <td>pour le, pour les</td>\n",
       "      <td>pour noël, pour information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>que</td>\n",
       "      <td>mais que, ce que</td>\n",
       "      <td>patron que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qui</td>\n",
       "      <td>cest qui, qui ça</td>\n",
       "      <td>maître qui, qui enquête</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tu</td>\n",
       "      <td>tu les, tu ne</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>un</td>\n",
       "      <td>jai un, dans un</td>\n",
       "      <td>un whisky, un message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>une</td>\n",
       "      <td>jai une, en une</td>\n",
       "      <td>une surprise, une carte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vous</td>\n",
       "      <td>et vous, pas vous</td>\n",
       "      <td>vous docteur, vous amiral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ça</td>\n",
       "      <td>cest ça, qui ça</td>\n",
       "      <td>ça fond, fait ça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>des</td>\n",
       "      <td>NaN</td>\n",
       "      <td>des japonais, des as</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word             twogram              twogram_pair_turkish\n",
       "0     ce       ce que, de ce            ce symbole, ce message\n",
       "1   cest   cest ça, cest qui  cest intéressant, cest personnel\n",
       "2   dans    dans le, dans un                     japonais dans\n",
       "3     de               de ce             merci de, de biologie\n",
       "4     en              en une             en partie, en théorie\n",
       "5    est      il est, on est              est partie, gene est\n",
       "6     et    et vous, et nous              et surprise, et noël\n",
       "7     il       il est, il la          il téléphone, il enquête\n",
       "8    jai     jai un, jai une            docteur jai, jai sport\n",
       "9     je      je ne, mais je               merci je, madame je\n",
       "10    la        on la, il la                la bombe, la carte\n",
       "11    le    dans le, pour le                le film, le garçon\n",
       "12   les    tu les, pour les            les archives, les lire\n",
       "13  mais   mais je, mais que            mais madame, mais chef\n",
       "14    ne        je ne, tu ne                               NaN\n",
       "15  nous   et nous, pas nous                               NaN\n",
       "16    on       on la, on est             on fait, on téléphone\n",
       "17   pas  pas vous, pas nous        pas intéressant, pas rouge\n",
       "18  pour   pour le, pour les       pour noël, pour information\n",
       "19   que    mais que, ce que                        patron que\n",
       "20   qui    cest qui, qui ça           maître qui, qui enquête\n",
       "21    tu       tu les, tu ne                               NaN\n",
       "22    un     jai un, dans un             un whisky, un message\n",
       "23   une     jai une, en une           une surprise, une carte\n",
       "24  vous   et vous, pas vous         vous docteur, vous amiral\n",
       "25    ça     cest ça, qui ça                  ça fond, fait ça\n",
       "26   des                 NaN              des japonais, des as"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11.to_excel(writer2, sheet_name='Word_Part11', index=False)\n",
    "df_word_order_join_12.to_excel(writer2, sheet_name='Word_Part12', index=False)\n",
    "df_word_order_join_13.to_excel(writer2, sheet_name='Word_Part13', index=False)\n",
    "df_word_order_join_14.to_excel(writer2, sheet_name='Word_Part14', index=False)\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French_Turkish_28_Word_Step_7_Result1.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result2.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result3.xlsx',\n",
       " 'French_Turkish_28_Word_Step_7_Result4.xlsx',\n",
       " 'French_Turkish_28_Word_Step_28_Result1.xlsx',\n",
       " 'French_Turkish_28_Word_Result_With_Frequency.xlsx',\n",
       " 'French_Turkish_28_Word_Join_Result_Without_Frequency.xlsx']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
