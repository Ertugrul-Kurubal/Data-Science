{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_folder = \"Turkish\"  # Primary language\n",
    "lang_pair = \"Dutch\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164294</th>\n",
       "      <td>buldugumuzda</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164295</th>\n",
       "      <td>boşandıklarını</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164296</th>\n",
       "      <td>endişenlenme</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164297</th>\n",
       "      <td>uzaylıymışım</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164298</th>\n",
       "      <td>söylememis</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  frequency\n",
       "0                  bir   18835735\n",
       "1                   bu   11062659\n",
       "2                   ne    8025880\n",
       "3                   ve    7766036\n",
       "4                 için    5484109\n",
       "...                ...        ...\n",
       "164294    buldugumuzda         43\n",
       "164295  boşandıklarını         42\n",
       "164296    endişenlenme         42\n",
       "164297    uzaylıymışım         42\n",
       "164298      söylememis         38\n",
       "\n",
       "[164299 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence_All.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish_And_Dutch (nld)_Etymologeek_Result_All.xlsx']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>language_main</th>\n",
       "      <th>definition_main</th>\n",
       "      <th>dict_entry</th>\n",
       "      <th>language</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>şans</td>\n",
       "      <td>şans</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>(Noun) Fortune. Luck.Fortune. Luck.</td>\n",
       "      <td>dice</td>\n",
       "      <td>Dutch (nld)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loca</td>\n",
       "      <td>loca</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>(Noun) (masonic) lodge. Box (in theaters).(mas...</td>\n",
       "      <td>laubja</td>\n",
       "      <td>Dutch (nld)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_word dict_entry_main language_main  \\\n",
       "0        şans            şans       Turkish   \n",
       "1        loca            loca       Turkish   \n",
       "\n",
       "                                     definition_main dict_entry     language  \\\n",
       "0                (Noun) Fortune. Luck.Fortune. Luck.       dice  Dutch (nld)   \n",
       "1  (Noun) (masonic) lodge. Box (in theaters).(mas...     laubja  Dutch (nld)   \n",
       "\n",
       "   definition  \n",
       "0         NaN  \n",
       "1         NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.read_excel(f\"{lang_pair_list[0]}\")\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, bigger_than is integer\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, bigger_than is an integer\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list)\n",
    "    df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## while loop code block master\n",
    "#twogram_num = 100  # 2*step_num minimum: for each word takes two twogram\n",
    "#twogram_pair_num = 100  # 2*step_num minimum: for each word takes two twogram pair\n",
    "#word_thresh_num = 7\n",
    "#\n",
    "#word_start = 0  # 0\n",
    "#word_end = 28  # 10\n",
    "#step_num = word_end  # 10\n",
    "#word_limit = 28  # 200\n",
    "#part_num = 1\n",
    "#while word_end <= word_limit:\n",
    "#    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "#    df_word.reset_index(drop=True, inplace=True)\n",
    "#\n",
    "#    # language pair twogram\n",
    "#    ngram_list = []\n",
    "#    for i in df_pair[\"dict_entry_main\"]:\n",
    "#        for j in word_tokenize(i):\n",
    "#            for k in df_word[\"word\"]:\n",
    "#                twogram_1_2 = f\"{j} {k}\"\n",
    "#                ngram_list.append(twogram_1_2)\n",
    "#                twogram_2_1 = f\"{k} {j}\"\n",
    "#                ngram_list.append(twogram_2_1)\n",
    "#    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "#    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "#    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "#    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "#    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "#    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "#    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "#    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "#    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "#\n",
    "#    # twogram\n",
    "#    word_list = df_word[\"word\"].values.tolist()\n",
    "#    data_kind = \"twogram\"\n",
    "#    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "#    \n",
    "#    resultlist2 = []\n",
    "#\n",
    "#    manager = multiprocessing.Manager()\n",
    "#    resultlist2 = manager.list()\n",
    "#    \n",
    "#    def word_in_wordgroup2(list_var2):\n",
    "#        mergelist = []\n",
    "#        try:\n",
    "#            word = list_var2.split()\n",
    "#        except:\n",
    "#            pass\n",
    "#        var1 = range(len(word))\n",
    "#        for j in var1:\n",
    "#            if word[j] in word_list:\n",
    "#                mergelist.append(word[j])\n",
    "#                if len(mergelist) == len(word):\n",
    "#                        resultlist2.append(list_var2)\n",
    "#                            \n",
    "#    if __name__ == '__main__':\n",
    "#        # with Pool(16) as p:\n",
    "#        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "#            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "#\n",
    "#    result_list2 = list(resultlist2)\n",
    "#    df_result2 = pd.DataFrame(result_list2)\n",
    "#    df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})\n",
    "#    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "#    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "#    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "#    df_merge_result2.drop_duplicates(inplace=True)\n",
    "#    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "#    df_twogram_result = df_merge_result2\n",
    "#    #df_twogram_result = df_twogram_result.head(100)\n",
    "#\n",
    "#    # output\n",
    "#    df_output_result = pd.concat([df_word, df_twogram_result, df_lang_pair_twogram], axis=1)\n",
    "#\n",
    "#    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "#    a = 0\n",
    "#    b = 0\n",
    "#\n",
    "#    for i in range(0,110):\n",
    "#        # Insert words and their count \n",
    "#        try:\n",
    "#            word = df_output_result.iloc[i,0]  # word\n",
    "#            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "#            df_lesson_result.loc[i,\"word\"] = word\n",
    "#            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "#        except:\n",
    "#            pass\n",
    "#         \n",
    "#        # Insert n grams\n",
    "#        try:\n",
    "#            var1 = df_output_result.iloc[a,2]\n",
    "#            freq_var1 = df_output_result.iloc[a,3]\n",
    "#            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "#                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "#                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "#                try:\n",
    "#                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [\"twogram\"]): # word count result                \n",
    "#                        a += 1\n",
    "#                        var1 = df_output_result.iloc[a,2]\n",
    "#                        freq_var1 = df_output_result.iloc[a,3]\n",
    "#                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "#                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "#                    else:\n",
    "#                        pass\n",
    "#                except:\n",
    "#                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "#                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "#            else:\n",
    "#                pass\n",
    "#        except:\n",
    "#            pass\n",
    "#        a += 1\n",
    "#\n",
    "#        try:\n",
    "#            var2 = df_output_result.iloc[b,4]\n",
    "#            freq_var2 = df_output_result.iloc[b,5]\n",
    "#            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "#                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "#                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "#                try:\n",
    "#                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "#                        b += 1\n",
    "#                        var2 = df_output_result.iloc[b,4]\n",
    "#                        freq_var2 = df_output_result.iloc[b,5]\n",
    "#                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "#                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "#                    else:\n",
    "#                        pass\n",
    "#                except:\n",
    "#                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "#                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "#            else:\n",
    "#                pass\n",
    "#        except:\n",
    "#            pass\n",
    "#        b += 1\n",
    "#\n",
    "#    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "#    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "#    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "#    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "#\n",
    "#    word_start += step_num\n",
    "#    word_end += step_num\n",
    "#    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop code block word and twogram pair\n",
    "twogram_num = 100  # 2*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = 100  # 2*step_num minimum: for each word takes two twogram pair\n",
    "word_thresh_num = 2\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 7  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word \n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert twogram pair\n",
    "        try:\n",
    "            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                        freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Operation (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_Arabic_28_Word_Step_7_Result1.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result2.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result3.xlsx',\n",
       " 'Turkish_Arabic_28_Word_Step_7_Result4.xlsx']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result*.xlsx\")\n",
    "part_result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_pair_arabic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir dakika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir saniye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hayır ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ne yani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>şey ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ciddi mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bu mükemmel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tamam mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>şey için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ve hayır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ve tekrar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aşk için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tamam mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hayır değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hayır mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>evet elbette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>evet tamam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mümkün değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>çok garip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>çok tuhaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>elbette var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lütfen ama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>merhaba de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ama şey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lütfen de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hareket var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hayır lütfen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>elbette hayır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>aynı şey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>yani sen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>aptal şey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sen ye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bana müsaade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tamam da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yani bana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>daha basit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>daha temiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dünya kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>adam da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ye kadar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hayır yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>seni aptal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>yok hayır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tamam iyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>şey gibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>seni ahmak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>çek onu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ye onu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ye beni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rüya gibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>çek beni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>adam iyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>bunu asla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>yani bunu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   twogram_pair_arabic\n",
       "0           bir dakika\n",
       "1           bir saniye\n",
       "2             ne kadar\n",
       "3             bu kadar\n",
       "4            hayır ben\n",
       "5              ne yani\n",
       "6              şey ben\n",
       "7             ciddi mi\n",
       "8          bu mükemmel\n",
       "9             tamam mi\n",
       "10            şey için\n",
       "11            ve hayır\n",
       "12           ve tekrar\n",
       "13            aşk için\n",
       "14            tamam mı\n",
       "15         hayır değil\n",
       "16            hayır mı\n",
       "17        evet elbette\n",
       "18          evet tamam\n",
       "19        mümkün değil\n",
       "20           çok garip\n",
       "21           çok tuhaf\n",
       "22         elbette var\n",
       "23          lütfen ama\n",
       "24          merhaba de\n",
       "25             ama şey\n",
       "26           lütfen de\n",
       "27         hareket var\n",
       "28        hayır lütfen\n",
       "29       elbette hayır\n",
       "30            aynı şey\n",
       "31            yani sen\n",
       "32           aptal şey\n",
       "33              sen ye\n",
       "34        bana müsaade\n",
       "35            tamam da\n",
       "36           yani bana\n",
       "37          daha basit\n",
       "38          daha temiz\n",
       "39         dünya kadar\n",
       "40             adam da\n",
       "41            ye kadar\n",
       "42           hayır yok\n",
       "43          seni aptal\n",
       "44           yok hayır\n",
       "45           tamam iyi\n",
       "46            şey gibi\n",
       "47          seni ahmak\n",
       "48             çek onu\n",
       "49              ye onu\n",
       "50             ye beni\n",
       "51           rüya gibi\n",
       "52            çek beni\n",
       "53            adam iyi\n",
       "54           bunu asla\n",
       "55           yani bunu"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_all = pd.DataFrame()\n",
    "for i in part_result_file:\n",
    "    df_var = pd.read_excel(f\"{i}\")\n",
    "    df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "df_part_twogram_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adam da',\n",
       " 'adam iyi',\n",
       " 'ama şey',\n",
       " 'aptal şey',\n",
       " 'aynı şey',\n",
       " 'aşk için',\n",
       " 'bana müsaade',\n",
       " 'bir dakika',\n",
       " 'bir saniye',\n",
       " 'bu kadar',\n",
       " 'bu mükemmel',\n",
       " 'bunu asla',\n",
       " 'ciddi mi',\n",
       " 'daha basit',\n",
       " 'daha temiz',\n",
       " 'dünya kadar',\n",
       " 'elbette hayır',\n",
       " 'elbette var',\n",
       " 'evet elbette',\n",
       " 'evet tamam',\n",
       " 'hareket var',\n",
       " 'hayır ben',\n",
       " 'hayır değil',\n",
       " 'hayır lütfen',\n",
       " 'hayır mı',\n",
       " 'hayır yok',\n",
       " 'lütfen ama',\n",
       " 'lütfen de',\n",
       " 'merhaba de',\n",
       " 'mümkün değil',\n",
       " 'ne kadar',\n",
       " 'ne yani',\n",
       " 'rüya gibi',\n",
       " 'sen ye',\n",
       " 'seni ahmak',\n",
       " 'seni aptal',\n",
       " 'tamam da',\n",
       " 'tamam iyi',\n",
       " 'tamam mi',\n",
       " 'tamam mı',\n",
       " 've hayır',\n",
       " 've tekrar',\n",
       " 'yani bana',\n",
       " 'yani bunu',\n",
       " 'yani sen',\n",
       " 'ye beni',\n",
       " 'ye kadar',\n",
       " 'ye onu',\n",
       " 'yok hayır',\n",
       " 'çek beni',\n",
       " 'çek onu',\n",
       " 'çok garip',\n",
       " 'çok tuhaf',\n",
       " 'şey ben',\n",
       " 'şey gibi',\n",
       " 'şey için'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "set_part_twogram_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_part_twogram_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acaba beni',\n",
       " 'acaba bunu',\n",
       " 'acaba onu',\n",
       " 'acaba seni',\n",
       " 'acaba yok',\n",
       " 'adalet yok',\n",
       " 'adam gibi',\n",
       " 'adam iyi',\n",
       " 'adam seni',\n",
       " 'adam yok',\n",
       " 'ahmak seni',\n",
       " 'aile gibi',\n",
       " 'aile iyi',\n",
       " 'aile yok',\n",
       " 'alet yok',\n",
       " 'alkol yok',\n",
       " 'aman iyi',\n",
       " 'amber iyi',\n",
       " 'aptal gibi',\n",
       " 'aptal seni',\n",
       " 'araba gibi',\n",
       " 'araba iyi',\n",
       " 'araba yok',\n",
       " 'asker gibi',\n",
       " 'asker yok',\n",
       " 'asla yok',\n",
       " 'asıl onu',\n",
       " 'aynı gibi',\n",
       " 'aziz gibi',\n",
       " 'aşk gibi',\n",
       " 'aşk yok',\n",
       " 'barut gibi',\n",
       " 'barut yok',\n",
       " 'basit gibi',\n",
       " 'beni affetmek',\n",
       " 'beni asla',\n",
       " 'beni hala',\n",
       " 'beni hayır',\n",
       " 'beni rahat',\n",
       " 'beni yani',\n",
       " 'beni ye',\n",
       " 'beni çek',\n",
       " 'beni şey',\n",
       " 'bez yok',\n",
       " 'bina gibi',\n",
       " 'budala seni',\n",
       " 'bunu asla',\n",
       " 'bunu hayır',\n",
       " 'bunu kabul',\n",
       " 'bunu mesela',\n",
       " 'bunu ye',\n",
       " 'bunu çek',\n",
       " 'bunu şey',\n",
       " 'cahil gibi',\n",
       " 'cehennem gibi',\n",
       " 'cehennem iyi',\n",
       " 'cehennem yok',\n",
       " 'cenaze gibi',\n",
       " 'cenaze yok',\n",
       " 'cennet gibi',\n",
       " 'cennet yok',\n",
       " 'ceset gibi',\n",
       " 'ceset yok',\n",
       " 'cevap yok',\n",
       " 'ceza gibi',\n",
       " 'ceza yok',\n",
       " 'ciddi gibi',\n",
       " 'cihaz yok',\n",
       " 'cin gibi',\n",
       " 'cuma iyi',\n",
       " 'daire iyi',\n",
       " 'ders yok',\n",
       " 'dünya gibi',\n",
       " 'dünya yok',\n",
       " 'elbette iyi',\n",
       " 'elbette seni',\n",
       " 'elbette yok',\n",
       " 'emniyet yok',\n",
       " 'eylül yok',\n",
       " 'eziyet gibi',\n",
       " 'eşya yok',\n",
       " 'fahişe gibi',\n",
       " 'fahişe seni',\n",
       " 'fahişe yok',\n",
       " 'fakat bunu',\n",
       " 'fakat iyi',\n",
       " 'fakat yok',\n",
       " 'fare gibi',\n",
       " 'fare yok',\n",
       " 'fark yok',\n",
       " 'fayda yok',\n",
       " 'fikir yok',\n",
       " 'fıstık gibi',\n",
       " 'fıstık yok',\n",
       " 'gibi yani',\n",
       " 'gitar iyi',\n",
       " 'gurur yok',\n",
       " 'haber iyi',\n",
       " 'haber yok',\n",
       " 'hala iyi',\n",
       " 'hala yok',\n",
       " 'halk yok',\n",
       " 'halka yok',\n",
       " 'halı gibi',\n",
       " 'halı yok',\n",
       " 'hamile gibi',\n",
       " 'hap gibi',\n",
       " 'hap yok',\n",
       " 'hareket yok',\n",
       " 'harita yok',\n",
       " 'hata yok',\n",
       " 'hatıra gibi',\n",
       " 'hatıra yok',\n",
       " 'havuz yok',\n",
       " 'hayat gibi',\n",
       " 'hayat iyi',\n",
       " 'hayat yok',\n",
       " 'hayvan gibi',\n",
       " 'hayvan seni',\n",
       " 'hayvan yok',\n",
       " 'hayır beni',\n",
       " 'hayır bunu',\n",
       " 'hayır iyi',\n",
       " 'hayır onu',\n",
       " 'hayır seni',\n",
       " 'hayır yok',\n",
       " 'hazine yok',\n",
       " 'hazır gibi',\n",
       " 'hedef iyi',\n",
       " 'hedef yok',\n",
       " 'hediye yok',\n",
       " 'hesap yok',\n",
       " 'heyecan yok',\n",
       " 'heykel gibi',\n",
       " 'hikaye gibi',\n",
       " 'hikaye yok',\n",
       " 'huzur yok',\n",
       " 'insan gibi',\n",
       " 'iyi adam',\n",
       " 'iyi fikir',\n",
       " 'iyi haber',\n",
       " 'iyi hareket',\n",
       " 'iyi hikaye',\n",
       " 'iyi kahve',\n",
       " 'iyi nokta',\n",
       " 'iyi tamam',\n",
       " 'iyi taraf',\n",
       " 'izin yok',\n",
       " 'kader gibi',\n",
       " 'kafa yok',\n",
       " 'kahve gibi',\n",
       " 'kahve iyi',\n",
       " 'kahve yok',\n",
       " 'kale gibi',\n",
       " 'kale yok',\n",
       " 'kalem yok',\n",
       " 'kanun yok',\n",
       " 'karar yok',\n",
       " 'kasap gibi',\n",
       " 'katil gibi',\n",
       " 'katil seni',\n",
       " 'katil yok',\n",
       " 'kayıp gibi',\n",
       " 'kayıp yok',\n",
       " 'kayıt yok',\n",
       " 'kaza gibi',\n",
       " 'kaza yok',\n",
       " 'kelime yok',\n",
       " 'kitap gibi',\n",
       " 'kitap yok',\n",
       " 'kurban gibi',\n",
       " 'kurban yok',\n",
       " 'kütüphane gibi',\n",
       " 'kılıf yok',\n",
       " 'kırmızı iyi',\n",
       " 'lütfen beni',\n",
       " 'lütfen bunu',\n",
       " 'lütfen onu',\n",
       " 'maalesef yok',\n",
       " 'maaş yok',\n",
       " 'macera yok',\n",
       " 'mantık yok',\n",
       " 'mavi iyi',\n",
       " 'maymun gibi',\n",
       " 'maymun seni',\n",
       " 'maymun yok',\n",
       " 'mağara gibi',\n",
       " 'mağara yok',\n",
       " 'mektup yok',\n",
       " 'melek gibi',\n",
       " 'merhaba yok',\n",
       " 'mermi gibi',\n",
       " 'mermi yok',\n",
       " 'mesela beni',\n",
       " 'mesela bunu',\n",
       " 'mesela seni',\n",
       " 'mesele yok',\n",
       " 'mezar gibi',\n",
       " 'mezar yok',\n",
       " 'miras gibi',\n",
       " 'misafir yok',\n",
       " 'mucize gibi',\n",
       " 'mucize yok',\n",
       " 'muhtemelen beni',\n",
       " 'muhtemelen bunu',\n",
       " 'muhtemelen iyi',\n",
       " 'muhtemelen yok',\n",
       " 'mutfak yok',\n",
       " 'mükemmel gibi',\n",
       " 'mükemmel iyi',\n",
       " 'mürekkep yok',\n",
       " 'müsaade yok',\n",
       " 'müşteri yok',\n",
       " 'mıknatıs gibi',\n",
       " 'nehir gibi',\n",
       " 'nehir yok',\n",
       " 'onu acaba',\n",
       " 'onu asla',\n",
       " 'onu hayır',\n",
       " 'onu rahat',\n",
       " 'onu tamam',\n",
       " 'onu ye',\n",
       " 'onu çek',\n",
       " 'onu şey',\n",
       " 'rahip gibi',\n",
       " 'rahip yok',\n",
       " 'rekabet yok',\n",
       " 'resim gibi',\n",
       " 'resim iyi',\n",
       " 'resim yok',\n",
       " 'ruh yok',\n",
       " 'rüya gibi',\n",
       " 'rüşvet gibi',\n",
       " 'saat gibi',\n",
       " 'saat yok',\n",
       " 'sabun yok',\n",
       " 'salim iyi',\n",
       " 'salı gibi',\n",
       " 'salı iyi',\n",
       " 'sanat gibi',\n",
       " 'sandalye yok',\n",
       " 'sebep yok',\n",
       " 'selam iyi',\n",
       " 'selam yok',\n",
       " 'seni ahmak',\n",
       " 'seni aptal',\n",
       " 'seni asi',\n",
       " 'seni asla',\n",
       " 'seni budala',\n",
       " 'seni cahil',\n",
       " 'seni casus',\n",
       " 'seni ceset',\n",
       " 'seni fahişe',\n",
       " 'seni fare',\n",
       " 'seni hala',\n",
       " 'seni has',\n",
       " 'seni hayvan',\n",
       " 'seni iblis',\n",
       " 'seni ihtiyar',\n",
       " 'seni kasap',\n",
       " 'seni katil',\n",
       " 'seni maymun',\n",
       " 'seni vahşi',\n",
       " 'seni velet',\n",
       " 'seni yani',\n",
       " 'seni zalim',\n",
       " 'seni zayıf',\n",
       " 'seni zenci',\n",
       " 'seni çaylak',\n",
       " 'seni şeker',\n",
       " 'seni şey',\n",
       " 'seni şeytan',\n",
       " 'seyahat gibi',\n",
       " 'sihir gibi',\n",
       " 'sihir yok',\n",
       " 'sihirbaz gibi',\n",
       " 'silah gibi',\n",
       " 'silah yok',\n",
       " 'sohbet yok',\n",
       " 'sokak gibi',\n",
       " 'tabak gibi',\n",
       " 'tabak yok',\n",
       " 'tamam bunu',\n",
       " 'tamam gibi',\n",
       " 'tamam iyi',\n",
       " 'tamam seni',\n",
       " 'tamam yok',\n",
       " 'tamamen iyi',\n",
       " 'taraf yok',\n",
       " 'tarif yok',\n",
       " 'tarih gibi',\n",
       " 'tarih yok',\n",
       " 'tatil gibi',\n",
       " 'tehlike yok',\n",
       " 'teklif yok',\n",
       " 'tekrar yok',\n",
       " 'temiz gibi',\n",
       " 'temmuz gibi',\n",
       " 'tercih yok',\n",
       " 'tesadüf gibi',\n",
       " 'ticaret gibi',\n",
       " 'tuhaf iyi',\n",
       " 'vaat yok',\n",
       " 'vakit yok',\n",
       " 'vali yok',\n",
       " 'vatan yok',\n",
       " 'veda yok',\n",
       " 'velet seni',\n",
       " 'vicdan yok',\n",
       " 'yani beni',\n",
       " 'yani bunu',\n",
       " 'yani iyi',\n",
       " 'yani onu',\n",
       " 'yani seni',\n",
       " 'yani yok',\n",
       " 'ye beni',\n",
       " 'ye bunu',\n",
       " 'ye onu',\n",
       " 'yok ahbap',\n",
       " 'yok asker',\n",
       " 'yok asla',\n",
       " 'yok aynı',\n",
       " 'yok elbette',\n",
       " 'yok hayır',\n",
       " 'yok lütfen',\n",
       " 'yok maalesef',\n",
       " 'yok rahibe',\n",
       " 'yok ressam',\n",
       " 'yok sınıf',\n",
       " 'yok tamam',\n",
       " 'yok tesadüf',\n",
       " 'yok yani',\n",
       " 'yok şey',\n",
       " 'zafer yok',\n",
       " 'zarar yok',\n",
       " 'ziyaret yok',\n",
       " 'çaylak seni',\n",
       " 'çek beni',\n",
       " 'çek bunu',\n",
       " 'çek onu',\n",
       " 'çek yok',\n",
       " 'özür yok',\n",
       " 'ücret yok',\n",
       " 'şarap gibi',\n",
       " 'şarap yok',\n",
       " 'şarkı gibi',\n",
       " 'şarkı iyi',\n",
       " 'şarkı yok',\n",
       " 'şart yok',\n",
       " 'şeker gibi',\n",
       " 'şeker yok',\n",
       " 'şey beni',\n",
       " 'şey bunu',\n",
       " 'şey gibi',\n",
       " 'şey iyi',\n",
       " 'şey yok',\n",
       " 'şeytan gibi',\n",
       " 'şeytan seni',\n",
       " 'şeytan yok',\n",
       " 'şiir gibi',\n",
       " 'şikâyet yok',\n",
       " 'şirket yok',\n",
       " 'şüphe yok'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "set_lang_pair_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_lang_pair_twogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acaba beni',\n",
       " 'acaba bunu',\n",
       " 'acaba onu',\n",
       " 'acaba seni',\n",
       " 'acaba yok',\n",
       " 'adalet yok',\n",
       " 'adam gibi',\n",
       " 'adam seni',\n",
       " 'adam yok',\n",
       " 'ahmak seni',\n",
       " 'aile gibi',\n",
       " 'aile iyi',\n",
       " 'aile yok',\n",
       " 'alet yok',\n",
       " 'alkol yok',\n",
       " 'aman iyi',\n",
       " 'amber iyi',\n",
       " 'aptal gibi',\n",
       " 'aptal seni',\n",
       " 'araba gibi',\n",
       " 'araba iyi',\n",
       " 'araba yok',\n",
       " 'asker gibi',\n",
       " 'asker yok',\n",
       " 'asla yok',\n",
       " 'asıl onu',\n",
       " 'aynı gibi',\n",
       " 'aziz gibi',\n",
       " 'aşk gibi',\n",
       " 'aşk yok',\n",
       " 'barut gibi',\n",
       " 'barut yok',\n",
       " 'basit gibi',\n",
       " 'beni affetmek',\n",
       " 'beni asla',\n",
       " 'beni hala',\n",
       " 'beni hayır',\n",
       " 'beni rahat',\n",
       " 'beni yani',\n",
       " 'beni ye',\n",
       " 'beni çek',\n",
       " 'beni şey',\n",
       " 'bez yok',\n",
       " 'bina gibi',\n",
       " 'budala seni',\n",
       " 'bunu hayır',\n",
       " 'bunu kabul',\n",
       " 'bunu mesela',\n",
       " 'bunu ye',\n",
       " 'bunu çek',\n",
       " 'bunu şey',\n",
       " 'cahil gibi',\n",
       " 'cehennem gibi',\n",
       " 'cehennem iyi',\n",
       " 'cehennem yok',\n",
       " 'cenaze gibi',\n",
       " 'cenaze yok',\n",
       " 'cennet gibi',\n",
       " 'cennet yok',\n",
       " 'ceset gibi',\n",
       " 'ceset yok',\n",
       " 'cevap yok',\n",
       " 'ceza gibi',\n",
       " 'ceza yok',\n",
       " 'ciddi gibi',\n",
       " 'cihaz yok',\n",
       " 'cin gibi',\n",
       " 'cuma iyi',\n",
       " 'daire iyi',\n",
       " 'ders yok',\n",
       " 'dünya gibi',\n",
       " 'dünya yok',\n",
       " 'elbette iyi',\n",
       " 'elbette seni',\n",
       " 'elbette yok',\n",
       " 'emniyet yok',\n",
       " 'eylül yok',\n",
       " 'eziyet gibi',\n",
       " 'eşya yok',\n",
       " 'fahişe gibi',\n",
       " 'fahişe seni',\n",
       " 'fahişe yok',\n",
       " 'fakat bunu',\n",
       " 'fakat iyi',\n",
       " 'fakat yok',\n",
       " 'fare gibi',\n",
       " 'fare yok',\n",
       " 'fark yok',\n",
       " 'fayda yok',\n",
       " 'fikir yok',\n",
       " 'fıstık gibi',\n",
       " 'fıstık yok',\n",
       " 'gibi yani',\n",
       " 'gitar iyi',\n",
       " 'gurur yok',\n",
       " 'haber iyi',\n",
       " 'haber yok',\n",
       " 'hala iyi',\n",
       " 'hala yok',\n",
       " 'halk yok',\n",
       " 'halka yok',\n",
       " 'halı gibi',\n",
       " 'halı yok',\n",
       " 'hamile gibi',\n",
       " 'hap gibi',\n",
       " 'hap yok',\n",
       " 'hareket yok',\n",
       " 'harita yok',\n",
       " 'hata yok',\n",
       " 'hatıra gibi',\n",
       " 'hatıra yok',\n",
       " 'havuz yok',\n",
       " 'hayat gibi',\n",
       " 'hayat iyi',\n",
       " 'hayat yok',\n",
       " 'hayvan gibi',\n",
       " 'hayvan seni',\n",
       " 'hayvan yok',\n",
       " 'hayır beni',\n",
       " 'hayır bunu',\n",
       " 'hayır iyi',\n",
       " 'hayır onu',\n",
       " 'hayır seni',\n",
       " 'hazine yok',\n",
       " 'hazır gibi',\n",
       " 'hedef iyi',\n",
       " 'hedef yok',\n",
       " 'hediye yok',\n",
       " 'hesap yok',\n",
       " 'heyecan yok',\n",
       " 'heykel gibi',\n",
       " 'hikaye gibi',\n",
       " 'hikaye yok',\n",
       " 'huzur yok',\n",
       " 'insan gibi',\n",
       " 'iyi adam',\n",
       " 'iyi fikir',\n",
       " 'iyi haber',\n",
       " 'iyi hareket',\n",
       " 'iyi hikaye',\n",
       " 'iyi kahve',\n",
       " 'iyi nokta',\n",
       " 'iyi tamam',\n",
       " 'iyi taraf',\n",
       " 'izin yok',\n",
       " 'kader gibi',\n",
       " 'kafa yok',\n",
       " 'kahve gibi',\n",
       " 'kahve iyi',\n",
       " 'kahve yok',\n",
       " 'kale gibi',\n",
       " 'kale yok',\n",
       " 'kalem yok',\n",
       " 'kanun yok',\n",
       " 'karar yok',\n",
       " 'kasap gibi',\n",
       " 'katil gibi',\n",
       " 'katil seni',\n",
       " 'katil yok',\n",
       " 'kayıp gibi',\n",
       " 'kayıp yok',\n",
       " 'kayıt yok',\n",
       " 'kaza gibi',\n",
       " 'kaza yok',\n",
       " 'kelime yok',\n",
       " 'kitap gibi',\n",
       " 'kitap yok',\n",
       " 'kurban gibi',\n",
       " 'kurban yok',\n",
       " 'kütüphane gibi',\n",
       " 'kılıf yok',\n",
       " 'kırmızı iyi',\n",
       " 'lütfen beni',\n",
       " 'lütfen bunu',\n",
       " 'lütfen onu',\n",
       " 'maalesef yok',\n",
       " 'maaş yok',\n",
       " 'macera yok',\n",
       " 'mantık yok',\n",
       " 'mavi iyi',\n",
       " 'maymun gibi',\n",
       " 'maymun seni',\n",
       " 'maymun yok',\n",
       " 'mağara gibi',\n",
       " 'mağara yok',\n",
       " 'mektup yok',\n",
       " 'melek gibi',\n",
       " 'merhaba yok',\n",
       " 'mermi gibi',\n",
       " 'mermi yok',\n",
       " 'mesela beni',\n",
       " 'mesela bunu',\n",
       " 'mesela seni',\n",
       " 'mesele yok',\n",
       " 'mezar gibi',\n",
       " 'mezar yok',\n",
       " 'miras gibi',\n",
       " 'misafir yok',\n",
       " 'mucize gibi',\n",
       " 'mucize yok',\n",
       " 'muhtemelen beni',\n",
       " 'muhtemelen bunu',\n",
       " 'muhtemelen iyi',\n",
       " 'muhtemelen yok',\n",
       " 'mutfak yok',\n",
       " 'mükemmel gibi',\n",
       " 'mükemmel iyi',\n",
       " 'mürekkep yok',\n",
       " 'müsaade yok',\n",
       " 'müşteri yok',\n",
       " 'mıknatıs gibi',\n",
       " 'nehir gibi',\n",
       " 'nehir yok',\n",
       " 'onu acaba',\n",
       " 'onu asla',\n",
       " 'onu hayır',\n",
       " 'onu rahat',\n",
       " 'onu tamam',\n",
       " 'onu ye',\n",
       " 'onu çek',\n",
       " 'onu şey',\n",
       " 'rahip gibi',\n",
       " 'rahip yok',\n",
       " 'rekabet yok',\n",
       " 'resim gibi',\n",
       " 'resim iyi',\n",
       " 'resim yok',\n",
       " 'ruh yok',\n",
       " 'rüşvet gibi',\n",
       " 'saat gibi',\n",
       " 'saat yok',\n",
       " 'sabun yok',\n",
       " 'salim iyi',\n",
       " 'salı gibi',\n",
       " 'salı iyi',\n",
       " 'sanat gibi',\n",
       " 'sandalye yok',\n",
       " 'sebep yok',\n",
       " 'selam iyi',\n",
       " 'selam yok',\n",
       " 'seni asi',\n",
       " 'seni asla',\n",
       " 'seni budala',\n",
       " 'seni cahil',\n",
       " 'seni casus',\n",
       " 'seni ceset',\n",
       " 'seni fahişe',\n",
       " 'seni fare',\n",
       " 'seni hala',\n",
       " 'seni has',\n",
       " 'seni hayvan',\n",
       " 'seni iblis',\n",
       " 'seni ihtiyar',\n",
       " 'seni kasap',\n",
       " 'seni katil',\n",
       " 'seni maymun',\n",
       " 'seni vahşi',\n",
       " 'seni velet',\n",
       " 'seni yani',\n",
       " 'seni zalim',\n",
       " 'seni zayıf',\n",
       " 'seni zenci',\n",
       " 'seni çaylak',\n",
       " 'seni şeker',\n",
       " 'seni şey',\n",
       " 'seni şeytan',\n",
       " 'seyahat gibi',\n",
       " 'sihir gibi',\n",
       " 'sihir yok',\n",
       " 'sihirbaz gibi',\n",
       " 'silah gibi',\n",
       " 'silah yok',\n",
       " 'sohbet yok',\n",
       " 'sokak gibi',\n",
       " 'tabak gibi',\n",
       " 'tabak yok',\n",
       " 'tamam bunu',\n",
       " 'tamam gibi',\n",
       " 'tamam seni',\n",
       " 'tamam yok',\n",
       " 'tamamen iyi',\n",
       " 'taraf yok',\n",
       " 'tarif yok',\n",
       " 'tarih gibi',\n",
       " 'tarih yok',\n",
       " 'tatil gibi',\n",
       " 'tehlike yok',\n",
       " 'teklif yok',\n",
       " 'tekrar yok',\n",
       " 'temiz gibi',\n",
       " 'temmuz gibi',\n",
       " 'tercih yok',\n",
       " 'tesadüf gibi',\n",
       " 'ticaret gibi',\n",
       " 'tuhaf iyi',\n",
       " 'vaat yok',\n",
       " 'vakit yok',\n",
       " 'vali yok',\n",
       " 'vatan yok',\n",
       " 'veda yok',\n",
       " 'velet seni',\n",
       " 'vicdan yok',\n",
       " 'yani beni',\n",
       " 'yani iyi',\n",
       " 'yani onu',\n",
       " 'yani seni',\n",
       " 'yani yok',\n",
       " 'ye bunu',\n",
       " 'yok ahbap',\n",
       " 'yok asker',\n",
       " 'yok asla',\n",
       " 'yok aynı',\n",
       " 'yok elbette',\n",
       " 'yok lütfen',\n",
       " 'yok maalesef',\n",
       " 'yok rahibe',\n",
       " 'yok ressam',\n",
       " 'yok sınıf',\n",
       " 'yok tamam',\n",
       " 'yok tesadüf',\n",
       " 'yok yani',\n",
       " 'yok şey',\n",
       " 'zafer yok',\n",
       " 'zarar yok',\n",
       " 'ziyaret yok',\n",
       " 'çaylak seni',\n",
       " 'çek bunu',\n",
       " 'çek yok',\n",
       " 'özür yok',\n",
       " 'ücret yok',\n",
       " 'şarap gibi',\n",
       " 'şarap yok',\n",
       " 'şarkı gibi',\n",
       " 'şarkı iyi',\n",
       " 'şarkı yok',\n",
       " 'şart yok',\n",
       " 'şeker gibi',\n",
       " 'şeker yok',\n",
       " 'şey beni',\n",
       " 'şey bunu',\n",
       " 'şey iyi',\n",
       " 'şey yok',\n",
       " 'şeytan gibi',\n",
       " 'şeytan seni',\n",
       " 'şeytan yok',\n",
       " 'şiir gibi',\n",
       " 'şikâyet yok',\n",
       " 'şirket yok',\n",
       " 'şüphe yok'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lang_pair_twogram.difference(set_part_twogram_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_pair_arabic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hayır bunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sabun yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cahil gibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>veda yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haber yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>maymun yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>fare yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>fıstık gibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>hayır beni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>elbette yok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    twogram_pair_arabic\n",
       "0            hayır bunu\n",
       "1             sabun yok\n",
       "2            cahil gibi\n",
       "3              veda yok\n",
       "4             haber yok\n",
       "..                  ...\n",
       "344          maymun yok\n",
       "345            fare yok\n",
       "346         fıstık gibi\n",
       "347          hayır beni\n",
       "348         elbette yok\n",
       "\n",
       "[349 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "df_set_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_lang_pair_twogram.difference(set_part_twogram_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram_pair_arabic</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vakit yok</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cevap yok</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elbette yok</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silah yok</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bunu ye</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>halk yok</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>cahil gibi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>hatıra yok</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>bina gibi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>aile iyi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    twogram_pair_arabic  frequency\n",
       "0             vakit yok       1366\n",
       "1             cevap yok       1075\n",
       "2           elbette yok       1027\n",
       "3             silah yok        822\n",
       "4               bunu ye        399\n",
       "..                  ...        ...\n",
       "344            halk yok          3\n",
       "345          cahil gibi          3\n",
       "346          hatıra yok          3\n",
       "347           bina gibi          3\n",
       "348            aile iyi          3\n",
       "\n",
       "[349 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_set_pair_twogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_Portuguese_28_Word_Step_7_Result1.xlsx',\n",
       " 'Turkish_Portuguese_28_Word_Step_7_Result2.xlsx',\n",
       " 'Turkish_Portuguese_28_Word_Step_7_Result3.xlsx',\n",
       " 'Turkish_Portuguese_28_Word_Step_7_Result4.xlsx']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result*.xlsx\")\n",
    "part_result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read previous part result\n",
    "df_part_all = pd.DataFrame()\n",
    "for i in part_result_file:\n",
    "    df_var = pd.read_excel(f\"{i}\")\n",
    "    df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "\n",
    "# while loop code block\n",
    "twogram_num = 100  # 2*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = 100  # 2*step_num minimum: for each word takes two twogram pair\n",
    "word_thresh_num = 7\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 28  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = 28  # 200\n",
    "part_num = 1\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    ngram_list = []\n",
    "    for i in df_pair[\"dict_entry_main\"]:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in df_word[\"word\"]:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(0,110):\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num-5), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532</td>\n",
       "      <td>harita için</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972</td>\n",
       "      <td>bu harita</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386</td>\n",
       "      <td>ve sandviç</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652</td>\n",
       "      <td>bir mango</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>çok iyi</td>\n",
       "      <td>33627</td>\n",
       "      <td>sandviç var</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>hayır değil</td>\n",
       "      <td>18740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>evet var</td>\n",
       "      <td>11138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>bu iyi</td>\n",
       "      <td>10399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>sen de</td>\n",
       "      <td>10089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>evet ama</td>\n",
       "      <td>6846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>bir daha</td>\n",
       "      <td>5168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>ve sen</td>\n",
       "      <td>4648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>bana mı</td>\n",
       "      <td>3593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>bir şey</td>\n",
       "      <td>1611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>bana da</td>\n",
       "      <td>1498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>1314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>daha çok</td>\n",
       "      <td>1129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>ama yok</td>\n",
       "      <td>927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>bunu da</td>\n",
       "      <td>717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>ve bunu</td>\n",
       "      <td>492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>yok gibi</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>seni beni</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>beni seni</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>iyi</td>\n",
       "      <td>2383224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word      twogram freq_twogram twogram_pair_portuguese  \\\n",
       "0     bir  18835735.0       ne var        62532             harita için   \n",
       "1      bu  11062659.0       ben de        59972               bu harita   \n",
       "2      ne   8025880.0     değil mi        58386              ve sandviç   \n",
       "3      ve   7766036.0       ben mi        33652               bir mango   \n",
       "4    için   5484109.0      çok iyi        33627             sandviç var   \n",
       "5      mi   5362714.0      ne için        31857                     NaN   \n",
       "6     ben   4908913.0  hayır değil        18740                     NaN   \n",
       "7      de   4880315.0     hayır mı        15769                     NaN   \n",
       "8     çok   4852169.0     bu kadar        15745                     NaN   \n",
       "9     ama   4661966.0     evet var        11138                     NaN   \n",
       "10    var   4389551.0       bu iyi        10399                     NaN   \n",
       "11   evet   4324786.0       sen de        10089                     NaN   \n",
       "12     mı   4001316.0     evet ama         6846                     NaN   \n",
       "13  değil   3883885.0     bir daha         5168                     NaN   \n",
       "14     da   3610161.0       ve sen         4648                     NaN   \n",
       "15    şey   3602024.0      bana mı         3593                     NaN   \n",
       "16  hayır   3406992.0      bir şey         1611                     NaN   \n",
       "17   daha   3317577.0      bana da         1498                     NaN   \n",
       "18    sen   3283654.0     şey gibi         1314                     NaN   \n",
       "19  kadar   2697900.0     daha çok         1129                     NaN   \n",
       "20   bana   2659182.0      ama yok          927                     NaN   \n",
       "21    yok   2491685.0      bunu da          717                     NaN   \n",
       "22    onu   2486889.0      ve bunu          492                     NaN   \n",
       "23   seni   2454988.0     yok gibi           87                     NaN   \n",
       "24   beni   2446696.0    seni beni            7                     NaN   \n",
       "25   bunu   2445337.0    beni seni            4                     NaN   \n",
       "26   gibi   2427957.0          NaN          NaN                     NaN   \n",
       "27    iyi   2383224.0          NaN          NaN                     NaN   \n",
       "28    NaN         NaN          NaN          NaN                     NaN   \n",
       "\n",
       "   freq_twogram_pair_portuguese  word_count  \n",
       "0                          15.0         3.0  \n",
       "1                          12.0         3.0  \n",
       "2                           7.0         2.0  \n",
       "3                           5.0         3.0  \n",
       "4                           3.0         2.0  \n",
       "5                           NaN         2.0  \n",
       "6                           NaN         2.0  \n",
       "7                           NaN         2.0  \n",
       "8                           NaN         2.0  \n",
       "9                           NaN         2.0  \n",
       "10                          NaN         3.0  \n",
       "11                          NaN         2.0  \n",
       "12                          NaN         2.0  \n",
       "13                          NaN         2.0  \n",
       "14                          NaN         2.0  \n",
       "15                          NaN         2.0  \n",
       "16                          NaN         2.0  \n",
       "17                          NaN         2.0  \n",
       "18                          NaN         2.0  \n",
       "19                          NaN         1.0  \n",
       "20                          NaN         2.0  \n",
       "21                          NaN         2.0  \n",
       "22                          NaN         NaN  \n",
       "23                          NaN         2.0  \n",
       "24                          NaN         2.0  \n",
       "25                          NaN         2.0  \n",
       "26                          NaN         2.0  \n",
       "27                          NaN         2.0  \n",
       "28                          NaN         NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>çok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ve</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>var</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seni</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ne</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mı</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iyi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hayır</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>evet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>değil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>de</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>daha</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>da</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>beni</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ben</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>şey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>için</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kadar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  word_count\n",
       "0     ama           2\n",
       "1    bana           2\n",
       "2     çok           2\n",
       "3     yok           2\n",
       "4      ve           2\n",
       "5     var           2\n",
       "6    seni           2\n",
       "7     sen           2\n",
       "8      ne           2\n",
       "9      mı           2\n",
       "10     mi           2\n",
       "11    iyi           2\n",
       "12  hayır           2\n",
       "13   gibi           2\n",
       "14   evet           2\n",
       "15  değil           2\n",
       "16     de           2\n",
       "17   daha           2\n",
       "18     da           2\n",
       "19   bunu           2\n",
       "20     bu           2\n",
       "21    bir           2\n",
       "22   beni           2\n",
       "23    ben           2\n",
       "24    şey           2\n",
       "25   için           1\n",
       "26  kadar           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harita</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandviç</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mango</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>var</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  word_count\n",
       "0   harita           2\n",
       "1  sandviç           2\n",
       "2      bir           1\n",
       "3       bu           1\n",
       "4     için           1\n",
       "5    mango           1\n",
       "6      var           1\n",
       "7       ve           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "      <td>bir harita</td>\n",
       "      <td>247.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "      <td>sandviç mi</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "      <td>bir sandviç</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "      <td>harita bu</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "      <td>köri mi</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  freq_word twogram_pair_portuguese  freq_twogram_pair_portuguese  \\\n",
       "0   bir   18835735              bir harita                         247.0   \n",
       "1    bu   11062659              sandviç mi                         111.0   \n",
       "2    ne    8025880             bir sandviç                          43.0   \n",
       "3    ve    7766036               harita bu                          17.0   \n",
       "4  için    5484109                 köri mi                          13.0   \n",
       "5    mi    5362714                     NaN                           NaN   \n",
       "6   ben    4908913                     NaN                           NaN   \n",
       "\n",
       "   word_count  \n",
       "0         2.0  \n",
       "1         1.0  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         2.0  \n",
       "6         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result1.xlsx\")\n",
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315</td>\n",
       "      <td>harita mı</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169</td>\n",
       "      <td>evet harita</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966</td>\n",
       "      <td>sandviç değil</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551</td>\n",
       "      <td>sandviç de</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_portuguese  freq_twogram_pair_portuguese  \\\n",
       "0     de    4880315               harita mı                         166.0   \n",
       "1    çok    4852169             evet harita                           9.0   \n",
       "2    ama    4661966           sandviç değil                           4.0   \n",
       "3    var    4389551              sandviç de                           3.0   \n",
       "4   evet    4324786                     NaN                           NaN   \n",
       "5     mı    4001316                     NaN                           NaN   \n",
       "6  değil    3883885                     NaN                           NaN   \n",
       "\n",
       "   word_count  \n",
       "0         1.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         1.0  \n",
       "5         1.0  \n",
       "6         1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_12 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result2.xlsx\")\n",
    "df_part_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161</td>\n",
       "      <td>hayır mango</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_portuguese  freq_twogram_pair_portuguese  \\\n",
       "0     da    3610161             hayır mango                          10.0   \n",
       "1    şey    3602024                     NaN                           NaN   \n",
       "2  hayır    3406992                     NaN                           NaN   \n",
       "3   daha    3317577                     NaN                           NaN   \n",
       "4    sen    3283654                     NaN                           NaN   \n",
       "5  kadar    2697900                     NaN                           NaN   \n",
       "6   bana    2659182                     NaN                           NaN   \n",
       "\n",
       "   word_count  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         1.0  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_13 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result3.xlsx\")\n",
    "df_part_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685</td>\n",
       "      <td>harita yok</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iyi</td>\n",
       "      <td>2383224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  freq_word twogram_pair_portuguese  freq_twogram_pair_portuguese  \\\n",
       "0   yok    2491685              harita yok                          25.0   \n",
       "1   onu    2486889                     NaN                           NaN   \n",
       "2  seni    2454988                     NaN                           NaN   \n",
       "3  beni    2446696                     NaN                           NaN   \n",
       "4  bunu    2445337                     NaN                           NaN   \n",
       "5  gibi    2427957                     NaN                           NaN   \n",
       "6   iyi    2383224                     NaN                           NaN   \n",
       "\n",
       "   word_count  \n",
       "0         1.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_14 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result4.xlsx\")\n",
    "df_part_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>harita için</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>bu harita</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>ve sandviç</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>bir mango</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "      <td>çok iyi</td>\n",
       "      <td>33627.0</td>\n",
       "      <td>sandviç var</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913</td>\n",
       "      <td>hayır değil</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315</td>\n",
       "      <td>hayır mı</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966</td>\n",
       "      <td>evet var</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551</td>\n",
       "      <td>bu iyi</td>\n",
       "      <td>10399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786</td>\n",
       "      <td>sen de</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316</td>\n",
       "      <td>evet ama</td>\n",
       "      <td>6846.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885</td>\n",
       "      <td>bir daha</td>\n",
       "      <td>5168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161</td>\n",
       "      <td>ve sen</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024</td>\n",
       "      <td>bana mı</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992</td>\n",
       "      <td>bir şey</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577</td>\n",
       "      <td>bana da</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654</td>\n",
       "      <td>şey gibi</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900</td>\n",
       "      <td>daha çok</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182</td>\n",
       "      <td>ama yok</td>\n",
       "      <td>927.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685</td>\n",
       "      <td>bunu da</td>\n",
       "      <td>717.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889</td>\n",
       "      <td>ve bunu</td>\n",
       "      <td>492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988</td>\n",
       "      <td>yok gibi</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696</td>\n",
       "      <td>seni beni</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337</td>\n",
       "      <td>beni seni</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>iyi</td>\n",
       "      <td>2383224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq_word      twogram  freq_twogram twogram_pair_portuguese  \\\n",
       "0     bir   18835735       ne var       62532.0             harita için   \n",
       "1      bu   11062659       ben de       59972.0               bu harita   \n",
       "2      ne    8025880     değil mi       58386.0              ve sandviç   \n",
       "3      ve    7766036       ben mi       33652.0               bir mango   \n",
       "4    için    5484109      çok iyi       33627.0             sandviç var   \n",
       "5      mi    5362714      ne için       31857.0                     NaN   \n",
       "6     ben    4908913  hayır değil       18740.0                     NaN   \n",
       "7      de    4880315     hayır mı       15769.0                     NaN   \n",
       "8     çok    4852169     bu kadar       15745.0                     NaN   \n",
       "9     ama    4661966     evet var       11138.0                     NaN   \n",
       "10    var    4389551       bu iyi       10399.0                     NaN   \n",
       "11   evet    4324786       sen de       10089.0                     NaN   \n",
       "12     mı    4001316     evet ama        6846.0                     NaN   \n",
       "13  değil    3883885     bir daha        5168.0                     NaN   \n",
       "14     da    3610161       ve sen        4648.0                     NaN   \n",
       "15    şey    3602024      bana mı        3593.0                     NaN   \n",
       "16  hayır    3406992      bir şey        1611.0                     NaN   \n",
       "17   daha    3317577      bana da        1498.0                     NaN   \n",
       "18    sen    3283654     şey gibi        1314.0                     NaN   \n",
       "19  kadar    2697900     daha çok        1129.0                     NaN   \n",
       "20   bana    2659182      ama yok         927.0                     NaN   \n",
       "21    yok    2491685      bunu da         717.0                     NaN   \n",
       "22    onu    2486889      ve bunu         492.0                     NaN   \n",
       "23   seni    2454988     yok gibi          87.0                     NaN   \n",
       "24   beni    2446696    seni beni           7.0                     NaN   \n",
       "25   bunu    2445337    beni seni           4.0                     NaN   \n",
       "26   gibi    2427957          NaN           NaN                     NaN   \n",
       "27    iyi    2383224          NaN           NaN                     NaN   \n",
       "\n",
       "    freq_twogram_pair_portuguese  word_count  \n",
       "0                           15.0         3.0  \n",
       "1                           12.0         3.0  \n",
       "2                            7.0         2.0  \n",
       "3                            5.0         3.0  \n",
       "4                            3.0         2.0  \n",
       "5                            NaN         2.0  \n",
       "6                            NaN         2.0  \n",
       "7                            NaN         2.0  \n",
       "8                            NaN         2.0  \n",
       "9                            NaN         2.0  \n",
       "10                           NaN         3.0  \n",
       "11                           NaN         2.0  \n",
       "12                           NaN         2.0  \n",
       "13                           NaN         2.0  \n",
       "14                           NaN         2.0  \n",
       "15                           NaN         2.0  \n",
       "16                           NaN         2.0  \n",
       "17                           NaN         2.0  \n",
       "18                           NaN         2.0  \n",
       "19                           NaN         1.0  \n",
       "20                           NaN         2.0  \n",
       "21                           NaN         2.0  \n",
       "22                           NaN         NaN  \n",
       "23                           NaN         2.0  \n",
       "24                           NaN         2.0  \n",
       "25                           NaN         2.0  \n",
       "26                           NaN         2.0  \n",
       "27                           NaN         2.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_21 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_28_Result1.xlsx\")\n",
    "df_part_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_11.to_excel(writer, sheet_name='Word_Part11', index=False)\n",
    "df_part_12.to_excel(writer, sheet_name='Word_Part12', index=False)\n",
    "df_part_13.to_excel(writer, sheet_name='Word_Part13', index=False)\n",
    "df_part_14.to_excel(writer, sheet_name='Word_Part14', index=False)\n",
    "df_part_21.to_excel(writer, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "      <th>freq_twogram_pair_portuguese</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "      <td>bir harita</td>\n",
       "      <td>247.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "      <td>sandviç mi</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "      <td>bir sandviç</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "      <td>harita bu</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "      <td>köri mi</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  freq_word twogram_pair_portuguese  freq_twogram_pair_portuguese  \\\n",
       "0   bir   18835735              bir harita                         247.0   \n",
       "1    bu   11062659              sandviç mi                         111.0   \n",
       "2    ne    8025880             bir sandviç                          43.0   \n",
       "3    ve    7766036               harita bu                          17.0   \n",
       "4  için    5484109                 köri mi                          13.0   \n",
       "5    mi    5362714                     NaN                           NaN   \n",
       "6   ben    4908913                     NaN                           NaN   \n",
       "\n",
       "   word_count  \n",
       "0         2.0  \n",
       "1         1.0  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "5         2.0  \n",
       "6         NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir harita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir sandviç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu</td>\n",
       "      <td>harita bu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mi</td>\n",
       "      <td>sandviç mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mi</td>\n",
       "      <td>köri mi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word twogram_pair_portuguese\n",
       "0  bir              bir harita\n",
       "1  bir             bir sandviç\n",
       "2   bu               harita bu\n",
       "3   mi              sandviç mi\n",
       "4   mi                 köri mi"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_11 = word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_12 = word_in_twogram(df_part_12, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_13 = word_in_twogram(df_part_13, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_14 = word_in_twogram(df_part_14, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_21 = word_in_twogram(df_part_21, \"word\", f\"twogram\") \n",
    "df_word_order_212 = word_in_twogram(df_part_21, \"word\", f\"twogram_pair_{lang_pair.lower()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11 = df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_12 = df_word_order_12.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_13 = df_word_order_13.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_14 = df_word_order_14.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_portuguese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>evet ama, ama yok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana mı, bana da</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben de, ben mi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>seni beni, beni seni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir daha, bir şey</td>\n",
       "      <td>bir mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu kadar, bu iyi</td>\n",
       "      <td>bu harita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bunu</td>\n",
       "      <td>bunu da, ve bunu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>da</td>\n",
       "      <td>bana da, bunu da</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daha</td>\n",
       "      <td>bir daha, daha çok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de</td>\n",
       "      <td>ben de, sen de</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>değil</td>\n",
       "      <td>değil mi, hayır değil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>evet var, evet ama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gibi</td>\n",
       "      <td>şey gibi, yok gibi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hayır</td>\n",
       "      <td>hayır değil, hayır mı</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iyi</td>\n",
       "      <td>çok iyi, bu iyi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>için</td>\n",
       "      <td>ne için</td>\n",
       "      <td>harita için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kadar</td>\n",
       "      <td>bu kadar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mi</td>\n",
       "      <td>değil mi, ben mi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mı</td>\n",
       "      <td>hayır mı, bana mı</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne var, ne için</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sen</td>\n",
       "      <td>sen de, ve sen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seni</td>\n",
       "      <td>seni beni, beni seni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>var</td>\n",
       "      <td>ne var, evet var</td>\n",
       "      <td>sandviç var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve sen, ve bunu</td>\n",
       "      <td>ve sandviç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yok</td>\n",
       "      <td>ama yok, yok gibi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>çok</td>\n",
       "      <td>çok iyi, daha çok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>şey</td>\n",
       "      <td>bir şey, şey gibi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                twogram twogram_pair_portuguese\n",
       "0     ama      evet ama, ama yok                     NaN\n",
       "1    bana       bana mı, bana da                     NaN\n",
       "2     ben         ben de, ben mi                     NaN\n",
       "3    beni   seni beni, beni seni                     NaN\n",
       "4     bir      bir daha, bir şey               bir mango\n",
       "5      bu       bu kadar, bu iyi               bu harita\n",
       "6    bunu       bunu da, ve bunu                     NaN\n",
       "7      da       bana da, bunu da                     NaN\n",
       "8    daha     bir daha, daha çok                     NaN\n",
       "9      de         ben de, sen de                     NaN\n",
       "10  değil  değil mi, hayır değil                     NaN\n",
       "11   evet     evet var, evet ama                     NaN\n",
       "12   gibi     şey gibi, yok gibi                     NaN\n",
       "13  hayır  hayır değil, hayır mı                     NaN\n",
       "14    iyi        çok iyi, bu iyi                     NaN\n",
       "15   için                ne için             harita için\n",
       "16  kadar               bu kadar                     NaN\n",
       "17     mi       değil mi, ben mi                     NaN\n",
       "18     mı      hayır mı, bana mı                     NaN\n",
       "19     ne        ne var, ne için                     NaN\n",
       "20    sen         sen de, ve sen                     NaN\n",
       "21   seni   seni beni, beni seni                     NaN\n",
       "22    var       ne var, evet var             sandviç var\n",
       "23     ve        ve sen, ve bunu              ve sandviç\n",
       "24    yok      ama yok, yok gibi                     NaN\n",
       "25    çok      çok iyi, daha çok                     NaN\n",
       "26    şey      bir şey, şey gibi                     NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11.to_excel(writer2, sheet_name='Word_Part11', index=False)\n",
    "df_word_order_join_12.to_excel(writer2, sheet_name='Word_Part12', index=False)\n",
    "df_word_order_join_13.to_excel(writer2, sheet_name='Word_Part13', index=False)\n",
    "df_word_order_join_14.to_excel(writer2, sheet_name='Word_Part14', index=False)\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Youtube Sentence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_num = 300\n",
    "#df_word_youtube = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/Turkish/Word Tokenize Merge/Youtube_Word_Tokenize_Merge.csv\")\n",
    "#df_word_select = df_word_youtube.head(word_num)\n",
    "#df_word_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:02:51.948</td>\n",
       "      <td>00:02:58.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:03:00.956</td>\n",
       "      <td>00:03:04.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:03:13.434</td>\n",
       "      <td>00:03:16.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:03:17.235</td>\n",
       "      <td>00:03:21.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:03:27.806</td>\n",
       "      <td>00:03:33.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>00:07:51.970</td>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>00:07:52.470</td>\n",
       "      <td>00:08:02.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>00:08:02.498</td>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>00:08:04.178</td>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>00:08:08.089</td>\n",
       "      <td>00:08:11.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time      end_time  \\\n",
       "0        00:02:51.948  00:02:58.829   \n",
       "1        00:03:00.956  00:03:04.236   \n",
       "2        00:03:13.434  00:03:16.327   \n",
       "3        00:03:17.235  00:03:21.338   \n",
       "4        00:03:27.806  00:03:33.383   \n",
       "...               ...           ...   \n",
       "3036932  00:07:51.970  00:07:52.470   \n",
       "3036933  00:07:52.470  00:08:02.304   \n",
       "3036934  00:08:02.498  00:08:04.178   \n",
       "3036935  00:08:04.178  00:08:08.089   \n",
       "3036936  00:08:08.089  00:08:11.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_youtube = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Youtube/Result/Turkish/Sentence Clean Merge/Clean_Youtube_Sentence_Merge_Result.csv\")\n",
    "df_sent_youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_youtube['start_time'] = pd.to_timedelta(df_sent_youtube['start_time']) # data type converted timedelta for second \n",
    "df_sent_youtube['end_time'] = pd.to_timedelta(df_sent_youtube['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.948</td>\n",
       "      <td>178.829</td>\n",
       "      <td>özgür bunlar normalde kamyon daha büyük araçla...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.956</td>\n",
       "      <td>184.236</td>\n",
       "      <td>burcu arka tarafı bağlamak kolay olmayacak</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.434</td>\n",
       "      <td>196.327</td>\n",
       "      <td>özgür arabaya yarım tur attıracağım</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197.235</td>\n",
       "      <td>201.338</td>\n",
       "      <td>burcu biraz daha devam et devam et tamam oldu</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207.806</td>\n",
       "      <td>213.383</td>\n",
       "      <td>burcu şimdilik iki tekere takacağız ama kar ka...</td>\n",
       "      <td>8V9tq1pe8eI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036932</th>\n",
       "      <td>471.970</td>\n",
       "      <td>472.470</td>\n",
       "      <td>umarız ki bu büyük ve güçlü teknoloji yanlış e...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036933</th>\n",
       "      <td>472.470</td>\n",
       "      <td>482.304</td>\n",
       "      <td>daha faydalı ve özgün kurumlarda herkesin eşit...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036934</th>\n",
       "      <td>482.498</td>\n",
       "      <td>484.178</td>\n",
       "      <td>i zlediğiniz için teşekkürler</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036935</th>\n",
       "      <td>484.178</td>\n",
       "      <td>488.089</td>\n",
       "      <td>yararlandığım kaynakları açıklamada link olara...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036936</th>\n",
       "      <td>488.089</td>\n",
       "      <td>491.770</td>\n",
       "      <td>i leri düzey okuma ve araştırma yapmak isteyen...</td>\n",
       "      <td>YFFJ5FyZj4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3036937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time  end_time  \\\n",
       "0           171.948   178.829   \n",
       "1           180.956   184.236   \n",
       "2           193.434   196.327   \n",
       "3           197.235   201.338   \n",
       "4           207.806   213.383   \n",
       "...             ...       ...   \n",
       "3036932     471.970   472.470   \n",
       "3036933     472.470   482.304   \n",
       "3036934     482.498   484.178   \n",
       "3036935     484.178   488.089   \n",
       "3036936     488.089   491.770   \n",
       "\n",
       "                                                  sentence     video_id  \n",
       "0        özgür bunlar normalde kamyon daha büyük araçla...  8V9tq1pe8eI  \n",
       "1               burcu arka tarafı bağlamak kolay olmayacak  8V9tq1pe8eI  \n",
       "2                      özgür arabaya yarım tur attıracağım  8V9tq1pe8eI  \n",
       "3            burcu biraz daha devam et devam et tamam oldu  8V9tq1pe8eI  \n",
       "4        burcu şimdilik iki tekere takacağız ama kar ka...  8V9tq1pe8eI  \n",
       "...                                                    ...          ...  \n",
       "3036932  umarız ki bu büyük ve güçlü teknoloji yanlış e...  YFFJ5FyZj4Q  \n",
       "3036933  daha faydalı ve özgün kurumlarda herkesin eşit...  YFFJ5FyZj4Q  \n",
       "3036934                      i zlediğiniz için teşekkürler  YFFJ5FyZj4Q  \n",
       "3036935  yararlandığım kaynakları açıklamada link olara...  YFFJ5FyZj4Q  \n",
       "3036936  i leri düzey okuma ve araştırma yapmak isteyen...  YFFJ5FyZj4Q  \n",
       "\n",
       "[3036937 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_youtube['start_time'] = df_sent_youtube['start_time'].apply(lambda x: x.total_seconds()) # convert seconds\n",
    "df_sent_youtube['end_time'] = df_sent_youtube['end_time'].apply(lambda x: x.total_seconds())\n",
    "df_sent_youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_list = df_word_select.iloc[:,0].to_list()\n",
    "word_list = [\"her şey yolunda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>67.294</td>\n",
       "      <td>72.004</td>\n",
       "      <td>nasıl gidiyor o iyi her şey yolunda</td>\n",
       "      <td>ud9s8aerIJE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>332.360</td>\n",
       "      <td>333.780</td>\n",
       "      <td>sevgi her şey yolunda mı</td>\n",
       "      <td>OPfevmWgETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>460.320</td>\n",
       "      <td>462.860</td>\n",
       "      <td>sıkıntı yok gayet iyi her şey yolunda</td>\n",
       "      <td>CNPzcVvZ1nU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1384.160</td>\n",
       "      <td>1387.380</td>\n",
       "      <td>mamasını da yemiş her şey yolunda dün serum al...</td>\n",
       "      <td>GjlduZjqHxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1572.000</td>\n",
       "      <td>1573.920</td>\n",
       "      <td>ateşi yok her şey yolunda değil mi</td>\n",
       "      <td>k1ni27c9C2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>2927.180</td>\n",
       "      <td>2930.161</td>\n",
       "      <td>onu merak etme her şey yolunda hiçbir şeyden h...</td>\n",
       "      <td>v8eY_Xa5SGw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>454.370</td>\n",
       "      <td>455.640</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>axyvWKQ4MQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1073.550</td>\n",
       "      <td>1075.852</td>\n",
       "      <td>yok canım bir şey olduğu yok her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>3824.874</td>\n",
       "      <td>3826.462</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1971.493</td>\n",
       "      <td>1972.555</td>\n",
       "      <td>her şey yolunda mı</td>\n",
       "      <td>DUiumyUqZsQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  start_time  end_time  \\\n",
       "0    her şey yolunda      67.294    72.004   \n",
       "1    her şey yolunda     332.360   333.780   \n",
       "2    her şey yolunda     460.320   462.860   \n",
       "3    her şey yolunda    1384.160  1387.380   \n",
       "4    her şey yolunda    1572.000  1573.920   \n",
       "..               ...         ...       ...   \n",
       "395  her şey yolunda    2927.180  2930.161   \n",
       "396  her şey yolunda     454.370   455.640   \n",
       "397  her şey yolunda    1073.550  1075.852   \n",
       "398  her şey yolunda    3824.874  3826.462   \n",
       "399  her şey yolunda    1971.493  1972.555   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                  nasıl gidiyor o iyi her şey yolunda  ud9s8aerIJE  \n",
       "1                             sevgi her şey yolunda mı  OPfevmWgETE  \n",
       "2                sıkıntı yok gayet iyi her şey yolunda  CNPzcVvZ1nU  \n",
       "3    mamasını da yemiş her şey yolunda dün serum al...  GjlduZjqHxA  \n",
       "4                   ateşi yok her şey yolunda değil mi  k1ni27c9C2k  \n",
       "..                                                 ...          ...  \n",
       "395  onu merak etme her şey yolunda hiçbir şeyden h...  v8eY_Xa5SGw  \n",
       "396                                    her şey yolunda  axyvWKQ4MQw  \n",
       "397       yok canım bir şey olduğu yok her şey yolunda  psNiD0Ks_uk  \n",
       "398                                    her şey yolunda  psNiD0Ks_uk  \n",
       "399                                 her şey yolunda mı  DUiumyUqZsQ  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result = pd.DataFrame()\n",
    "for i in word_list:\n",
    "    try:\n",
    "        word_in_video = df_sent_youtube[df_sent_youtube.sentence.str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)]\n",
    "        #word_in_video = df_sent_youtube[df_sent_youtube.sentence.str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].sample(200) # try and except will try for sample\n",
    "    except:\n",
    "        pass\n",
    "        #word_in_video = df_sent_youtube[df_sent_youtube.sentence.str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(200)         \n",
    "    word_in_video.insert(0,\"word\",i)\n",
    "    df_word_result = pd.concat([df_word_result,word_in_video], axis=0)\n",
    "df_word_result.reset_index(drop=True, inplace=True)\n",
    "df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_time_loc_list = []\n",
    "def word_time_loc(df):\n",
    "    for i in range(len(df)):\n",
    "        word = df.loc[i,\"word\"]\n",
    "        start_time = df.loc[i,\"start_time\"]\n",
    "        end_time = df.loc[i,\"end_time\"]\n",
    "        sentence = df.loc[i,\"sentence\"]\n",
    "        video_id = df.loc[i,\"video_id\"]\n",
    "        time_length = end_time-start_time\n",
    "        sentence_length = len(sentence)\n",
    "        time_length_ratio = time_length/sentence_length\n",
    "        loc_list = []\n",
    "        for j in re.finditer(fr\"(?:\\s|^){word}(?:\\s|$)\", sentence, re.IGNORECASE|re.UNICODE):\n",
    "            loc_list.append(j)\n",
    "            start = loc_list[0].start()\n",
    "            end = loc_list[0].end()\n",
    "            start_loc = start_time+(start*time_length_ratio)\n",
    "            end_loc = start_time+(end*time_length_ratio)\n",
    "        word_time_loc_list.append([word,start_loc,end_loc,sentence,video_id])\n",
    "    df_word_time_loc = pd.DataFrame(word_time_loc_list, columns=[\"word\",\"start_time\",\"end_time\",\"sentence\",\"video_id\"])\n",
    "\n",
    "    return df_word_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>69.850857</td>\n",
       "      <td>72.004000</td>\n",
       "      <td>nasıl gidiyor o iyi her şey yolunda</td>\n",
       "      <td>ud9s8aerIJE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>332.655833</td>\n",
       "      <td>333.661667</td>\n",
       "      <td>sevgi her şey yolunda mı</td>\n",
       "      <td>OPfevmWgETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>461.761622</td>\n",
       "      <td>462.860000</td>\n",
       "      <td>sıkıntı yok gayet iyi her şey yolunda</td>\n",
       "      <td>CNPzcVvZ1nU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1385.212692</td>\n",
       "      <td>1386.265385</td>\n",
       "      <td>mamasını da yemiş her şey yolunda dün serum al...</td>\n",
       "      <td>GjlduZjqHxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1572.508235</td>\n",
       "      <td>1573.468235</td>\n",
       "      <td>ateşi yok her şey yolunda değil mi</td>\n",
       "      <td>k1ni27c9C2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>2927.938800</td>\n",
       "      <td>2928.860200</td>\n",
       "      <td>onu merak etme her şey yolunda hiçbir şeyden h...</td>\n",
       "      <td>v8eY_Xa5SGw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>454.370000</td>\n",
       "      <td>455.640000</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>axyvWKQ4MQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1075.014909</td>\n",
       "      <td>1075.852000</td>\n",
       "      <td>yok canım bir şey olduğu yok her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>3824.874000</td>\n",
       "      <td>3826.462000</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1971.493000</td>\n",
       "      <td>1972.437000</td>\n",
       "      <td>her şey yolunda mı</td>\n",
       "      <td>DUiumyUqZsQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word   start_time     end_time  \\\n",
       "0    her şey yolunda    69.850857    72.004000   \n",
       "1    her şey yolunda   332.655833   333.661667   \n",
       "2    her şey yolunda   461.761622   462.860000   \n",
       "3    her şey yolunda  1385.212692  1386.265385   \n",
       "4    her şey yolunda  1572.508235  1573.468235   \n",
       "..               ...          ...          ...   \n",
       "395  her şey yolunda  2927.938800  2928.860200   \n",
       "396  her şey yolunda   454.370000   455.640000   \n",
       "397  her şey yolunda  1075.014909  1075.852000   \n",
       "398  her şey yolunda  3824.874000  3826.462000   \n",
       "399  her şey yolunda  1971.493000  1972.437000   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                  nasıl gidiyor o iyi her şey yolunda  ud9s8aerIJE  \n",
       "1                             sevgi her şey yolunda mı  OPfevmWgETE  \n",
       "2                sıkıntı yok gayet iyi her şey yolunda  CNPzcVvZ1nU  \n",
       "3    mamasını da yemiş her şey yolunda dün serum al...  GjlduZjqHxA  \n",
       "4                   ateşi yok her şey yolunda değil mi  k1ni27c9C2k  \n",
       "..                                                 ...          ...  \n",
       "395  onu merak etme her şey yolunda hiçbir şeyden h...  v8eY_Xa5SGw  \n",
       "396                                    her şey yolunda  axyvWKQ4MQw  \n",
       "397       yok canım bir şey olduğu yok her şey yolunda  psNiD0Ks_uk  \n",
       "398                                    her şey yolunda  psNiD0Ks_uk  \n",
       "399                                 her şey yolunda mı  DUiumyUqZsQ  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result = word_time_loc(df_word_result)\n",
    "df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>69.350857</td>\n",
       "      <td>72.504000</td>\n",
       "      <td>nasıl gidiyor o iyi her şey yolunda</td>\n",
       "      <td>ud9s8aerIJE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>332.155833</td>\n",
       "      <td>334.161667</td>\n",
       "      <td>sevgi her şey yolunda mı</td>\n",
       "      <td>OPfevmWgETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>461.261622</td>\n",
       "      <td>463.360000</td>\n",
       "      <td>sıkıntı yok gayet iyi her şey yolunda</td>\n",
       "      <td>CNPzcVvZ1nU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1384.712692</td>\n",
       "      <td>1386.765385</td>\n",
       "      <td>mamasını da yemiş her şey yolunda dün serum al...</td>\n",
       "      <td>GjlduZjqHxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1572.008235</td>\n",
       "      <td>1573.968235</td>\n",
       "      <td>ateşi yok her şey yolunda değil mi</td>\n",
       "      <td>k1ni27c9C2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>2927.438800</td>\n",
       "      <td>2929.360200</td>\n",
       "      <td>onu merak etme her şey yolunda hiçbir şeyden h...</td>\n",
       "      <td>v8eY_Xa5SGw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>453.870000</td>\n",
       "      <td>456.140000</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>axyvWKQ4MQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1074.514909</td>\n",
       "      <td>1076.352000</td>\n",
       "      <td>yok canım bir şey olduğu yok her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>3824.374000</td>\n",
       "      <td>3826.962000</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1970.993000</td>\n",
       "      <td>1972.937000</td>\n",
       "      <td>her şey yolunda mı</td>\n",
       "      <td>DUiumyUqZsQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word   start_time     end_time  \\\n",
       "0    her şey yolunda    69.350857    72.504000   \n",
       "1    her şey yolunda   332.155833   334.161667   \n",
       "2    her şey yolunda   461.261622   463.360000   \n",
       "3    her şey yolunda  1384.712692  1386.765385   \n",
       "4    her şey yolunda  1572.008235  1573.968235   \n",
       "..               ...          ...          ...   \n",
       "395  her şey yolunda  2927.438800  2929.360200   \n",
       "396  her şey yolunda   453.870000   456.140000   \n",
       "397  her şey yolunda  1074.514909  1076.352000   \n",
       "398  her şey yolunda  3824.374000  3826.962000   \n",
       "399  her şey yolunda  1970.993000  1972.937000   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                  nasıl gidiyor o iyi her şey yolunda  ud9s8aerIJE  \n",
       "1                             sevgi her şey yolunda mı  OPfevmWgETE  \n",
       "2                sıkıntı yok gayet iyi her şey yolunda  CNPzcVvZ1nU  \n",
       "3    mamasını da yemiş her şey yolunda dün serum al...  GjlduZjqHxA  \n",
       "4                   ateşi yok her şey yolunda değil mi  k1ni27c9C2k  \n",
       "..                                                 ...          ...  \n",
       "395  onu merak etme her şey yolunda hiçbir şeyden h...  v8eY_Xa5SGw  \n",
       "396                                    her şey yolunda  axyvWKQ4MQw  \n",
       "397       yok canım bir şey olduğu yok her şey yolunda  psNiD0Ks_uk  \n",
       "398                                    her şey yolunda  psNiD0Ks_uk  \n",
       "399                                 her şey yolunda mı  DUiumyUqZsQ  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_shift = 0.5\n",
    "df_word_result.start_time = df_word_result.start_time.apply(lambda x: (x-time_shift))\n",
    "df_word_result.end_time = df_word_result.end_time.apply(lambda x: (x+time_shift))\n",
    "df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sentence</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "      <td>nasıl gidiyor o iyi her şey yolunda</td>\n",
       "      <td>ud9s8aerIJE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>332</td>\n",
       "      <td>334</td>\n",
       "      <td>sevgi her şey yolunda mı</td>\n",
       "      <td>OPfevmWgETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>461</td>\n",
       "      <td>463</td>\n",
       "      <td>sıkıntı yok gayet iyi her şey yolunda</td>\n",
       "      <td>CNPzcVvZ1nU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1385</td>\n",
       "      <td>1387</td>\n",
       "      <td>mamasını da yemiş her şey yolunda dün serum al...</td>\n",
       "      <td>GjlduZjqHxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1572</td>\n",
       "      <td>1574</td>\n",
       "      <td>ateşi yok her şey yolunda değil mi</td>\n",
       "      <td>k1ni27c9C2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>2927</td>\n",
       "      <td>2929</td>\n",
       "      <td>onu merak etme her şey yolunda hiçbir şeyden h...</td>\n",
       "      <td>v8eY_Xa5SGw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>454</td>\n",
       "      <td>456</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>axyvWKQ4MQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1075</td>\n",
       "      <td>1076</td>\n",
       "      <td>yok canım bir şey olduğu yok her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>3824</td>\n",
       "      <td>3827</td>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>psNiD0Ks_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>her şey yolunda</td>\n",
       "      <td>1971</td>\n",
       "      <td>1973</td>\n",
       "      <td>her şey yolunda mı</td>\n",
       "      <td>DUiumyUqZsQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  start_time  end_time  \\\n",
       "0    her şey yolunda          69        73   \n",
       "1    her şey yolunda         332       334   \n",
       "2    her şey yolunda         461       463   \n",
       "3    her şey yolunda        1385      1387   \n",
       "4    her şey yolunda        1572      1574   \n",
       "..               ...         ...       ...   \n",
       "395  her şey yolunda        2927      2929   \n",
       "396  her şey yolunda         454       456   \n",
       "397  her şey yolunda        1075      1076   \n",
       "398  her şey yolunda        3824      3827   \n",
       "399  her şey yolunda        1971      1973   \n",
       "\n",
       "                                              sentence     video_id  \n",
       "0                  nasıl gidiyor o iyi her şey yolunda  ud9s8aerIJE  \n",
       "1                             sevgi her şey yolunda mı  OPfevmWgETE  \n",
       "2                sıkıntı yok gayet iyi her şey yolunda  CNPzcVvZ1nU  \n",
       "3    mamasını da yemiş her şey yolunda dün serum al...  GjlduZjqHxA  \n",
       "4                   ateşi yok her şey yolunda değil mi  k1ni27c9C2k  \n",
       "..                                                 ...          ...  \n",
       "395  onu merak etme her şey yolunda hiçbir şeyden h...  v8eY_Xa5SGw  \n",
       "396                                    her şey yolunda  axyvWKQ4MQw  \n",
       "397       yok canım bir şey olduğu yok her şey yolunda  psNiD0Ks_uk  \n",
       "398                                    her şey yolunda  psNiD0Ks_uk  \n",
       "399                                 her şey yolunda mı  DUiumyUqZsQ  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result.start_time = df_word_result.start_time.apply(lambda x: round(x))\n",
    "df_word_result.end_time = df_word_result.end_time.apply(lambda x: round(x))\n",
    "df_word_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_result.to_excel(\"Youtube_Sentence_Select_Word_Time_Interval.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160, 145, 1510, 1000, 539, 143, 793, 277, 977, 627]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result.start_time.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[163, 148, 1512, 1001, 551, 153, 798, 281, 978, 628]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result.end_time.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A4wf93zJZIQ',\n",
       " 'gOq59m1pUi4',\n",
       " 'ifxg2zkaN5E',\n",
       " 'yKx4zO8_Jhk',\n",
       " 'CNPzcVvZ1nU',\n",
       " 'GWzi144zrEs',\n",
       " 'GWzi144zrEs',\n",
       " '6FtA8_D7Ynw',\n",
       " 'M5zJ_X8i3rI',\n",
       " 'WYcGfSiTbYY']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_result.video_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c9ymkFAiZDk,BsRzeONLa28,dWIJFBbJSn4,GhMqYDwawUU,A4wf93zJZIQ,gOq59m1pUi4,vOWbfQ0tIyU,uzYXX4RgcO0,6FtA8_D7Ynw,F7OQWEJJR34'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(df_word_result.video_id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Twogram Sent In Sent Threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence_All.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext.\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir şey</td>\n",
       "      <td>859944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>değil mi</td>\n",
       "      <td>585879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben de</td>\n",
       "      <td>377765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>370619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>322758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457029</th>\n",
       "      <td>fikret cibran</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457030</th>\n",
       "      <td>romalı fikret</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457031</th>\n",
       "      <td>fikret ciooney</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457032</th>\n",
       "      <td>fikret cisco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457033</th>\n",
       "      <td>seyretmeliyim fikret</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0                     bir şey     859944\n",
       "1                    değil mi     585879\n",
       "2                      ben de     377765\n",
       "3             teşekkür ederim     370619\n",
       "4                     ne oldu     322758\n",
       "...                       ...        ...\n",
       "4457029         fikret cibran          3\n",
       "4457030         romalı fikret          3\n",
       "4457031        fikret ciooney          3\n",
       "4457032          fikret cisco          3\n",
       "4457033  seyretmeliyim fikret          3\n",
       "\n",
       "[4457034 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twogram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_twogram_sent = set(df_twogram_sent.twogram)\n",
    "set_twogram = set(df_twogram.twogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olunca insanlar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fikret bilgisayarı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oy toplama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bunu anlatmalıydın</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el kitabının</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171721</th>\n",
       "      <td>eliyle çalışıyor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171722</th>\n",
       "      <td>daima güvenebileceğim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171723</th>\n",
       "      <td>pariste yaptırmış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171724</th>\n",
       "      <td>i̇kâmet belgemi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171725</th>\n",
       "      <td>deceptionlar mı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4171726 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0              olunca insanlar\n",
       "1           fikret bilgisayarı\n",
       "2                   oy toplama\n",
       "3           bunu anlatmalıydın\n",
       "4                 el kitabının\n",
       "...                        ...\n",
       "4171721       eliyle çalışıyor\n",
       "4171722  daima güvenebileceğim\n",
       "4171723      pariste yaptırmış\n",
       "4171724        i̇kâmet belgemi\n",
       "4171725        deceptionlar mı\n",
       "\n",
       "[4171726 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram = pd.DataFrame(set_twogram.difference(set_twogram_sent))\n",
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olunca insanlar',\n",
       " 'fikret bilgisayarı',\n",
       " 'oy toplama',\n",
       " 'bunu anlatmalıydın',\n",
       " 'el kitabının',\n",
       " 've istenmeyen',\n",
       " 'ey garip',\n",
       " 'edeceğini şaşırmıştı',\n",
       " 'peşinde brill',\n",
       " 'hani size',\n",
       " 'minseok babasız',\n",
       " 'evdeki sürtüğe',\n",
       " 'belicoff bana',\n",
       " 'olası karın',\n",
       " 'kilit de',\n",
       " 'tozu getirdim',\n",
       " 'mı beklemeyi',\n",
       " 'uçuş united',\n",
       " 'konuşabilen bir',\n",
       " 'lima peruya',\n",
       " 'xavier slaughtery',\n",
       " 'çayı burada',\n",
       " 'isyanlar ve',\n",
       " 'gözünden kaçmayacak',\n",
       " 'noktalama işaretiyle',\n",
       " '222 ve',\n",
       " 'zamanında yetişirse',\n",
       " 'gülerim onlara',\n",
       " 'güldüren adamları',\n",
       " 'hediyesini kira',\n",
       " 'seni tanımadan',\n",
       " 'çekini kontrol',\n",
       " 'karı bul',\n",
       " 'yüzyılın ilişkisiydi',\n",
       " 'sadece bolonez',\n",
       " 'ben cinayettenim',\n",
       " 'bay tamnusı',\n",
       " 'bozuyordu çünkü',\n",
       " 'malzeme beklemiyoruz',\n",
       " 'araba satman',\n",
       " 'edilmesine kalan',\n",
       " 'oraya hissettiğim',\n",
       " 'chrysler fabrikasında',\n",
       " 'bekleyebilirim diye',\n",
       " 'adım arkamda',\n",
       " 'sürücü öğretmenisin',\n",
       " 'bunu karşılayacak',\n",
       " 'olduğu kanıtlanamadı',\n",
       " 'hiromichi horikawa',\n",
       " 'önce duymamışsınız',\n",
       " 'istersem istediğim',\n",
       " 'mevzunun gözlerden',\n",
       " 'yasal olduğundan',\n",
       " 'bugün para',\n",
       " 'anlaşması imzaladıklarını',\n",
       " 'görürsek ona',\n",
       " 'düşersen kaybedersin',\n",
       " 'bizi gasp',\n",
       " 'rophenol hapın',\n",
       " 'açacağımı bilemiyordum',\n",
       " '500 batı',\n",
       " 'çünkü güvendiğim',\n",
       " 'yaltaklandıklarını görecektin',\n",
       " 'sanırım alt',\n",
       " 'ölürsem farketmez',\n",
       " 'adam tanırdım',\n",
       " 'istedim büyük',\n",
       " 'hepsi sevgili',\n",
       " 'planının parçası',\n",
       " 'cristal fikret',\n",
       " 'olası ölü',\n",
       " 'zaman açıktır',\n",
       " 'değiştirmiş olduk',\n",
       " 'yani tekmeleyip',\n",
       " 'yüzden mankafanın',\n",
       " 'bayan şanghaya',\n",
       " 'eltonların yaptığı',\n",
       " 'olmasanız çok',\n",
       " 'uçaklarından bazıları',\n",
       " 'durum gücüne',\n",
       " 'ev alüminyumdandı',\n",
       " 'payı arabada',\n",
       " 'pişmanlık duydun',\n",
       " 'detroitten önce',\n",
       " 'i̇hmal ettiklerini',\n",
       " 'olmayı hatırlıyorum',\n",
       " 'almaya razıyım',\n",
       " 'ucunda memphis',\n",
       " 'ölen kedisini',\n",
       " 've rogueu',\n",
       " 'hayatıma girmeyecek',\n",
       " 'hanımefendi hava',\n",
       " 'kılıcı dünyadaki',\n",
       " 'kez görüşün',\n",
       " 'itibaren haberleşmeye',\n",
       " 'hakim olamadan',\n",
       " 'üzerime yükleme',\n",
       " 'ibret olucak',\n",
       " 'açıklanamayan kayıp',\n",
       " 'klara minicik',\n",
       " 'tamam kalkabilir',\n",
       " 'döndüm durdum',\n",
       " 'boyayıp daire',\n",
       " 'burada bulunmamasını',\n",
       " 'gözü savunmada',\n",
       " 'zencilere ilk',\n",
       " 'kişiyi incitmiştir',\n",
       " 'raylar yoldan',\n",
       " 'bu bataryayı',\n",
       " 'de davranırsın',\n",
       " 'bir doowop',\n",
       " 'american 77',\n",
       " 'bak boynunda',\n",
       " 'editörleri amerikan',\n",
       " 'tür takım',\n",
       " 'uğraş gerektirdiği',\n",
       " 've unutulmuş',\n",
       " 'kolay oraya',\n",
       " 'kalamıyorum duramıyorum',\n",
       " 'aracın bu',\n",
       " 'onlar yapılandırılmış',\n",
       " 'hatta hizmetçisini',\n",
       " 'kadarını izleyeceğiz',\n",
       " 'numara yapmalıydım',\n",
       " 'korktuğun önemli',\n",
       " 'tris her',\n",
       " 'manüel sürüşe',\n",
       " 'satış opsiyonu',\n",
       " 'doğru yanıtladı',\n",
       " 'minik ince',\n",
       " 'ama joffreyden',\n",
       " 'henüz haberi',\n",
       " 't barnum',\n",
       " 'hissettikleri tek',\n",
       " 'kullandığımızı biliyor',\n",
       " 've tazının',\n",
       " 'pisliğe batarsan',\n",
       " 'o darth',\n",
       " 'horrigan gizli',\n",
       " 'o tweetleri',\n",
       " 'senden viviandan',\n",
       " 'önce bilmek',\n",
       " 'planı arkanı',\n",
       " 'seferinde odama',\n",
       " 'sürekli kfar',\n",
       " 'tuzakları kurduklarını',\n",
       " 'i̇lk aşamadan',\n",
       " 'alçalacağını ummadık',\n",
       " 'kolay diz',\n",
       " 'peni kırmızı',\n",
       " 'kalıpta değilim',\n",
       " 'şeyi yapmasaydım',\n",
       " 'koşturma evlat',\n",
       " 'çıkarır gibi',\n",
       " 'charlesın bu',\n",
       " 'kendi kurtuluşum',\n",
       " 'jamieden haber',\n",
       " 'braun bile',\n",
       " 'dödüğün için',\n",
       " 'hamile kızla',\n",
       " 'vajinaya girildiğini',\n",
       " 'koşsak ne',\n",
       " 'yapabildiğini öğrenecek',\n",
       " 'meleklerden mi',\n",
       " 'değer verenlere',\n",
       " 'irileriyle de',\n",
       " 'inanç statü',\n",
       " 'önce şehri',\n",
       " 'taco gecesidir',\n",
       " 'ya stig',\n",
       " 'ama ifademi',\n",
       " 'bulup iade',\n",
       " 'annesine aşıksın',\n",
       " 'jeffersonı modaratör',\n",
       " 'koymanda sana',\n",
       " 'batan japon',\n",
       " 'ofisim olacak',\n",
       " 'hudgensden dr',\n",
       " '1977 yılının',\n",
       " 'anda anlayabileceğinden',\n",
       " 'epifani yaşamadığın',\n",
       " 'aileme olanları',\n",
       " 'gibi alçaklarla',\n",
       " 'hedef dışı',\n",
       " 'zamanlar kuzey',\n",
       " 'defa kaçamayacaksın',\n",
       " 'sadakati hakkında',\n",
       " 'casino channel',\n",
       " 'neredeyse touchdown',\n",
       " 'kuvvet çok',\n",
       " 'değil 784e',\n",
       " 'çünkü sesini',\n",
       " 'ikiniz gelmiyor',\n",
       " 'da dağılmaya',\n",
       " 'birçok haydut',\n",
       " 'kabilelerinin ticaret',\n",
       " 'sefer hazırım',\n",
       " 'benderı ben',\n",
       " 'yazma sebebim',\n",
       " 'hedefin açığa',\n",
       " 'ağustosta gelip',\n",
       " 'benim baş',\n",
       " 'office 6',\n",
       " 've davranışlarınla',\n",
       " 'üşüdüklerini söylüyorlar',\n",
       " 'işini ailelerimiz',\n",
       " 'kzi hisselerine',\n",
       " 'havuzda olmadığına',\n",
       " 'torrhen kalesi',\n",
       " 'artık teayla',\n",
       " 've farklar',\n",
       " 'hiçbir gücüm',\n",
       " 'bir leğen',\n",
       " 'bana kostüm',\n",
       " 'sakarı bize',\n",
       " 'kesilse diyorum',\n",
       " 'de söylerdi',\n",
       " 'karanlık hoşuma',\n",
       " 'saçmalama gerek',\n",
       " 'taşların değersiz',\n",
       " 'gibi düzüşüyorsun',\n",
       " 'dinlemeden birçok',\n",
       " 'azından anlıyorsun',\n",
       " 'kargo gemilerimizden',\n",
       " 'ziyaretçisinin hikayesini',\n",
       " 'kanama zamanını',\n",
       " 'bir arkeoloji',\n",
       " 'vuruşu tekrarlayamazsın',\n",
       " 'anlamadan sevebiliriz',\n",
       " 'destroyeri daha',\n",
       " 'evet tanışıklığımız',\n",
       " 'musun üçünü',\n",
       " 'iğne almak',\n",
       " 'bilseydim evi',\n",
       " 'arkadaşlarımın hoşuna',\n",
       " 'mıhlamanı istiyorum',\n",
       " 'istiyorsak sessiz',\n",
       " 'depolayacak şekilde',\n",
       " 'iddianame hazırlayıp',\n",
       " 'fikret mccarmick',\n",
       " 'son birayı',\n",
       " 'şey sorun',\n",
       " 'demeksiniz çocuklar',\n",
       " 'akashla evlenmelisin',\n",
       " 'sizi durdurmasın',\n",
       " 'girdi artık',\n",
       " 'pasta dışında',\n",
       " 'kalkıp kendini',\n",
       " '2000 eder',\n",
       " 'sanki kahrolası',\n",
       " 'devletleri artık',\n",
       " 'alphahffte 0sana',\n",
       " 'olmadığını anlamazlarsa',\n",
       " 'da olalım',\n",
       " 'dünkü kaydı',\n",
       " 'noel bağışlanma',\n",
       " 'hem deli',\n",
       " 'olaylardan niye',\n",
       " 'aynı kişiyse',\n",
       " 'karısı kodu',\n",
       " 'belirtilen konumdan',\n",
       " 'albay packardla',\n",
       " 'kızgın hali',\n",
       " 'kollanıyoruz fikret',\n",
       " 'karşındaki kapıyı',\n",
       " 'şeyi kesmiyoruz',\n",
       " 'ucuz atlatmış',\n",
       " 'chung wana',\n",
       " 'yatak görüyor',\n",
       " 'dimdik biri',\n",
       " 'antenlerini kur',\n",
       " 'hem kalloorun',\n",
       " 'fikret grau',\n",
       " 'toshi iyi',\n",
       " 'için eşzamanlı',\n",
       " 'sadık asil',\n",
       " 'kayalık bölge',\n",
       " 'striptizci fikret',\n",
       " 'fad4402003ch8500acfnalbinofs24b1daha da',\n",
       " 'isimlerini yazdı',\n",
       " 'yabani soğanlar',\n",
       " 'boru döşüyor',\n",
       " 'bu tedavileriyle',\n",
       " 'mı sevişiyorsun',\n",
       " 'bacaklar kırılacak',\n",
       " 'kere silmeniz',\n",
       " 'gece 18',\n",
       " 'göre silahlarınızı',\n",
       " 'gözünle gördün',\n",
       " 'kıyısından gidecekler',\n",
       " 'sürü kimyasalla',\n",
       " 'eylem planına',\n",
       " 'benim kimliğim',\n",
       " 'buradaki çavuş',\n",
       " 'şirketlerinin patronu',\n",
       " 'yani bekleyecek',\n",
       " 'kadın beyni',\n",
       " 'direk yağdan',\n",
       " 'gevezelik yapıp',\n",
       " 'isteği yaptım',\n",
       " 'bu varsın',\n",
       " 'güzel sikini',\n",
       " 'sistemi içeri',\n",
       " 'bile verebilir',\n",
       " 'kafasından çok',\n",
       " 'kampanyalar düzenliyor',\n",
       " 'mısırlılar kolonilerden',\n",
       " 'beklediğin vazife',\n",
       " 'tuhafsın doğrusu',\n",
       " 'arkadaşı transformasyonu',\n",
       " 'hepinize gününü',\n",
       " 'i̇mparatoriçe 1845te',\n",
       " 'yitireli çok',\n",
       " 'yumurtasını da',\n",
       " 'bokunla ilgilen',\n",
       " 'da tutayım',\n",
       " 'yüzün rahatsız',\n",
       " 'hayvanlar zamanla',\n",
       " 'sığınakları yerle',\n",
       " 'buradan gidiş',\n",
       " 've öylesine',\n",
       " 'beşinci de',\n",
       " 'tutucu buldum',\n",
       " 'mı basacağım',\n",
       " 'evlerinde kalmalarını',\n",
       " 'etmenizi istedigim',\n",
       " 'hoşsunuz kaptan',\n",
       " 'kez girecek',\n",
       " 'dickynin aklından',\n",
       " 'ayıran en',\n",
       " 'kendi çoraplarımı',\n",
       " 'kovalama için',\n",
       " 'ajan tweede',\n",
       " 'boyunca ötmek',\n",
       " 'zamanlar çöl',\n",
       " 'kederlenmiyor sessizlik',\n",
       " 'yelkenleri açılmış',\n",
       " 'hayran olunmak',\n",
       " 'askerlerini hazırla',\n",
       " 'soyguncusu mu',\n",
       " 'sürpriz planlıyordum',\n",
       " 'bekleyin 411',\n",
       " 'etrafında iyi',\n",
       " 'oğlu beş',\n",
       " 'bizler çocuğuz',\n",
       " 'için ayırtıyorum',\n",
       " 'iyi yemek',\n",
       " 'evlenen her',\n",
       " 'deli kızıl',\n",
       " '25000 yıl',\n",
       " 'anlasan çok',\n",
       " 'hristiyan ordular',\n",
       " 'tutumunu duymak',\n",
       " 'senin yarattığını',\n",
       " 'neler hissettiriyor',\n",
       " 'sarhoşken daha',\n",
       " 'artık zehir',\n",
       " 'model dostum',\n",
       " 'çıkarmış olabilirsin',\n",
       " 'bize gerekmiyor',\n",
       " 'dışarıdayım ve',\n",
       " 'havaya fırlatır',\n",
       " 'çünkü yerimizi',\n",
       " 'amcana hoşçakal',\n",
       " 'yanlış nedenlerden',\n",
       " 'kadar akılları',\n",
       " 'azlığına mı',\n",
       " 'ihtimali düşünmüşsün',\n",
       " 'basına şunu',\n",
       " 'zorunlu hafıza',\n",
       " 'dönüyor her',\n",
       " 'sorabileceğin hiç',\n",
       " 'yerde kenara',\n",
       " 'yapıp ölmekten',\n",
       " 'zaman duvara',\n",
       " 'eğittiğim şekilde',\n",
       " 'ten sonra',\n",
       " 'tür rastlantı',\n",
       " 'sana açarım',\n",
       " 'davası açılıyor',\n",
       " 'bütün dişleri',\n",
       " 'için patikalar',\n",
       " 'baş balerinini',\n",
       " '351 altimetre',\n",
       " 'fakat hesapları',\n",
       " 'dünyamıza gelmeye',\n",
       " '24üncü yüzyıldan',\n",
       " 'etmem gerekmemişti',\n",
       " 'burada çekecek',\n",
       " 'kez hareket',\n",
       " 'da kalkmayın',\n",
       " 'fabrikasında bırakmıştın',\n",
       " 'tekrar kötüleşti',\n",
       " 'tek atsın',\n",
       " 'ezmesi beni',\n",
       " 'farketmedim tuhaf',\n",
       " 'sen endişe',\n",
       " 'dörtadımı kullandığında',\n",
       " 'şu binalarla',\n",
       " 'uğrayışın mı',\n",
       " 'neden erkeklerle',\n",
       " 'janson onları',\n",
       " 'haydi çocuklarbunu',\n",
       " 'gece tartıştılar',\n",
       " 'sağlamdı ama',\n",
       " 'konumuz beyler',\n",
       " 'için yastık',\n",
       " 'edildiğini düşünenler',\n",
       " 'şeye silahını',\n",
       " 'telesekreterde cindyden',\n",
       " 'ağlıyor bağırıyor',\n",
       " 've bilgeliğin',\n",
       " 'mü wick',\n",
       " 'oldum fikret',\n",
       " '4 saatliğine',\n",
       " 'bilmem teknelerden',\n",
       " 'yurttaşlarım bir',\n",
       " 'kaderimizde görüşmek',\n",
       " 'yerinden bahsedelim',\n",
       " 'bud iki',\n",
       " 'anlattığıma inanamıyorum',\n",
       " 'girme nedeniniz',\n",
       " 'anlaşmaları berbat',\n",
       " 'varsa kanıtlayabilir',\n",
       " 'için olta',\n",
       " 'fazla ısınmasını',\n",
       " 'etme esrarlı',\n",
       " 'başlatan taraf',\n",
       " 'yönde sekizinci',\n",
       " 'schwartz ulusal',\n",
       " 'olsaydın vincentı',\n",
       " 'tankın yerini',\n",
       " 'yaptık koca',\n",
       " 'onu çölde',\n",
       " 'yolda yalan',\n",
       " 'canavar parsa',\n",
       " 'sapığı anında',\n",
       " 'bileytaşı arıyorum',\n",
       " 'kadın kartları',\n",
       " 'pis şaka',\n",
       " 'sekizde savaş',\n",
       " 'evin soyulmadıysa',\n",
       " 'günlerinin sayılı',\n",
       " 'araştırmadan kaynaklanıyor',\n",
       " 'belki rahibe',\n",
       " 'mi zamanını',\n",
       " 'kitaplar yüzünden',\n",
       " 'söylerken göğsü',\n",
       " 'janetle birlikte',\n",
       " 'bilgim sizin',\n",
       " 'öğrenemeyeceğiz sanırım',\n",
       " 'yakışıklı parlak',\n",
       " 'evlat plan',\n",
       " 'şansımız olur',\n",
       " 'kadar üçe',\n",
       " 'güçlü ha',\n",
       " 'bazı uyum',\n",
       " 'kaybettiğinden bilgin',\n",
       " 'hemen başlatmalıyız',\n",
       " 'bunları ayırırsanız',\n",
       " 'erkekseniz çekin',\n",
       " 'sevişmek ne',\n",
       " 'desteklerini bilim',\n",
       " 'birşeyimiz kalmadı',\n",
       " 'nesin be',\n",
       " 'concha mısın',\n",
       " 'yıldan söz',\n",
       " 'the seekerda',\n",
       " 'günü kıçını',\n",
       " 'beraber chicago',\n",
       " 'duyuyor derdiniz',\n",
       " 'gelince anne',\n",
       " 'katılıyorum sonuncusunu',\n",
       " 'birini veririm',\n",
       " 'öyleyse tanıdıkları',\n",
       " 'bilerek çıplak',\n",
       " 'geçeniniz var',\n",
       " 'hayır kalbini',\n",
       " 'ödeyeceğime polisleri',\n",
       " 'koruma saydım',\n",
       " 'gibi sıranızı',\n",
       " 'efendim ihtiyacınız',\n",
       " 'vatansever olmayan',\n",
       " 'yogaya gidiyor',\n",
       " 'nedeni inanmaktır',\n",
       " 'güney bölgesinin',\n",
       " 'boyu öksürmüştüm',\n",
       " 'queen destekleyen',\n",
       " 'ekspres hizmetinizde',\n",
       " 'yana açın',\n",
       " 'edilmek isteriz',\n",
       " 'terfi teklifini',\n",
       " 'yara kelimesinden',\n",
       " 'tehlike bölgesi',\n",
       " 'camelotun önceki',\n",
       " 'çabuk ilerledi',\n",
       " 'etmediler eğer',\n",
       " 'ansızın o',\n",
       " 'pilot dizi',\n",
       " 'swayzak nasılsınız',\n",
       " 'önce eğlenmek',\n",
       " 'shaquille sanıyordum',\n",
       " 'okula bırakan',\n",
       " 'puanını bilmeyecek',\n",
       " 'elle seni',\n",
       " 'gönüllüsü efendim',\n",
       " 'sandık onu',\n",
       " 'fazlasını alabilirim',\n",
       " 'kadınla röportaj',\n",
       " 'kolonisine saldırmak',\n",
       " 'hiç ayaktayken',\n",
       " 'abinin rahat',\n",
       " 'anyaydı değil',\n",
       " 'çocuğu tutuklamıştım',\n",
       " 'kimse dr',\n",
       " 'ama proteus',\n",
       " 'yeri aramış',\n",
       " 'hapse girmiştin',\n",
       " 'alan denir',\n",
       " 'tutam sincap',\n",
       " 'bunları takmanı',\n",
       " 'pisişe yaramaz',\n",
       " 'gezintiye gelmeni',\n",
       " 'durumdu lil',\n",
       " 'icadım üretimi',\n",
       " 'sarıp oynat',\n",
       " 'bir gökkuşağında',\n",
       " 'kapıyı arkasından',\n",
       " 'bolivyada çalışmak',\n",
       " 'şu akirayı',\n",
       " 'komisyonda geçiriyorum',\n",
       " 'baksana özür',\n",
       " 'kolay yolları',\n",
       " 'ısmarladın mı',\n",
       " 'işi sonlandırmanın',\n",
       " 'doğru 50',\n",
       " 'mekanikler bunları',\n",
       " 'beni aday',\n",
       " '3 feet',\n",
       " 'babam insanları',\n",
       " 'önsözünde belirtmişti',\n",
       " 'ayrılma yanında',\n",
       " 'meteor tarafından',\n",
       " 'birlikte bu',\n",
       " 'sana anlatmayı',\n",
       " 'kadın hayatlarını',\n",
       " 'i̇malatçıları partisine',\n",
       " 'karmakarışık olur',\n",
       " 'kenara uzaklığı',\n",
       " 'süreliğine ara',\n",
       " 'karşı ayaklandın',\n",
       " 'madelyn bennettın',\n",
       " 'yatışınca saklandığı',\n",
       " 'de canton',\n",
       " 'lapinsky lösemiden',\n",
       " 'birileri tanık',\n",
       " 'terapistimin verdiği',\n",
       " 'dr schiff',\n",
       " 'paulina tipli',\n",
       " 'ölü sanıyor',\n",
       " 'çıkardın mi',\n",
       " 'ben nerden',\n",
       " 'yayınlamak zorundalar',\n",
       " 'şimdi hissettiğime',\n",
       " 'içki dükkânı',\n",
       " 'hesaplar tam',\n",
       " 'şahsen ilgilendiren',\n",
       " 'öldüğünde yasını',\n",
       " 'ayyaşım ayyaşlar',\n",
       " 'aralarında kadınlar',\n",
       " 'korkarım ikimizi',\n",
       " 'japonyaya defedecek',\n",
       " 'miden berbattır',\n",
       " 'artık hanımefendi',\n",
       " 'beni ekmeye',\n",
       " 'ilçe arayışı',\n",
       " 'i̇şlerin ters',\n",
       " 'yazdıklarını gözden',\n",
       " 'buluştu da',\n",
       " 'grup eleman',\n",
       " 'arabanın tamponundaki',\n",
       " 'anki halimi',\n",
       " 'kıppır kıppır',\n",
       " 'dağlarının bundan',\n",
       " 'lan kimse',\n",
       " 'düğmeden açiliyor',\n",
       " 'ol hagrid',\n",
       " 'müzisyenleri tanımazsın',\n",
       " 'numarayı yapabilirsin',\n",
       " 'günün benim',\n",
       " 'tüm okurlarınız',\n",
       " 'soğuk tuttuğu',\n",
       " 'sorun tamam',\n",
       " 'ırkı asla',\n",
       " 'temiz tutman',\n",
       " 'soylulara haklar',\n",
       " 'ana müsabakanın',\n",
       " 'jacobsonlarla gideceğim',\n",
       " 'centilmenlerin oynadığı',\n",
       " 'güvenilir yargıçlara',\n",
       " 'senet yapmam',\n",
       " 'görüneceğimden endişe',\n",
       " 'diagramma yayınlandıktan',\n",
       " 'bu vicdanın',\n",
       " 'sokakta kurşunlardan',\n",
       " 'unutulmaz deneyim',\n",
       " 'i̇çi uyuşturucu',\n",
       " 'bahsettiğin benim',\n",
       " 'gal derler',\n",
       " 'birlik burada',\n",
       " 'defolana dek',\n",
       " '1000 ışık',\n",
       " 'söyledin yalan',\n",
       " 'özlüyorum tatlım',\n",
       " 'kadar varım',\n",
       " 'nadiren ortak',\n",
       " 'yerken yapma',\n",
       " 've bilgiyi',\n",
       " 'fırsatını ne',\n",
       " 'yardımcım olmayacak',\n",
       " 'dürbünü at',\n",
       " 'masalı bitti',\n",
       " 'politika beni',\n",
       " 'eminim fitchbergda',\n",
       " 'fikret satterfielddım',\n",
       " 'şişman olacaksınız',\n",
       " 'demek işte',\n",
       " 'fikret soyu',\n",
       " 'bakma ayı',\n",
       " 'parmaklarla seçime',\n",
       " 'cesedi olduğunu',\n",
       " 'sağır olsaydım',\n",
       " 'giymiş olan',\n",
       " 'tabaktaki diş',\n",
       " 'üzgünüm çatur',\n",
       " 'taşın oyuluşunu',\n",
       " 'mahallimiz yoktu',\n",
       " 'fikret wetherhold',\n",
       " 'kaç sadık',\n",
       " 'kadar dedi',\n",
       " 'görmezlikten gelmemiz',\n",
       " 'havuz evinden',\n",
       " 'i̇kinci dil',\n",
       " 'biz üstün',\n",
       " 'seçtim sevgili',\n",
       " 'langın nesi',\n",
       " 'babasını toprağa',\n",
       " 'saati gitmeden',\n",
       " 'kumak için',\n",
       " 'sistemine sızdı',\n",
       " 'eve bırakın',\n",
       " 'yapabilirmişsiniz ki',\n",
       " 'düzene koydu',\n",
       " 'açmış olmalı',\n",
       " 'partide olmak',\n",
       " 'bir göstergeydi',\n",
       " 'laftan anlamıyorsa',\n",
       " 'hazırlamanı söylüyor',\n",
       " 'iş bulduğu',\n",
       " 'sütü yer',\n",
       " 'tahta dişleri',\n",
       " 'hâli kalmadı',\n",
       " 'gürültücü oluyorsun',\n",
       " 'karmaşıklığın çözümü',\n",
       " 've yetkiye',\n",
       " 'şekellerinize ihtiyacı',\n",
       " 'geçmişler buradan',\n",
       " 'milyon verecekmiş',\n",
       " 'kadar uyanmazsam',\n",
       " 'derece gereksiz',\n",
       " 'gluant cinayeti',\n",
       " 'demiryumruk fikret',\n",
       " 'one tree',\n",
       " 'oyunculardan birinin',\n",
       " 'rock kulüpleri',\n",
       " 'ama tunusta',\n",
       " 'dışarda benim',\n",
       " 'adam patlıyordu',\n",
       " 'yerde yaşayamazdım',\n",
       " 'denemekten zarar',\n",
       " 'açan gerizekalıdan',\n",
       " 'özgüvenin yerine',\n",
       " 'bir citizen',\n",
       " 'hareketten iki',\n",
       " 'da hadım',\n",
       " 'currahee günlüğü',\n",
       " 'göndererek kızını',\n",
       " 'okumalarınızın birinde',\n",
       " 'tekerlekli sandalyenin',\n",
       " 'kaybettiğiniz bebeği',\n",
       " 'birbirimiz görmesek',\n",
       " 'bu geçiyordu',\n",
       " 'evet karşı',\n",
       " 'çiçek hareket',\n",
       " 'dizaynınıza göre',\n",
       " 'olsun köklerini',\n",
       " 'kocasına ya',\n",
       " 'bayanlar hakkında',\n",
       " '7 saatlik',\n",
       " 'olarak kaçınılmaz',\n",
       " 'buraya çağırmanı',\n",
       " 'veremeyecek tek',\n",
       " 've adrenal',\n",
       " 'kaçamadığım şeydi',\n",
       " 'o günlerdeki',\n",
       " 'buralarda besi',\n",
       " 'dallamayı tutmadan',\n",
       " 'gibi hisleri',\n",
       " 'bir kapısın',\n",
       " 'pepperoni gaz',\n",
       " 'böceğin teki',\n",
       " 'engel oldunuz',\n",
       " '8000 ciltlik',\n",
       " 'duyunca seni',\n",
       " 'hedstrom tekniği',\n",
       " 'killifer ne',\n",
       " 'annemin tvsini',\n",
       " 'erkek olamıyorum',\n",
       " 'antika arabayı',\n",
       " 'korkmamak arasında',\n",
       " 'hidrolik sıvısını',\n",
       " 'otomobillerle cehenneme',\n",
       " 'ihtimal nedir',\n",
       " 'salim aç',\n",
       " 'fikret enerjin',\n",
       " 'olur son',\n",
       " 'hoşlanmayı öğrenmeyeceği',\n",
       " 'herhalde aletini',\n",
       " 'anne teresanın',\n",
       " 'içmeye odaklanabiliyorlar',\n",
       " 'hâlâ mööleyeninden',\n",
       " 'insan muamelesi',\n",
       " 'buzağı gibi',\n",
       " 'uzağız tabii',\n",
       " 'aksine bayan',\n",
       " 'nefretle çatılmalı',\n",
       " 'daha çanlar',\n",
       " 'derinliği efendim',\n",
       " 'karşı olmamın',\n",
       " 'çatıda görüp',\n",
       " 'etkileri iyi',\n",
       " 'koltuklar küçülmedi',\n",
       " 'başka katılan',\n",
       " 'şu hortumun',\n",
       " 'uğrayacağını söyledi',\n",
       " 'düzeltme günü',\n",
       " 'görmezsem bu',\n",
       " 'düzgün gizleme',\n",
       " 'an kayın',\n",
       " 'kadar yıllarca',\n",
       " 'kral bize',\n",
       " 'karakuşa güveniyoruz',\n",
       " 'var odunun',\n",
       " 'mutluluğunuz var',\n",
       " 'ama patronun',\n",
       " 'istiyorum aptal',\n",
       " 'seninle kaç',\n",
       " 'bahane bulamadığımız',\n",
       " 'ediyor muhtemelen',\n",
       " 'dizaynı bir',\n",
       " 'waldemar manfredini',\n",
       " 'tea adacherın',\n",
       " 'gösteririz gününü',\n",
       " 'hayatım değişimden',\n",
       " 'kayıp eşyadan',\n",
       " 'dil biraz',\n",
       " 'bakın önümüzde',\n",
       " 'çocuklarını alabilirsiniz',\n",
       " 'haydi işlerini',\n",
       " 'adını hayat',\n",
       " 'anlıyorum dostunuz',\n",
       " 'bonn bir',\n",
       " 'zaman pencerenin',\n",
       " 'kısa don',\n",
       " 'süredir uzaklardasın',\n",
       " 'dostlarınızın mayoları',\n",
       " 'mütevazı olmana',\n",
       " 'birlikte evinde',\n",
       " 'tvye çıkıyordun',\n",
       " 'atlı birileri',\n",
       " 'kadınla böylesine',\n",
       " 'güle prenderg',\n",
       " 'eylemlerimizi açıklamak',\n",
       " '177 kilometre',\n",
       " 'öyküsüdür bu',\n",
       " 'probleminizin olduğu',\n",
       " 'bulsun tamam',\n",
       " 'bireylerden oluşmuş',\n",
       " 'dahi mucize',\n",
       " 'başım öldürüyor',\n",
       " 'söylersin ona',\n",
       " 'krizlerini tetikler',\n",
       " 've thanatos',\n",
       " 'gece ısınmak',\n",
       " 'yeğenimin yapabileceği',\n",
       " 'alınan patentli',\n",
       " 'şu sözü',\n",
       " 'sökmez bana',\n",
       " 'bu kızağa',\n",
       " 'endokrinoloğa ihtiyacım',\n",
       " 'tavşancıkları dışarı',\n",
       " 'büyük görünmeli',\n",
       " 'batıdan hiç',\n",
       " 'dünyaya sarkıtan',\n",
       " 'değii fareieri',\n",
       " 'olduğunu çok',\n",
       " 'edebiyatının ana',\n",
       " 'oğlun ölür',\n",
       " 'suda iz',\n",
       " 'kocama öyle',\n",
       " 'fikret todd',\n",
       " 'bir maaşa',\n",
       " 'top kumaşın',\n",
       " 'sebepden dolayı',\n",
       " 'oynaşmasaydı bağırsaklarından',\n",
       " 'ne hâlin',\n",
       " 'tellerden 1',\n",
       " 'bilgisayar belleğinde',\n",
       " 'kardeşime karşı',\n",
       " 'glabiusun öldürülmesi',\n",
       " 'vorpak kılıcı',\n",
       " 'haltı karıştırabilirsin',\n",
       " 'resme ihtiyacım',\n",
       " 'lezbiyenle ilişkiye',\n",
       " 'aylardır görmüyorum',\n",
       " 'aramızda kurul',\n",
       " 'kelimeleri hissederek',\n",
       " 'sahnede dolaşacağına',\n",
       " 've hakları',\n",
       " 'hadi ceplerini',\n",
       " 'yapabiliriz millet',\n",
       " 'paulieye aitti',\n",
       " 'akşamlar oda',\n",
       " 'yaratmaya çalıştı',\n",
       " 'hayır grege',\n",
       " 'detayları da',\n",
       " 'benim maça',\n",
       " 'aileden kaçarak',\n",
       " 'üretmedikçe keşif',\n",
       " 'ölmesine çok',\n",
       " 'sonunun olduğunu',\n",
       " 'çekerim biz',\n",
       " 'canına ya',\n",
       " 'bekliyor sağ',\n",
       " 'büyülü yaratıklar',\n",
       " 'tıkır çalıştıran',\n",
       " 'çalışmasını ben',\n",
       " 'olmak belki',\n",
       " 'müteahhit gelecek',\n",
       " 'nakli yapan',\n",
       " 'bankadaki veznedara',\n",
       " 'kötü tepki',\n",
       " 'kanadının altında',\n",
       " 'kurtardık sizin',\n",
       " 'bunu düşünmemeye',\n",
       " 'dolandırıcılığı kredi',\n",
       " 'fizik sorusunda',\n",
       " 'şeyi zaman',\n",
       " 'taktığın çiçek',\n",
       " 'çarpıcı görünüyor',\n",
       " 'kellemizi istiyor',\n",
       " 'fikret görmem',\n",
       " 'hizmet verdikten',\n",
       " 'ibneye çok',\n",
       " 'i̇spanyada mezuniyetimi',\n",
       " 'bu kalplerimizle',\n",
       " 'atarsanız ölürsünüz',\n",
       " 'arnavutlukta onları',\n",
       " 'rock benimle',\n",
       " 'atışı hariç',\n",
       " 'dnasından bir',\n",
       " 'harika kılan',\n",
       " 'hamlede mat',\n",
       " 'aslında mikeın',\n",
       " 'ki virajları',\n",
       " 'olduğuna güvendim',\n",
       " 'karı cebe',\n",
       " 'muymuş hiç',\n",
       " 'gaia bir',\n",
       " 'uluyan bekçi',\n",
       " 'taraflı açılan',\n",
       " 'notalı bir',\n",
       " 'çok üşüyorlarmış',\n",
       " 'o sekiz',\n",
       " 'bunu camton',\n",
       " 'yaşayabildiğine göre',\n",
       " 'köpeği uyutmamışlardı',\n",
       " 'hemen yan',\n",
       " 'kim çağrıldı',\n",
       " 'zaman bitirelim',\n",
       " 'ben tekvando',\n",
       " 'bulmak enderdir',\n",
       " 'sana adarım',\n",
       " 'seni hırpaladığım',\n",
       " 'bas sonra',\n",
       " 'zavallı varsa',\n",
       " 'sen dallas',\n",
       " 'direksiyondayken trafik',\n",
       " 'olduysa demek',\n",
       " 'derin çok',\n",
       " 'da çekmiyor',\n",
       " 'hazırlayalım o',\n",
       " 'yankees ücretinin',\n",
       " 'çağı geldi',\n",
       " 'gebertmek için',\n",
       " 'tanıdık aileler',\n",
       " 'sedye üzerinde',\n",
       " 'atması yaklaşan',\n",
       " 'kalçaları işe',\n",
       " 'gürültüsü kadar',\n",
       " 'olurdun hep',\n",
       " 'yerine gelmeyecektir',\n",
       " 'açıdan bilmiyorum',\n",
       " 've dineshin',\n",
       " 'bun senin',\n",
       " 'henüz başvurunun',\n",
       " 'etme duygusunu',\n",
       " 'alıp fundalığa',\n",
       " 'gülüm sıradan',\n",
       " 'yanlız bırakmayacağız',\n",
       " 'siz çocuklarda',\n",
       " 'kahraman demeyin',\n",
       " 'istediğim kelimlerle',\n",
       " 'mahrum edersek',\n",
       " 'senin oynamanı',\n",
       " 'ben vahşet',\n",
       " 'giderken görmüşsündür',\n",
       " 'kehanet agathanın',\n",
       " 'ikinci salı',\n",
       " 'bezini yerim',\n",
       " 'frenini çekeceğim',\n",
       " 'de dediğin',\n",
       " 'sanırım illegal',\n",
       " 'ailemizi rezil',\n",
       " 'pflüger geri',\n",
       " 'bile tutmuştum',\n",
       " 'franke aşık',\n",
       " 'ambulansta ormanda',\n",
       " 'telefonuna ait',\n",
       " 'açısından zayıftı',\n",
       " 'kwame demin',\n",
       " 'korkusuzluk ve',\n",
       " 'için sabırsızlanırdım',\n",
       " 'sağmal inek',\n",
       " 'olduğumu sadece',\n",
       " 'yılında rahim',\n",
       " 'uzak davrandı',\n",
       " 'demek şimdilik',\n",
       " 'ihtimalle telefonda',\n",
       " 'cadı odur',\n",
       " 'madalyasını almayı',\n",
       " 'yapmayı öğretirsem',\n",
       " 'onu duymuştur',\n",
       " 'dilinizi dekonstrüksiyon',\n",
       " 'ışığını gördü',\n",
       " 'göstermesi gerek',\n",
       " 'song shoushu',\n",
       " 'hareket ettirmiyorsun',\n",
       " 'ummadıkları birine',\n",
       " 'izinsiz karıştırmam',\n",
       " 'ha sarmısak',\n",
       " 'tetiklediğini mutlaka',\n",
       " 'seviyorum şeker',\n",
       " 'kapıldın sanırım',\n",
       " 'birisinin kötülüğünü',\n",
       " 'dönüşünü kutluyoruz',\n",
       " 'gelip ilgilenir',\n",
       " 'yavaşlatacağını bilir',\n",
       " 'ikisini nasıl',\n",
       " 'şüphelileri araştırmak',\n",
       " 'birşey varmış',\n",
       " 'nükleer kaçakçılık',\n",
       " 'yazarak anlattıklarımın',\n",
       " 'vietnam savaşıdır',\n",
       " 'benim ahlaksız',\n",
       " 'şeylerden endişelenmeyi',\n",
       " 'sabit alışkanlıkları',\n",
       " 'fırsat kaçmaz',\n",
       " 'pistine gitmek',\n",
       " 'yıllar hayatım',\n",
       " 'berbat zenginler',\n",
       " 'adam kafasından',\n",
       " 'satış yapıyorsun',\n",
       " 'isim olamazdı',\n",
       " 'artık modestoda',\n",
       " 'istiyorum sakıncası',\n",
       " 'ben fahişelerden',\n",
       " 'nelerden hoşlandıklarını',\n",
       " 'reddetme çocukluktan',\n",
       " 'monje orada',\n",
       " 'bir aşırılıkla',\n",
       " 'bu beklemek',\n",
       " 'kaybedersen bir',\n",
       " 'peru 2',\n",
       " 'yere hislerim',\n",
       " 'deneyime yüzde',\n",
       " 'deneyimlerimi anlatan',\n",
       " 'değilseniz kimsiniz',\n",
       " 'rekor hala',\n",
       " 'fikret kanenin',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_list = df_ngram.iloc[:,0].to_list()\n",
    "n_gram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")\n",
    "df_n_sent = df_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from multiprocessing import Process, Manager, Pool, Queue\n",
    "manager = multiprocessing.Manager()\n",
    "result_df = manager.list()\n",
    "\n",
    "def wordgroup_in_wordgroup(n_gram_list):\n",
    "    df_wordgroup_result = pd.DataFrame()\n",
    "    df_result = df_n_sent[df_n_sent.iloc[:,0].str.contains(fr\"(^|\\s){n_gram_list}(\\s|$)\")]\n",
    "    df_result.insert(0,f\"all_ngram\",n_gram_list)\n",
    "    df_wordgroup_result = pd.concat([df_wordgroup_result,df_result], axis=0)\n",
    "    df_wordgroup_result.reset_index(drop=True, inplace=True)\n",
    "    result_df.append(df_wordgroup_result)    \n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(wordgroup_in_wordgroup, n_gram_list) # string_word liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df_list = list(result_df)\n",
    "df_concat = pd.DataFrame()\n",
    "for i in multi_df_list:\n",
    "    df_concat = pd.concat([df_concat,i],axis=0)\n",
    "df_concat.sort_values(by=\"frequency\",ascending=False, inplace=True)\n",
    "df_concat.reset_index(drop=True, inplace=True)\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_excel(\"Not_Twogram_Sent_In_Threegram_Sent.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
