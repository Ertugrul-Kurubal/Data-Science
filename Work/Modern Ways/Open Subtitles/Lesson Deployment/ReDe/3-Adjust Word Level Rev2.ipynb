{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"French\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = True  # True, False  # True for adding prefix suffix word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)  # create path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988212</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988213</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988214</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988215</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988216</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "988212     karneleme          5\n",
       "988213       karnaya          5\n",
       "988214   dörtlümüzün          5\n",
       "988215  karnavalınız          5\n",
       "988216      hurmanın          5\n",
       "\n",
       "[988217 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teşekkür ederim</td>\n",
       "      <td>244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>öyle mi</td>\n",
       "      <td>209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne oldu</td>\n",
       "      <td>195799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aman tanrım</td>\n",
       "      <td>189521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>özür dilerim</td>\n",
       "      <td>153784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036515</th>\n",
       "      <td>güzeldi tommy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036516</th>\n",
       "      <td>durumu tuhaflaştırma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036517</th>\n",
       "      <td>güzeldi canım</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036518</th>\n",
       "      <td>güzeldi daniel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036519</th>\n",
       "      <td>güzelce vurdular</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      twogram  frequency\n",
       "0             teşekkür ederim     244149\n",
       "1                     öyle mi     209900\n",
       "2                     ne oldu     195799\n",
       "3                 aman tanrım     189521\n",
       "4                özür dilerim     153784\n",
       "...                       ...        ...\n",
       "1036515         güzeldi tommy          3\n",
       "1036516  durumu tuhaflaştırma          3\n",
       "1036517         güzeldi canım          3\n",
       "1036518        güzeldi daniel          3\n",
       "1036519      güzelce vurdular          3\n",
       "\n",
       "[1036520 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")\n",
    "df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "df_twogram_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_pair_list = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_And_{lang_pair.lower().capitalize()}*_All.xlsx\")\n",
    "#lang_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>french_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abajur</td>\n",
       "      <td>abat-jour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandone</td>\n",
       "      <td>abandonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abiye</td>\n",
       "      <td>habillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>yeniçeri</td>\n",
       "      <td>janissaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>yoğurt</td>\n",
       "      <td>yaourt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zèbre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>zürafa</td>\n",
       "      <td>girafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main french_word\n",
       "0             abajur   abat-jour\n",
       "1             abaküs      abacus\n",
       "2           abandone  abandonner\n",
       "3              abiye     habillé\n",
       "4             abluka      blocus\n",
       "...              ...         ...\n",
       "1593        yeniçeri  janissaire\n",
       "1594          yoğurt      yaourt\n",
       "1595           zebra       zèbre\n",
       "1596           zombi      zombie\n",
       "1597          zürafa      girafe\n",
       "\n",
       "[1598 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_pair_ety = pd.read_excel(f\"{lang_pair_list[0]}\")  # need only dict_entry_main column\n",
    "df_pair_ety = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair_ety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>french_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abajur</td>\n",
       "      <td>abat-jour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>abandonner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abiye</td>\n",
       "      <td>habillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>zombileri</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>zombiye</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>zürafa</td>\n",
       "      <td>girafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>zürafalar</td>\n",
       "      <td>girafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>zürafayı</td>\n",
       "      <td>girafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main french_word\n",
       "0             abajur   abat-jour\n",
       "1             abaküs      abacus\n",
       "2          abandoned  abandonner\n",
       "3              abiye     habillé\n",
       "4             abluka      blocus\n",
       "...              ...         ...\n",
       "5385       zombileri      zombie\n",
       "5386         zombiye      zombie\n",
       "5387          zürafa      girafe\n",
       "5388       zürafalar      girafe\n",
       "5389        zürafayı      girafe\n",
       "\n",
       "[5390 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.lower().capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "    df_prefix_suffix_select = df_prefix_suffix_select.loc[:,[\"search_word\",\"word\"]]\n",
    "    df_prefix_suffix_select.rename(columns={\"search_word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_merge = pd.merge(df_pair_ety,df_prefix_suffix_select, how=\"inner\", on=\"dict_entry_main\")\n",
    "    df_pair_merge.drop_duplicates(inplace=True)\n",
    "    df_pair_merge.reset_index(drop=True, inplace=True)\n",
    "    df_pair_merge = df_pair_merge.loc[:,[\"word\",f\"{lang_pair.lower()}_word\"]]\n",
    "    df_pair_merge.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "    df_pair_all = df_pair_merge\n",
    "else:\n",
    "    df_pair_all = df_pair_ety\n",
    "\n",
    "df_pair_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_pair_all[\"dict_entry_main\"].values.tolist()\n",
    "disable_set = set(disable_list)\n",
    "words_set = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>makyajımı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>galanın</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reyonda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kanepe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>demokrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>veteriner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>zombiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>rekoru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>briyantin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5253 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main\n",
       "0          makyajımı\n",
       "1            galanın\n",
       "2            reyonda\n",
       "3            garland\n",
       "4             kanepe\n",
       "...              ...\n",
       "5248        demokrat\n",
       "5249       veteriner\n",
       "5250        zombiler\n",
       "5251          rekoru\n",
       "5252       briyantin\n",
       "\n",
       "[5253 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair = pd.DataFrame(list(words_set.difference(disable_set)), columns=[\"dict_entry_main\"])\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependency Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetition(word_group):\n",
    "    '''\n",
    "    remove_repetition(word_group): detect word repetion in word group \n",
    "    '''\n",
    "    words = word_tokenize(word_group)\n",
    "    word_unique = set(words)\n",
    "    if len(word_unique) == 1:\n",
    "        return \"repetitive_word_group\"\n",
    "    else:\n",
    "        return word_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_bool(df, word_thresh_num, column_list): # df is a dataframe, word_thresh_num is an integer, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, word_thresh_num, column_list):\\n\n",
    "    df is a dataframe, word_thresh_num is an integer, column_list is df column names\\n\n",
    "    word_count_bool(df, 7, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count[\"count\"][df_word_count.loc[:,\"count\"] > word_thresh_num].any()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4):\n",
    "    '''\n",
    "    default parameter:\\n    \n",
    "    condition1(word_start_num = 0, word_limit_num = 28, thresh_num = 2, total_part_num = 4) \\n\n",
    "    word_end 28/4 = 7 word group\n",
    "    '''\n",
    "\n",
    "    # while loop code block word and twogram pair\n",
    "    word_thresh_num = thresh_num  # want how many word sample \n",
    "    word_start = word_start_num  # 0\n",
    "    word_end = int((word_limit_num-word_start_num)/total_part_num)  \n",
    "    step_num = word_end  \n",
    "    word_limit = word_limit_num   \n",
    "    part_num = 1  # first output file extention\n",
    "    \n",
    "    #twogram_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "    twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "    \n",
    "    while word_end <= word_limit:\n",
    "        df_word = df_word_all.iloc[word_start:word_end,]  # must be include word and frequency column\n",
    "        df_word.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        # language pair twogram\n",
    "        word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "        word_list = df_word[\"word\"].to_list()  # *****    \n",
    "        ngram_list = []\n",
    "        for i in word_pair_list:\n",
    "            for j in word_tokenize(i):\n",
    "                for k in word_list:\n",
    "                    twogram_1_2 = f\"{j} {k}\"\n",
    "                    ngram_list.append(twogram_1_2)\n",
    "                    twogram_2_1 = f\"{k} {j}\"\n",
    "                    ngram_list.append(twogram_2_1)\n",
    "        df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "        #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # ******\n",
    "        df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "        df_pair_ngram.drop_duplicates(inplace=True)\n",
    "        df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "        df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "        df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "        df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "        #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    \n",
    "        # output\n",
    "        df_output_result = pd.concat([df_word, df_lang_pair_twogram], axis=1)\n",
    "    \n",
    "        df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "        a = 0\n",
    "        #for i in range(0,110):\n",
    "        for i in range(len(df_output_result)):  # *****\n",
    "            # Insert words and their count \n",
    "            try:\n",
    "                word = df_output_result.iloc[i,0]  # word \n",
    "                freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "                df_lesson_result.loc[i,\"word\"] = word\n",
    "                df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Insert twogram pair\n",
    "            try:\n",
    "                var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    try:\n",
    "                        while word_count_bool(df_lesson_result, word_thresh_num, [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                            a += 1\n",
    "                            var2 = df_output_result.loc[a,f\"twogram_pair_{lang_pair.lower()}\"]\n",
    "                            freq_var2 = df_output_result.iloc[a,3]  # twogram_pair frequency\n",
    "                            df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                            df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            a += 1\n",
    "    \n",
    "        df_lesson_word_count = word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "        df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "        df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "        df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "    \n",
    "        word_start += step_num\n",
    "        word_end += step_num\n",
    "        part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameter Part ---\n",
    "\n",
    "# condition 1\n",
    "condition1_word_start = 0\n",
    "condition1_word_limit = 28\n",
    "condition1_word_thresh_num = 2\n",
    "condition1_total_part_num = 4  # 28/4 = 7 word group\n",
    "\n",
    "# condition 2\n",
    "condition1_dependency = True  # True, False\n",
    "word_thresh_num = 10\n",
    "twogram_thresh_minus = 0  # for optional twogram thresh number \n",
    "twogram_pair_thresh_minus = 0  # for optinal twogram pair thresh number.\n",
    "\n",
    "word_start = 0  # 0\n",
    "word_end = 28  # 10\n",
    "step_num = word_end  # 10\n",
    "word_limit = word_end  # 200\n",
    "part_num = 1\n",
    "    \n",
    "if condition1_dependency:        \n",
    "    # Read previous part result\n",
    "    condition1(word_start_num = condition1_word_start, word_limit_num = condition1_word_limit, thresh_num = condition1_word_thresh_num, total_part_num = condition1_total_part_num)  # word_end 28/4 = 7 word group. Condition 1 parameters \n",
    "    df_part_all = pd.DataFrame()\n",
    "    part_result_file = glob.glob(f\"{lang_folder}_{lang_pair}_*_Word_Step_*_Result*.xlsx\")\n",
    "    for i in part_result_file:\n",
    "        df_var = pd.read_excel(f\"{i}\")\n",
    "        df_part_all = pd.concat([df_part_all,df_var], axis=0)\n",
    "    df_part_twogram_pair = df_part_all.loc[:,[f\"twogram_pair_{lang_pair.lower()}\"]]\n",
    "    df_part_twogram_pair.reset_index(drop=True, inplace=True)\n",
    "    set_part_twogram_pair = set(df_part_twogram_pair[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "else:\n",
    "    set_part_twogram_pair = set([])  # option for skip Condition 1\n",
    "# --- Parameter End ---\n",
    "\n",
    "# while loop code block\n",
    "\n",
    "twogram_num = word_thresh_num * step_num   # word_thresh_num*step_num minimum: for each word takes two twogram\n",
    "twogram_pair_num = word_thresh_num * step_num  # word_thresh_num*step_num minimum: for each word takes two twogram pair\n",
    "\n",
    "while word_end <= word_limit:\n",
    "    df_word = df_word_all.iloc[word_start:word_end,]\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # language pair twogram\n",
    "    word_pair_list = df_pair[\"dict_entry_main\"].to_list()  # *****\n",
    "    word_list = df_word[\"word\"].to_list()  # ***** \n",
    "    ngram_list = []\n",
    "    for i in word_pair_list:\n",
    "        for j in word_tokenize(i):\n",
    "            for k in word_list:\n",
    "                twogram_1_2 = f\"{j} {k}\"\n",
    "                ngram_list.append(twogram_1_2)\n",
    "                twogram_2_1 = f\"{k} {j}\"\n",
    "                ngram_list.append(twogram_2_1)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list)\n",
    "    df_pair_ngram = pd.DataFrame(ngram_list, columns=[\"twogram\"])\n",
    "    #df_pair_ngram.rename(columns={0:\"twogram\"}, inplace=True)  # *****\n",
    "    df_pair_ngram.iloc[:,0] = df_pair_ngram.iloc[:,0].apply(lambda x: remove_repetition(x))\n",
    "    df_pair_ngram.drop_duplicates(inplace=True)\n",
    "    df_pair_ngram.reset_index(drop=True, inplace=True)\n",
    "    df_lang_pair_twogram = pd.merge(df_twogram_sent, df_pair_ngram, how=\"inner\", on=\"twogram\")\n",
    "    df_lang_pair_twogram.rename(columns={\"twogram\":f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_lang_pair_twogram.drop_duplicates(inplace=True)\n",
    "    #df_lang_pair_twogram = df_lang_pair_twogram.head(100)\n",
    "    set_lang_pair_twogram = set(df_lang_pair_twogram[f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_set_result = pd.DataFrame(set_lang_pair_twogram.difference(set_part_twogram_pair))\n",
    "    df_set_result.rename(columns={0:f\"twogram_pair_{lang_pair.lower()}\"}, inplace=True)\n",
    "    df_set_pair_twogram = pd.merge(df_lang_pair_twogram, df_set_result, how=\"inner\", on=f\"twogram_pair_{lang_pair.lower()}\")\n",
    "\n",
    "    # twogram\n",
    "    word_list = df_word[\"word\"].values.tolist()\n",
    "    data_kind = \"twogram\"\n",
    "    twogram_list  = df_twogram_sent.iloc[:,0].values.tolist()\n",
    "    \n",
    "    resultlist2 = []\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    resultlist2 = manager.list()\n",
    "    \n",
    "    def word_in_wordgroup2(list_var2):\n",
    "        mergelist = []\n",
    "        try:\n",
    "            word = list_var2.split()\n",
    "        except:\n",
    "            pass\n",
    "        var1 = range(len(word))\n",
    "        for j in var1:\n",
    "            if word[j] in word_list:\n",
    "                mergelist.append(word[j])\n",
    "                if len(mergelist) == len(word):\n",
    "                        resultlist2.append(list_var2)\n",
    "                            \n",
    "    if __name__ == '__main__':\n",
    "        # with Pool(16) as p:\n",
    "        with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "            p.map(word_in_wordgroup2, twogram_list) # string_word liste \n",
    "\n",
    "    result_list2 = list(resultlist2)\n",
    "    df_result2 = pd.DataFrame(result_list2)\n",
    "    df_result2 = pd.DataFrame(result_list2, columns=[f\"{data_kind}\"])  # *****\n",
    "    #df_result2 = df_result2.rename(columns = {0: f\"{data_kind}\"})  # *****\n",
    "    df_result2.iloc[:,0] = df_result2.iloc[:,0].apply(lambda x: remove_repetition(x)) # **\n",
    "    df_merge2 = pd.merge(df_result2, df_twogram_sent, how=\"inner\", on=f\"{data_kind}\")\n",
    "    df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_merge_result2.drop_duplicates(inplace=True)\n",
    "    df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "    df_twogram_result = df_merge_result2\n",
    "    #df_twogram_result = df_twogram_result.head(100)\n",
    "\n",
    "    # output\n",
    "    df_output_result = pd.concat([df_word, df_twogram_result, df_set_pair_twogram], axis=1)\n",
    "\n",
    "    df_lesson_result = pd.DataFrame(columns=[\"word\",\"freq_word\",\"twogram\",\"freq_twogram\",f\"twogram_pair_{lang_pair.lower()}\",f\"freq_twogram_pair_{lang_pair.lower()}\"])\n",
    "    a = 0\n",
    "    b = 0\n",
    "\n",
    "    for i in range(len(df_output_result)):  # *****\n",
    "        # Insert words and their count \n",
    "        try:\n",
    "            word = df_output_result.iloc[i,0]  # word\n",
    "            freq_word = df_output_result.iloc[i,1]  # word freq\n",
    "            df_lesson_result.loc[i,\"word\"] = word\n",
    "            df_lesson_result.loc[i,\"freq_word\"] = freq_word\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "        # Insert n grams\n",
    "        try:\n",
    "            var1 = df_output_result.iloc[a,2]\n",
    "            freq_var1 = df_output_result.iloc[a,3]\n",
    "            if (len(df_lesson_result[\"twogram\"]) < twogram_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_thresh_minus), [\"twogram\"]): # word count result                \n",
    "                        a += 1\n",
    "                        var1 = df_output_result.iloc[a,2]\n",
    "                        freq_var1 = df_output_result.iloc[a,3]\n",
    "                        df_lesson_result.loc[i,\"twogram\"] = var1\n",
    "                        df_lesson_result.loc[i,\"freq_twogram\"] = freq_var1\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,\"twogram\"] = np.nan\n",
    "                    df_lesson_result.loc[i,\"freq_twogram\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        a += 1\n",
    "\n",
    "        try:\n",
    "            var2 = df_output_result.iloc[b,4]\n",
    "            freq_var2 = df_output_result.iloc[b,5]\n",
    "            if (len(df_lesson_result[f\"twogram_pair_{lang_pair.lower()}\"]) < twogram_pair_num): # and (not(word_count(df_lesson_result, word_thresh_num))):\n",
    "                df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                try:\n",
    "                    while word_count_bool(df_lesson_result, (word_thresh_num - twogram_pair_thresh_minus), [f\"twogram_pair_{lang_pair.lower()}\"]): # word count result                \n",
    "                        b += 1\n",
    "                        var2 = df_output_result.iloc[b,4]\n",
    "                        freq_var2 = df_output_result.iloc[b,5]\n",
    "                        df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = var2\n",
    "                        df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = freq_var2\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    df_lesson_result.loc[i,f\"twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "                    df_lesson_result.loc[i,f\"freq_twogram_pair_{lang_pair.lower()}\"] = np.nan\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "        b += 1\n",
    "\n",
    "    df_lesson_word_count = word_count_result(df_lesson_result, [\"twogram\",f\"twogram_pair_{lang_pair.lower()}\"])\n",
    "    df_lesson_result = pd.merge(df_lesson_result, df_lesson_word_count, how=\"left\", on=\"word\")\n",
    "    df_lesson_result = df_lesson_result.drop_duplicates()\n",
    "    df_lesson_result.to_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result{part_num}.xlsx\", index=False)\n",
    "\n",
    "    word_start += step_num\n",
    "    word_end += step_num\n",
    "    part_num += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>evet ekselansları</td>\n",
       "      <td>467</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>ne sürpriz</td>\n",
       "      <td>401</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>pardon ne</td>\n",
       "      <td>382</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>çok normal</td>\n",
       "      <td>380</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>ne romantik</td>\n",
       "      <td>370</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha basma</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama beni</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beni bastın</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bazen beni</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word   twogram freq_twogram twogram_pair_french  \\\n",
       "0     bir  18835735.0    ne var      62532.0   evet ekselansları   \n",
       "1      bu  11062659.0    ben de      59972.0          ne sürpriz   \n",
       "2      ne   8025880.0  değil mi      58386.0           pardon ne   \n",
       "3      ve   7766036.0    ben mi      33652.0          çok normal   \n",
       "4    için   5484109.0   ne için      31857.0         ne romantik   \n",
       "..    ...         ...       ...          ...                 ...   \n",
       "241   NaN         NaN       NaN          NaN          daha basma   \n",
       "242   NaN         NaN       NaN          NaN          drama beni   \n",
       "243   NaN         NaN       NaN          NaN         beni bastın   \n",
       "244   NaN         NaN       NaN          NaN          bazen beni   \n",
       "245   NaN         NaN       NaN          NaN                 NaN   \n",
       "\n",
       "    freq_twogram_pair_french  word_count  \n",
       "0                        467        20.0  \n",
       "1                        401        20.0  \n",
       "2                        382        20.0  \n",
       "3                        380        20.0  \n",
       "4                        370        14.0  \n",
       "..                       ...         ...  \n",
       "241                        4         NaN  \n",
       "242                        4         NaN  \n",
       "243                        3         NaN  \n",
       "244                        3         NaN  \n",
       "245                      NaN         NaN  \n",
       "\n",
       "[246 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesson_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [\"twogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_result(df_lesson_result, [f\"twogram_pair_{lang_pair.lower()}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Output File And Multi Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>polis mi</td>\n",
       "      <td>2526</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>bir numara</td>\n",
       "      <td>1272</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>bu komik</td>\n",
       "      <td>994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ne duydun</td>\n",
       "      <td>954</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>bebek mi</td>\n",
       "      <td>861</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>ne planı</td>\n",
       "      <td>835</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>bu normal</td>\n",
       "      <td>828</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve motor</td>\n",
       "      <td>776</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir şartla</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şans için</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron o</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek için</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o polis</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_french  freq_twogram_pair_french  word_count\n",
       "0    bir  18835735.0            polis mi                      2526         2.0\n",
       "1     bu  11062659.0          bir numara                      1272         2.0\n",
       "2     ne   8025880.0            bu komik                       994         2.0\n",
       "3     ve   7766036.0           ne duydun                       954         1.0\n",
       "4   için   5484109.0            bebek mi                       861         2.0\n",
       "5     mi   5362714.0            ne planı                       835         2.0\n",
       "6      o   5013838.0           bu normal                       828         2.0\n",
       "7    NaN         NaN            ve motor                       776         NaN\n",
       "8    NaN         NaN          bir şartla                       718         NaN\n",
       "9    NaN         NaN           şans için                       305         NaN\n",
       "10   NaN         NaN            patron o                       251         NaN\n",
       "11   NaN         NaN          bebek için                       173         NaN\n",
       "12   NaN         NaN             o polis                       133         NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result1.xlsx\")\n",
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ben</td>\n",
       "      <td>4908913.0</td>\n",
       "      <td>çok komik</td>\n",
       "      <td>13097</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>4880315.0</td>\n",
       "      <td>çok basit</td>\n",
       "      <td>4669</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>çok</td>\n",
       "      <td>4852169.0</td>\n",
       "      <td>evet duydum</td>\n",
       "      <td>3278</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ama</td>\n",
       "      <td>4661966.0</td>\n",
       "      <td>evet komutanım</td>\n",
       "      <td>2522</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>4389551.0</td>\n",
       "      <td>ben doktorum</td>\n",
       "      <td>1830</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evet</td>\n",
       "      <td>4324786.0</td>\n",
       "      <td>randevum var</td>\n",
       "      <td>916</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mı</td>\n",
       "      <td>4001316.0</td>\n",
       "      <td>plan mı</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bomba mı</td>\n",
       "      <td>541</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ben avukatım</td>\n",
       "      <td>410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bomba var</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ama bazen</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon ama</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gene de</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_french  freq_twogram_pair_french  word_count\n",
       "0    ben  4908913.0           çok komik                     13097         2.0\n",
       "1     de  4880315.0           çok basit                      4669         1.0\n",
       "2    çok  4852169.0         evet duydum                      3278         2.0\n",
       "3    ama  4661966.0      evet komutanım                      2522         2.0\n",
       "4    var  4389551.0        ben doktorum                      1830         2.0\n",
       "5   evet  4324786.0        randevum var                       916         2.0\n",
       "6     mı  4001316.0             plan mı                       556         2.0\n",
       "7    NaN        NaN            bomba mı                       541         NaN\n",
       "8    NaN        NaN        ben avukatım                       410         NaN\n",
       "9    NaN        NaN           bomba var                       326         NaN\n",
       "10   NaN        NaN           ama bazen                       195         NaN\n",
       "11   NaN        NaN          pardon ama                       103         NaN\n",
       "12   NaN        NaN             gene de                        68         NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_12 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result2.xlsx\")\n",
    "df_part_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>değil</td>\n",
       "      <td>3883885.0</td>\n",
       "      <td>komik değil</td>\n",
       "      <td>1785</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da</td>\n",
       "      <td>3610161.0</td>\n",
       "      <td>fazla değil</td>\n",
       "      <td>1756</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>şey</td>\n",
       "      <td>3602024.0</td>\n",
       "      <td>daha fazla</td>\n",
       "      <td>1738</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hayır</td>\n",
       "      <td>3406992.0</td>\n",
       "      <td>hayır komutanım</td>\n",
       "      <td>764</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daha</td>\n",
       "      <td>3317577.0</td>\n",
       "      <td>hayır doktor</td>\n",
       "      <td>481</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sen</td>\n",
       "      <td>3283654.0</td>\n",
       "      <td>sen defol</td>\n",
       "      <td>176</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kadar</td>\n",
       "      <td>2697900.0</td>\n",
       "      <td>sen yat</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>komik şey</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha basit</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şeker şey</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pardon da</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>senatoya da</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>atmosfere kadar</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  freq_word twogram_pair_french  freq_twogram_pair_french  word_count\n",
       "0   değil  3883885.0         komik değil                      1785         2.0\n",
       "1      da  3610161.0         fazla değil                      1756         2.0\n",
       "2     şey  3602024.0          daha fazla                      1738         2.0\n",
       "3   hayır  3406992.0     hayır komutanım                       764         2.0\n",
       "4    daha  3317577.0        hayır doktor                       481         2.0\n",
       "5     sen  3283654.0           sen defol                       176         2.0\n",
       "6   kadar  2697900.0             sen yat                       156         1.0\n",
       "7     NaN        NaN           komik şey                        76         NaN\n",
       "8     NaN        NaN          daha basit                        76         NaN\n",
       "9     NaN        NaN           şeker şey                        70         NaN\n",
       "10    NaN        NaN           pardon da                        43         NaN\n",
       "11    NaN        NaN         senatoya da                        33         NaN\n",
       "12    NaN        NaN     atmosfere kadar                        16         NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_13 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result3.xlsx\")\n",
    "df_part_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bana</td>\n",
       "      <td>2659182.0</td>\n",
       "      <td>beni duydun</td>\n",
       "      <td>3541</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yok</td>\n",
       "      <td>2491685.0</td>\n",
       "      <td>seni duydum</td>\n",
       "      <td>1703</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onu</td>\n",
       "      <td>2486889.0</td>\n",
       "      <td>onu duydun</td>\n",
       "      <td>1473</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seni</td>\n",
       "      <td>2454988.0</td>\n",
       "      <td>bunu duydum</td>\n",
       "      <td>839</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beni</td>\n",
       "      <td>2446696.0</td>\n",
       "      <td>problem yok</td>\n",
       "      <td>746</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bunu</td>\n",
       "      <td>2445337.0</td>\n",
       "      <td>sinyal yok</td>\n",
       "      <td>742</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gibi</td>\n",
       "      <td>2427957.0</td>\n",
       "      <td>seni manyak</td>\n",
       "      <td>279</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bomba gibi</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek gibi</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beni duydu</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yatır onu</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>telefon bana</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bunu basın</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  freq_word twogram_pair_french  freq_twogram_pair_french  word_count\n",
       "0   bana  2659182.0         beni duydun                      3541         1.0\n",
       "1    yok  2491685.0         seni duydum                      1703         2.0\n",
       "2    onu  2486889.0          onu duydun                      1473         2.0\n",
       "3   seni  2454988.0         bunu duydum                       839         2.0\n",
       "4   beni  2446696.0         problem yok                       746         2.0\n",
       "5   bunu  2445337.0          sinyal yok                       742         2.0\n",
       "6   gibi  2427957.0         seni manyak                       279         2.0\n",
       "7    NaN        NaN          bomba gibi                       236         NaN\n",
       "8    NaN        NaN          bebek gibi                       175         NaN\n",
       "9    NaN        NaN          beni duydu                       125         NaN\n",
       "10   NaN        NaN           yatır onu                        68         NaN\n",
       "11   NaN        NaN        telefon bana                        28         NaN\n",
       "12   NaN        NaN          bunu basın                        27         NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_14 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_7_Result4.xlsx\")\n",
    "df_part_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>freq_twogram</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>ne var</td>\n",
       "      <td>62532.0</td>\n",
       "      <td>evet ekselansları</td>\n",
       "      <td>467</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>ben de</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>ne sürpriz</td>\n",
       "      <td>401</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>değil mi</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>pardon ne</td>\n",
       "      <td>382</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ben mi</td>\n",
       "      <td>33652.0</td>\n",
       "      <td>çok normal</td>\n",
       "      <td>380</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>ne için</td>\n",
       "      <td>31857.0</td>\n",
       "      <td>ne romantik</td>\n",
       "      <td>370</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha amerikan</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daha basma</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drama beni</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beni bastın</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bazen beni</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word   freq_word   twogram  freq_twogram twogram_pair_french  \\\n",
       "0     bir  18835735.0    ne var       62532.0   evet ekselansları   \n",
       "1      bu  11062659.0    ben de       59972.0          ne sürpriz   \n",
       "2      ne   8025880.0  değil mi       58386.0           pardon ne   \n",
       "3      ve   7766036.0    ben mi       33652.0          çok normal   \n",
       "4    için   5484109.0   ne için       31857.0         ne romantik   \n",
       "..    ...         ...       ...           ...                 ...   \n",
       "240   NaN         NaN       NaN           NaN       daha amerikan   \n",
       "241   NaN         NaN       NaN           NaN          daha basma   \n",
       "242   NaN         NaN       NaN           NaN          drama beni   \n",
       "243   NaN         NaN       NaN           NaN         beni bastın   \n",
       "244   NaN         NaN       NaN           NaN          bazen beni   \n",
       "\n",
       "     freq_twogram_pair_french  word_count  \n",
       "0                         467        20.0  \n",
       "1                         401        20.0  \n",
       "2                         382        20.0  \n",
       "3                         380        20.0  \n",
       "4                         370        14.0  \n",
       "..                        ...         ...  \n",
       "240                         4         NaN  \n",
       "241                         4         NaN  \n",
       "242                         4         NaN  \n",
       "243                         3         NaN  \n",
       "244                         3         NaN  \n",
       "\n",
       "[245 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_21 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_28_Result1.xlsx\")\n",
    "df_part_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_11.to_excel(writer, sheet_name='Word_Part11', index=False)\n",
    "df_part_12.to_excel(writer, sheet_name='Word_Part12', index=False)\n",
    "df_part_13.to_excel(writer, sheet_name='Word_Part13', index=False)\n",
    "df_part_14.to_excel(writer, sheet_name='Word_Part14', index=False)\n",
    "df_part_21.to_excel(writer, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Result_With_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var.to_excel(writer, sheet_name=f'Word_Part1{i}', index=False)            \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_part_var2.to_excel(writer, sheet_name=f'Word_Part21', index=False)        \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output File Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "      <th>freq_twogram_pair_french</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735.0</td>\n",
       "      <td>polis mi</td>\n",
       "      <td>2526</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659.0</td>\n",
       "      <td>bir numara</td>\n",
       "      <td>1272</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880.0</td>\n",
       "      <td>bu komik</td>\n",
       "      <td>994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036.0</td>\n",
       "      <td>ne duydun</td>\n",
       "      <td>954</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109.0</td>\n",
       "      <td>bebek mi</td>\n",
       "      <td>861</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mi</td>\n",
       "      <td>5362714.0</td>\n",
       "      <td>ne planı</td>\n",
       "      <td>835</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>o</td>\n",
       "      <td>5013838.0</td>\n",
       "      <td>bu normal</td>\n",
       "      <td>828</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve motor</td>\n",
       "      <td>776</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir şartla</td>\n",
       "      <td>718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>şans için</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patron o</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bebek için</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o polis</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   freq_word twogram_pair_french  freq_twogram_pair_french  word_count\n",
       "0    bir  18835735.0            polis mi                      2526         2.0\n",
       "1     bu  11062659.0          bir numara                      1272         2.0\n",
       "2     ne   8025880.0            bu komik                       994         2.0\n",
       "3     ve   7766036.0           ne duydun                       954         1.0\n",
       "4   için   5484109.0            bebek mi                       861         2.0\n",
       "5     mi   5362714.0            ne planı                       835         2.0\n",
       "6      o   5013838.0           bu normal                       828         2.0\n",
       "7    NaN         NaN            ve motor                       776         NaN\n",
       "8    NaN         NaN          bir şartla                       718         NaN\n",
       "9    NaN         NaN           şans için                       305         NaN\n",
       "10   NaN         NaN            patron o                       251         NaN\n",
       "11   NaN         NaN          bebek için                       173         NaN\n",
       "12   NaN         NaN             o polis                       133         NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_twogram(df, list_column, target_column):\n",
    "\n",
    "    '''word_in_twogram(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, list_column and target_column are \n",
    "       dataframe column string name. list_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_word_result = pd.DataFrame()\n",
    "    for i in df[f\"{list_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_twogram = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)] \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_twogram.insert(0,\"word\",i)\n",
    "        df_word_result = pd.concat([df_word_result,word_in_twogram], axis=0)\n",
    "    df_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir numara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir şartla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu komik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne duydun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne planı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>için</td>\n",
       "      <td>şans için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>için</td>\n",
       "      <td>bebek için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mi</td>\n",
       "      <td>polis mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mi</td>\n",
       "      <td>bebek mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>o</td>\n",
       "      <td>patron o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o</td>\n",
       "      <td>o polis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word twogram_pair_french\n",
       "0    bir          bir numara\n",
       "1    bir          bir şartla\n",
       "2     bu            bu komik\n",
       "3     bu           bu normal\n",
       "4     ne           ne duydun\n",
       "5     ne            ne planı\n",
       "6     ve            ve motor\n",
       "7   için           şans için\n",
       "8   için          bebek için\n",
       "9     mi            polis mi\n",
       "10    mi            bebek mi\n",
       "11     o            patron o\n",
       "12     o             o polis"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_11 = word_in_twogram(df_part_11, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_12 = word_in_twogram(df_part_12, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_13 = word_in_twogram(df_part_13, \"word\", f\"twogram_pair_{lang_pair.lower()}\") \n",
    "df_word_order_14 = word_in_twogram(df_part_14, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_21 = word_in_twogram(df_part_21, \"word\", f\"twogram\") \n",
    "df_word_order_212 = word_in_twogram(df_part_21, \"word\", f\"twogram_pair_{lang_pair.lower()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11 = df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()   # df_word_order_11.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].transform(lambda x: ','.join(x))\n",
    "df_word_order_join_12 = df_word_order_12.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_13 = df_word_order_13.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_14 = df_word_order_14.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>twogram</th>\n",
       "      <th>twogram_pair_french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>evet ama, ama ben, ama ne, ama bu, ama sen, ha...</td>\n",
       "      <td>ama general, ama amatörler, ama madam, duydum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana mı, bana da, bana değil, ve bana, bana bi...</td>\n",
       "      <td>bana spesiyal, bana hamburger, bana vanilyalı,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben de, ben mi, hayır ben, ama ben, ben değil,...</td>\n",
       "      <td>ben patronum, ben bekarım, ben doktor, bazen b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beni</td>\n",
       "      <td>beni mi, beni de, beni değil, ve beni, beni ço...</td>\n",
       "      <td>çarp beni, gazla beni, beni ispiyonladı, mesaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>bir daha, bu bir, bir şey, bir de, bir mi, ben...</td>\n",
       "      <td>bir mesaj, bir telefon, bir sürpriz, bir fare,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bu</td>\n",
       "      <td>bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...</td>\n",
       "      <td>bu doktor, adres bu, doktor bu, numara bu, bu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bunu</td>\n",
       "      <td>bunu da, ve bunu, bunu için, bunu bana, bunu g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>da</td>\n",
       "      <td>bu da, bana da, o da, bunu da, onu da, daha da...</td>\n",
       "      <td>motor da, pasaportumu da, doktor da, şanslı da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daha</td>\n",
       "      <td>daha değil, bir daha, daha çok, daha var, daha...</td>\n",
       "      <td>daha komik, daha konforlu, daha klas, daha nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de</td>\n",
       "      <td>ben de, sen de, seni de, bir de, evet de, beni...</td>\n",
       "      <td>ceketini de, patates de, polis de, polise de, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>değil</td>\n",
       "      <td>değil mi, hayır değil, daha değil, ben değil, ...</td>\n",
       "      <td>numara değil, sürpriz değil, doktor değil, beb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>evet</td>\n",
       "      <td>evet var, evet ama, evet o, evet mi, evet ben,...</td>\n",
       "      <td>evet ekselansları, evet pardon, evet komik, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gibi</td>\n",
       "      <td>ne gibi, şey gibi, gibi mi, yok gibi, var gibi...</td>\n",
       "      <td>randevu gibi, müzik gibi, fare gibi, televizyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hayır</td>\n",
       "      <td>hayır değil, hayır mı, hayır yok, hayır ben, y...</td>\n",
       "      <td>hayır şerif, hayır bebek, hayır pardon, hayır ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>için</td>\n",
       "      <td>ne için, şey için, bunu için, yok için</td>\n",
       "      <td>prens için, film için, onur için, bisiklet içi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kadar</td>\n",
       "      <td>ne kadar, bu kadar, o kadar, kadar mı</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mi</td>\n",
       "      <td>değil mi, ben mi, sen mi, evet mi, beni mi, bi...</td>\n",
       "      <td>kanser mi, fare mi, müzik mi, prenses mi, test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mı</td>\n",
       "      <td>hayır mı, bana mı, var mı, daha mı, kadar mı, ...</td>\n",
       "      <td>şantaj mı, fotoğraf mı, okulda mı, çikolata mı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne var, ne için, bu ne, ne kadar, ne gibi, o n...</td>\n",
       "      <td>ne sürpriz, pardon ne, ne romantik, ne listesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>o</td>\n",
       "      <td>bu o, o ne, o kadar, evet o, ne o, o değil, am...</td>\n",
       "      <td>o telefonda, o psikopat, o şoför, o duşta, o m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>onu</td>\n",
       "      <td>onu da, ve onu, onu bana, onu var, onu bunu</td>\n",
       "      <td>onu tart, tart onu, onu kurdum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sen</td>\n",
       "      <td>sen de, sen mi, ve sen, evet sen, sen ne, sen ...</td>\n",
       "      <td>sen ajansın, bar sen, sen puding, bisikleti se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>seni</td>\n",
       "      <td>seni de, seni mi, ve seni, seni beni, beni seni</td>\n",
       "      <td>seni psikopat, seni fare, seni barbar, defol s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>var</td>\n",
       "      <td>ne var, evet var, var mı, hayır var, çok var, ...</td>\n",
       "      <td>astımım var, parti var, potansiyeli var, bilet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ve</td>\n",
       "      <td>ve sen, ve ben, ve bu, ve bunu, ve bir, ve de,...</td>\n",
       "      <td>ve doktor, ve banyo, ve polis, ve şampanya, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yok</td>\n",
       "      <td>hayır yok, yok hayır, ama yok, daha yok, çok y...</td>\n",
       "      <td>telefonum yok, planım yok, müzik yok, mesaj yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>çok</td>\n",
       "      <td>bu çok, çok değil, daha çok, sen çok, çok şey,...</td>\n",
       "      <td>çok normal, çok pardon, çok şanslı, çok klas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>şey</td>\n",
       "      <td>şey ben, şey evet, evet şey, ben şey, bir şey,...</td>\n",
       "      <td>şey duydum, şey şef, şey disket, sempatik şey,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word                                            twogram  \\\n",
       "0     ama  evet ama, ama ben, ama ne, ama bu, ama sen, ha...   \n",
       "1    bana  bana mı, bana da, bana değil, ve bana, bana bi...   \n",
       "2     ben  ben de, ben mi, hayır ben, ama ben, ben değil,...   \n",
       "3    beni  beni mi, beni de, beni değil, ve beni, beni ço...   \n",
       "4     bir  bir daha, bu bir, bir şey, bir de, bir mi, ben...   \n",
       "5      bu  bu ne, bu o, bu kadar, ne bu, ama bu, bu da, b...   \n",
       "6    bunu  bunu da, ve bunu, bunu için, bunu bana, bunu g...   \n",
       "7      da  bu da, bana da, o da, bunu da, onu da, daha da...   \n",
       "8    daha  daha değil, bir daha, daha çok, daha var, daha...   \n",
       "9      de  ben de, sen de, seni de, bir de, evet de, beni...   \n",
       "10  değil  değil mi, hayır değil, daha değil, ben değil, ...   \n",
       "11   evet  evet var, evet ama, evet o, evet mi, evet ben,...   \n",
       "12   gibi  ne gibi, şey gibi, gibi mi, yok gibi, var gibi...   \n",
       "13  hayır  hayır değil, hayır mı, hayır yok, hayır ben, y...   \n",
       "14   için             ne için, şey için, bunu için, yok için   \n",
       "15  kadar              ne kadar, bu kadar, o kadar, kadar mı   \n",
       "16     mi  değil mi, ben mi, sen mi, evet mi, beni mi, bi...   \n",
       "17     mı  hayır mı, bana mı, var mı, daha mı, kadar mı, ...   \n",
       "18     ne  ne var, ne için, bu ne, ne kadar, ne gibi, o n...   \n",
       "19      o  bu o, o ne, o kadar, evet o, ne o, o değil, am...   \n",
       "20    onu        onu da, ve onu, onu bana, onu var, onu bunu   \n",
       "21    sen  sen de, sen mi, ve sen, evet sen, sen ne, sen ...   \n",
       "22   seni    seni de, seni mi, ve seni, seni beni, beni seni   \n",
       "23    var  ne var, evet var, var mı, hayır var, çok var, ...   \n",
       "24     ve  ve sen, ve ben, ve bu, ve bunu, ve bir, ve de,...   \n",
       "25    yok  hayır yok, yok hayır, ama yok, daha yok, çok y...   \n",
       "26    çok  bu çok, çok değil, daha çok, sen çok, çok şey,...   \n",
       "27    şey  şey ben, şey evet, evet şey, ben şey, bir şey,...   \n",
       "\n",
       "                                  twogram_pair_french  \n",
       "0   ama general, ama amatörler, ama madam, duydum ...  \n",
       "1   bana spesiyal, bana hamburger, bana vanilyalı,...  \n",
       "2   ben patronum, ben bekarım, ben doktor, bazen b...  \n",
       "3   çarp beni, gazla beni, beni ispiyonladı, mesaj...  \n",
       "4   bir mesaj, bir telefon, bir sürpriz, bir fare,...  \n",
       "5   bu doktor, adres bu, doktor bu, numara bu, bu ...  \n",
       "6                                                 NaN  \n",
       "7   motor da, pasaportumu da, doktor da, şanslı da...  \n",
       "8   daha komik, daha konforlu, daha klas, daha nor...  \n",
       "9   ceketini de, patates de, polis de, polise de, ...  \n",
       "10  numara değil, sürpriz değil, doktor değil, beb...  \n",
       "11  evet ekselansları, evet pardon, evet komik, ba...  \n",
       "12  randevu gibi, müzik gibi, fare gibi, televizyo...  \n",
       "13  hayır şerif, hayır bebek, hayır pardon, hayır ...  \n",
       "14  prens için, film için, onur için, bisiklet içi...  \n",
       "15                                                NaN  \n",
       "16  kanser mi, fare mi, müzik mi, prenses mi, test...  \n",
       "17  şantaj mı, fotoğraf mı, okulda mı, çikolata mı...  \n",
       "18  ne sürpriz, pardon ne, ne romantik, ne listesi...  \n",
       "19  o telefonda, o psikopat, o şoför, o duşta, o m...  \n",
       "20                     onu tart, tart onu, onu kurdum  \n",
       "21  sen ajansın, bar sen, sen puding, bisikleti se...  \n",
       "22  seni psikopat, seni fare, seni barbar, defol s...  \n",
       "23  astımım var, parti var, potansiyeli var, bilet...  \n",
       "24  ve doktor, ve banyo, ve polis, ve şampanya, ve...  \n",
       "25  telefonum yok, planım yok, müzik yok, mesaj yo...  \n",
       "26  çok normal, çok pardon, çok şanslı, çok klas, ...  \n",
       "27  şey duydum, şey şef, şey disket, sempatik şey,...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_order_join_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_order_join_11.to_excel(writer2, sheet_name='Word_Part11', index=False)\n",
    "df_word_order_join_12.to_excel(writer2, sheet_name='Word_Part12', index=False)\n",
    "df_word_order_join_13.to_excel(writer2, sheet_name='Word_Part13', index=False)\n",
    "df_word_order_join_14.to_excel(writer2, sheet_name='Word_Part14', index=False)\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer2 = pd.ExcelWriter(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Join_Result_Without_Frequency.xlsx\", engine='xlsxwriter')\n",
    "    for i in range(1, (condition1_total_part_num+1)):        \n",
    "        if condition1_dependency:\n",
    "            df_part_var = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{int(condition1_word_limit/condition1_total_part_num)}_Result{i}.xlsx\")\n",
    "            df_part_var_order = word_in_twogram(df_part_var, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "            df_part_var_order_join = df_part_var_order.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "            df_part_var_order_join.to_excel(writer2, sheet_name=f'Word_Part1{i}', index=False)          \n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_part_var2 = pd.read_excel(f\"{lang_folder}_{lang_pair}_{word_limit}_Word_Step_{step_num}_Result1.xlsx\")\n",
    "df_word_order_21 = word_in_twogram(df_part_var2, \"word\", f\"twogram\")\n",
    "df_word_order_212 = word_in_twogram(df_part_var2, \"word\", f\"twogram_pair_{lang_pair.lower()}\")\n",
    "df_word_order_join_211 = df_word_order_21.groupby([\"word\"])[\"twogram\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_212 = df_word_order_212.groupby([\"word\"])[f\"twogram_pair_{lang_pair.lower()}\"].apply(\", \".join).reset_index()\n",
    "df_word_order_join_21 = pd.merge(df_word_order_join_211, df_word_order_join_212, how=\"outer\", on=\"word\")\n",
    "df_word_order_join_21.to_excel(writer2, sheet_name='Word_Part21', index=False)        \n",
    "writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_limit}_Word_*.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Deployment/Result/3-Adjust Word Level/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
