{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel File Columns Value To Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def excel_to_text(excel_file, excel_column, text_file_name): # (\"Spark_Sentence.xlsx\", \"sentence\", \"sentence_text\")\n",
    "    '''\n",
    "    excel_to_text(excel_file, excel_column, text_file_name) excel_file is data file, excel_column is converting data column\\n\n",
    "    text_file_name is output file name to local path. \n",
    "    '''\n",
    "    df = pd.read_excel(excel_file)\n",
    "    word_list = df[excel_column].to_list()\n",
    "    text_result = \" \".join(word_list)\n",
    "    with open(text_file_name, \"w\", encoding=\"utf8\") as file:\n",
    "        file.write(text_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N Gram From DataFrame Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "\n",
    "df_sent = pd.read_csv(\"....csv\") # assume include 'sentence' column\n",
    "\n",
    "def n_gram_sentence(n, n_gram_type): # (3, \"Threegram\")\n",
    "    n = n\n",
    "    n_gram_list = [] \n",
    "    n_gram_freq_list = []\n",
    "    count_index = 0\n",
    "    for i in df_sent.sentence: # df_sent.sentence variable\n",
    "        try:\n",
    "            n_gram = ngrams(i.split(),n)\n",
    "            for j in n_gram:\n",
    "                j = \" \".join(j)\n",
    "                freq = df_sent.iloc[count_index, 1] # count_index for row and 1 for frequeny columns\n",
    "                n_gram_list.append(j)\n",
    "                n_gram_freq_list.append(freq)\n",
    "        except:\n",
    "            pass\n",
    "        count_index += 1  \n",
    "\n",
    "    df_result = pd.DataFrame([n_gram_list, n_gram_freq_list]).transpose()\n",
    "    df_result.rename(columns={0:f\"{n_gram_type.lower()}\",1:\"frequency\"}, inplace=True)\n",
    "\n",
    "    df_result_sort = df_result.groupby(f\"{n_gram_type.lower()}\")[\"frequency\"].sum().sort_values(ascending=False)\n",
    "    df_n_gram = pd.DataFrame(df_result_sort)\n",
    "    df_n_gram.reset_index(inplace=True)\n",
    "\n",
    "    df_n_gram.to_excel(f\"{n_gram_type.capitalize()}_From_Sentence.xlsx\", sheet_name=f'{n_gram_type.capitalize()}', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelarate Python Def Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from functools import cache # 1\n",
    "\n",
    "#from functools import lru_cache # 2\n",
    "\n",
    "#import ray # 3\n",
    "#ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache # 1\n",
    "#@lru_cache(maxsize=10) # 2\n",
    "#@ray.remote\n",
    "def fib(n):\n",
    "    if n<=1 :\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "start = time.time()\n",
    "result = fib(35)\n",
    "end = time.time()\n",
    "\n",
    "print(result)\n",
    "print(f\"It took {end -start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Library Version And Upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install regex --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df, column_list, set_condition=False): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        if set_condition:\n",
    "            var_list = set(df[f\"{i}\"].dropna().tolist())\n",
    "        else:\n",
    "            var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    df_word_count.sort_values(\"word_count\", ascending=False, inplace=True)\n",
    "    df_word_count.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
