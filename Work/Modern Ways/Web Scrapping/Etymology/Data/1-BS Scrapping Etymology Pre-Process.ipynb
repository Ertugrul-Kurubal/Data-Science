{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etymology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to web scrapping and etymology data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from json2html import *\n",
    "import re\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib import parse\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_folder = \"Turkish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etymologeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/Word/Merge/Word_Merge2.xlsx\")\n",
    "#df_word = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Result/Word/Merge/Word_Merge2.csv\")\n",
    "df_word = df_word.head(10000)\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_lemma = []\n",
    "#for word in df_word[\"word\"]:\n",
    "#    word_lemma.append(WordNetLemmatizer().lemmatize(word))\n",
    "#    word_unique = set(word_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(word_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(word_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word[\"word\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "#for i in word_unique:\n",
    "for i in word_list:\n",
    "    try:\n",
    "        response = requests.get(f\"https://etymologeek.com/search/all/{i}\")\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        word = soup.find('tbody', attrs={\"id\":\"tb\"})\n",
    "        dict_word = word.findAll('td', attrs={\"data-th\":\"Dic. entry\"})\n",
    "        lang = word.findAll('td', attrs={\"data-th\":\"Language\"})\n",
    "        definition = word.findAll('td', attrs={\"data-th\":\"Definition\"})\n",
    "        a_href = word.findAll('td', attrs={\"data-th\":\"Dic. entry\"})\n",
    "        iter_values = zip(dict_word, lang, definition, a_href)\n",
    "        for a, b, c, d in iter_values:\n",
    "            var1 = a.get_text()\n",
    "            var2 = b.get_text()  # string\n",
    "            var3 = c.get_text()  # string\n",
    "            var4 = d.find('a').get('href')\n",
    "            var5 = f\"https://etymologeek.com{var4}\"\n",
    "            result_list.append([i, var1, var2, var3, var5])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_result = pd.DataFrame(result_list)\n",
    "df_result.rename(columns={0:\"search_word\", 1:\"dict_entry\", 2:\"language\", 3:\"definition\", 4:\"href\"}, inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel(f\"{lang_folder.capitalize()}_Etymologeek_Main_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping Additional Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_word = pd.read_excel(f\"{lang_folder.capitalize()}_Etymologeek_Main_Result.xlsx\")\n",
    "df_main_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_word.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_word.language.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_word = df_main_word[\"search_word\"].to_list()\n",
    "dict_entry_main = df_main_word[\"dict_entry\"].to_list()\n",
    "language_main = df_main_word[\"language\"].to_list()\n",
    "definition_main = df_main_word[\"definition\"].to_list()\t\n",
    "href_url = df_main_word[\"href\"].to_list()\n",
    "main_iter_values = zip(search_word, dict_entry_main, language_main, definition_main, href_url)\n",
    "result_list2 = []\n",
    "for search, dict_ent, lang_main, def_main, href in main_iter_values:\n",
    "    try:\n",
    "        response = requests.get(f\"{href}\")\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        word = soup.find('tbody', attrs={\"id\":\"tb\"})\n",
    "        dict_entry = word.findAll('td', attrs={\"data-th\":\"Dic. entry\"})\n",
    "        lang = word.findAll('td', attrs={\"data-th\":\"Language\"})\n",
    "        definition = word.findAll('td', attrs={\"data-th\":\"Definition\"})\n",
    "        iter_values = zip(dict_entry, lang, definition)\n",
    "        for a, b, c in iter_values:\n",
    "            var1 = a.get_text()\n",
    "            var2 = b.get_text()\n",
    "            var3 = c.get_text()\n",
    "            result_list2.append([search, dict_ent, lang_main, def_main, var1, var2, var3])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_result2 = pd.DataFrame(result_list2)\n",
    "df_result2.rename(columns={0:\"search_word\", 1:\"dict_entry_main\", 2:\"language_main\", 3:\"definition_main\", 4:\"dict_entry\", 5:\"language\", 6:\"definition\"}, inplace=True)\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.language_main = df_result2.language_main.apply(lambda x: x.strip())\n",
    "df_result2.language = df_result2.language.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.to_excel(f\"{lang_folder.capitalize()}_Etymologeek_Main_And_Additional_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github Data Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_github = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology.csv\")\n",
    "df_github"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_github.loc[:,[\"lang\",\"term\",\"reltype\",\"related_lang\",\"related_term\"]]\n",
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.drop_duplicates(inplace=True)\n",
    "df_select.dropna(inplace=True)\n",
    "df_select.reset_index(drop=True, inplace=True)\n",
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.to_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select2 = df_github.loc[:,[\"term_id\",\"lang\",\"term\",\"reltype\",\"related_term_id\",\"related_lang\",\"related_term\"]]\n",
    "df_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select2.drop_duplicates(inplace=True)\n",
    "df_select2.dropna(inplace=True)\n",
    "df_select2.reset_index(drop=True, inplace=True)\n",
    "df_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select2.to_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_clean2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_clean.csv\")\n",
    "df_clean = df_clean.head(150000)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"lang\"] = df_clean[\"lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean[\"lang\"] = df_clean[\"lang\"].apply(lambda x: x.strip())\n",
    "df_clean[\"term\"] = df_clean[\"term\"].apply(lambda x: x.lower())\n",
    "df_clean[\"term\"] = df_clean[\"term\"].apply(lambda x: x.strip())\n",
    "df_clean[\"related_lang\"] = df_clean[\"related_lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean[\"related_lang\"] = df_clean[\"related_lang\"].apply(lambda x: x.strip())\n",
    "df_clean[\"related_term\"] = df_clean[\"related_term\"].apply(lambda x: x.lower())\n",
    "df_clean[\"related_term\"] = df_clean[\"related_term\"].apply(lambda x: x.strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(len(df_clean)):\n",
    "    lang_11 = df_clean.loc[i,\"lang\"]\n",
    "    term_11 = df_clean.loc[i,\"term\"]\n",
    "    reltype_11\t= df_clean.loc[i,\"reltype\"]\n",
    "    lang_12 = df_clean.loc[i,\"related_lang\"]\n",
    "    term_12 = df_clean.loc[i,\"related_term\"]\n",
    "    \n",
    "    try:\n",
    "        df_var = df_clean[(df_clean[\"term\"] == f\"{term_12}\")]\n",
    "        df_var.reset_index(drop=True, inplace=True)\n",
    "        j = 0\n",
    "        while j < len(df_var):                    \n",
    "            lang_21 = df_var.loc[j,\"lang\"]\n",
    "            term_21 = df_var.loc[j,\"term\"]\n",
    "            #reltype_21\t= df_var.loc[j,\"reltype\"]\n",
    "            lang_22 = df_var.loc[j,\"related_lang\"]\n",
    "            term_22 = df_var.loc[j,\"related_term\"]\n",
    "            if ((f\"{lang_21}\" == f\"{lang_12}\") & (f\"{term_21}\" == f\"{term_12}\")):\n",
    "                result_list.append([lang_11,term_11,reltype_11,lang_22,term_22])\n",
    "            else:\n",
    "                result_list.append([lang_11,term_11,reltype_11,lang_12,term_12])\n",
    "            \n",
    "            j+=1\n",
    "    except:\n",
    "        result_list.append([lang_11,term_11,reltype_11,lang_12,term_12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(result_list, columns=[\"lang\",\"term\",\"reltype\",\"related_lang\",\"related_term\"])\n",
    "df_result.drop_duplicates(inplace=True)\n",
    "df_result.reset_index(drop=True,inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_csv(\"etymology_cross_check_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-Way\n",
    "df_clean = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_clean.csv\")\n",
    "df_clean = df_clean.head(150000)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"lang\"] = df_clean[\"lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean[\"lang\"] = df_clean[\"lang\"].apply(lambda x: x.strip())\n",
    "df_clean[\"term\"] = df_clean[\"term\"].apply(lambda x: x.lower())\n",
    "df_clean[\"term\"] = df_clean[\"term\"].apply(lambda x: x.strip())\n",
    "df_clean[\"related_lang\"] = df_clean[\"related_lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean[\"related_lang\"] = df_clean[\"related_lang\"].apply(lambda x: x.strip())\n",
    "df_clean[\"related_term\"] = df_clean[\"related_term\"].apply(lambda x: x.lower())\n",
    "df_clean[\"related_term\"] = df_clean[\"related_term\"].apply(lambda x: x.strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = range(len(df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from multiprocessing import Process, Manager, Pool, Queue\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist = manager.list()\n",
    "\n",
    "def cross_check(i):\n",
    "    lang_11 = df_clean.loc[i,\"lang\"]\n",
    "    term_11 = df_clean.loc[i,\"term\"]\n",
    "    reltype_11\t= df_clean.loc[i,\"reltype\"]\n",
    "    lang_12 = df_clean.loc[i,\"related_lang\"]\n",
    "    term_12 = df_clean.loc[i,\"related_term\"]\n",
    "    \n",
    "    try:\n",
    "        df_var = df_clean[(df_clean[\"term\"] == f\"{term_12}\")]\n",
    "        df_var.reset_index(drop=True, inplace=True)\n",
    "        j = 0\n",
    "        while j < len(df_var):                    \n",
    "            lang_21 = df_var.loc[j,\"lang\"]\n",
    "            term_21 = df_var.loc[j,\"term\"]\n",
    "            reltype_21\t= df_var.loc[j,\"reltype\"]\n",
    "            lang_22 = df_var.loc[j,\"related_lang\"]\n",
    "            term_22 = df_var.loc[j,\"related_term\"]\n",
    "            if ((f\"{lang_21}\" == f\"{lang_12}\") & (f\"{term_21}\" == f\"{term_12}\")):\n",
    "                resultlist.append([lang_11,term_11,reltype_21,lang_22,term_22])\n",
    "            else:\n",
    "                resultlist.append([lang_11,term_11,reltype_11,lang_12,term_12])\n",
    "            \n",
    "            j+=1\n",
    "    except:\n",
    "        resultlist.append([lang_11,term_11,reltype_11,lang_12,term_12])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(cross_check, d_list) # string_word liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = list(resultlist)\n",
    "df_result = pd.DataFrame(result_list, columns=[\"lang\",\"term\",\"reltype\",\"related_lang\",\"related_term\"])\n",
    "df_result.drop_duplicates(inplace=True)\n",
    "df_result.reset_index(drop=True,inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_csv(\"etymology_cross_check.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_excel(\"etymology_cross_check.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Way (Master)\n",
    "df_clean2 = pd.read_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_clean2.csv\")\n",
    "df_clean2 = df_clean2.head(150000)\n",
    "df_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2[\"lang\"] = df_clean2[\"lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean2[\"lang\"] = df_clean2[\"lang\"].apply(lambda x: x.strip())\n",
    "df_clean2[\"term_id\"] = df_clean2[\"term_id\"].apply(lambda x: x.strip())\n",
    "df_clean2[\"related_lang\"] = df_clean2[\"related_lang\"].apply(lambda x: x.capitalize())\n",
    "df_clean2[\"related_lang\"] = df_clean2[\"related_lang\"].apply(lambda x: x.strip())\n",
    "df_clean2[\"related_term_id\"] = df_clean2[\"related_term_id\"].apply(lambda x: x.strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list2 = range(len(df_clean2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultlist2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from multiprocessing import Process, Manager, Pool, Queue\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist2 = manager.list()\n",
    "\n",
    "def cross_check(i):\n",
    "    term_id_11 = df_clean2.loc[i,\"term_id\"]\n",
    "    lang_11 = df_clean2.loc[i,\"lang\"]\n",
    "    term_11 = df_clean2.loc[i,\"term\"]\n",
    "    reltype_11\t= df_clean2.loc[i,\"reltype\"]\n",
    "    term_id_12 = df_clean2.loc[i,\"related_term_id\"]\n",
    "    lang_12 = df_clean2.loc[i,\"related_lang\"]\n",
    "    term_12 = df_clean2.loc[i,\"related_term\"]\n",
    "    \n",
    "    try:\n",
    "        df_var = df_clean2[(df_clean2[\"term_id\"] == f\"{term_id_12}\")]\n",
    "        df_var.reset_index(drop=True, inplace=True)\n",
    "        j = 0\n",
    "        while j < len(df_var):\n",
    "            term_id_21 = df_var.loc[j,\"term_id\"]\n",
    "            #lang_21 = df_var.loc[j,\"lang\"]\n",
    "            #term_21 = df_var.loc[j,\"term\"]\n",
    "            reltype_21\t= df_var.loc[j,\"reltype\"]\n",
    "            term_id_22 = df_var.loc[j,\"related_term_id\"]\n",
    "            lang_22 = df_var.loc[j,\"related_lang\"]\n",
    "            term_22 = df_var.loc[j,\"related_term\"]\n",
    "            if (f\"{term_id_21}\" == f\"{term_id_12}\"):\n",
    "                resultlist2.append([term_id_11,lang_11,term_11,reltype_21,term_id_22,lang_22,term_22])\n",
    "            else:\n",
    "                resultlist2.append([term_id_11,lang_11,term_11,reltype_11,term_id_12,lang_12,term_12])\n",
    "            \n",
    "            j+=1\n",
    "    except:\n",
    "        resultlist2.append([term_id_11,lang_11,term_11,reltype_11,term_id_12,lang_12,term_12])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(cross_check, d_list2) # string_word liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list2 = list(resultlist2)\n",
    "df_result2 = pd.DataFrame(result_list2, columns=[\"term_id\",\"lang\",\"term\",\"reltype\",\"related_term_id\",\"related_lang\",\"related_term\"])\n",
    "df_result2.drop_duplicates(inplace=True)\n",
    "df_result2.reset_index(drop=True,inplace=True)\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.to_csv(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/etymology_cross_check2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etimoloji Sözlük"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_folder = \"Turkish\"\n",
    "start_num = 0\n",
    "end_num = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fikret</td>\n",
       "      <td>12101580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>ekipmanlar</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>şanslılar</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>aksanıyla</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>yargılanacak</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>tepkisini</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  frequency\n",
       "0               bir   18835735\n",
       "1            fikret   12101580\n",
       "2                bu   11062659\n",
       "3                ne    8025880\n",
       "4                ve    7766036\n",
       "...             ...        ...\n",
       "39995    ekipmanlar        974\n",
       "39996     şanslılar        974\n",
       "39997     aksanıyla        974\n",
       "39998  yargılanacak        974\n",
       "39999     tepkisini        974\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/Word/Merge/Word_Merge2.xlsx\")\n",
    "df_word = df_word.iloc[start_num:end_num,]\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word[\"word\"].tolist()\n",
    "#word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "      <th>lang</th>\n",
       "      <th>word_root</th>\n",
       "      <th>koken</th>\n",
       "      <th>lang_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>Bir</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "      <td>bir</td>\n",
       "      <td>Eski Türkçe bir sözcüğünden evrilmiştir.</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ve</td>\n",
       "      <td>Ve</td>\n",
       "      <td>Arapça</td>\n",
       "      <td>wa</td>\n",
       "      <td>Arapça wa و z \"ve (bağlaç), - adına (edat)\" f...</td>\n",
       "      <td>Arapça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>için</td>\n",
       "      <td>İçin</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "      <td>üçün</td>\n",
       "      <td>Eski Türkçe üçün \"nedensellik edatı\" sözcüğün...</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>çok</td>\n",
       "      <td>Çok</td>\n",
       "      <td>Ana Türkçe</td>\n",
       "      <td>*çaw-</td>\n",
       "      <td>Ana Türkçe yazılı örneği bulunmayan *çaw- \"ba...</td>\n",
       "      <td>Ana Türkçe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ama</td>\n",
       "      <td>Ama</td>\n",
       "      <td>Arapça</td>\n",
       "      <td>ammā</td>\n",
       "      <td>Arapça ammā أمّا z \"gelgelelim, maamafih (bağ...</td>\n",
       "      <td>Arapça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>masör</td>\n",
       "      <td>Masör</td>\n",
       "      <td>Fransızca\\r</td>\n",
       "      <td>masseur</td>\n",
       "      <td>Fransızca\\r masseur \"masaj yapan\" sözcüğünden...</td>\n",
       "      <td>Fransızca\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>baraka</td>\n",
       "      <td>Baraka</td>\n",
       "      <td>İtalyanca\\r</td>\n",
       "      <td>baracca</td>\n",
       "      <td>İtalyanca\\r baracca \"kulübe, derme çatma yapı...</td>\n",
       "      <td>İtalyanca\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>oğlak</td>\n",
       "      <td>Oğlak</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "      <td>ogul</td>\n",
       "      <td>Eski Türkçe ogul sözcüğünden +Ak sonekiyle tü...</td>\n",
       "      <td>Eski Türkçe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>boykot</td>\n",
       "      <td>Boykot</td>\n",
       "      <td>İngilizce\\r</td>\n",
       "      <td>boycott</td>\n",
       "      <td>İngilizce\\r boycott \"bir mal veya hizmeti sat...</td>\n",
       "      <td>İngilizce\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>ermek</td>\n",
       "      <td>Ermek</td>\n",
       "      <td>Arapça</td>\n",
       "      <td>mlw</td>\n",
       "      <td>Arapça mlw kökünden gelen imlāˀ إملاء z \"dikt...</td>\n",
       "      <td>Aramice/Süryanice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3663 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word    word         lang word_root  \\\n",
       "0            bir     Bir  Eski Türkçe       bir   \n",
       "1             ve      Ve       Arapça        wa   \n",
       "2           için    İçin  Eski Türkçe      üçün   \n",
       "3            çok     Çok   Ana Türkçe     *çaw-   \n",
       "4            ama     Ama       Arapça      ammā   \n",
       "...          ...     ...          ...       ...   \n",
       "3658       masör   Masör  Fransızca\\r   masseur   \n",
       "3659      baraka  Baraka  İtalyanca\\r   baracca   \n",
       "3660       oğlak   Oğlak  Eski Türkçe      ogul   \n",
       "3661      boykot  Boykot  İngilizce\\r   boycott   \n",
       "3662       ermek   Ermek       Arapça       mlw   \n",
       "\n",
       "                                                  koken          lang_root  \n",
       "0             Eski Türkçe bir sözcüğünden evrilmiştir.         Eski Türkçe  \n",
       "1      Arapça wa و z \"ve (bağlaç), - adına (edat)\" f...             Arapça  \n",
       "2      Eski Türkçe üçün \"nedensellik edatı\" sözcüğün...        Eski Türkçe  \n",
       "3      Ana Türkçe yazılı örneği bulunmayan *çaw- \"ba...         Ana Türkçe  \n",
       "4      Arapça ammā أمّا z \"gelgelelim, maamafih (bağ...             Arapça  \n",
       "...                                                 ...                ...  \n",
       "3658   Fransızca\\r masseur \"masaj yapan\" sözcüğünden...        Fransızca\\r  \n",
       "3659   İtalyanca\\r baracca \"kulübe, derme çatma yapı...        İtalyanca\\r  \n",
       "3660   Eski Türkçe ogul sözcüğünden +Ak sonekiyle tü...        Eski Türkçe  \n",
       "3661   İngilizce\\r boycott \"bir mal veya hizmeti sat...        İngilizce\\r  \n",
       "3662   Arapça mlw kökünden gelen imlāˀ إملاء z \"dikt...  Aramice/Süryanice  \n",
       "\n",
       "[3663 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list = []\n",
    "#for i in word_unique:\n",
    "for i in word_list:\n",
    "    try:\n",
    "        response = requests.get(f\"https://www.etimolojiturkce.com/kelime/{i}\")\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        data = soup.find('div', attrs={\"class\":\"holder\"})\n",
    "        data_main = data.find('div', attrs={\"class\":\"main\"})\n",
    "        word = data_main.find('h1').get_text()        \n",
    "        all_paraf = data_main.find_all('p')        \n",
    "        koken = all_paraf[3].get_text()\n",
    "        span = all_paraf[3].span        \n",
    "        all_b = span.find_all('b')\n",
    "        all_i = span.find_all('i')  # option\n",
    "        word_root = all_i[0].get_text()  # option         \n",
    "        lang = all_b[0].get_text()        \n",
    "        lang_root = all_b[-1].get_text()\n",
    "\n",
    "        result_list.append([i, word, lang, word_root, koken, lang_root])  # option\n",
    "        #result_list.append([i, word, lang, koken, lang_root])    \n",
    "                \n",
    "        #iter_values = zip(word3, koken2)\n",
    "        #for a, b in iter_values:\n",
    "        #    var1 = a  # span\n",
    "        #    var2 = b  # string\n",
    "        #   \n",
    "        #    result_list.append([i, var1, var2])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_result = pd.DataFrame(result_list)\n",
    "df_result.rename(columns={0:\"search_word\", 1:\"word\", 2:\"lang\", 3:\"word_root\", 4:\"koken\", 5:\"lang_root\"}, inplace=True)  # option\n",
    "#df_result.rename(columns={0:\"search_word\", 1:\"word\", 2:\"lang\", 3:\"koken\", 4:\"lang_root\"}, inplace=True) \n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"word\"] = df_result[\"word\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(x):\n",
    "    try:\n",
    "        x = x.replace(\"_x000D_\",\"\")\n",
    "        x = x.replace(\"\\n\",\"\")\n",
    "        x = x.replace(\"\\r\",\"\")\n",
    "        x = x.strip()\n",
    "    except:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"lang\"] = df_result[\"lang\"].apply(lambda x: remove(x))\n",
    "df_result[\"koken\"] = df_result[\"koken\"].apply(lambda x: remove(x))\n",
    "df_result[\"lang_root\"] = df_result[\"lang_root\"].apply(lambda x: remove(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_excel(\"Sample.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/{lang_folder.capitalize()}_{start_num}-{end_num}_Word_Etimoloji_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nisanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_plus_nisanyan = pd.read_excel(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/Nisanyan Words Contain Plus.xlsx\")\n",
    "df_word_plus_nisanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(x):\n",
    "    try:\n",
    "        x = x.replace(\"\\n\",\"\")\n",
    "        x = x.replace(\"\\r\",\"\")\n",
    "        x = x.strip()\n",
    "    except:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_plus_nisanyan[\"term\"] = df_word_plus_nisanyan[\"term\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan[\"related_lang\"] = df_word_plus_nisanyan[\"related_lang\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan[\"related_term\"] = df_word_plus_nisanyan[\"related_term\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Result/Word/Merge/Word_Merge2.xlsx\")\n",
    "#df_word = df_word.head(10000)\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_term_list = [\"+ark\",\"+gen\",\"+gon\",\"di+\",\"+men\",\"deka+\",\"desi+\",\"bis+\",\"end(o)+\",\"fil(o)+\",\"mili+\",\"ö+\",\"or(o)+\",\"pan(to)+\",\"poli+\",\"port+\",\"post+\",\"vaz(o)+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_plus_term = set(df_word_plus_nisanyan.loc[:,\"term\"].values.tolist())\n",
    "set_disable_term = set(disable_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_term_diff = pd.DataFrame(set_plus_term.difference(set_disable_term), columns=[\"term\"])\n",
    "df_term_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_term_diff.loc[:,\"term\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_result = pd.DataFrame()\n",
    "for i in word_list:\n",
    "    if i.startswith(\"+\"):\n",
    "        j = i.lstrip(\"+\")\n",
    "        word_in_video = df_word[df_word.word.str.contains(fr\"{j}(?:$)\", na=True)]  # string+ext=> word\n",
    "        word_in_video.insert(0,\"term\",i)\n",
    "    elif i.endswith(\"+\"):\n",
    "        j = i.rstrip(\"+\")\n",
    "        word_in_video = df_word[df_word.word.str.contains(fr\"(?:^){j}\", na=True)]  # ext+string=> word\n",
    "        word_in_video.insert(0,\"term\",i)\n",
    "    else:\n",
    "        pass\n",
    "    #word_in_video.insert(0,\"word_ext\",i)\n",
    "    df_word_result = pd.concat([df_word_result,word_in_video], axis=0)\n",
    "#df_word_result = df_word_result.sort_values(by=\"frequency\", ascending=False)\n",
    "df_word_result.reset_index(drop=True, inplace=True)\n",
    "df_word_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge = pd.merge(df_word_result,df_word_plus_nisanyan, how=\"inner\", on=\"term\")\n",
    "df_pre_suff_nis_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge.to_excel(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/Nisanyan_Prefix_Suffix_Term_In_Word.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SparkNLP Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_lemma = pd.read_json(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/wR3tE0i-zc6Pl8revsMq4.json\")  # AWS Marketplace lemma result\n",
    "df_spark_lemma = df_spark_lemma.loc[:,[\"lem\",\"token\"]]\n",
    "df_spark_lemma.rename(columns={\"token\":\"word\"}, inplace=True)\n",
    "df_spark_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_lemma.lem.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge = pd.read_excel(\"Nisanyan_Prefix_Suffix_Term_In_Word.xlsx\")\n",
    "df_pre_suff_nis_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge = pd.merge(df_pre_suff_nis_merge,df_spark_lemma, how=\"inner\", on=\"word\")\n",
    "df_lemma_merge.drop_duplicates(inplace=True)\n",
    "df_lemma_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge.drop_duplicates(subset=\"lem\", inplace=True)\n",
    "df_lemma_merge.reset_index(drop=True, inplace=True)\n",
    "df_lemma_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge.to_excel(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/Nisanyan_Prefix_Suffix_Term_In_Word_Lemma_Process.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
