{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etymology Prefix Suffix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nişanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_plus_nisanyan = pd.read_excel(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/Nisanyan Words Contain Plus.xlsx\")\n",
    "df_word_plus_nisanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(x):\n",
    "    try:\n",
    "        x = x.replace(\"\\n\",\"\")\n",
    "        x = x.replace(\"\\r\",\"\")\n",
    "        x = x.strip()\n",
    "    except:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_plus_nisanyan[\"term\"] = df_word_plus_nisanyan[\"term\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan[\"related_lang\"] = df_word_plus_nisanyan[\"related_lang\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan[\"related_term\"] = df_word_plus_nisanyan[\"related_term\"].apply(lambda x: remove(x))\n",
    "df_word_plus_nisanyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Result/Word/Merge/Word_Merge2.xlsx\")\n",
    "#df_word = df_word.head(10000)\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_term_list = [\"+ark\",\"+gen\",\"+gon\",\"di+\",\"+men\",\"deka+\",\"desi+\",\"bis+\",\"end(o)+\",\"fil(o)+\",\"mili+\",\"ö+\",\"or(o)+\",\"pan(to)+\",\"poli+\",\"port+\",\"post+\",\"vaz(o)+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_plus_term = set(df_word_plus_nisanyan.loc[:,\"term\"].values.tolist())\n",
    "set_disable_term = set(disable_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_term_diff = pd.DataFrame(set_plus_term.difference(set_disable_term), columns=[\"term\"])\n",
    "df_term_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_term_diff.loc[:,\"term\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_result = pd.DataFrame()\n",
    "for i in word_list:\n",
    "    if i.startswith(\"+\"):\n",
    "        j = i.lstrip(\"+\")\n",
    "        word_in_video = df_word[df_word.word.str.contains(fr\"{j}(?:$)\", na=True)]  # string+ext=> word\n",
    "        word_in_video.insert(0,\"term\",i)\n",
    "    elif i.endswith(\"+\"):\n",
    "        j = i.rstrip(\"+\")\n",
    "        word_in_video = df_word[df_word.word.str.contains(fr\"(?:^){j}\", na=True)]  # ext+string=> word\n",
    "        word_in_video.insert(0,\"term\",i)\n",
    "    else:\n",
    "        pass\n",
    "    #word_in_video.insert(0,\"word_ext\",i)\n",
    "    df_word_result = pd.concat([df_word_result,word_in_video], axis=0)\n",
    "#df_word_result = df_word_result.sort_values(by=\"frequency\", ascending=False)\n",
    "df_word_result.reset_index(drop=True, inplace=True)\n",
    "df_word_result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge = pd.merge(df_word_result,df_word_plus_nisanyan, how=\"inner\", on=\"term\")\n",
    "df_pre_suff_nis_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge.to_excel(\"Nisanyan_Prefix_Suffix_Term_In_Word.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SparkNLP Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_lemma = pd.read_json(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/All/wR3tE0i-zc6Pl8revsMq4.json\")  # lemma result\n",
    "df_spark_lemma = df_spark_lemma.loc[:,[\"lem\",\"token\"]]\n",
    "df_spark_lemma.rename(columns={\"token\":\"word\"}, inplace=True)\n",
    "df_spark_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_lemma.lem.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_suff_nis_merge = pd.read_excel(\"Nisanyan_Prefix_Suffix_Term_In_Word.xlsx\")\n",
    "df_pre_suff_nis_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge = pd.merge(df_pre_suff_nis_merge,df_spark_lemma, how=\"inner\", on=\"word\")\n",
    "df_lemma_merge.drop_duplicates(inplace=True)\n",
    "df_lemma_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge.drop_duplicates(subset=\"lem\", inplace=True)\n",
    "df_lemma_merge.reset_index(drop=True, inplace=True)\n",
    "df_lemma_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma_merge.to_excel(\"Nisanyan_Prefix_Suffix_Term_In_Word_Lemma_Process.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etymology Word Prefix Suffix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# pre-suffix select\n",
    "prefix = True  # True, False\n",
    "suffix = True  # True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_prefix_suffix_word(df, df_column, word_ety_list, prefix_word=True, suffix_word=False):\n",
    "    '''\n",
    "    default parameter:\\n\n",
    "    detect_prefix_suffix_word(df, df_column, word_ety_list, prefix_word=True, suffix_word=False)\\n\n",
    "    detect_prefix_suffix_word(df, \"word\", [\"abacus\",\"aba\",\"su\"], prefix=True, suffix=True)\\n\n",
    "    df is dataframe. Each word of word_ety_list search in df_column according to prefix_word and suffix_word condition.\\n\n",
    "    prefix_word and suffix_word are not extention. they represents location of word of word_ety_list (word before or after)\n",
    "    '''    \n",
    "    df_ety_prefix_suffix_word_result = pd.DataFrame()\n",
    "    for i in word_ety_list:\n",
    "        # suffix result\n",
    "        if suffix_word:\n",
    "            word_ety_in_word = df[df[f\"{df_column}\"].str.contains(fr\"{i}(?:$)\", na=True)]  # string+ext=> word\n",
    "            word_ety_in_word.insert(0,\"search_word\",i)\n",
    "            df_ety_prefix_suffix_word_result = pd.concat([df_ety_prefix_suffix_word_result,word_ety_in_word], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        # prefix result\n",
    "        if prefix_word:\n",
    "            word_ety_in_word = df[df[f\"{df_column}\"].str.contains(fr\"(?:^){i}\", na=True)]  # ext+string=> word\n",
    "            word_ety_in_word.insert(0,\"search_word\",i)\n",
    "            df_ety_prefix_suffix_word_result = pd.concat([df_ety_prefix_suffix_word_result,word_ety_in_word], axis=0)\n",
    "        else:\n",
    "            pass    \n",
    "        \n",
    "    #df_ety_suffix_word_result = df_word_result.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_ety_prefix_suffix_word_result.drop_duplicates(inplace=True)\n",
    "    df_ety_prefix_suffix_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_ety_prefix_suffix_word_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_prefix_suffix(df, source_column, target_column):\n",
    "    '''\n",
    "    exract_prefix_suffix(df, source_column, target_column):\\n\n",
    "    exract_prefix_suffix(df, \"word_pair\", \"word\"):\\n\n",
    "    df is dataframe. word of source_column search in target_column\\n\n",
    "    and exract prefix or suffix. \n",
    "    '''\n",
    "    for i in range(len(df)):\n",
    "        source_word = df.loc[i,f\"{source_column}\"]\n",
    "        target_word = df.loc[i,f\"{target_column}\"]\n",
    "        try:\n",
    "            search_loc = re.search(fr\"{source_word}\", target_word, re.UNICODE|re.IGNORECASE)\n",
    "            search_loc_start = search_loc.span()[0]\n",
    "            search_loc_end = search_loc.span()[1]\n",
    "            if search_loc_start > 0:\n",
    "                var1= target_word[0:search_loc_start]\n",
    "                prefix_suffix = f\"{var1}+\"\n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix                \n",
    "            else:\n",
    "                var2 = target_word[search_loc_end:]\n",
    "                prefix_suffix = f\"+{var2}\" \n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix \n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}_{lang_pair.lower().capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "#df_pair = df_pair.head(200)\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ety_list = df_pair[\"dict_entry_main\"].values.tolist()\n",
    "#word_ety_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_word = detect_prefix_suffix_word(df_word_all, \"word\", word_ety_list, prefix_word=True, suffix_word=False)\n",
    "df_prefix_suffix_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix = exract_prefix_suffix(df_prefix_suffix_word, \"search_word\", \"word\")\n",
    "df_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
