{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etymology Prefix Suffix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from kneed import KneeLocator\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# pre-suffix select\n",
    "prefix = True  # True, False  word is prefix  example: prefix = True and suffix = False for Turkish word\n",
    "suffix = False # True, False  word is suffix\n",
    "\n",
    "# native word select\n",
    "word_analysis = False  # True, False  Not: True for native word analysis, False for etymological word analysis\n",
    "word_num = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix Suffix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_prefix_suffix_word(df, df_column, word_ety_list, prefix_word=True, suffix_word=False):\n",
    "    '''\n",
    "    default parameter:\\n\n",
    "    detect_prefix_suffix_word(df, df_column, word_ety_list, prefix_word=True, suffix_word=False)\\n\n",
    "    detect_prefix_suffix_word(df, \"word\", [\"abacus\",\"aba\",\"su\"], prefix=True, suffix=True)\\n\n",
    "    df is dataframe. Each word of word_ety_list search in df_column according to prefix_word and suffix_word condition.\\n\n",
    "    prefix_word and suffix_word are not extention. they represents location of word of word_ety_list (word before or after)\n",
    "    '''    \n",
    "    df_ety_prefix_suffix_word_result = pd.DataFrame()\n",
    "    for i in word_ety_list:\n",
    "        # suffix result\n",
    "        if suffix_word:\n",
    "            word_ety_in_word = df[df[f\"{df_column}\"].str.contains(fr\"{i}(?:$)\", na=True)]  # string+ext=> word\n",
    "            word_ety_in_word.insert(0,\"search_word\",i)\n",
    "            df_ety_prefix_suffix_word_result = pd.concat([df_ety_prefix_suffix_word_result,word_ety_in_word], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        # prefix result\n",
    "        if prefix_word:\n",
    "            word_ety_in_word = df[df[f\"{df_column}\"].str.contains(fr\"(?:^){i}\", na=True)]  # ext+string=> word\n",
    "            word_ety_in_word.insert(0,\"search_word\",i)\n",
    "            df_ety_prefix_suffix_word_result = pd.concat([df_ety_prefix_suffix_word_result,word_ety_in_word], axis=0)\n",
    "        else:\n",
    "            pass    \n",
    "        \n",
    "    #df_ety_suffix_word_result = df_word_result.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_ety_prefix_suffix_word_result.drop_duplicates(inplace=True)\n",
    "    df_ety_prefix_suffix_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_ety_prefix_suffix_word_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_prefix_suffix(df, source_column, target_column):\n",
    "    '''\n",
    "    exract_prefix_suffix(df, source_column, target_column):\\n\n",
    "    exract_prefix_suffix(df, \"word_pair\", \"word\"):\\n\n",
    "    df is dataframe. word of source_column search in target_column\\n\n",
    "    and exract prefix or suffix. \n",
    "    '''\n",
    "    for i in range(len(df)):\n",
    "        source_word = df.loc[i,f\"{source_column}\"]\n",
    "        target_word = df.loc[i,f\"{target_column}\"]\n",
    "        try:\n",
    "            search_loc = re.search(fr\"{source_word}\", target_word, re.UNICODE|re.IGNORECASE)\n",
    "            search_loc_start = search_loc.span()[0]\n",
    "            search_loc_end = search_loc.span()[1]\n",
    "            if search_loc_start > 0:\n",
    "                var1= target_word[0:search_loc_start]\n",
    "                prefix_suffix = f\"{var1}+\"\n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix                \n",
    "            else:\n",
    "                var2 = target_word[search_loc_end:]\n",
    "                prefix_suffix = f\"+{var2}\" \n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix \n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prefix Suffix All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988212</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988213</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988214</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988215</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988216</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "988212     karneleme          5\n",
       "988213       karnaya          5\n",
       "988214   dörtlümüzün          5\n",
       "988215  karnavalınız          5\n",
       "988216      hurmanın          5\n",
       "\n",
       "[988217 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_entry_main</th>\n",
       "      <th>english_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abluka</td>\n",
       "      <td>blockade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorbe</td>\n",
       "      <td>absorb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absürt</td>\n",
       "      <td>absurd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>açelya</td>\n",
       "      <td>azalea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>zebra</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>zikzak</td>\n",
       "      <td>zigzag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>zombi</td>\n",
       "      <td>zombie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>zooloji</td>\n",
       "      <td>zoology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>zum</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dict_entry_main english_word\n",
       "0             abaküs       abacus\n",
       "1             abluka     blockade\n",
       "2            absorbe       absorb\n",
       "3             absürt       absurd\n",
       "4             açelya       azalea\n",
       "...              ...          ...\n",
       "1773           zebra        zebra\n",
       "1774          zikzak       zigzag\n",
       "1775           zombi       zombie\n",
       "1776         zooloji      zoology\n",
       "1777             zum         zoom\n",
       "\n",
       "[1778 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if word_analysis:\n",
    "    df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "    df_pair = df_pair.head(word_num)\n",
    "    df_pair.rename(columns={\"word\":\"dict_entry_main\"}, inplace=True)\n",
    "else:\n",
    "    df_pair = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Vocabulary.xlsx\")\n",
    "df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ety_list = df_pair[\"dict_entry_main\"].values.tolist()\n",
    "#word_ety_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_word = detect_prefix_suffix_word(df_word_all, \"word\", word_ety_list, prefix_word=prefix, suffix_word=suffix)\n",
    "df_prefix_suffix_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix = exract_prefix_suffix(df_prefix_suffix_word, \"search_word\", \"word\")\n",
    "df_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_analysis:\n",
    "    df_prefix_suffix.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_num}_Word_Prefix_Suffix_All.xlsx\", index=False)\n",
    "else:\n",
    "    df_prefix_suffix.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_All.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select From Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_analysis:\n",
    "    df_prefix_suffix = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_num}_Word_Prefix_Suffix_All.xlsx\")\n",
    "else:\n",
    "    df_prefix_suffix = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_All.xlsx\")\n",
    "df_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix[\"prefix_suffix_len\"] = df_prefix_suffix[\"prefix_suffix\"].apply(lambda x: (len(x)-1))\n",
    "df_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix_mean = int(round(df_prefix_suffix[\"prefix_suffix_len\"].mean(),0))\n",
    "prefix_suffix_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_select = df_prefix_suffix[df_prefix_suffix[\"prefix_suffix\"].str.len() <= prefix_suffix_mean]\n",
    "df_prefix_suffix_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_analysis:\n",
    "    df_prefix_suffix_select.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_num}_Word_Prefix_Suffix_Select.xlsx\", index=False)\n",
    "else:\n",
    "    df_prefix_suffix_select.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Select.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select With Prefix Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_analysis:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_num}_Word_Prefix_Suffix_Select.xlsx\")\n",
    "else:\n",
    "    df_prefix_suffix_select = pd.read_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Select.xlsx\")\n",
    "df_prefix_suffix_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq = df_prefix_suffix_select[[\"prefix_suffix\"]].value_counts().reset_index()\n",
    "df_prefix_suffix_freq.rename(columns={0:\"frequency\"}, inplace=True)\n",
    "df_prefix_suffix_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix_freq_sum = df_prefix_suffix_freq.loc[:,\"frequency\"].sum()\n",
    "prefix_suffix_freq_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq[\"ratio\"] = round(((df_prefix_suffix_freq.loc[:,\"frequency\"]/prefix_suffix_freq_sum)*100),7)\n",
    "df_prefix_suffix_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq[\"cumul_ratio\"] = np.cumsum(df_prefix_suffix_freq[\"ratio\"])\n",
    "df_prefix_suffix_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix_kneedle = KneeLocator(x=df_prefix_suffix_freq.cumul_ratio.index, y=df_prefix_suffix_freq.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "prefix_suffix_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_prefix_suffix = round(prefix_suffix_kneedle.knee_y)\n",
    "knee_point_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_knee = df_prefix_suffix_freq[df_prefix_suffix_freq.cumul_ratio <= knee_point_prefix_suffix]\n",
    "df_prefix_suffix_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix_list = df_prefix_suffix_knee[\"prefix_suffix\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_prefix_suffix_list = [\"+anityi\",\"+bidir\",\"+workun\",\"+düktörlere\",\"+rysin\",\"+ein\",\"+ei\",\"+x\",\"+ren\",\"+hul\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prefix_suffix = set(prefix_suffix_list)\n",
    "set_disable_prefix_suffix = set(disable_prefix_suffix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix_custom_list = list(set_prefix_suffix.difference(set_disable_prefix_suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_custom = pd.DataFrame()\n",
    "for i in prefix_suffix_custom_list:\n",
    "    df_var = df_prefix_suffix[df_prefix_suffix[\"prefix_suffix\"] == f\"{i}\"]\n",
    "    df_prefix_suffix_custom = pd.concat([df_prefix_suffix_custom, df_var], axis=0)\n",
    "df_prefix_suffix_custom.sort_values(by=\"word\", inplace=True)\n",
    "df_prefix_suffix_custom.reset_index(drop=True, inplace=True)\n",
    "df_prefix_suffix_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequency_mean = df_prefix_suffix_custom.groupby([\"search_word\"])[[\"frequency\"]].mean()\n",
    "df_frequency_mean.reset_index(inplace=True)\n",
    "df_frequency_mean.rename(columns={\"frequency\":\"frequency_mean\"}, inplace=True)\n",
    "df_frequency_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq_mean = pd.merge(df_prefix_suffix_custom, df_frequency_mean, how=\"inner\", on=\"search_word\")\n",
    "df_prefix_suffix_freq_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq_mean_select = df_prefix_suffix_freq_mean[(df_prefix_suffix_freq_mean.frequency >= df_prefix_suffix_freq_mean.frequency_mean)]\n",
    "df_prefix_suffix_freq_mean_select.reset_index(drop=True, inplace=True)\n",
    "df_prefix_suffix_freq_mean_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq_mean_select.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefix_suffix_freq_mean_select.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_analysis:\n",
    "    df_prefix_suffix_freq_mean_select.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_{word_num}_Word_Prefix_Suffix_Custom_Result.xlsx\", index=False)\n",
    "else:\n",
    "    df_prefix_suffix_freq_mean_select.to_excel(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file1 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Prefix_Suffix_*Result.xlsx\")\n",
    "output_file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file1:\n",
    "    source = k # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file1:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file2 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Prefix_Suffix_*.xlsx\")\n",
    "output_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file2:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file2:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat Native And Etymology Prefix Suffix Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"Italian\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish Italian/Turkish_Italian_28_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_file = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "native_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>ama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ben</td>\n",
       "      <td>bence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ben</td>\n",
       "      <td>bende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeyler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylerden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeyleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylerin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_word       word\n",
       "0           ama        ama\n",
       "1          bana       bana\n",
       "2           ben        ben\n",
       "3           ben      bence\n",
       "4           ben      bende\n",
       "..          ...        ...\n",
       "162         şey     şeyler\n",
       "163         şey  şeylerden\n",
       "164         şey    şeylere\n",
       "165         şey    şeyleri\n",
       "166         şey   şeylerin\n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native = pd.read_excel(native_file[0])\n",
    "df_native = df_native[[\"search_word\",\"word\"]]\n",
    "df_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish Italian/Turkish_Italian_Shared_Word_Prefix_Suffix_Custom_Result.xlsx']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etymology_file = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "etymology_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abone</td>\n",
       "      <td>abone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abone</td>\n",
       "      <td>abonelik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abone</td>\n",
       "      <td>aboneliği</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absorbe</td>\n",
       "      <td>absorbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absürt</td>\n",
       "      <td>absürt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyenin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0          abone       abone\n",
       "1          abone    abonelik\n",
       "2          abone   aboneliği\n",
       "3        absorbe     absorbe\n",
       "4         absürt      absürt\n",
       "...          ...         ...\n",
       "4835     şövalye  şövalyenin\n",
       "4836     şövalye   şövalyesi\n",
       "4837     şırınga     şırınga\n",
       "4838     şırınga  şırıngayla\n",
       "4839     şırınga   şırıngayı\n",
       "\n",
       "[4840 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etmology = pd.read_excel(etymology_file[0])\n",
    "df_etmology = df_etmology[[\"search_word\",\"word\"]]\n",
    "df_etmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>ama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ben</td>\n",
       "      <td>bence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ben</td>\n",
       "      <td>bende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyenin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0            ama         ama\n",
       "1           bana        bana\n",
       "2            ben         ben\n",
       "3            ben       bence\n",
       "4            ben       bende\n",
       "...          ...         ...\n",
       "4835     şövalye  şövalyenin\n",
       "4836     şövalye   şövalyesi\n",
       "4837     şırınga     şırınga\n",
       "4838     şırınga  şırıngayla\n",
       "4839     şırınga   şırıngayı\n",
       "\n",
       "[5007 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native_etymology_concat = pd.concat([df_native,df_etmology], axis=0)\n",
    "df_native_etymology_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>ama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bana</td>\n",
       "      <td>bana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ben</td>\n",
       "      <td>ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ben</td>\n",
       "      <td>bence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ben</td>\n",
       "      <td>bende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyenin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>şövalye</td>\n",
       "      <td>şövalyesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0            ama         ama\n",
       "1           bana        bana\n",
       "2            ben         ben\n",
       "3            ben       bence\n",
       "4            ben       bende\n",
       "...          ...         ...\n",
       "5002     şövalye  şövalyenin\n",
       "5003     şövalye   şövalyesi\n",
       "5004     şırınga     şırınga\n",
       "5005     şırınga  şırıngayla\n",
       "5006     şırınga   şırıngayı\n",
       "\n",
       "[5007 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native_etymology_concat[\"search_word\"] = df_native_etymology_concat[\"search_word\"].apply(lambda x : lower_strip(x))\n",
    "df_native_etymology_concat[\"word\"] = df_native_etymology_concat[\"word\"].apply(lambda x : lower_strip(x))\n",
    "df_native_etymology_concat.drop_duplicates(inplace=True)\n",
    "df_native_etymology_concat.reset_index(drop=True, inplace=True)\n",
    "df_native_etymology_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_native_etymology_concat.to_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} \\\n",
    "{lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Native_And_Shared_Word_Prefix_Suffix_Custom_Concat.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English, French, German, Spanish, Portuguese, Dutch, Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair1 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish English/Turkish_English_Shared_Vocabulary.xlsx\")\n",
    "#df_pair1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair2 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish French/Turkish_French_Shared_Vocabulary.xlsx\")\n",
    "#df_pair2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair3 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish German/Turkish_German_Shared_Vocabulary.xlsx\")\n",
    "#df_pair3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair4 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Spanish/Turkish_Spanish_Shared_Vocabulary.xlsx\")\n",
    "#df_pair4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair5 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Portuguese/Turkish_Portuguese_Shared_Vocabulary.xlsx\")\n",
    "#df_pair5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair6 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Dutch/Turkish_Dutch_Shared_Vocabulary.xlsx\")\n",
    "#df_pair6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair7 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Italian/Turkish_Italian_Shared_Vocabulary.xlsx\")\n",
    "#df_pair7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set1 = set(df_pair1.dict_entry_main)\n",
    "#set2 = set(df_pair2.dict_entry_main)\n",
    "#set3 = set(df_pair3.dict_entry_main)\n",
    "#set4 = set(df_pair4.dict_entry_main)\n",
    "#set5 = set(df_pair5.dict_entry_main)\n",
    "#set6 = set(df_pair6.dict_entry_main)\n",
    "#set7 = set(df_pair7.dict_entry_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ety_intersect = pd.DataFrame((((((set7.intersection(set6)).intersection(set5)).intersection(set4)).intersection(set3)).intersection(set2)).intersection(set1), columns=[\"dict_entry_main\"])\n",
    "#df_ety_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ety_intersect.to_excel(\"Turkish_Intersect_Shared_Vocabulary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
