{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Selection Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 45000  # 28 native word end index\n",
    "\n",
    "# word all usage in twogram\n",
    "word_use_num_min = 1  # word usage in selected twograms \n",
    "word_use_num_max = 2\n",
    "\n",
    "# sentence check\n",
    "twogram_sentence_check = False  # True, False\n",
    "threegram_sentence_check = False\n",
    "fourgram_sentence_check = False\n",
    "fivegram_sentence_check = False\n",
    "sixgram_sentence_check = False\n",
    "sevengram_sentence_check = False\n",
    "eightgram_sentence_check = False\n",
    "ninegram_sentence_check = False\n",
    "tengram_sentence_check = False\n",
    "\n",
    "\n",
    "# n gram select\n",
    "twogram_select_start = 0\n",
    "twogram_select_end = 10000\n",
    "\n",
    "threegram_select_start = 0\n",
    "threegram_select_end = 10000\n",
    "\n",
    "fourgram_select_start = 0\n",
    "fourgram_select_end = 10000\n",
    "\n",
    "fivegram_select_start = 0\n",
    "fivegram_select_end = 10000\n",
    "\n",
    "sixgram_select_start = 0\n",
    "sixgram_select_end = 10000\n",
    "\n",
    "sevengram_select_start = 0\n",
    "sevengram_select_end = 10000\n",
    "\n",
    "eightgram_select_start = 0\n",
    "eightgram_select_end = 10000\n",
    "\n",
    "ninegram_select_start = 0\n",
    "ninegram_select_end = 10000\n",
    "\n",
    "tengram_select_start = 0\n",
    "tengram_select_end = 10000\n",
    "\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False: True for adding prefix suffix word\n",
    "native_word = True # True for adding native word\n",
    "\n",
    "# adding output file extention\n",
    "if prefix_suffix & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "    \n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Text Selection/Data/1-Text Selection Data Prepare\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(df):\n",
    "    for i in df.columns:\n",
    "        new_name = i.strip()\n",
    "        df.rename(columns={f\"{i}\":f\"{new_name}\"}, inplace=True)\n",
    "        df[f\"{new_name}\"] = df[f\"{new_name}\"].apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}/{lang_folder.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "    df_word = df_word.loc[:,[\"word\",\"frequency\"]]\n",
    "    df_word = pd.concat([df_word,df_word_select], axis=0)\n",
    "    df_word.drop_duplicates(inplace=True)    \n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df_word = df_word_select\n",
    "\n",
    "if native_word:\n",
    "    df_word\n",
    "else:\n",
    "    df_word = df_word.head(0)\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word.to_excel(\"Word_Selected_45000.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select = df_word[\"word\"].values.tolist()\n",
    "word_select_set = set(word_select)\n",
    "disable_word_set = set(disable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_select_set.difference(disable_word_set))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ngrams Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if twogram_sentence_check:\n",
    "    df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_twogram = df_twogram_sent.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "else:\n",
    "    df_twogram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")  \n",
    "    df_twogram = df_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "\n",
    "df_twogram = df_twogram[df_twogram[\"frequency\"] > 5]\n",
    "df_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list2  = df_twogram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist2 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist2 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list2):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list2.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist2.append(d_list2)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list2) # string_word liste\n",
    "\n",
    "result_list2 = list(resultlist2)\n",
    "df_result2 = pd.DataFrame(result_list2, columns=[0])  # add columns parameter for empty result\n",
    "df_result2 = df_result2.rename(columns = {0: \"twogram\"})\n",
    "df_merge2 = pd.merge(df_result2, df_twogram, how=\"left\", on=\"twogram\")\n",
    "df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result2.drop_duplicates(inplace=True)\n",
    "df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "df_twogram_select = df_merge_result2\n",
    "df_twogram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_frequency = df_twogram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_select[\"ratio\"] = round(((df_twogram_select.iloc[:,1]/twogram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_select[\"cumul_ratio\"] = np.cumsum(df_twogram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_kneedle = KneeLocator(x=df_twogram_select.cumul_ratio.index, y=df_twogram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "twogram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_twogram = round(twogram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_knee = df_twogram_select[df_twogram_select.cumul_ratio <= knee_point_twogram]\n",
    "df_twogram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_twogram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_select2 = df_twogram_select.iloc[twogram_select_start:twogram_select_end,]\n",
    "df_twogram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_knee.to_csv(\"Twogram_Selected.csv\", index=False)\n",
    "df_twogram_select2.to_excel(f\"Twogram_Selected_{twogram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threegram_sentence_check:\n",
    "    df_threegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Three_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_threegram_sent.rename(columns={\"three_gram\":\"threegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_threegram = df_threegram_sent.loc[:,[\"threegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_threegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")  \n",
    "    df_threegram = df_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "\n",
    "df_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list3  = df_threegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist3 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist3 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list3):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list3.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist3.append(d_list3)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list3) # string_word liste\n",
    "\n",
    "result_list3 = list(resultlist3)\n",
    "df_result3 = pd.DataFrame(result_list3, columns=[0])  # add columns parameter for empty result\n",
    "df_result3 = df_result3.rename(columns = {0: \"threegram\"})\n",
    "df_merge3 = pd.merge(df_result3, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_merge_result3 = df_merge3.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result3.drop_duplicates(inplace=True)\n",
    "df_merge_result3.reset_index(drop=True, inplace=True)\n",
    "df_threegram_select = df_merge_result3\n",
    "df_threegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegram_frequency = df_threegram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_select[\"ratio\"] = round(((df_threegram_select.iloc[:,1]/threegram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_select[\"cumul_ratio\"] = np.cumsum(df_threegram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegram_kneedle = KneeLocator(x=df_threegram_select.cumul_ratio.index, y=df_threegram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "threegram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_threegram = round(threegram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_knee = df_threegram_select[df_threegram_select.cumul_ratio <= knee_point_threegram]\n",
    "df_threegram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_threegram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_select2 = df_threegram_select.iloc[threegram_select_start:threegram_select_end,]\n",
    "df_threegram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_knee.to_csv(\"Threegram_Selected.csv\", index=False)\n",
    "df_threegram_select2.to_excel(f\"Threegram_Selected_{threegram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fourgram_sentence_check:\n",
    "    df_fourgram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Four_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fourgram_sent.rename(columns={\"four_gram\":\"fourgram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fourgram = df_fourgram_sent.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fourgram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")  \n",
    "    df_fourgram = df_fourgram.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "\n",
    "df_fourgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list4  = df_fourgram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist4 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist4 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list4):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list4.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist4.append(d_list4)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list4) # string_word liste\n",
    "\n",
    "result_list4 = list(resultlist4)\n",
    "df_result4 = pd.DataFrame(result_list4, columns=[0])  # add columns parameter for empty result\n",
    "df_result4 = df_result4.rename(columns = {0: \"fourgram\"})\n",
    "df_merge4 = pd.merge(df_result4, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_merge_result4 = df_merge4.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result4.drop_duplicates(inplace=True)\n",
    "df_merge_result4.reset_index(drop=True, inplace=True)\n",
    "df_fourgram_select = df_merge_result4\n",
    "df_fourgram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_frequency = df_fourgram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_select[\"ratio\"] = round(((df_fourgram_select.iloc[:,1]/fourgram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_select[\"cumul_ratio\"] = np.cumsum(df_fourgram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgram_kneedle = KneeLocator(x=df_fourgram_select.cumul_ratio.index, y=df_fourgram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "fourgram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_fourgram = round(fourgram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_knee = df_fourgram_select[df_fourgram_select.cumul_ratio <= knee_point_fourgram]\n",
    "df_fourgram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_fourgram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_select2 = df_fourgram_select.iloc[fourgram_select_start:fourgram_select_end,]\n",
    "df_fourgram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourgram_knee.to_csv(\"Fourgram_Selected.csv\", index=False)\n",
    "df_fourgram_select2.to_excel(f\"Fourgram_Selected_{fourgram_select_end}.xlsx\", index=False, encoding=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fivegram_sentence_check:\n",
    "    df_fivegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Five_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fivegram_sent.rename(columns={\"five_gram\":\"fivegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fivegram = df_fivegram_sent.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fivegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")  \n",
    "    df_fivegram = df_fivegram.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "\n",
    "df_fivegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list5  = df_fivegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist5 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist5 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list5):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list5.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist5.append(d_list5)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list5) # string_word liste\n",
    "\n",
    "result_list5 = list(resultlist5)\n",
    "df_result5 = pd.DataFrame(result_list5, columns=[0])  # add columns parameter for empty result\n",
    "df_result5 = df_result5.rename(columns = {0: \"fivegram\"})\n",
    "df_merge5 = pd.merge(df_result5, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_merge_result5 = df_merge5.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result5.drop_duplicates(inplace=True)\n",
    "df_merge_result5.reset_index(drop=True, inplace=True)\n",
    "df_fivegram_select = df_merge_result5\n",
    "df_fivegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivegram_frequency = df_fivegram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_select[\"ratio\"] = round(((df_fivegram_select.iloc[:,1]/fivegram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_select[\"cumul_ratio\"] = np.cumsum(df_fivegram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivegram_kneedle = KneeLocator(x=df_fivegram_select.cumul_ratio.index, y=df_fivegram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "fivegram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_fivegram = round(fivegram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_knee = df_fivegram_select[df_fivegram_select.cumul_ratio <= knee_point_fivegram]\n",
    "df_fivegram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_fivegram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_select2 = df_fivegram_select.iloc[fivegram_select_start:fivegram_select_end,]\n",
    "df_fivegram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fivegram_knee.to_csv(\"Fivegram_Selected.csv\", index=False)\n",
    "df_fivegram_select2.to_excel(f\"Fivegram_Selected_{fivegram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sixgram_sentence_check:\n",
    "    df_sixgram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Six_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_sixgram_sent.rename(columns={\"six_gram\":\"sixgram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_sixgram = df_sixgram_sent.loc[:,[\"sixgram\",\"frequency\"]]\n",
    "else:\n",
    "    df_sixgram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Sixgram_Merge.csv\")  \n",
    "    df_sixgram = df_sixgram.loc[:,[\"sixgram\",\"frequency\"]]\n",
    "\n",
    "df_sixgram = df_sixgram[df_sixgram[\"frequency\"] > 5]\n",
    "df_sixgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list6  = df_sixgram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist6 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist6 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list6):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list6.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist6.append(d_list6)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list6) # string_word liste\n",
    "\n",
    "result_list6 = list(resultlist6)\n",
    "df_result6 = pd.DataFrame(result_list6, columns=[0])  # add columns parameter for empty result\n",
    "df_result6 = df_result6.rename(columns = {0: \"sixgram\"})\n",
    "df_merge6 = pd.merge(df_result6, df_sixgram, how=\"left\", on=\"sixgram\")\n",
    "df_merge_result6 = df_merge6.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result6.drop_duplicates(inplace=True)\n",
    "df_merge_result6.reset_index(drop=True, inplace=True)\n",
    "df_sixgram_select = df_merge_result6\n",
    "df_sixgram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixgram_frequency = df_sixgram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sixgram_select[\"ratio\"] = round(((df_sixgram_select.iloc[:,1]/sixgram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sixgram_select[\"cumul_ratio\"] = np.cumsum(df_sixgram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixgram_kneedle = KneeLocator(x=df_sixgram_select.cumul_ratio.index, y=df_sixgram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "sixgram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_sixgram = round(sixgram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sixgram_knee = df_sixgram_select[df_sixgram_select.cumul_ratio <= knee_point_sixgram]\n",
    "df_sixgram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_sixgram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sixgram_select2 = df_sixgram_select.iloc[sixgram_select_start:sixgram_select_end,]\n",
    "df_sixgram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sixgram_knee.to_csv(\"Sixgram_Selected.csv\", index=False)\n",
    "df_sixgram_select2.to_excel(f\"Sixgram_Selected_{sixgram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sevengram_sentence_check:\n",
    "    df_sevengram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Seven_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_sevengram_sent.rename(columns={\"seven_gram\":\"sevengram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_sevengram = df_sevengram_sent.loc[:,[\"sevengram\",\"frequency\"]]\n",
    "else:\n",
    "    df_sevengram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Sevengram_Merge.csv\")  \n",
    "    df_sevengram = df_sevengram.loc[:,[\"sevengram\",\"frequency\"]]\n",
    "\n",
    "df_sevengram = df_sevengram[df_sevengram[\"frequency\"] > 5]\n",
    "df_sevengram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list7  = df_sevengram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist7 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist7 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list7):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list7.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist7.append(d_list7)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list7) # string_word liste\n",
    "\n",
    "result_list7 = list(resultlist7)\n",
    "df_result7 = pd.DataFrame(result_list7, columns=[0])  # add columns parameter for empty result\n",
    "df_result7 = df_result7.rename(columns = {0: \"sevengram\"})\n",
    "df_merge7 = pd.merge(df_result7, df_sevengram, how=\"left\", on=\"sevengram\")\n",
    "df_merge_result7 = df_merge7.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result7.drop_duplicates(inplace=True)\n",
    "df_merge_result7.reset_index(drop=True, inplace=True)\n",
    "df_sevengram_select = df_merge_result7\n",
    "df_sevengram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevengram_frequency = df_sevengram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sevengram_select[\"ratio\"] = round(((df_sevengram_select.iloc[:,1]/sevengram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sevengram_select[\"cumul_ratio\"] = np.cumsum(df_sevengram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevengram_kneedle = KneeLocator(x=df_sevengram_select.cumul_ratio.index, y=df_sevengram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "sevengram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_sevengram = round(sevengram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sevengram_knee = df_sevengram_select[df_sevengram_select.cumul_ratio <= knee_point_sevengram]\n",
    "df_sevengram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_sevengram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sevengram_select2 = df_sevengram_select.iloc[sevengram_select_start:sevengram_select_end,]\n",
    "df_sevengram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sevengram_knee.to_csv(\"Sevengram_Selected.csv\", index=False)\n",
    "df_sevengram_select2.to_excel(f\"Sevengram_Selected_{sevengram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eightgram_sentence_check:\n",
    "    df_eightgram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Eight_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_eightgram_sent.rename(columns={\"eight_gram\":\"eightgram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_eightgram = df_eightgram_sent.loc[:,[\"eightgram\",\"frequency\"]]\n",
    "else:\n",
    "    df_eightgram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Eightgram_Merge.csv\")  \n",
    "    df_eightgram = df_eightgram.loc[:,[\"eightgram\",\"frequency\"]]\n",
    "\n",
    "df_eightgram = df_eightgram[df_eightgram[\"frequency\"] >= 5]\n",
    "df_eightgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list8  = df_eightgram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist8 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist8 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list8):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list8.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist8.append(d_list8)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list8) # string_word liste\n",
    "\n",
    "result_list8 = list(resultlist8)\n",
    "df_result8 = pd.DataFrame(result_list8, columns=[0])  # add columns parameter for empty result\n",
    "df_result8 = df_result8.rename(columns = {0: \"eightgram\"})\n",
    "df_merge8 = pd.merge(df_result8, df_eightgram, how=\"left\", on=\"eightgram\")\n",
    "df_merge_result8 = df_merge8.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result8.drop_duplicates(inplace=True)\n",
    "df_merge_result8.reset_index(drop=True, inplace=True)\n",
    "df_eightgram_select = df_merge_result8\n",
    "df_eightgram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eightgram_frequency = df_eightgram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eightgram_select[\"ratio\"] = round(((df_eightgram_select.iloc[:,1]/eightgram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eightgram_select[\"cumul_ratio\"] = np.cumsum(df_eightgram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eightgram_kneedle = KneeLocator(x=df_eightgram_select.cumul_ratio.index, y=df_eightgram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "eightgram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_eightgram = round(eightgram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eightgram_knee = df_eightgram_select[df_eightgram_select.cumul_ratio <= knee_point_eightgram]\n",
    "df_eightgram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_eightgram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eightgram_select2 = df_eightgram_select.iloc[eightgram_select_start:eightgram_select_end,]\n",
    "df_eightgram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eightgram_knee.to_csv(\"Eightgram_Selected.csv\", index=False)\n",
    "df_eightgram_select2.to_excel(f\"Eightgram_Selected_{eightgram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ninegram_sentence_check:\n",
    "    df_ninegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Nine_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_ninegram_sent.rename(columns={\"nine_gram\":\"ninegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_ninegram = df_ninegram_sent.loc[:,[\"ninegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_ninegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Ninegram_Merge.csv\")  \n",
    "    df_ninegram = df_ninegram.loc[:,[\"ninegram\",\"frequency\"]]\n",
    "\n",
    "df_ninegram = df_ninegram[df_ninegram[\"frequency\"] >= 5]\n",
    "df_ninegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list9  = df_ninegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist9 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist9 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list9):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list9.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist9.append(d_list9)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list9) # string_word liste\n",
    "\n",
    "result_list9 = list(resultlist9)\n",
    "df_result9 = pd.DataFrame(result_list9, columns=[0])  # add columns parameter for empty result\n",
    "df_result9 = df_result9.rename(columns = {0: \"ninegram\"})\n",
    "df_merge9 = pd.merge(df_result9, df_ninegram, how=\"left\", on=\"ninegram\")\n",
    "df_merge_result9 = df_merge9.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result9.drop_duplicates(inplace=True)\n",
    "df_merge_result9.reset_index(drop=True, inplace=True)\n",
    "df_ninegram_select = df_merge_result9\n",
    "df_ninegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninegram_frequency = df_ninegram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ninegram_select[\"ratio\"] = round(((df_ninegram_select.iloc[:,1]/ninegram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ninegram_select[\"cumul_ratio\"] = np.cumsum(df_ninegram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninegram_kneedle = KneeLocator(x=df_ninegram_select.cumul_ratio.index, y=df_ninegram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "ninegram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_ninegram = round(ninegram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ninegram_knee = df_ninegram_select[df_ninegram_select.cumul_ratio <= knee_point_ninegram]\n",
    "df_ninegram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_ninegram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ninegram_select2 = df_ninegram_select.iloc[ninegram_select_start:ninegram_select_end,]\n",
    "df_ninegram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ninegram_knee.to_csv(\"Ninegram_Selected.csv\", index=False)\n",
    "df_ninegram_select2.to_excel(f\"Ninegram_Selected_{ninegram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tengram_sentence_check:\n",
    "    df_tengram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Ten_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_tengram_sent.rename(columns={\"ten_gram\":\"tengram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_tengram = df_tengram_sent.loc[:,[\"tengram\",\"frequency\"]]\n",
    "else:\n",
    "    df_tengram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Tengram_Merge.csv\")  \n",
    "    df_tengram = df_tengram.loc[:,[\"tengram\",\"frequency\"]]\n",
    "\n",
    "#df_tengram = df_tengram[df_ninegram[\"frequency\"] > 5]\n",
    "df_tengram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list10  = df_tengram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist10 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist10 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list10):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list10.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist10.append(d_list10)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list10) # string_word liste\n",
    "\n",
    "result_list10 = list(resultlist10)\n",
    "df_result10 = pd.DataFrame(result_list10, columns=[0])  # add columns parameter for empty result\n",
    "df_result10 = df_result10.rename(columns = {0: \"tengram\"})\n",
    "df_merge10 = pd.merge(df_result10, df_tengram, how=\"left\", on=\"tengram\")\n",
    "df_merge_result10 = df_merge10.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result10.drop_duplicates(inplace=True)\n",
    "df_merge_result10.reset_index(drop=True, inplace=True)\n",
    "df_tengram_select = df_merge_result10\n",
    "df_tengram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tengram_frequency = df_tengram_select.iloc[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tengram_select[\"ratio\"] = round(((df_tengram_select.iloc[:,1]/tengram_frequency)*100),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tengram_select[\"cumul_ratio\"] = np.cumsum(df_tengram_select[\"ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tengram_kneedle = KneeLocator(x=df_tengram_select.cumul_ratio.index, y=df_tengram_select.cumul_ratio, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "tengram_kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_point_tengram = round(tengram_kneedle.knee_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tengram_knee = df_tengram_select[df_tengram_select.cumul_ratio <= knee_point_tengram]\n",
    "df_tengram_knee.drop([\"ratio\",\"cumul_ratio\"], axis=1, inplace=True)\n",
    "df_tengram_knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tengram_select2 = df_tengram_select.iloc[tengram_select_start:tengram_select_end,]\n",
    "df_tengram_select2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tengram_knee.to_csv(\"Tengram_Selected.csv\", index=False)\n",
    "df_tengram_select2.to_excel(f\"Tengram_Selected_{tengram_select_end}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"*_Selected*\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file:\n",
    "    source = l # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_concat = pd.concat([df_twogram_select, df_threegram_select, df_fourgram_select, df_fivegram_select], axis=1)\n",
    "df_ngram_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"threegram\",threegram_sample)\n",
    "df_two_in_four = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fourgram\",fourgram_sample)\n",
    "df_two_in_five = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fivegram\",fivegram_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_order_join_threegram = df_two_in_three.groupby([\"twogram\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fourgram = df_two_in_four.groupby([\"twogram\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fivegram = df_two_in_five.groupby([\"twogram\"])[\"fivegram\"].apply(\", \".join).reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_twogram_order_join_threegram, df_twogram_order_join_fourgram, df_twogram_order_join_fivegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = reduce(lambda  left,right: pd.merge(left,right, on=['twogram'], how='outer'), dfs)\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = pd.merge(df_ngram_sample_join_merge, df_twogram_select, how=\"right\", on=\"twogram\")\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge.rename(columns={\"frequency\":\"two_freq\"}, inplace=True)\n",
    "df_ngram_sample_join_merge.sort_values(by=\"two_freq\", ascending=False, inplace=True)\n",
    "df_ngram_sample_join_merge.reset_index(drop=True, inplace=True)\n",
    "df_ngram_sample_join_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge.to_excel(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Join_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Frequency For Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three_freq = pd.merge(df_two_in_three, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_two_in_three_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_three_freq.rename(columns={\"frequency\":\"three_freq\"}, inplace=True)\n",
    "df_two_in_three_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_three_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_four_freq = pd.merge(df_two_in_four, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_two_in_four_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_four_freq.rename(columns={\"frequency\":\"four_freq\"}, inplace=True)\n",
    "df_two_in_four_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_four_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_five_freq = pd.merge(df_two_in_five, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_two_in_five_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_five_freq.rename(columns={\"frequency\":\"five_freq\"}, inplace=True)\n",
    "df_two_in_five_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_five_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat = pd.concat([df_twogram_select,df_two_in_three_freq, df_two_in_four_freq, df_two_in_five_freq], axis=1)\n",
    "df_ngram_sample_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat.to_excel(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Frequency_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Result And Select Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_threegram_unique = df_ngram_sample_concat[[\"threegram\",\"three_freq\"]].drop_duplicates()\n",
    "df_ngram_fourgram_unique = df_ngram_sample_concat[[\"fourgram\",\"four_freq\"]].drop_duplicates()\n",
    "df_ngram_fivegram_unique = df_ngram_sample_concat[[\"fivegram\",\"five_freq\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_result_freq = df_twogram_select[\"frequency\"].sum()\n",
    "threegram_result_freq = df_ngram_threegram_unique[\"three_freq\"].sum()\n",
    "fourgram_result_freq = df_ngram_fourgram_unique[\"four_freq\"].sum()\n",
    "fivegram_result_freq = df_ngram_fivegram_unique[\"five_freq\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_select_freq = df_twogram.iloc[twogram_select_start:twogram_select_end,][\"frequency\"].sum()\n",
    "threegram_select_freq = df_threegram.iloc[threegram_select_start:threegram_select_end,][\"frequency\"].sum()\n",
    "fourgram_select_freq = df_fourgram.iloc[fourgram_select_start:fourgram_select_end,][\"frequency\"].sum()\n",
    "fivegram_select_freq = df_fivegram.iloc[fivegram_select_start:fivegram_select_end,][\"frequency\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(twogram_result_freq/twogram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(threegram_result_freq/threegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fourgram_result_freq/fourgram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fivegram_result_freq/fivegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_*_Result.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 200  # 28 native word end index\n",
    "\n",
    "# word all usage in twogram\n",
    "word_use_num_min = 1  # word usage in selected twograms \n",
    "word_use_num_max = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word_select[\"word\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_three = pd.read_excel(\"/home/kurubal/Downloads/Twogram Threegram.xlsx\")\n",
    "df_two_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_result(df_two_three,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_three[\"twogram\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_three[\"threegram\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three = word_in_wordgroup_simple(df_two_three, \"twogram\",\"threegram\",threegram_sample)\n",
    "df_two_in_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_twogram = set(df_two_three[\"twogram\"].dropna().to_list())\n",
    "set_twogram_in_threegram = set(df_two_in_three[\"twogram\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_twogram.difference(set_twogram_in_threegram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_threegram_cover_twogram = set(df_two_in_three[\"threegram\"].to_list())\n",
    "df_selected_threegram = pd.DataFrame(set_threegram_cover_twogram,columns=[\"threegram\"])\n",
    "df_selected_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_threegram.to_excel(\"Threegram_Selected.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_result(df_selected_threegram,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threegram_word_usage_select = word_usage_result(word_list, df_selected_threegram, \"threegram\", word_use_num_min, word_use_num_max)\n",
    "df_threegram_word_usage_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_result(df_threegram_word_usage_select,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
