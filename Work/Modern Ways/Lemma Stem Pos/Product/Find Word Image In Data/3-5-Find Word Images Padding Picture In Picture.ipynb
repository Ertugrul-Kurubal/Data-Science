{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Word Images Padding Picture In Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "file_ext = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_lemma_all_data_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "#Lemma Stem POS/Result/3-2-Word In Visual Genome Merge\"\n",
    "\n",
    "visual_genome_process_data_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-0-Visual Genome Process\"\n",
    "\n",
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-5-Find Word Images Padding Picture In Picture\"\n",
    "\n",
    "#Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding_aspect_ratio(data_folder_name, data_path, out_folder_name, out_path, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9):\n",
    "       '''\n",
    "       image_padding_aspect_ratio(data_folder_name, data_path, out_folder_name, out_path, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9)\\n\n",
    "       data_folder_name that include image files, data_path that for data_folder_name, out_folder_name, out_path that for out_folder_name are path and folder in string(str).\\n\n",
    "       others are cv2 parameter and image aspect ratio parameter.\\n\n",
    "       ex.\\n\n",
    "       output_path = f\"/home/kurubal/Documents/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/28 Words\"\\n\n",
    "       image_path = f\"/home/kurubal/Documents/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/28 Words\"\\n\n",
    "       image_padding_aspect_ratio(\"Images_SV_Rename\", image_path, \"Images_SV\", output_path, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9)\n",
    "       '''\n",
    "       error_file_list = []\n",
    "       result_path = f\"{out_path}/{out_folder_name}\"\n",
    "       data_folder_path = f\"{data_path}/{data_folder_name}\"\n",
    "       Path(result_path).mkdir(parents=True, exist_ok=True)\n",
    "       files=[f for f in os.listdir(data_folder_path) if isfile(join(data_folder_path,f))]   \n",
    "       for i in range(len(files)):       \n",
    "          pathfilename=data_folder_path+'/'+files[i]\n",
    "          #filename_without_ext = os.path.splitext(files[i])[0]\n",
    "          #text = f\"{text}\"\n",
    "          if isfile(f\"{result_path}/{files[i]}\"):\n",
    "                 pass\n",
    "          else:\n",
    "                 try:\n",
    "                        img = cv2.imread(f\"{pathfilename}\")\n",
    "                        old_image_height, old_image_width, channels = img.shape  # 2718  1988\n",
    "\n",
    "                        #aspect_ratio_width = 16\n",
    "                        #aspect_ratio_height = 9\n",
    "\n",
    "                        if (old_image_height/aspect_ratio_height) > (old_image_width/aspect_ratio_width):\n",
    "                               new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                               new_image_height = int(old_image_height)\n",
    "                        elif (old_image_height/aspect_ratio_height) < (old_image_width/aspect_ratio_width):\n",
    "                               new_image_width = int(old_image_width)\n",
    "                               new_image_height = int((old_image_width/aspect_ratio_width)*aspect_ratio_height)\n",
    "                        elif (old_image_height/aspect_ratio_height) == (old_image_width/aspect_ratio_width):\n",
    "                               new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                               new_image_height = int(old_image_height)\n",
    "                        else:\n",
    "                               new_image_width = old_image_width\n",
    "                               new_image_height = old_image_height\n",
    "\n",
    "                        color = padding_color\n",
    "                        result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "                        # compute center offset\n",
    "                        x_center = (new_image_width - old_image_width) // 2\n",
    "                        y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "                        # copy img image into center of result image\n",
    "                        result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = img            \n",
    "\n",
    "                        cv2.imwrite(f\"{result_path}/{files[i]}\", result)\n",
    "                 except:\n",
    "                        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "                        error_file_list.append(files[i])\n",
    "                        \n",
    "       return error_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False):\n",
    "       '''\n",
    "       image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False)\\n\n",
    "       image_path_file that is only one image file and result image save in same path. If overwrite True, result image will overwrite to main file, otherwise result\\n\n",
    "       image save with padded extention. others are cv2 parameter and image aspect ratio parameter.\\n\n",
    "       ex.\\n\n",
    "       image_path_file = \"/home/kurubal/Downloads/2333869.jpg\"\\n\n",
    "       image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False)\n",
    "       '''\n",
    "       error_file_list = []\n",
    "       size = (1600, 900)  # image new size (width, height)\n",
    "       # path process\n",
    "       path_split_list = os.path.split(image_path_file)\n",
    "       main_path = path_split_list[0]  # part of before last one\n",
    "       file = path_split_list[1]  # last file or folder\n",
    "       filename_without_ext = os.path.splitext(file)[0]  # file without .jpg\n",
    "       filename_ext = os.path.splitext(file)[1]  # file extention as .jpg\n",
    "       # file process\n",
    "       if isfile(f\"{main_path}/{filename_without_ext}_padded{filename_ext}\"):\n",
    "              pass\n",
    "       else:\n",
    "              try:\n",
    "                     img = cv2.imread(f\"{image_path_file}\")\n",
    "                     old_image_height, old_image_width, channels = img.shape \n",
    "\n",
    "                     if (old_image_height/aspect_ratio_height) > (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                            new_image_height = int(old_image_height)\n",
    "                     elif (old_image_height/aspect_ratio_height) < (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int(old_image_width)\n",
    "                            new_image_height = int((old_image_width/aspect_ratio_width)*aspect_ratio_height)\n",
    "                     elif (old_image_height/aspect_ratio_height) == (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                            new_image_height = int(old_image_height)\n",
    "                     else:\n",
    "                            new_image_width = old_image_width\n",
    "                            new_image_height = old_image_height\n",
    "\n",
    "                     color = padding_color\n",
    "                     result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "                     # compute center offset\n",
    "                     x_center = (new_image_width - old_image_width) // 2\n",
    "                     y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "                     # copy img image into center of result image\n",
    "                     result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = img\n",
    "\n",
    "                     # image resize\n",
    "                     result_resize = cv2.resize(result, size, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                     if overwrite:\n",
    "                            cv2.imwrite(f\"{main_path}/{filename_without_ext}{filename_ext}\", result_resize)  # for overwrite\n",
    "                     else:\n",
    "                            cv2.imwrite(f\"{main_path}/{filename_without_ext}_padded{filename_ext}\", result_resize)\n",
    "              except:\n",
    "                     print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "                     error_file_list.append(image_path_file)\n",
    "                        \n",
    "       return error_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def picture_in_picture(main_image_file_path, add_image_file_path, add_pic_size=8, add_pic_pos=[\"top\",\"left\"], add_pic_margin=10, border_color=\"red\"):\n",
    "    '''picture_in_picture(main_image_file_path, add_image_file_path, add_pic_size=8, add_pic_pos=[\"top\",\"left\"], add_pic_margin=10, border_color=\"red\")\\n\n",
    "    main_image_file_path is master image file path or result of image file, add_image_file_path is slave image that use for paste on master image.\\n\n",
    "    add_pic_size is slave image size that is master_image_width(1600px)/add_pic_size(8)=200px. add_pic_pos refers to slave image position on master image.\\n\n",
    "    add_pic_margin is slave image shift from edges. border_color is slave image border color for highlight.\\n\n",
    "    ex.\\n\n",
    "    picture_in_picture(\"gibi.jpg\", \"Group 36.jpg\", add_pic_pos = [\"bottom\",\"left\"], add_pic_margin = 10, border_color = \"red\")\n",
    "    '''\n",
    "    # main image\n",
    "    try:  \n",
    "        image_main = Image.open(f\"{main_image_file_path}\")  # 1600*900 px, image file path\n",
    "    except:\n",
    "        image_main = main_image_file_path  # picture of result from RAM\n",
    "        \n",
    "    width_main, height_main = image_main.size\n",
    "\n",
    "    # additional image\n",
    "    image_add = Image.open(f\"{add_image_file_path}\")  # square image\n",
    "    height_add_edit = int(width_main/add_pic_size)  # 1600/8 = 200 px\n",
    "    width_add_edit = int(width_main/add_pic_size)\n",
    "    new_size_add = (width_add_edit, height_add_edit)  # (height_add_edit ,width_add_edit) ??\n",
    "    image_add_resize = image_add.resize(new_size_add)\n",
    "    # border\n",
    "    border_thickness = (3, 3, 3, 3)\n",
    "    image_add_resize_border = ImageOps.expand(image_add_resize, border=border_thickness, fill=border_color)\n",
    "    width_add, height_add = image_add_resize_border.size\n",
    "\n",
    "    if (add_pic_pos[0] == \"top\") and (add_pic_pos[1] == \"left\"):\n",
    "        image_main.paste(image_add_resize_border, (add_pic_margin, add_pic_margin)) # x_koor, y_koor\n",
    "    elif (add_pic_pos[0] == \"top\") and (add_pic_pos[1] == \"right\"):\n",
    "        image_main.paste(image_add_resize_border, ((width_main-width_add-add_pic_margin), add_pic_margin))\n",
    "    elif (add_pic_pos[0] == \"bottom\") and (add_pic_pos[1] == \"left\"):\n",
    "        image_main.paste(image_add_resize_border, (add_pic_margin, (height_main-height_add-add_pic_margin)))\n",
    "    elif (add_pic_pos[0] == \"bottom\") and (add_pic_pos[1] == \"right\"):\n",
    "        image_main.paste(image_add_resize_border, ((width_main-width_add-add_pic_margin), (height_main-height_add-add_pic_margin)))\n",
    "    elif (add_pic_pos[0] == \"center\") and (add_pic_pos[1] == \"center\"):\n",
    "        image_main.paste(image_add_resize_border, ((int(width_main/2)-int(width_add/2)), (int(height_main/2)-int(height_add/2))))\n",
    "    elif (add_pic_pos[0] == \"left\") and (add_pic_pos[1] == \"center\"):\n",
    "        image_main.paste(image_add_resize_border, (add_pic_margin, (int(height_main/2)-int(height_add/2))))\n",
    "    elif (add_pic_pos[0] == \"right\") and (add_pic_pos[1] == \"center\"):\n",
    "       image_main.paste(image_add_resize_border, (width_main-width_add-add_pic_margin, (int(height_main/2)-int(height_add/2))))\n",
    "    elif (add_pic_pos[0] == \"top\") and (add_pic_pos[1] == \"center\"):\n",
    "        image_main.paste(image_add_resize_border, ((int(width_main/2)-int(width_add/2)), add_pic_margin))\n",
    "    elif (add_pic_pos[0] == \"bottom\") and (add_pic_pos[1] == \"center\"):\n",
    "        image_main.paste(image_add_resize_border, ((int(width_main/2)-int(width_add/2)), (height_main-height_add-add_pic_margin)))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return image_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns Image Padding Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron_output_path = f\"/home/kurubal/Downloads\"\n",
    "\n",
    "Path(pron_output_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron_image_path = f\"/home/kurubal/Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_padding_aspect_ratio(\"Pronouns\", pron_image_path, \"Pronouns_Padding\", pron_output_path, padding_color = (255,255,255), aspect_ratio_width = 1, aspect_ratio_height = 1)  # /media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Image Audio Video/Data/Pronouns_Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Image Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/{file_ext} Words/Image_Genome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL_OTHER_FOLDER',\n",
       " 'ALL_VERB_FOLDER',\n",
       " 'ALL_ADJ_ADV_PRON_FOLDER',\n",
       " 'Backup',\n",
       " 'ALL_NOUN_FOLDER']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_main_folder_list = os.listdir(f\"{select_image_path}\")\n",
    "image_main_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_file_list = glob.glob(f\"{select_image_path}/ALL_OTHER_FOLDER/*/*\")  # other .jpg files\n",
    "#other_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_file_list = glob.glob(f\"{select_image_path}/ALL_VERB_FOLDER/*/*/*\")  # verb .jpg files\n",
    "#verb_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_adv_pros_file_list = glob.glob(f\"{select_image_path}/ALL_ADJ_ADV_PRON_FOLDER/*/*/*\")  # adj adv pros .jpg files\n",
    "#adj_adv_pros_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_file_list = glob.glob(f\"{select_image_path}/ALL_NOUN_FOLDER/*/*/*\")  # noun .jpg files\n",
    "#noun_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_path_file in other_file_list:\n",
    "#    image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_path_file in verb_file_list:\n",
    "#    image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_path_file in adj_adv_pros_file_list:\n",
    "#    image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image_path_file in noun_file_list:\n",
    "#    image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Genome Word Lemma All Category Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path And Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/{file_ext} Words/Image_Genome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL_OTHER_FOLDER',\n",
       " 'ALL_VERB_FOLDER',\n",
       " 'ALL_ADJ_ADV_PRON_FOLDER',\n",
       " 'Backup',\n",
       " 'ALL_NOUN_FOLDER']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_main_folder_list = os.listdir(f\"{main_image_path}\")\n",
    "image_main_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_image_path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/Pronouns_Padding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_folder = \"/home/kurubal/Downloads/Genome_Picture_In_Picture\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>prefix_suffix</th>\n",
       "      <th>tense</th>\n",
       "      <th>person</th>\n",
       "      <th>case</th>\n",
       "      <th>plural</th>\n",
       "      <th>mean</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biraz</td>\n",
       "      <td>biraz</td>\n",
       "      <td>bir</td>\n",
       "      <td>a little</td>\n",
       "      <td>a little</td>\n",
       "      <td>1269641</td>\n",
       "      <td>+az</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biri</td>\n",
       "      <td>biri</td>\n",
       "      <td>bir</td>\n",
       "      <td>somebody</td>\n",
       "      <td>somebody</td>\n",
       "      <td>837400</td>\n",
       "      <td>+i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>belirtme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birlikte</td>\n",
       "      <td>birlikte</td>\n",
       "      <td>bir</td>\n",
       "      <td>together</td>\n",
       "      <td>together</td>\n",
       "      <td>409940</td>\n",
       "      <td>+likte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birini</td>\n",
       "      <td>biri</td>\n",
       "      <td>bir</td>\n",
       "      <td>one</td>\n",
       "      <td>somebody</td>\n",
       "      <td>259916</td>\n",
       "      <td>+ini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>belirtme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyorum</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>i give</td>\n",
       "      <td>give</td>\n",
       "      <td>126290</td>\n",
       "      <td>+um</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.tekil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyor</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>giving</td>\n",
       "      <td>give</td>\n",
       "      <td>68163</td>\n",
       "      <td>+</td>\n",
       "      <td>şimdiki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>okul</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okul</td>\n",
       "      <td>okul</td>\n",
       "      <td>oku</td>\n",
       "      <td>school</td>\n",
       "      <td>school</td>\n",
       "      <td>68160</td>\n",
       "      <td>+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>suçlu</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suçlu</td>\n",
       "      <td>suç</td>\n",
       "      <td>suç</td>\n",
       "      <td>guilty</td>\n",
       "      <td>crime</td>\n",
       "      <td>68124</td>\n",
       "      <td>+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.tekil</td>\n",
       "      <td>belirtme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>mesela</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mesela</td>\n",
       "      <td>mesela</td>\n",
       "      <td>mesela</td>\n",
       "      <td>for example</td>\n",
       "      <td>for example</td>\n",
       "      <td>68096</td>\n",
       "      <td>+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word  POS1 POS2       word lemma.spacy    stem word_en_translate  \\\n",
       "0            bir   NUM  NaN        bir         bir     bir                 a   \n",
       "1            bir   ADV  NaN      biraz       biraz     bir          a little   \n",
       "2            bir  PRON  NaN       biri        biri     bir          somebody   \n",
       "3            bir   ADV  NaN   birlikte    birlikte     bir          together   \n",
       "4            bir  NOUN  NaN     birini        biri     bir               one   \n",
       "...          ...   ...  ...        ...         ...     ...               ...   \n",
       "1619     veriyor  VERB  NaN  veriyorum         ver     ver            i give   \n",
       "1620     veriyor  VERB  NaN    veriyor         ver     ver            giving   \n",
       "1621        okul  NOUN  NaN       okul        okul     oku            school   \n",
       "1622       suçlu  NOUN  NaN      suçlu         suç     suç            guilty   \n",
       "1623      mesela   ADV  NaN     mesela      mesela  mesela       for example   \n",
       "\n",
       "     lemma_en_translate  frequency prefix_suffix    tense   person      case  \\\n",
       "0                     a   18835735             +      NaN      NaN       NaN   \n",
       "1              a little    1269641           +az      NaN      NaN       NaN   \n",
       "2              somebody     837400            +i      NaN      NaN  belirtme   \n",
       "3              together     409940        +likte      NaN      NaN       NaN   \n",
       "4              somebody     259916          +ini      NaN      NaN  belirtme   \n",
       "...                 ...        ...           ...      ...      ...       ...   \n",
       "1619               give     126290           +um      NaN  1.tekil       NaN   \n",
       "1620               give      68163             +  şimdiki      NaN       NaN   \n",
       "1621             school      68160             +      NaN      NaN       NaN   \n",
       "1622              crime      68124             +      NaN  3.tekil  belirtme   \n",
       "1623        for example      68096             +      NaN      NaN       NaN   \n",
       "\n",
       "     plural mean other  \n",
       "0       NaN  NaN   NaN  \n",
       "1       NaN  NaN   NaN  \n",
       "2       NaN  NaN   NaN  \n",
       "3       NaN  NaN   NaN  \n",
       "4       NaN  NaN   NaN  \n",
       "...     ...  ...   ...  \n",
       "1619    NaN  NaN   NaN  \n",
       "1620    NaN  NaN   NaN  \n",
       "1621    NaN  NaN   NaN  \n",
       "1622    NaN  NaN   NaN  \n",
       "1623    NaN  NaN   NaN  \n",
       "\n",
       "[1624 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_prefix_suffix_file = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/2-1-Word Prefix Suffix Analysis/{lang_folder.capitalize()}_{file_ext}_Word_Person_Case_Tense_Plural_Mean_Manuel.xlsx\")\n",
    "df_word_prefix_suffix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_word_prefix_suffix_file = df_word_prefix_suffix_file.head(20)  # for test\n",
    "# df_word_prefix_suffix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_prefix_suffix_file[\"word\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word_prefix_suffix_file[\"word\"].unique()\n",
    "#word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tense_image_name = list(df_word_prefix_suffix_file[\"tense\"].dropna().unique())\n",
    "person_image_name = list(df_word_prefix_suffix_file[\"person\"].dropna().unique())\n",
    "case_image_name = list(df_word_prefix_suffix_file[\"case\"].dropna().unique())\n",
    "plural_image_name = list(df_word_prefix_suffix_file[\"plural\"].dropna().unique())\n",
    "mean_image_name = list(df_word_prefix_suffix_file[\"mean\"].dropna().unique())\n",
    "other_image_name = list(df_word_prefix_suffix_file[\"other\"].dropna().unique())\n",
    "POS2_image_name = list(df_word_prefix_suffix_file[\"POS2\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geçmiş',\n",
       " 'şimdiki',\n",
       " 'gelecek',\n",
       " '3.tekil',\n",
       " '2.tekil',\n",
       " '1.tekil',\n",
       " '3.çoğul',\n",
       " '1.çoğul',\n",
       " '2.çoğul',\n",
       " 'belirtme',\n",
       " 'yönelme',\n",
       " 'ayrılma',\n",
       " 'bulunma',\n",
       " 'çoğul',\n",
       " 'olumsuz',\n",
       " 'imperative',\n",
       " 'to be',\n",
       " 'Q',\n",
       " 'NEG',\n",
       " 'GRE',\n",
       " 'TIME']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_image_list = tense_image_name + person_image_name + case_image_name + plural_image_name + mean_image_name + other_image_name + POS2_image_name\n",
    "add_image_list\n",
    "# Note: This add image list must be image file name as belirtme.jpg, yönelme.jpg etc. for next step is picture in picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main image and additional image picture in  picture\n",
    "for row_num in range(len(df_word_prefix_suffix_file)):\n",
    "    # main file result\n",
    "    df_var = df_word_prefix_suffix_file.iloc[[row_num],]\n",
    "    word = \"\".join(df_var[\"word\"])\n",
    "    try:\n",
    "        tense = \"\".join(df_var[\"tense\"])\n",
    "        tense_file = glob.glob(f\"{add_image_path_folder}/{tense}.jpg\")\n",
    "    except:\n",
    "        tense_file = []\n",
    "    try:\n",
    "        person = \"\".join(df_var[\"person\"])\n",
    "        person_file = glob.glob(f\"{add_image_path_folder}/{person}.jpg\")\n",
    "    except:\n",
    "        person_file = []\n",
    "    try:\n",
    "        case = \"\".join(df_var[\"case\"])\n",
    "        case_file = glob.glob(f\"{add_image_path_folder}/{case}.jpg\")\n",
    "    except:\n",
    "        case_file = []\n",
    "    try:\n",
    "        plural = \"\".join(df_var[\"plural\"])\n",
    "        plural_file = glob.glob(f\"{add_image_path_folder}/{plural}.jpg\")\n",
    "    except:\n",
    "        plural_file = []\n",
    "    try:\n",
    "        mean = \"\".join(df_var[\"mean\"])\n",
    "        mean_file = glob.glob(f\"{add_image_path_folder}/{mean}.jpg\")\n",
    "    except:\n",
    "        mean_file = []\n",
    "    try:\n",
    "        other = \"\".join(df_var[\"other\"])\n",
    "        other_file = glob.glob(f\"{add_image_path_folder}/{other}.jpg\")\n",
    "    except:\n",
    "        other_file = []\n",
    "    try:\n",
    "        pos = \"\".join(df_var[\"POS2\"])\n",
    "        pos_file = glob.glob(f\"{add_image_path_folder}/{pos}.jpg\")\n",
    "    except:\n",
    "        pos_file = []\n",
    "\n",
    "    add_image_file_list = tense_file + person_file + case_file + plural_file + mean_file + other_file + pos_file\n",
    "    \n",
    "    # word search in word folders\n",
    "    file_list1 = glob.glob(f\"{main_image_path}/ALL_VERB_FOLDER/*/{word}/*\")\n",
    "    file_list2 = glob.glob(f\"{main_image_path}/ALL_NOUN_FOLDER/*/{word}/*\")\n",
    "    file_list3 = glob.glob(f\"{main_image_path}/ALL_ADJ_ADV_PRON_FOLDER/*/{word}/*\")\n",
    "    file_list4 = glob.glob(f\"{main_image_path}/ALL_OTHER_FOLDER/{word}/*\")\n",
    "\n",
    "    main_image_file_list = file_list1 + file_list2 + file_list3 + file_list4\n",
    "\n",
    "    # create folder\n",
    "    if len(main_image_file_list) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        folder_name = f\"{word}\"\n",
    "        Path(f\"{output_path_folder}/{folder_name}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # main image and additional image picture_in_picture\n",
    "    main_num = 1\n",
    "    for main_image_path_file in main_image_file_list:  # Note: when main_image_file_list is empty, process will pass automatically. \n",
    "        main_image = Image.open(f\"{main_image_path_file}\") \n",
    "        add_num = 1\n",
    "        for add_image in add_image_file_list:\n",
    "            if add_num == 1:\n",
    "                main_image = picture_in_picture(main_image, f\"{add_image}\", add_pic_pos = [\"top\",\"left\"], add_pic_margin = 10, border_color = \"red\")\n",
    "            elif add_num == 2:\n",
    "                main_image = picture_in_picture(main_image, f\"{add_image}\", add_pic_pos = [\"top\",\"right\"], add_pic_margin = 10, border_color = \"red\")\n",
    "            elif add_num == 3:\n",
    "                main_image = picture_in_picture(main_image, f\"{add_image}\", add_pic_pos = [\"bottom\",\"left\"], add_pic_margin = 10, border_color = \"red\")\n",
    "            elif add_num == 4:\n",
    "                main_image = picture_in_picture(main_image, f\"{add_image}\", add_pic_pos = [\"bottom\",\"right\"], add_pic_margin = 10, border_color = \"red\")\n",
    "            else:\n",
    "                pass\n",
    "            add_num += 1\n",
    "\n",
    "        if isfile(f\"{output_path_folder}/{word}/{word}{main_num}.jpg\"):\n",
    "            pass\n",
    "        else:\n",
    "            main_image.save(f\"{output_path_folder}/{word}/{word}{main_num}.jpg\")\n",
    "\n",
    "        main_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronouns Image New Size (For All Prons Image Same Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_file = \"/home/kurubal/Downloads/Pronouns_Padding/imperative.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding_aspect_ratio_standalone(image_path_file, padding_color = (255,255,255), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False):\n",
    "       '''\n",
    "       image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False)\\n\n",
    "       image_path_file that is only one image file and result image save in same path. If overwrite True, result image will overwrite to main file, otherwise result\\n\n",
    "       image save with padded extention. others are cv2 parameter and image aspect ratio parameter.\\n\n",
    "       ex.\\n\n",
    "       image_path_file = \"/home/kurubal/Downloads/2333869.jpg\"\\n\n",
    "       image_padding_aspect_ratio_standalone(image_path_file, padding_color = (0,0,0), aspect_ratio_width = 16, aspect_ratio_height = 9, overwrite = False)\n",
    "       '''\n",
    "       error_file_list = []\n",
    "       size = (200, 200)  # image new size (width, height)\n",
    "       # path process\n",
    "       path_split_list = os.path.split(image_path_file)\n",
    "       main_path = path_split_list[0]  # part of before last one\n",
    "       file = path_split_list[1]  # last file or folder\n",
    "       filename_without_ext = os.path.splitext(file)[0]  # file without .jpg\n",
    "       filename_ext = os.path.splitext(file)[1]  # file extention as .jpg\n",
    "       # file process\n",
    "       if isfile(f\"{main_path}/{filename_without_ext}_padded{filename_ext}\"):\n",
    "              pass\n",
    "       else:\n",
    "              try:\n",
    "                     img = cv2.imread(f\"{image_path_file}\")\n",
    "                     old_image_height, old_image_width, channels = img.shape \n",
    "\n",
    "                     if (old_image_height/aspect_ratio_height) > (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                            new_image_height = int(old_image_height)\n",
    "                     elif (old_image_height/aspect_ratio_height) < (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int(old_image_width)\n",
    "                            new_image_height = int((old_image_width/aspect_ratio_width)*aspect_ratio_height)\n",
    "                     elif (old_image_height/aspect_ratio_height) == (old_image_width/aspect_ratio_width):\n",
    "                            new_image_width = int((old_image_height/aspect_ratio_height)*aspect_ratio_width)\n",
    "                            new_image_height = int(old_image_height)\n",
    "                     else:\n",
    "                            new_image_width = old_image_width\n",
    "                            new_image_height = old_image_height\n",
    "\n",
    "                     color = padding_color\n",
    "                     result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "                     # compute center offset\n",
    "                     x_center = (new_image_width - old_image_width) // 2\n",
    "                     y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "                     # copy img image into center of result image\n",
    "                     result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = img\n",
    "\n",
    "                     # image resize\n",
    "                     result_resize = cv2.resize(result, size, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                     if overwrite:\n",
    "                            cv2.imwrite(f\"{main_path}/{filename_without_ext}{filename_ext}\", result_resize)  # for overwrite\n",
    "                     else:\n",
    "                            cv2.imwrite(f\"{main_path}/{filename_without_ext}_padded{filename_ext}\", result_resize)\n",
    "              except:\n",
    "                     print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "                     error_file_list.append(image_path_file)\n",
    "                        \n",
    "       return error_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_padding_aspect_ratio_standalone(image_path_file, padding_color = (255,255,255), aspect_ratio_width = 1, aspect_ratio_height = 1)  # 200*200px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f42fef0e501d15e7ffc29462fb079408e9033a09ba77cf75c7f739a9f9db1301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
