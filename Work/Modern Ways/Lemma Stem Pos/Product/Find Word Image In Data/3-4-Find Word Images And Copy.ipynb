{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Word Images And Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "file_ext = 1000\n",
    "\n",
    "# image result parameter\n",
    "select_image_num = 1  # 10 image sample number big and equal this number\n",
    "take_image_sample_num = 1000  # 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemma_data_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-2-Word In Visual Genome Merge\"\n",
    "\n",
    "word_lemma_data_path2 = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-3-Find Word Images Mask Fade\"\n",
    "\n",
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-4-Find Word Images And Copy\"\n",
    "\n",
    "#Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe(df, search_list, target_column, sample_num):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True).head(sample_num)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len()).head(sample_num)               \n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe_all(df, search_list, target_column):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len())\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)        \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50):\n",
    "    '''take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then sort_target_column is sorting according to sort_ascending condition.\\n\n",
    "    Finally, taking sample_num each word_list values.\\n \n",
    "    ex.\\n\n",
    "    take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat, word_list, \"word\", \"search_text\", sort_ascending=True, sample_num=50)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "        df_select = df_select.sort_values(f\"{sort_target_column}\",key=lambda x:x.str.len(), ascending=sort_ascending).head(sample_num)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, image_folder_path, output_path_folder):\n",
    "#    '''create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, image_folder_path, output_path_folder)\\n\n",
    "#    df_source is a dataframe and word_list is equal in word_source_column. Then word image id search in image_id_column and image copy to\\n\n",
    "#    output_path_folder from image_folder_path.\\n\n",
    "#    ex.\\n\n",
    "#    image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images\"\\n\n",
    "#    output_path_folder = \"/home/kurubal/Downloads/temp folder\"\\n\n",
    "#    create_word_folder_and_copy_image(df_sample_result, word_list, \"word\", \"image_id\", image_path, output_path_folder)\n",
    "#    '''\n",
    "#    df_search_result = pd.DataFrame()\n",
    "#    for word in word_list:\n",
    "#        path = f\"{output_path_folder}/{word}\"\n",
    "#        Path(path).mkdir(parents=True, exist_ok=True)        \n",
    "#        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "#        for image_id in df_select[f\"{image_id_column}\"]:\n",
    "#            image_file = glob.glob(f\"{image_folder_path}/*/{image_id}.jpg\")\n",
    "#            for l in image_file:\n",
    "#                source = l # source directory\n",
    "#                destination = path\n",
    "#                shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, opt_column, image_folder_path, mask_folder_path, output_path_folder):\n",
    "    '''create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, image_folder_path, mask_folder_path, output_path_folder)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then word image id search in image_id_column and image copy to\\n\n",
    "    output_path_folder from mask_folder_path (search in firstly) and image_folder_path. opt_column used for additional features\\n\n",
    "    ex.\\n\n",
    "    image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images\"\\n\n",
    "    output_path_folder = \"/home/kurubal/Downloads/temp folder\"\\n\n",
    "    create_word_folder_and_copy_image(df_sample_result, word_list, \"word\", \"image_id\", \"num\", image_path, mask_image_path output_path_folder)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            path = f\"{output_path_folder}/{word}\"\n",
    "            Path(path).mkdir(parents=True, exist_ok=True)        \n",
    "            df_var = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "            df_select = df_var.drop_duplicates(subset=[f\"{image_id_column}\"])  # ????\n",
    "            imageid_list = list(df_select[f\"{image_id_column}\"])\n",
    "            opt_column_list = list(df_select[f\"{opt_column}\"])\n",
    "            data_list_zip = zip(imageid_list, opt_column_list)\n",
    "            for image_id, opt in data_list_zip:\n",
    "                opt_num = int(opt)\n",
    "\n",
    "                #if isfile(f\"{image_folder_path}/VG_Mask_Blur/{image_id}_{opt_num}_mask_blur.jpg\"):  # ?????                \n",
    "                #    image_file = glob.glob(f\"{image_folder_path}/*/{image_id}_{opt_num}_mask_blur.jpg\")\n",
    "\n",
    "                if isfile(f\"{mask_folder_path}/{image_id}_{opt_num}.jpg\"):  # ?????                \n",
    "                    image_file = glob.glob(f\"{mask_folder_path}/{image_id}_{opt_num}.jpg\")\n",
    "                    for l in image_file:\n",
    "                        source = l # source directory\n",
    "                        destination = path\n",
    "                        shutil.copy2(source, destination)\n",
    "                else:\n",
    "                    image_file = glob.glob(f\"{image_folder_path}/*/{image_id}.jpg\")\n",
    "                    for l in image_file:\n",
    "                        source = l # source directory\n",
    "                        destination = path\n",
    "                        shutil.copy2(source, destination)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images\"\n",
    "mask_image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images/VG_Mask_Blur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Lemma Stem POS/Data/Visual Genome/images/VG_100K',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Lemma Stem POS/Data/Visual Genome/images/VG_100K_2',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Lemma Stem POS/Data/Visual Genome/images/VG_Mask_Blur']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_list = glob.glob(f\"{image_path}/*\")\n",
    "image_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Genome Word Lemma Translate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_Tag = \"AUX\" # NOUN, VERB, ADJ, ADV, NUM, PRON, CCONJ, ADP, AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_folder = f\"/home/kurubal/Downloads/Image_Select/{Pos_Tag}\"\n",
    "\n",
    "Path(output_path_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2390994</td>\n",
       "      <td>2920126305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2348965</td>\n",
       "      <td>129190150113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2348965</td>\n",
       "      <td>123317182233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349861</td>\n",
       "      <td>4615142168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349866</td>\n",
       "      <td>54188097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192717</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>airport check in kiosks</td>\n",
       "      <td>2317616</td>\n",
       "      <td>276026737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192718</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>red check of tablecloth</td>\n",
       "      <td>2400604</td>\n",
       "      <td>376517459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192719</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>a check is on the table</td>\n",
       "      <td>2386272</td>\n",
       "      <td>95132301236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192720</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>cleats with white check</td>\n",
       "      <td>2371210</td>\n",
       "      <td>2211405194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192721</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>check number on receipt</td>\n",
       "      <td>2404231</td>\n",
       "      <td>6140115286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192722 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POS1 POS2     word lemma.spacy stem word_en_translate  \\\n",
       "0        NUM  NaN      bir         bir  bir                 a   \n",
       "1        NUM  NaN      bir         bir  bir                 a   \n",
       "2        NUM  NaN      bir         bir  bir                 a   \n",
       "3        NUM  NaN      bir         bir  bir                 a   \n",
       "4        NUM  NaN      bir         bir  bir                 a   \n",
       "...      ...  ...      ...         ...  ...               ...   \n",
       "192717  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "192718  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "192719  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "192720  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "192721  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "\n",
       "       lemma_en_translate  frequency              search_text  image_id  \\\n",
       "0                       a   18835735                        a   2390994   \n",
       "1                       a   18835735                        a   2348965   \n",
       "2                       a   18835735                        a   2348965   \n",
       "3                       a   18835735                        a   2349861   \n",
       "4                       a   18835735                        a   2349866   \n",
       "...                   ...        ...                      ...       ...   \n",
       "192717              check      69201  airport check in kiosks   2317616   \n",
       "192718              check      69201  red check of tablecloth   2400604   \n",
       "192719              check      69201  a check is on the table   2386272   \n",
       "192720              check      69201  cleats with white check   2371210   \n",
       "192721              check      69201  check number on receipt   2404231   \n",
       "\n",
       "                 num  \n",
       "0         2920126305  \n",
       "1       129190150113  \n",
       "2       123317182233  \n",
       "3         4615142168  \n",
       "4           54188097  \n",
       "...              ...  \n",
       "192717     276026737  \n",
       "192718     376517459  \n",
       "192719   95132301236  \n",
       "192720    2211405194  \n",
       "192721    6140115286  \n",
       "\n",
       "[192722 rows x 11 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat = pd.read_csv(f\"{word_lemma_data_path}/Visual_Genome_{file_ext}_Word_Lemma_Search_Result.csv\")\n",
    "df_genome_word_lemma_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2353566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2327286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2369214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2367685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>how is it</td>\n",
       "      <td>2340925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165590</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>the letters mi on the street sign</td>\n",
       "      <td>2386741</td>\n",
       "      <td>523121973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165591</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>coburg rd mi min inside right arrow</td>\n",
       "      <td>2366858</td>\n",
       "      <td>30110170180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165592</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>oakway shopping ctr mi min in right arrow</td>\n",
       "      <td>2366858</td>\n",
       "      <td>40162166213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165593</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>valley river center mi min straight ahead</td>\n",
       "      <td>2366858</td>\n",
       "      <td>40164166247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165594</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>black screen with mi little pony wallpaper</td>\n",
       "      <td>713408</td>\n",
       "      <td>235228428303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1432 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       POS1 POS2   word lemma.spacy stem word_en_translate lemma_en_translate  \\\n",
       "3187    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3188    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3189    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3190    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3191    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "...     ...  ...    ...         ...  ...               ...                ...   \n",
       "165590  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165591  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165592  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165593  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165594  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "\n",
       "        frequency                                 search_text  image_id  \\\n",
       "3187      5362714                                   who is it   2353566   \n",
       "3188      5362714                                   who is it   2327286   \n",
       "3189      5362714                                   who is it   2369214   \n",
       "3190      5362714                                   who is it   2367685   \n",
       "3191      5362714                                   how is it   2340925   \n",
       "...           ...                                         ...       ...   \n",
       "165590     388689           the letters mi on the street sign   2386741   \n",
       "165591     388689         coburg rd mi min inside right arrow   2366858   \n",
       "165592     388689   oakway shopping ctr mi min in right arrow   2366858   \n",
       "165593     388689   valley river center mi min straight ahead   2366858   \n",
       "165594     388689  black screen with mi little pony wallpaper    713408   \n",
       "\n",
       "                 num  \n",
       "3187               0  \n",
       "3188               0  \n",
       "3189               0  \n",
       "3190               0  \n",
       "3191               0  \n",
       "...              ...  \n",
       "165590     523121973  \n",
       "165591   30110170180  \n",
       "165592   40162166213  \n",
       "165593   40164166247  \n",
       "165594  235228428303  \n",
       "\n",
       "[1432 rows x 11 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat = df_genome_word_lemma_concat[df_genome_word_lemma_concat[\"POS1\"] == Pos_Tag]\n",
    "df_genome_word_lemma_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mi</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>misin</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>misiniz</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miydi</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miyim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>miyiz</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>musun</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>musunuz</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mü</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mı</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mısın</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mısınız</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mıydı</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  image_id\n",
       "0       ise      True\n",
       "1        mi      True\n",
       "2     misin      True\n",
       "3   misiniz      True\n",
       "4     miydi      True\n",
       "5     miyim      True\n",
       "6     miyiz      True\n",
       "7        mu      True\n",
       "8     musun      True\n",
       "9   musunuz      True\n",
       "10       mü      True\n",
       "11       mı      True\n",
       "12    mısın      True\n",
       "13  mısınız      True\n",
       "14    mıydı      True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat_select = df_genome_word_lemma_concat.groupby(\"word\")[\"image_id\"].apply(lambda x: x.count()>=select_image_num).reset_index()\n",
    "df_genome_word_lemma_concat_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select_list = df_genome_word_lemma_concat_select[df_genome_word_lemma_concat_select[\"image_id\"] == True][\"word\"].to_list()\n",
    "#word_select_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2353566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2327286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2369214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2367685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>5362714</td>\n",
       "      <td>how is it</td>\n",
       "      <td>2340925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165590</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>the letters mi on the street sign</td>\n",
       "      <td>2386741</td>\n",
       "      <td>523121973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165591</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>coburg rd mi min inside right arrow</td>\n",
       "      <td>2366858</td>\n",
       "      <td>30110170180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165592</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>oakway shopping ctr mi min in right arrow</td>\n",
       "      <td>2366858</td>\n",
       "      <td>40162166213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165593</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>valley river center mi min straight ahead</td>\n",
       "      <td>2366858</td>\n",
       "      <td>40164166247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165594</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miyim</td>\n",
       "      <td>mi</td>\n",
       "      <td>mi</td>\n",
       "      <td>am i</td>\n",
       "      <td>mi</td>\n",
       "      <td>388689</td>\n",
       "      <td>black screen with mi little pony wallpaper</td>\n",
       "      <td>713408</td>\n",
       "      <td>235228428303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1432 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       POS1 POS2   word lemma.spacy stem word_en_translate lemma_en_translate  \\\n",
       "3187    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3188    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3189    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3190    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "3191    AUX  NaN     mi          mi   mi             is it              is it   \n",
       "...     ...  ...    ...         ...  ...               ...                ...   \n",
       "165590  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165591  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165592  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165593  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "165594  AUX  NaN  miyim          mi   mi              am i                 mi   \n",
       "\n",
       "        frequency                                 search_text  image_id  \\\n",
       "3187      5362714                                   who is it   2353566   \n",
       "3188      5362714                                   who is it   2327286   \n",
       "3189      5362714                                   who is it   2369214   \n",
       "3190      5362714                                   who is it   2367685   \n",
       "3191      5362714                                   how is it   2340925   \n",
       "...           ...                                         ...       ...   \n",
       "165590     388689           the letters mi on the street sign   2386741   \n",
       "165591     388689         coburg rd mi min inside right arrow   2366858   \n",
       "165592     388689   oakway shopping ctr mi min in right arrow   2366858   \n",
       "165593     388689   valley river center mi min straight ahead   2366858   \n",
       "165594     388689  black screen with mi little pony wallpaper    713408   \n",
       "\n",
       "                 num  \n",
       "3187               0  \n",
       "3188               0  \n",
       "3189               0  \n",
       "3190               0  \n",
       "3191               0  \n",
       "...              ...  \n",
       "165590     523121973  \n",
       "165591   30110170180  \n",
       "165592   40162166213  \n",
       "165593   40164166247  \n",
       "165594  235228428303  \n",
       "\n",
       "[1432 rows x 11 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat_select_result = df_genome_word_lemma_concat[df_genome_word_lemma_concat[\"word\"].isin(word_select_list)]\n",
    "df_genome_word_lemma_concat_select_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(df_genome_word_lemma_concat_select_result[\"word\"]))\n",
    "lemma_list = list(set(df_genome_word_lemma_concat_select_result[\"lemma.spacy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>1425461</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2353566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>1425461</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2396694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>1425461</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2396926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>1425461</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2344879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>mu</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>1425461</td>\n",
       "      <td>who is it</td>\n",
       "      <td>2414956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>442313</td>\n",
       "      <td>is it turquoise icing decoration or turquoise ...</td>\n",
       "      <td>2391633</td>\n",
       "      <td>5511023530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>442313</td>\n",
       "      <td>someone else will know what the pole is for al...</td>\n",
       "      <td>2391989</td>\n",
       "      <td>140136203201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>442313</td>\n",
       "      <td>it could be a giraffe hard to tell whatever it...</td>\n",
       "      <td>2322521</td>\n",
       "      <td>3552189204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>442313</td>\n",
       "      <td>because of technique or feigned technique phot...</td>\n",
       "      <td>2369850</td>\n",
       "      <td>4604601819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>mü</td>\n",
       "      <td>is it</td>\n",
       "      <td>is it</td>\n",
       "      <td>442313</td>\n",
       "      <td>is it possible front elephant got ahold of a t...</td>\n",
       "      <td>2385390</td>\n",
       "      <td>3051303133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1432 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     POS1 POS2 word lemma.spacy stem word_en_translate lemma_en_translate  \\\n",
       "0     AUX  NaN   mu          mu   mu             is it              is it   \n",
       "1     AUX  NaN   mu          mu   mu             is it              is it   \n",
       "2     AUX  NaN   mu          mu   mu             is it              is it   \n",
       "3     AUX  NaN   mu          mu   mu             is it              is it   \n",
       "4     AUX  NaN   mu          mu   mu             is it              is it   \n",
       "...   ...  ...  ...         ...  ...               ...                ...   \n",
       "1427  AUX  NaN   mü          mü   mü             is it              is it   \n",
       "1428  AUX  NaN   mü          mü   mü             is it              is it   \n",
       "1429  AUX  NaN   mü          mü   mü             is it              is it   \n",
       "1430  AUX  NaN   mü          mü   mü             is it              is it   \n",
       "1431  AUX  NaN   mü          mü   mü             is it              is it   \n",
       "\n",
       "      frequency                                        search_text  image_id  \\\n",
       "0       1425461                                          who is it   2353566   \n",
       "1       1425461                                          who is it   2396694   \n",
       "2       1425461                                          who is it   2396926   \n",
       "3       1425461                                          who is it   2344879   \n",
       "4       1425461                                          who is it   2414956   \n",
       "...         ...                                                ...       ...   \n",
       "1427     442313  is it turquoise icing decoration or turquoise ...   2391633   \n",
       "1428     442313  someone else will know what the pole is for al...   2391989   \n",
       "1429     442313  it could be a giraffe hard to tell whatever it...   2322521   \n",
       "1430     442313  because of technique or feigned technique phot...   2369850   \n",
       "1431     442313  is it possible front elephant got ahold of a t...   2385390   \n",
       "\n",
       "               num  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1427    5511023530  \n",
       "1428  140136203201  \n",
       "1429    3552189204  \n",
       "1430    4604601819  \n",
       "1431    3051303133  \n",
       "\n",
       "[1432 rows x 11 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_sample_result = take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat_select_result, word_list, \"word\", \n",
    "                                                                    \"search_text\", sort_ascending=True, sample_num=take_image_sample_num)\n",
    "df_genome_sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_sample_result[\"word\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder\n",
    "# for word in word_list:\n",
    "#    path = f\"{output_path_folder}/ALL_{Pos_Tag}_FOLDER/{word}\"\n",
    "#    Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word\n",
    "#create_word_folder_and_copy_image(df_genome_sample_result, word_list, \"word\", \"image_id\", \"num\", image_path, mask_image_path ,output_path_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder\n",
    "for lemma in lemma_list:\n",
    "    path = f\"{output_path_folder}/ALL_{Pos_Tag}_FOLDER/{lemma}\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    df_var = df_genome_sample_result[df_genome_sample_result[\"lemma.spacy\"] == f\"{lemma}\"]\n",
    "    for word in set(df_var[\"word\"]):\n",
    "        path2 = f\"{path}/{word}\"\n",
    "        Path(path2).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lemma\n",
    "create_word_folder_and_copy_image(df_genome_sample_result, lemma_list, \"lemma.spacy\", \"image_id\", \"num\", image_path, mask_image_path ,output_path_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Result 1\n",
    "#df_genome_word_lemma_concat_coor = pd.read_csv(f\"{word_lemma_data_path2}/Visual_Genome_{file_ext}_Word_Lemma_Coordinate_Search_Result.csv\")\n",
    "#df_genome_word_lemma_concat_coor = df_genome_word_lemma_concat_coor.drop([\"height\",\"width\",\"x_koor\",\"y_koor\"], axis=1)\n",
    "#df_genome_word_lemma_concat_coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Result 2\n",
    "#df_genome_word_lemma_concat_select_result_coor_merge = pd.merge(df_genome_word_lemma_concat_select_result,df_genome_word_lemma_concat_coor,how=\"left\", on=[\"word\",\"image_id\",\"word_en_translate\",\"lemma_en_translate\",\"lemma.spacy\",\"stem\",\"num\"])\n",
    "##df_genome_word_lemma_concat_select_result_coor_merge = pd.merge(df_genome_word_lemma_concat, df_genome_word_lemma_concat_coor,how=\"left\", on=[\"word\",\"image_id\"])\n",
    "#df_genome_word_lemma_concat_select_result_coor_merge = df_genome_word_lemma_concat_select_result_coor_merge.drop_duplicates()\n",
    "##df_genome_word_lemma_concat_select_result_coor_merge[\"num\"] = df_genome_word_lemma_concat_select_result_coor_merge[\"num\"].fillna(0)\n",
    "#df_genome_word_lemma_concat_select_result_coor_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genome_word_lemma_concat_select_result_coor_merge[\"word\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_list = list(set(df_genome_word_lemma_concat_select_result_coor_merge[\"word\"]))\n",
    "#lemma_list = list(set(df_genome_word_lemma_concat_select_result_coor_merge[\"lemma.spacy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genome_sample_result = take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat_select_result_coor_merge, word_list, \"word\", \n",
    "#                                                                    \"search_text\", sort_ascending=True, sample_num=take_image_sample_num)\n",
    "#df_genome_sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genome_sample_result[\"word\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
