{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Word Images And Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemma_data_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-2-Word In Visual Genome Merge\"\n",
    "\n",
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-3-Find Word Images And Copy\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe(df, search_list, target_column, sample_num):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True).head(sample_num)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len()).head(sample_num)               \n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe_all(df, search_list, target_column):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len())\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)        \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50):\n",
    "    '''take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then sort_target_column is sorting according to sort_ascending condition.\\n\n",
    "    Finally, taking sample_num each word_list values.\\n \n",
    "    ex.\\n\n",
    "    take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat, word_list, \"word\", \"search_text\", sort_ascending=True, sample_num=50)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "        df_select = df_select.sort_values(f\"{sort_target_column}\",key=lambda x:x.str.len(), ascending=sort_ascending).head(sample_num)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Genome Word Lemma Translate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2390994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2348965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176316</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>airport check in kiosks</td>\n",
       "      <td>2317616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176317</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>red check of tablecloth</td>\n",
       "      <td>2400604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176318</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>a check is on the table</td>\n",
       "      <td>2386272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176319</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>cleats with white check</td>\n",
       "      <td>2371210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176320</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>check number on receipt</td>\n",
       "      <td>2404231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176321 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POS1 POS2     word lemma.spacy stem word_en_translate  \\\n",
       "0        NUM  NaN      bir         bir  bir                 a   \n",
       "1        NUM  NaN      bir         bir  bir                 a   \n",
       "2        NUM  NaN      bir         bir  bir                 a   \n",
       "3        NUM  NaN      bir         bir  bir                 a   \n",
       "4        NUM  NaN      bir         bir  bir                 a   \n",
       "...      ...  ...      ...         ...  ...               ...   \n",
       "176316  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176317  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176318  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176319  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176320  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "\n",
       "       lemma_en_translate  frequency              search_text  image_id  \n",
       "0                       a   18835735                        a   2390994  \n",
       "1                       a   18835735                        a   2348965  \n",
       "2                       a   18835735                        a   2349861  \n",
       "3                       a   18835735                        a   2349866  \n",
       "4                       a   18835735                        a   2349935  \n",
       "...                   ...        ...                      ...       ...  \n",
       "176316              check      69201  airport check in kiosks   2317616  \n",
       "176317              check      69201  red check of tablecloth   2400604  \n",
       "176318              check      69201  a check is on the table   2386272  \n",
       "176319              check      69201  cleats with white check   2371210  \n",
       "176320              check      69201  check number on receipt   2404231  \n",
       "\n",
       "[176321 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat = pd.read_csv(f\"{word_lemma_data_path}/Visual_Genome_Word_Lemma_Search_Result.csv\")\n",
    "df_genome_word_lemma_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_concat[\"word\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(df_genome_word_lemma_concat[\"word\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>141855</td>\n",
       "      <td>what game is this</td>\n",
       "      <td>2368584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>141855</td>\n",
       "      <td>what game is this</td>\n",
       "      <td>2410005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>141855</td>\n",
       "      <td>what game is this</td>\n",
       "      <td>2344299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>141855</td>\n",
       "      <td>what game is this</td>\n",
       "      <td>2366019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>oyun</td>\n",
       "      <td>game</td>\n",
       "      <td>game</td>\n",
       "      <td>141855</td>\n",
       "      <td>what game is this</td>\n",
       "      <td>2366116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44365</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendime</td>\n",
       "      <td>kendi</td>\n",
       "      <td>kendi</td>\n",
       "      <td>to myself</td>\n",
       "      <td>own</td>\n",
       "      <td>72384</td>\n",
       "      <td>a brown own on a wood vase</td>\n",
       "      <td>2399061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44366</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendime</td>\n",
       "      <td>kendi</td>\n",
       "      <td>kendi</td>\n",
       "      <td>to myself</td>\n",
       "      <td>own</td>\n",
       "      <td>72384</td>\n",
       "      <td>the bird s own reflection</td>\n",
       "      <td>2410947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44367</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendime</td>\n",
       "      <td>kendi</td>\n",
       "      <td>kendi</td>\n",
       "      <td>to myself</td>\n",
       "      <td>own</td>\n",
       "      <td>72384</td>\n",
       "      <td>what animal is on its own</td>\n",
       "      <td>2391761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44368</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendime</td>\n",
       "      <td>kendi</td>\n",
       "      <td>kendi</td>\n",
       "      <td>to myself</td>\n",
       "      <td>own</td>\n",
       "      <td>72384</td>\n",
       "      <td>who own the dog and horse</td>\n",
       "      <td>2398506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44369</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kendime</td>\n",
       "      <td>kendi</td>\n",
       "      <td>kendi</td>\n",
       "      <td>to myself</td>\n",
       "      <td>own</td>\n",
       "      <td>72384</td>\n",
       "      <td>who has hands on own hips</td>\n",
       "      <td>107902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44370 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       POS1 POS2     word lemma.spacy   stem word_en_translate  \\\n",
       "0      NOUN  NaN     oyun        oyun   oyun              game   \n",
       "1      NOUN  NaN     oyun        oyun   oyun              game   \n",
       "2      NOUN  NaN     oyun        oyun   oyun              game   \n",
       "3      NOUN  NaN     oyun        oyun   oyun              game   \n",
       "4      NOUN  NaN     oyun        oyun   oyun              game   \n",
       "...     ...  ...      ...         ...    ...               ...   \n",
       "44365  NOUN  NaN  kendime       kendi  kendi         to myself   \n",
       "44366  NOUN  NaN  kendime       kendi  kendi         to myself   \n",
       "44367  NOUN  NaN  kendime       kendi  kendi         to myself   \n",
       "44368  NOUN  NaN  kendime       kendi  kendi         to myself   \n",
       "44369  NOUN  NaN  kendime       kendi  kendi         to myself   \n",
       "\n",
       "      lemma_en_translate  frequency                 search_text  image_id  \n",
       "0                   game     141855           what game is this   2368584  \n",
       "1                   game     141855           what game is this   2410005  \n",
       "2                   game     141855           what game is this   2344299  \n",
       "3                   game     141855           what game is this   2366019  \n",
       "4                   game     141855           what game is this   2366116  \n",
       "...                  ...        ...                         ...       ...  \n",
       "44365                own      72384  a brown own on a wood vase   2399061  \n",
       "44366                own      72384   the bird s own reflection   2410947  \n",
       "44367                own      72384   what animal is on its own   2391761  \n",
       "44368                own      72384   who own the dog and horse   2398506  \n",
       "44369                own      72384   who has hands on own hips    107902  \n",
       "\n",
       "[44370 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_result = take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat, word_list, \"word\", \"search_text\", sort_ascending=True, sample_num=50)\n",
    "df_sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, output_path_folder):\n",
    "    '''take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then sort_target_column is sorting according to sort_ascending condition.\\n\n",
    "    Finally, taking sample_num each word_list values.\\n \n",
    "    ex.\\n\n",
    "    take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat, word_list, \"word\", \"search_text\", sort_ascending=True, sample_num=50)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        path = f\"{output_path_folder}/{word}\"\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)        \n",
    "        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "        for image_id in df_select[f\"{image_id_column}\"]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visual_Genome_Question_Answers_Word_Result2.csv',\n",
       " 'Visual_Genome_Question_Answers_Lemma_Result2.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"Visual_Genome_*_Result*.csv\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file:\n",
    "    source = l # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
