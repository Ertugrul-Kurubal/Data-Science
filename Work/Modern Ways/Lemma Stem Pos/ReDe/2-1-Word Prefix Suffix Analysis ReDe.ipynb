{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Prefix Suffix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from kneed import KneeLocator\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian\n",
    "\n",
    "# pre-suffix select\n",
    "prefix = False  # True, False  word is prefix  example: prefix = True and suffix = False for Turkish word\n",
    "suffix = True # True, False  word is suffix\n",
    "\n",
    "# native word select\n",
    "file_ext = 1000\n",
    "word_start = 1000  # 0  # native word start index\n",
    "word_end = 5000  # 28  # native word end index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/2-1-Word Prefix Suffix Analysis\"\n",
    "\n",
    "#Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_prefix_suffix_word(df, df_column, word_list, prefix_word=True, suffix_word=False):\n",
    "    '''\n",
    "    default parameter:\\n\n",
    "    detect_prefix_suffix_word(df, df_column, word_ety_list, prefix_word=True, suffix_word=False)\\n\n",
    "    detect_prefix_suffix_word(df, \"word\", [\"abacus\",\"aba\",\"su\"], prefix=True, suffix=True)\\n\n",
    "    df is dataframe. Each word of word_ety_list search in df_column according to prefix_word and suffix_word condition.\\n\n",
    "    prefix_word and suffix_word are not extention. they represents location of word of word_ety_list (word before or after)\n",
    "    '''    \n",
    "    df_prefix_suffix_word_result = pd.DataFrame()\n",
    "    for i in word_list:\n",
    "        # suffix result\n",
    "        if prefix_word:\n",
    "            word_in_word = df[df[f\"{df_column}\"].str.contains(fr\"{i}(?:$)\", na=True)]  # string+ext=> word\n",
    "            word_in_word.insert(0,\"search_word\",i)\n",
    "            df_prefix_suffix_word_result = pd.concat([df_prefix_suffix_word_result, word_in_word], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "        # prefix result\n",
    "        if suffix_word:\n",
    "            word_in_word = df[df[f\"{df_column}\"].str.contains(fr\"(?:^){i}\", na=True)]  # ext+string=> word\n",
    "            word_in_word.insert(0,\"search_word\",i)\n",
    "            df_prefix_suffix_word_result = pd.concat([df_prefix_suffix_word_result, word_in_word], axis=0)\n",
    "        else:\n",
    "            pass    \n",
    "        \n",
    "    #df_ety_suffix_word_result = df_word_result.sort_values(by=\"frequency\", ascending=False)\n",
    "    df_prefix_suffix_word_result.drop_duplicates(inplace=True)\n",
    "    df_prefix_suffix_word_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_prefix_suffix_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exract_prefix_suffix(df, source_column, target_column):\n",
    "    '''\n",
    "    exract_prefix_suffix(df, source_column, target_column):\\n\n",
    "    exract_prefix_suffix(df, \"word_pair\", \"word\"):\\n\n",
    "    df is dataframe. word of source_column search in target_column\\n\n",
    "    and exract prefix or suffix. \n",
    "    '''\n",
    "    for i in range(len(df)):\n",
    "        source_word = df.loc[i,f\"{source_column}\"]\n",
    "        target_word = df.loc[i,f\"{target_column}\"]\n",
    "        try:\n",
    "            search_loc = re.search(fr\"{source_word}\", target_word, re.UNICODE|re.IGNORECASE)\n",
    "            search_loc_start = search_loc.span()[0]\n",
    "            search_loc_end = search_loc.span()[1]\n",
    "            if search_loc_start > 0:\n",
    "                var1= target_word[0:search_loc_start]\n",
    "                prefix_suffix = f\"{var1}+\"\n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix                \n",
    "            else:\n",
    "                var2 = target_word[search_loc_end:]\n",
    "                prefix_suffix = f\"+{var2}\" \n",
    "                df.loc[i,\"prefix_suffix\"] = prefix_suffix \n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_Tag = \"VERB\" # NOUN, VERB (ol, var stem ayrı), ADJ, ADV, NUM, PRON, CCONJ, ADP, AUX \n",
    "file_ext = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bu</td>\n",
       "      <td>bu</td>\n",
       "      <td>bu</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRON</td>\n",
       "      <td>Q</td>\n",
       "      <td>ne</td>\n",
       "      <td>ne</td>\n",
       "      <td>ne</td>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ve</td>\n",
       "      <td>ve</td>\n",
       "      <td>ve</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>için</td>\n",
       "      <td>için</td>\n",
       "      <td>için</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resmi</td>\n",
       "      <td>resmi</td>\n",
       "      <td>resmi</td>\n",
       "      <td>formal</td>\n",
       "      <td>formal</td>\n",
       "      <td>68287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyor</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>giving</td>\n",
       "      <td>give</td>\n",
       "      <td>68163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okul</td>\n",
       "      <td>okul</td>\n",
       "      <td>oku</td>\n",
       "      <td>school</td>\n",
       "      <td>school</td>\n",
       "      <td>68160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suçlu</td>\n",
       "      <td>suç</td>\n",
       "      <td>suç</td>\n",
       "      <td>guilty</td>\n",
       "      <td>crime</td>\n",
       "      <td>68124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mesela</td>\n",
       "      <td>mesela</td>\n",
       "      <td>mesela</td>\n",
       "      <td>for example</td>\n",
       "      <td>for example</td>\n",
       "      <td>68096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS1 POS2     word lemma.spacy    stem word_en_translate  \\\n",
       "0      NUM  NaN      bir         bir     bir                 a   \n",
       "1     PRON  NaN       bu          bu      bu              this   \n",
       "2     PRON    Q       ne          ne      ne              what   \n",
       "3    CCONJ  NaN       ve          ve      ve               and   \n",
       "4      ADP  NaN     için        için    için               for   \n",
       "..     ...  ...      ...         ...     ...               ...   \n",
       "995    ADJ  NaN    resmi       resmi   resmi            formal   \n",
       "996   VERB  NaN  veriyor         ver     ver            giving   \n",
       "997   NOUN  NaN     okul        okul     oku            school   \n",
       "998   NOUN  NaN    suçlu         suç     suç            guilty   \n",
       "999    ADV  NaN   mesela      mesela  mesela       for example   \n",
       "\n",
       "    lemma_en_translate  frequency  \n",
       "0                    a   18835735  \n",
       "1                 this   11062659  \n",
       "2                 what    8025880  \n",
       "3                  and    7766036  \n",
       "4                  for    5484109  \n",
       "..                 ...        ...  \n",
       "995             formal      68287  \n",
       "996               give      68163  \n",
       "997             school      68160  \n",
       "998              crime      68124  \n",
       "999        for example      68096  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_raw = pd.read_excel(f\"Turkish_{file_ext}_Process.xlsx\")\n",
    "df_word_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>4389551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NEG</td>\n",
       "      <td>yok</td>\n",
       "      <td>yok</td>\n",
       "      <td>yok</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>2491685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oldu</td>\n",
       "      <td>ol</td>\n",
       "      <td>ol</td>\n",
       "      <td>happened</td>\n",
       "      <td>be</td>\n",
       "      <td>1141161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bak</td>\n",
       "      <td>bak</td>\n",
       "      <td>bak</td>\n",
       "      <td>look</td>\n",
       "      <td>look</td>\n",
       "      <td>1016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>istiyorum</td>\n",
       "      <td>iste</td>\n",
       "      <td>iste</td>\n",
       "      <td>i want</td>\n",
       "      <td>want</td>\n",
       "      <td>978284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gider</td>\n",
       "      <td>git</td>\n",
       "      <td>git</td>\n",
       "      <td>goes</td>\n",
       "      <td>go</td>\n",
       "      <td>68755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konuş</td>\n",
       "      <td>konuş</td>\n",
       "      <td>konuş</td>\n",
       "      <td>talk</td>\n",
       "      <td>talk</td>\n",
       "      <td>68652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>find</td>\n",
       "      <td>find</td>\n",
       "      <td>68524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edeyim</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>let me</td>\n",
       "      <td>do</td>\n",
       "      <td>68506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyor</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>giving</td>\n",
       "      <td>give</td>\n",
       "      <td>68163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     POS1 POS2       word lemma.spacy   stem word_en_translate  \\\n",
       "11   VERB  NaN        var         var    var      there is/are   \n",
       "22   VERB  NEG        yok         yok    yok              none   \n",
       "55   VERB  NaN       oldu          ol     ol          happened   \n",
       "64   VERB  NaN        bak         bak    bak              look   \n",
       "65   VERB  NaN  istiyorum        iste   iste            i want   \n",
       "..    ...  ...        ...         ...    ...               ...   \n",
       "986  VERB  NaN      gider         git    git              goes   \n",
       "988  VERB  NaN      konuş       konuş  konuş              talk   \n",
       "991  VERB  NaN        bul         bul    bul              find   \n",
       "992  VERB  NaN     edeyim          et     et            let me   \n",
       "996  VERB  NaN    veriyor         ver    ver            giving   \n",
       "\n",
       "    lemma_en_translate  frequency  \n",
       "11        there is/are    4389551  \n",
       "22                none    2491685  \n",
       "55                  be    1141161  \n",
       "64                look    1016510  \n",
       "65                want     978284  \n",
       "..                 ...        ...  \n",
       "986                 go      68755  \n",
       "988               talk      68652  \n",
       "991               find      68524  \n",
       "992                 do      68506  \n",
       "996               give      68163  \n",
       "\n",
       "[283 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_raw_select = df_word_raw[df_word_raw[\"POS1\"] == Pos_Tag]\n",
    "df_word_raw_select = df_word_raw_select.drop_duplicates(subset=[\"word\"])\n",
    "df_word_raw_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word_raw_select[\"word\"].values.tolist()\n",
    "#word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>4389551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vardı</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there was</td>\n",
       "      <td>there is</td>\n",
       "      <td>451341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vardır</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there is</td>\n",
       "      <td>there is</td>\n",
       "      <td>199869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>varsa</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>if any</td>\n",
       "      <td>there is</td>\n",
       "      <td>138931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>varmış</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there was</td>\n",
       "      <td>there is</td>\n",
       "      <td>118304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>bul</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bulduk</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>we found</td>\n",
       "      <td>find</td>\n",
       "      <td>77535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>bul</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>find</td>\n",
       "      <td>find</td>\n",
       "      <td>68524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>edeyim</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edeyim</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>let me</td>\n",
       "      <td>do</td>\n",
       "      <td>68506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyorum</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>i give</td>\n",
       "      <td>give</td>\n",
       "      <td>126290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyor</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>giving</td>\n",
       "      <td>give</td>\n",
       "      <td>68163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_word  POS1 POS2       word lemma.spacy stem word_en_translate  \\\n",
       "0           var  VERB  NaN        var         var  var      there is/are   \n",
       "1           var  VERB  NaN      vardı         var  var         there was   \n",
       "2           var  VERB  NaN     vardır         var  var          there is   \n",
       "3           var  VERB  NaN      varsa         var  var            if any   \n",
       "4           var  VERB  NaN     varmış         var  var         there was   \n",
       "..          ...   ...  ...        ...         ...  ...               ...   \n",
       "500         bul  VERB  NaN     bulduk         bul  bul          we found   \n",
       "501         bul  VERB  NaN        bul         bul  bul              find   \n",
       "502      edeyim  VERB  NaN     edeyim          et   et            let me   \n",
       "503     veriyor  VERB  NaN  veriyorum         ver  ver            i give   \n",
       "504     veriyor  VERB  NaN    veriyor         ver  ver            giving   \n",
       "\n",
       "    lemma_en_translate  frequency  \n",
       "0         there is/are    4389551  \n",
       "1             there is     451341  \n",
       "2             there is     199869  \n",
       "3             there is     138931  \n",
       "4             there is     118304  \n",
       "..                 ...        ...  \n",
       "500               find      77535  \n",
       "501               find      68524  \n",
       "502                 do      68506  \n",
       "503               give     126290  \n",
       "504               give      68163  \n",
       "\n",
       "[505 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prefix_suffix_word = detect_prefix_suffix_word(df_word_raw_select, \"word\", word_list, prefix_word=prefix, suffix_word=suffix)\n",
    "df_prefix_suffix_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>prefix_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>there is/are</td>\n",
       "      <td>4389551</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vardı</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there was</td>\n",
       "      <td>there is</td>\n",
       "      <td>451341</td>\n",
       "      <td>+dı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vardır</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there is</td>\n",
       "      <td>there is</td>\n",
       "      <td>199869</td>\n",
       "      <td>+dır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>varsa</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>if any</td>\n",
       "      <td>there is</td>\n",
       "      <td>138931</td>\n",
       "      <td>+sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>varmış</td>\n",
       "      <td>var</td>\n",
       "      <td>var</td>\n",
       "      <td>there was</td>\n",
       "      <td>there is</td>\n",
       "      <td>118304</td>\n",
       "      <td>+mış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>bul</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bulduk</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>we found</td>\n",
       "      <td>find</td>\n",
       "      <td>77535</td>\n",
       "      <td>+duk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>bul</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>bul</td>\n",
       "      <td>find</td>\n",
       "      <td>find</td>\n",
       "      <td>68524</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>edeyim</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edeyim</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>let me</td>\n",
       "      <td>do</td>\n",
       "      <td>68506</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyorum</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>i give</td>\n",
       "      <td>give</td>\n",
       "      <td>126290</td>\n",
       "      <td>+um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>veriyor</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>veriyor</td>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>giving</td>\n",
       "      <td>give</td>\n",
       "      <td>68163</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_word  POS1 POS2       word lemma.spacy stem word_en_translate  \\\n",
       "0           var  VERB  NaN        var         var  var      there is/are   \n",
       "1           var  VERB  NaN      vardı         var  var         there was   \n",
       "2           var  VERB  NaN     vardır         var  var          there is   \n",
       "3           var  VERB  NaN      varsa         var  var            if any   \n",
       "4           var  VERB  NaN     varmış         var  var         there was   \n",
       "..          ...   ...  ...        ...         ...  ...               ...   \n",
       "500         bul  VERB  NaN     bulduk         bul  bul          we found   \n",
       "501         bul  VERB  NaN        bul         bul  bul              find   \n",
       "502      edeyim  VERB  NaN     edeyim          et   et            let me   \n",
       "503     veriyor  VERB  NaN  veriyorum         ver  ver            i give   \n",
       "504     veriyor  VERB  NaN    veriyor         ver  ver            giving   \n",
       "\n",
       "    lemma_en_translate  frequency prefix_suffix  \n",
       "0         there is/are    4389551             +  \n",
       "1             there is     451341           +dı  \n",
       "2             there is     199869          +dır  \n",
       "3             there is     138931           +sa  \n",
       "4             there is     118304          +mış  \n",
       "..                 ...        ...           ...  \n",
       "500               find      77535          +duk  \n",
       "501               find      68524             +  \n",
       "502                 do      68506             +  \n",
       "503               give     126290           +um  \n",
       "504               give      68163             +  \n",
       "\n",
       "[505 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prefix_suffix = exract_prefix_suffix(df_prefix_suffix_word, \"search_word\", \"word\")\n",
    "df_prefix_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prefix_suffix.search_word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prefix_suffix.word.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_5000_Word_Prefix_Suffix_Custom_Result.xlsx']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file1 = glob.glob(f\"Prefix_Suffix_*Result.*\")\n",
    "output_file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file1:\n",
    "    source = k # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file1:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turkish_English_5000_Word_Prefix_Suffix_All.csv',\n",
       " 'Turkish_English_5000_Word_Prefix_Suffix_Select.xlsx']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file2 = glob.glob(f\"{lang_folder.capitalize()}_{lang_pair.capitalize()}_*_Prefix_Suffix_*.*\")\n",
    "output_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file2:\n",
    "    source = l # source directory\n",
    "    destination = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Data/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}\"\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file2:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat Native And Etymology Prefix Suffix Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian, Intersect ==> native language\n",
    "\n",
    "# file extention\n",
    "file_ext = 1000  # native word number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_strip(x):\n",
    "    try:\n",
    "        var_low = x.lower()\n",
    "        var_out = var_low.strip()\n",
    "    except:\n",
    "        var_out = x\n",
    "    return var_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish English/Turkish_English_200_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_file = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{file_ext}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "native_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>adama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeyler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylerden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeyleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>şey</td>\n",
       "      <td>şeylerin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1623 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word       word\n",
       "0           adam       adam\n",
       "1           adam      adama\n",
       "2           adam    adamdan\n",
       "3           adam     adamdı\n",
       "4           adam    adamdır\n",
       "...          ...        ...\n",
       "1618         şey     şeyler\n",
       "1619         şey  şeylerden\n",
       "1620         şey    şeylere\n",
       "1621         şey    şeyleri\n",
       "1622         şey   şeylerin\n",
       "\n",
       "[1623 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native = pd.read_excel(native_file[0])\n",
    "df_native = df_native[[\"search_word\",\"word\"]]\n",
    "df_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish English/Turkish_English_Shared_Word_Prefix_Suffix_Custom_Result.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etymology_file = glob.glob(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} {lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_Shared_Word_Prefix_Suffix_Custom_Result.xlsx\")\n",
    "etymology_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaküs</td>\n",
       "      <td>abaküs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandone</td>\n",
       "      <td>abandoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abanoz</td>\n",
       "      <td>abanoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>abdomende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abluka</td>\n",
       "      <td>abluka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0         abaküs      abaküs\n",
       "1       abandone   abandoned\n",
       "2         abanoz      abanoz\n",
       "3        abdomen   abdomende\n",
       "4         abluka      abluka\n",
       "...          ...         ...\n",
       "6188         şut        şutu\n",
       "6189         şut      şutunu\n",
       "6190     şırınga     şırınga\n",
       "6191     şırınga  şırıngayla\n",
       "6192     şırınga   şırıngayı\n",
       "\n",
       "[6193 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etmology = pd.read_excel(etymology_file[0])\n",
    "df_etmology = df_etmology[[\"search_word\",\"word\"]]\n",
    "df_etmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>adama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0           adam        adam\n",
       "1           adam       adama\n",
       "2           adam     adamdan\n",
       "3           adam      adamdı\n",
       "4           adam     adamdır\n",
       "...          ...         ...\n",
       "6188         şut        şutu\n",
       "6189         şut      şutunu\n",
       "6190     şırınga     şırınga\n",
       "6191     şırınga  şırıngayla\n",
       "6192     şırınga   şırıngayı\n",
       "\n",
       "[7816 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native_etymology_concat = pd.concat([df_native,df_etmology], axis=0)\n",
    "df_native_etymology_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_word</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>adama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>adamdır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7811</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>şut</td>\n",
       "      <td>şutunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırınga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>şırınga</td>\n",
       "      <td>şırıngayı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     search_word        word\n",
       "0           adam        adam\n",
       "1           adam       adama\n",
       "2           adam     adamdan\n",
       "3           adam      adamdı\n",
       "4           adam     adamdır\n",
       "...          ...         ...\n",
       "7811         şut        şutu\n",
       "7812         şut      şutunu\n",
       "7813     şırınga     şırınga\n",
       "7814     şırınga  şırıngayla\n",
       "7815     şırınga   şırıngayı\n",
       "\n",
       "[7816 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_native_etymology_concat[\"search_word\"] = df_native_etymology_concat[\"search_word\"].apply(lambda x : lower_strip(x))\n",
    "df_native_etymology_concat[\"word\"] = df_native_etymology_concat[\"word\"].apply(lambda x : lower_strip(x))\n",
    "df_native_etymology_concat.drop_duplicates(inplace=True)\n",
    "df_native_etymology_concat.reset_index(drop=True, inplace=True)\n",
    "df_native_etymology_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_native_etymology_concat.to_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()} \\\n",
    "{lang_pair.capitalize()}/{lang_folder.capitalize()}_{lang_pair.capitalize()}_{file_ext}_Native_And_Shared_Word_Prefix_Suffix_Custom_Concat.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English, French, German, Spanish, Portuguese, Dutch, Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair1 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish English/Turkish_English_Shared_Vocabulary.xlsx\")\n",
    "#df_pair1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair2 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish French/Turkish_French_Shared_Vocabulary.xlsx\")\n",
    "#df_pair2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair3 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish German/Turkish_German_Shared_Vocabulary.xlsx\")\n",
    "#df_pair3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair4 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Spanish/Turkish_Spanish_Shared_Vocabulary.xlsx\")\n",
    "#df_pair4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair5 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Portuguese/Turkish_Portuguese_Shared_Vocabulary.xlsx\")\n",
    "#df_pair5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair6 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Dutch/Turkish_Dutch_Shared_Vocabulary.xlsx\")\n",
    "#df_pair6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair7 = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/\\\n",
    "#Turkish Italian/Turkish_Italian_Shared_Vocabulary.xlsx\")\n",
    "#df_pair7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set1 = set(df_pair1.dict_entry_main)\n",
    "#set2 = set(df_pair2.dict_entry_main)\n",
    "#set3 = set(df_pair3.dict_entry_main)\n",
    "#set4 = set(df_pair4.dict_entry_main)\n",
    "#set5 = set(df_pair5.dict_entry_main)\n",
    "#set6 = set(df_pair6.dict_entry_main)\n",
    "#set7 = set(df_pair7.dict_entry_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ety_intersect = pd.DataFrame((((((set7.intersection(set6)).intersection(set5)).intersection(set4)).intersection(set3)).intersection(set2)).intersection(set1), columns=[\"dict_entry_main\"])\n",
    "#df_ety_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ety_intersect.to_excel(\"Turkish_Intersect_Shared_Vocabulary.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_intersect = pd.read_excel(\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/Turkish/Turkish Intersect/Turkish_Intersect_Shared_Vocabulary.xlsx\")\n",
    "#df_intersect  # English, French, German, Spanish, Portuguese, Dutch, Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair1_merge = pd.merge(df_intersect,df_pair1, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair1_merge.drop_duplicates(inplace=True)\n",
    "#df_pair1_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair2_merge = pd.merge(df_pair1_merge,df_pair2, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair2_merge.drop_duplicates(inplace=True)\n",
    "#df_pair2_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair3_merge = pd.merge(df_pair2_merge,df_pair3, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair3_merge.drop_duplicates(inplace=True)\n",
    "#df_pair3_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair4_merge = pd.merge(df_pair3_merge,df_pair4, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair4_merge.drop_duplicates(inplace=True)\n",
    "#df_pair4_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair5_merge = pd.merge(df_pair4_merge,df_pair5, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair5_merge.drop_duplicates(inplace=True)\n",
    "#df_pair5_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair6_merge = pd.merge(df_pair5_merge,df_pair6, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair6_merge.drop_duplicates(inplace=True)\n",
    "#df_pair6_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair7_merge = pd.merge(df_pair6_merge,df_pair7, how=\"left\", on=\"dict_entry_main\")\n",
    "#df_pair7_merge.drop_duplicates(inplace=True)\n",
    "#df_pair7_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair7_merge.rename(columns={\"dict_entry_main\":\"turkish_word_intersect\"}, inplace=True)\n",
    "#df_pair7_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pair7_merge.to_excel(\"Turkish_Intersect_Shared_Vocabulary_With_Other_Languages.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
