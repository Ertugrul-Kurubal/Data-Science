{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Word Images Mask Fade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"English\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemma_all_data_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-2-Word In Visual Genome Merge\"\n",
    "\n",
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Lemma Stem POS/Result/3-4-Find Word Images Mask Fade\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe(df, search_list, target_column, sample_num):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True).head(sample_num)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len()).head(sample_num)               \n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_group_dataframe_all(df, search_list, target_column):\n",
    "    '''\n",
    "    word_group_dataframe(df_youtube_sentence, search_list, \"sentence\", 6)\\n\n",
    "    df_youtube_sentence is dataframe and \"sentence\" is its column for external searching_list\n",
    "    ''' \n",
    "    df_search_result = pd.DataFrame()\n",
    "    for j in search_list:\n",
    "        df_select = df[df[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){j}(?:\\s|$)\", na=False, regex=True)]\n",
    "        #df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len(), inplace=True)\n",
    "        df_select = df_select.sort_values(f\"{target_column}\",key=lambda x:x.str.len())\n",
    "        df_select.insert(0,\"search_string\",j)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)        \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50):\n",
    "    '''take_dataframe_word_sample_from_sorting(df_source, word_list, word_source_column, sort_target_column, sort_ascending=True, sample_num=50)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then sort_target_column is sorting according to sort_ascending condition.\\n\n",
    "    Finally, taking sample_num each word_list values.\\n \n",
    "    ex.\\n\n",
    "    take_dataframe_word_sample_from_sorting(df_genome_word_lemma_concat, word_list, \"word\", \"search_text\", sort_ascending=True, sample_num=50)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "        df_select = df_select.sort_values(f\"{sort_target_column}\",key=lambda x:x.str.len(), ascending=sort_ascending).head(sample_num)\n",
    "        df_search_result = pd.concat([df_search_result,df_select], axis=0)\n",
    "    \n",
    "    df_search_result.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, image_folder_path, output_path_folder):\n",
    "    '''create_word_folder_and_copy_image(df_source, word_list, word_source_column, image_id_column, image_folder_path, output_path_folder)\\n\n",
    "    df_source is a dataframe and word_list is equal in word_source_column. Then word image id search in image_id_column and image copy to\\n\n",
    "    output_path_folder from image_folder_path.\\n\n",
    "    ex.\\n\n",
    "    image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images\"\\n\n",
    "    output_path_folder = \"/home/kurubal/Downloads/temp folder\"\\n\n",
    "    create_word_folder_and_copy_image(df_sample_result, word_list, \"word\", \"image_id\", image_path, output_path_folder)\n",
    "    '''\n",
    "    df_search_result = pd.DataFrame()\n",
    "    for word in word_list:\n",
    "        path = f\"{output_path_folder}/{word}\"\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)        \n",
    "        df_select = df_source[df_source[f\"{word_source_column}\"] == word]\n",
    "        for image_id in df_select[f\"{image_id_column}\"]:\n",
    "            image_file = glob.glob(f\"{image_folder_path}/*/{image_id}.jpg\")\n",
    "            for l in image_file:\n",
    "                source = l # source directory\n",
    "                destination = path\n",
    "                shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Lemma Stem POS/Data/Visual Genome/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Lemma Stem POS/Data/Visual Genome/images/VG_100K',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Lemma Stem POS/Data/Visual Genome/images/VG_100K_2']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder_list = glob.glob(f\"{image_path}/*\")\n",
    "image_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_folder = \"/home/kurubal/Downloads/temp folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Genome Word Lemma All Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2390994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2348965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>bir</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>18835735</td>\n",
       "      <td>a</td>\n",
       "      <td>2349935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176316</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>airport check in kiosks</td>\n",
       "      <td>2317616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176317</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>red check of tablecloth</td>\n",
       "      <td>2400604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176318</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>a check is on the table</td>\n",
       "      <td>2386272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176319</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>cleats with white check</td>\n",
       "      <td>2371210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176320</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>çekilin</td>\n",
       "      <td>çek</td>\n",
       "      <td>çek</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>check</td>\n",
       "      <td>69201</td>\n",
       "      <td>check number on receipt</td>\n",
       "      <td>2404231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176321 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POS1 POS2     word lemma.spacy stem word_en_translate  \\\n",
       "0        NUM  NaN      bir         bir  bir                 a   \n",
       "1        NUM  NaN      bir         bir  bir                 a   \n",
       "2        NUM  NaN      bir         bir  bir                 a   \n",
       "3        NUM  NaN      bir         bir  bir                 a   \n",
       "4        NUM  NaN      bir         bir  bir                 a   \n",
       "...      ...  ...      ...         ...  ...               ...   \n",
       "176316  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176317  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176318  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176319  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "176320  VERB  NaN  çekilin         çek  çek          withdraw   \n",
       "\n",
       "       lemma_en_translate  frequency              search_text  image_id  \n",
       "0                       a   18835735                        a   2390994  \n",
       "1                       a   18835735                        a   2348965  \n",
       "2                       a   18835735                        a   2349861  \n",
       "3                       a   18835735                        a   2349866  \n",
       "4                       a   18835735                        a   2349935  \n",
       "...                   ...        ...                      ...       ...  \n",
       "176316              check      69201  airport check in kiosks   2317616  \n",
       "176317              check      69201  red check of tablecloth   2400604  \n",
       "176318              check      69201  a check is on the table   2386272  \n",
       "176319              check      69201  cleats with white check   2371210  \n",
       "176320              check      69201  check number on receipt   2404231  \n",
       "\n",
       "[176321 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genome_word_lemma_all_category_concat = pd.read_csv(f\"\")\n",
    "df_genome_word_lemma_all_category_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visual_Genome_Question_Answers_Word_Result2.csv',\n",
       " 'Visual_Genome_Question_Answers_Lemma_Result2.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = glob.glob(f\"\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in output_file:\n",
    "    source = l # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in output_file:\n",
    "    try:\n",
    "        os.remove(j)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma.spacy</th>\n",
       "      <th>stem</th>\n",
       "      <th>word_en_translate</th>\n",
       "      <th>lemma_en_translate</th>\n",
       "      <th>frequency</th>\n",
       "      <th>search_text</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üstünde</td>\n",
       "      <td>üst</td>\n",
       "      <td>üst</td>\n",
       "      <td>above</td>\n",
       "      <td>top</td>\n",
       "      <td>86801</td>\n",
       "      <td>top</td>\n",
       "      <td>2371537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üstünde</td>\n",
       "      <td>üst</td>\n",
       "      <td>üst</td>\n",
       "      <td>above</td>\n",
       "      <td>top</td>\n",
       "      <td>86801</td>\n",
       "      <td>top</td>\n",
       "      <td>2328281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üstünde</td>\n",
       "      <td>üst</td>\n",
       "      <td>üst</td>\n",
       "      <td>above</td>\n",
       "      <td>top</td>\n",
       "      <td>86801</td>\n",
       "      <td>top</td>\n",
       "      <td>2328272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üstünde</td>\n",
       "      <td>üst</td>\n",
       "      <td>üst</td>\n",
       "      <td>above</td>\n",
       "      <td>top</td>\n",
       "      <td>86801</td>\n",
       "      <td>top</td>\n",
       "      <td>2328221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üstünde</td>\n",
       "      <td>üst</td>\n",
       "      <td>üst</td>\n",
       "      <td>above</td>\n",
       "      <td>top</td>\n",
       "      <td>86801</td>\n",
       "      <td>top</td>\n",
       "      <td>2328063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konusunda</td>\n",
       "      <td>konu</td>\n",
       "      <td>konu</td>\n",
       "      <td>about</td>\n",
       "      <td>subject</td>\n",
       "      <td>167046</td>\n",
       "      <td>about half</td>\n",
       "      <td>2390601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konusunda</td>\n",
       "      <td>konu</td>\n",
       "      <td>konu</td>\n",
       "      <td>about</td>\n",
       "      <td>subject</td>\n",
       "      <td>167046</td>\n",
       "      <td>about half</td>\n",
       "      <td>2402492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konusunda</td>\n",
       "      <td>konu</td>\n",
       "      <td>konu</td>\n",
       "      <td>about</td>\n",
       "      <td>subject</td>\n",
       "      <td>167046</td>\n",
       "      <td>no subject</td>\n",
       "      <td>2318736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konusunda</td>\n",
       "      <td>konu</td>\n",
       "      <td>konu</td>\n",
       "      <td>about</td>\n",
       "      <td>subject</td>\n",
       "      <td>167046</td>\n",
       "      <td>no subject</td>\n",
       "      <td>2356446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>konusunda</td>\n",
       "      <td>konu</td>\n",
       "      <td>konu</td>\n",
       "      <td>about</td>\n",
       "      <td>subject</td>\n",
       "      <td>167046</td>\n",
       "      <td>no subject</td>\n",
       "      <td>2345949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS1 POS2       word lemma.spacy  stem word_en_translate  \\\n",
       "0      ADJ  NaN    üstünde         üst   üst             above   \n",
       "1      ADJ  NaN    üstünde         üst   üst             above   \n",
       "2      ADJ  NaN    üstünde         üst   üst             above   \n",
       "3      ADJ  NaN    üstünde         üst   üst             above   \n",
       "4      ADJ  NaN    üstünde         üst   üst             above   \n",
       "...    ...  ...        ...         ...   ...               ...   \n",
       "5395  NOUN  NaN  konusunda        konu  konu             about   \n",
       "5396  NOUN  NaN  konusunda        konu  konu             about   \n",
       "5397  NOUN  NaN  konusunda        konu  konu             about   \n",
       "5398  NOUN  NaN  konusunda        konu  konu             about   \n",
       "5399  NOUN  NaN  konusunda        konu  konu             about   \n",
       "\n",
       "     lemma_en_translate  frequency search_text  image_id  \n",
       "0                   top      86801         top   2371537  \n",
       "1                   top      86801         top   2328281  \n",
       "2                   top      86801         top   2328272  \n",
       "3                   top      86801         top   2328221  \n",
       "4                   top      86801         top   2328063  \n",
       "...                 ...        ...         ...       ...  \n",
       "5395            subject     167046  about half   2390601  \n",
       "5396            subject     167046  about half   2402492  \n",
       "5397            subject     167046  no subject   2318736  \n",
       "5398            subject     167046  no subject   2356446  \n",
       "5399            subject     167046  no subject   2345949  \n",
       "\n",
       "[5400 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_excel(\"image_text.xlsx\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Jun  4 2021, 12:28:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
