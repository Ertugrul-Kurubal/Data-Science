{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Photo Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 40000  # 28 native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/40000 Words/Images_Crop_Size\"\n",
    "path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Talk Time/Talk Time 6/Data/Deployment\"\n",
    "#file = \"Talk Time 6 Video List.xlsx\"\n",
    "#sheet = \"Sheet1\"  # Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_video_file = pd.read_excel(f\"{path_folder}/{file}\")\n",
    "#df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Twogram Video List.xlsx',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Threegram Video List.xlsx',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Fourgram Video List.xlsx',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Fivegram Video List.xlsx',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Sixgram Video List.xlsx',\n",
       " '/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Talk Time/Talk Time 6/Data/Deployment/Talk Time 6 Sevengram Video List.xlsx']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_video_file_list = glob.glob(f\"{path_folder}/Talk Time 6 * Video List.xlsx\")\n",
    "ngram_video_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram1</th>\n",
       "      <th>ngram2</th>\n",
       "      <th>ngram3</th>\n",
       "      <th>ngram4</th>\n",
       "      <th>ngram5</th>\n",
       "      <th>ngram6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her gün</td>\n",
       "      <td>kısa bir süre</td>\n",
       "      <td>bir şey söyleyeyim mi</td>\n",
       "      <td>bir şey varsa o da</td>\n",
       "      <td>bana söylemek istediğin bir şey var</td>\n",
       "      <td>söylemek istediğin başka bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>çok önemli</td>\n",
       "      <td>çok memnun oldum</td>\n",
       "      <td>benim için çok önemli</td>\n",
       "      <td>sana bir şey söyleyeyim mi</td>\n",
       "      <td>daha önce hiç böyle bir şey</td>\n",
       "      <td>bir iyi bir de kötü haberim var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burada bir</td>\n",
       "      <td>çok ama çok</td>\n",
       "      <td>öyle ya da böyle</td>\n",
       "      <td>bilmem gereken bir şey var</td>\n",
       "      <td>hakkında en ufak bir fikrim yok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tane daha</td>\n",
       "      <td>ne anlama geldiğini</td>\n",
       "      <td>elimden gelenin en iyisini</td>\n",
       "      <td>bize biraz izin verir misiniz</td>\n",
       "      <td>istediğiniz başka bir şey var mı</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir yere</td>\n",
       "      <td>bir süre sonra</td>\n",
       "      <td>gereken çok şey var</td>\n",
       "      <td>bu iyi bir şey değil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ihtiyacı var</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kusura bakma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kusura bakmayın</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mümkün değil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ne düşünüyorsun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ngram1               ngram2                      ngram3  \\\n",
       "0           her gün        kısa bir süre       bir şey söyleyeyim mi   \n",
       "1        çok önemli     çok memnun oldum       benim için çok önemli   \n",
       "2        burada bir          çok ama çok            öyle ya da böyle   \n",
       "3         tane daha  ne anlama geldiğini  elimden gelenin en iyisini   \n",
       "4          bir yere       bir süre sonra         gereken çok şey var   \n",
       "..              ...                  ...                         ...   \n",
       "67     ihtiyacı var                  NaN                         NaN   \n",
       "68     kusura bakma                  NaN                         NaN   \n",
       "69  kusura bakmayın                  NaN                         NaN   \n",
       "70     mümkün değil                  NaN                         NaN   \n",
       "71  ne düşünüyorsun                  NaN                         NaN   \n",
       "\n",
       "                           ngram4                               ngram5  \\\n",
       "0              bir şey varsa o da  bana söylemek istediğin bir şey var   \n",
       "1      sana bir şey söyleyeyim mi          daha önce hiç böyle bir şey   \n",
       "2      bilmem gereken bir şey var      hakkında en ufak bir fikrim yok   \n",
       "3   bize biraz izin verir misiniz     istediğiniz başka bir şey var mı   \n",
       "4            bu iyi bir şey değil                                  NaN   \n",
       "..                            ...                                  ...   \n",
       "67                            NaN                                  NaN   \n",
       "68                            NaN                                  NaN   \n",
       "69                            NaN                                  NaN   \n",
       "70                            NaN                                  NaN   \n",
       "71                            NaN                                  NaN   \n",
       "\n",
       "                                     ngram6  \n",
       "0   söylemek istediğin başka bir şey var mı  \n",
       "1           bir iyi bir de kötü haberim var  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "..                                      ...  \n",
       "67                                      NaN  \n",
       "68                                      NaN  \n",
       "69                                      NaN  \n",
       "70                                      NaN  \n",
       "71                                      NaN  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_file = pd.DataFrame()\n",
    "ngram_num = 1\n",
    "for file in ngram_video_file_list:\n",
    "    df_var = pd.read_excel(f\"{file}\")\n",
    "    df_var = df_var.iloc[:,[0]]\n",
    "    old_name = df_var.columns[0]\n",
    "    df_var = df_var.rename(columns={f\"{old_name}\":f\"ngram{ngram_num}\"})\n",
    "    df_video_file = pd.concat([df_video_file,df_var], axis=1)\n",
    "    ngram_num +=1 \n",
    "df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>şey</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>haberim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>görüyor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>görmek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>gördünüz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>kere</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count\n",
       "0         bir          63\n",
       "1         şey          33\n",
       "2          ne          23\n",
       "3          bu          16\n",
       "4         var          12\n",
       "..        ...         ...\n",
       "176   haberim           1\n",
       "177   görüyor           1\n",
       "178    görmek           1\n",
       "179  gördünüz           1\n",
       "180      kere           1\n",
       "\n",
       "[181 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file_count = word_count_result(df_video_file,df_video_file.columns)\n",
    "df_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_list = os.listdir(image_path_folder)\n",
    "filename_without_ext_list = []\n",
    "for file in image_file_list:\n",
    "    # file and extention\n",
    "    file_without_ext = os.path.splitext(file)[0]\n",
    "    filename_without_ext_list.append(file_without_ext)\n",
    "#filename_without_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_image_file = set(filename_without_ext_list)\n",
    "set_video_file = set(df_file_count[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acil',\n",
       " 'altında',\n",
       " 'aynen',\n",
       " 'az',\n",
       " 'bakma',\n",
       " 'bakmayın',\n",
       " 'bilmem',\n",
       " 'bitti',\n",
       " 'buldum',\n",
       " 'bırak',\n",
       " 'durum',\n",
       " 'duydun',\n",
       " 'dürüst',\n",
       " 'düşünüyorsun',\n",
       " 'edin',\n",
       " 'fena',\n",
       " 'geldin',\n",
       " 'gelenin',\n",
       " 'gelmek',\n",
       " 'gerekirse',\n",
       " 'gördünüz',\n",
       " 'görüyor',\n",
       " 'haberim',\n",
       " 'halde',\n",
       " 'hızlı',\n",
       " 'ihtiyacı',\n",
       " 'istediğini',\n",
       " 'iyisini',\n",
       " 'kadın',\n",
       " 'kere',\n",
       " 'kontrol',\n",
       " 'korkunç',\n",
       " 'kulağa',\n",
       " 'kusura',\n",
       " 'mümkün',\n",
       " 'neydi',\n",
       " 'neyse',\n",
       " 'olmamış',\n",
       " 'olun',\n",
       " 'soracağım',\n",
       " 'sorunun',\n",
       " 'söyleyeceğim',\n",
       " 'söyleyeyim',\n",
       " 'tabi',\n",
       " 'varsa',\n",
       " 'verir',\n",
       " 'yapmak',\n",
       " 'yaptığını',\n",
       " 'yerde',\n",
       " 'yere',\n",
       " 'zorunda',\n",
       " 'önemi',\n",
       " 'özel'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_video_file.difference(set_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Jun  4 2021, 12:28:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
