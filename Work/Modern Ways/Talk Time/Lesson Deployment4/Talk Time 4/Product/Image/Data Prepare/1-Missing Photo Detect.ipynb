{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Photo Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 10000  # 28 native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/10000 Words/Images_Crop_Size\"\n",
    "path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Talk Time/Talk Time 4/Data/Deployment\"\n",
    "file = \"Talk Time 4 Video List.xlsx\"\n",
    "sheet = \"Sheet1\"  # Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2Gram</th>\n",
       "      <th>3Gram</th>\n",
       "      <th>4Gram</th>\n",
       "      <th>5Gram</th>\n",
       "      <th>6Gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>şu an</td>\n",
       "      <td>güzel değil mi</td>\n",
       "      <td>bu ne anlama geliyor</td>\n",
       "      <td>söylemek istediğim bir şey var</td>\n",
       "      <td>istediğin başka bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu harika</td>\n",
       "      <td>bu doğru değil</td>\n",
       "      <td>onun gibi bir şey</td>\n",
       "      <td>başka bir şey daha var</td>\n",
       "      <td>söylemek istediğiniz bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bir şeyler</td>\n",
       "      <td>hiçbir fikrim yok</td>\n",
       "      <td>başka bir şey değil</td>\n",
       "      <td>istediğin bir şey var mı</td>\n",
       "      <td>o kadar çok şey var ki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evet efendim</td>\n",
       "      <td>her zamanki gibi</td>\n",
       "      <td>bir şey göstermek istiyorum</td>\n",
       "      <td>ne kadar zor olabilir ki</td>\n",
       "      <td>gereken başka bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne olmuş</td>\n",
       "      <td>ben de öyle</td>\n",
       "      <td>bir şey yok mu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>söylemek istediğin bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hem de</td>\n",
       "      <td>bir şey değil</td>\n",
       "      <td>bu ne demek oluyor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iyi bir</td>\n",
       "      <td>bir şey yok</td>\n",
       "      <td>iyi bir fikir değil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nasıl gidiyor</td>\n",
       "      <td>ne demek oluyor</td>\n",
       "      <td>bir soru sorabilir miyim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorun değil</td>\n",
       "      <td>o da ne</td>\n",
       "      <td>doğum günün kutlu olsun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>şuna bak</td>\n",
       "      <td>o kadar da</td>\n",
       "      <td>ne var biliyor musun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2Gram              3Gram                        4Gram  \\\n",
       "0          şu an     güzel değil mi         bu ne anlama geliyor   \n",
       "1      bu harika     bu doğru değil            onun gibi bir şey   \n",
       "2     bir şeyler  hiçbir fikrim yok          başka bir şey değil   \n",
       "3   evet efendim   her zamanki gibi  bir şey göstermek istiyorum   \n",
       "4       ne olmuş        ben de öyle               bir şey yok mu   \n",
       "5         hem de      bir şey değil           bu ne demek oluyor   \n",
       "6        iyi bir        bir şey yok          iyi bir fikir değil   \n",
       "7  nasıl gidiyor    ne demek oluyor     bir soru sorabilir miyim   \n",
       "8    sorun değil            o da ne      doğum günün kutlu olsun   \n",
       "9       şuna bak         o kadar da         ne var biliyor musun   \n",
       "\n",
       "                            5Gram                                6Gram  \n",
       "0  söylemek istediğim bir şey var       istediğin başka bir şey var mı  \n",
       "1          başka bir şey daha var  söylemek istediğiniz bir şey var mı  \n",
       "2        istediğin bir şey var mı               o kadar çok şey var ki  \n",
       "3        ne kadar zor olabilir ki         gereken başka bir şey var mı  \n",
       "4                             NaN    söylemek istediğin bir şey var mı  \n",
       "5                             NaN                                  NaN  \n",
       "6                             NaN                                  NaN  \n",
       "7                             NaN                                  NaN  \n",
       "8                             NaN                                  NaN  \n",
       "9                             NaN                                  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_file = pd.read_excel(f\"{path_folder}/{file}\")\n",
    "df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>şey</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>var</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ne</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>değil</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hiçbir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>istediğim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>anlama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>istiyorum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>şuna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count\n",
       "0         bir          17\n",
       "1         şey          14\n",
       "2         var           9\n",
       "3          ne           7\n",
       "4       değil           6\n",
       "..        ...         ...\n",
       "60     hiçbir           1\n",
       "61  istediğim           1\n",
       "62     anlama           1\n",
       "63  istiyorum           1\n",
       "64       şuna           1\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file_count = word_count_result(df_video_file,df_video_file.columns)\n",
    "df_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ama',\n",
       " 'artık',\n",
       " 'asla',\n",
       " 'aslında',\n",
       " 'aynı',\n",
       " 'baba',\n",
       " 'bak',\n",
       " 'bakalım',\n",
       " 'bana',\n",
       " 'belki',\n",
       " 'ben',\n",
       " 'beni',\n",
       " 'benimle',\n",
       " 'bile',\n",
       " 'biliyorsun',\n",
       " 'biliyorum',\n",
       " 'diye',\n",
       " 'acele',\n",
       " 'biri',\n",
       " 'biz',\n",
       " 'bize',\n",
       " 'bizi',\n",
       " 'bizim',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bunu',\n",
       " 'burada',\n",
       " 'buraya',\n",
       " 'bütün',\n",
       " 'gerçek',\n",
       " 'böyle',\n",
       " 'çok',\n",
       " 'de',\n",
       " 'doğru',\n",
       " 'dostum',\n",
       " 'dur',\n",
       " 'ederim',\n",
       " 'efendim',\n",
       " 'et',\n",
       " 'evet',\n",
       " 'fazla',\n",
       " 'gece',\n",
       " 'gel',\n",
       " 'geldi',\n",
       " 'geliyor',\n",
       " 'gerçekten',\n",
       " 'geri',\n",
       " 'gibi',\n",
       " 'misin',\n",
       " 'ana',\n",
       " 'göre',\n",
       " 'gün',\n",
       " 'güzel',\n",
       " 'hadi',\n",
       " 'hala',\n",
       " 'harika',\n",
       " 'haydi',\n",
       " 'her',\n",
       " 'herkes',\n",
       " 'hey',\n",
       " 'hiçbir',\n",
       " 'için',\n",
       " 'ile',\n",
       " 'ilk',\n",
       " 'iş',\n",
       " 'istiyorsun',\n",
       " 'istiyorum',\n",
       " 'iyi',\n",
       " 'izin',\n",
       " 'kadar',\n",
       " 'mısın',\n",
       " 'işte',\n",
       " 'ki',\n",
       " 'kız',\n",
       " 'lazım',\n",
       " 'lütfen',\n",
       " 'merhaba',\n",
       " 'musun',\n",
       " 'anda',\n",
       " 'basit',\n",
       " 'nerede',\n",
       " 'o',\n",
       " 'olabilir',\n",
       " 'olacak',\n",
       " 'olan',\n",
       " 'olarak',\n",
       " 'oldu',\n",
       " 'olduğunu',\n",
       " 'olmak',\n",
       " 'olmaz',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'oluyor',\n",
       " 'ona',\n",
       " 'önce',\n",
       " 'onları',\n",
       " 'onu',\n",
       " 'onunla',\n",
       " 'orada',\n",
       " 'öyle',\n",
       " 'pekala',\n",
       " 'sadece',\n",
       " 'sana',\n",
       " 'sanırım',\n",
       " 'şekilde',\n",
       " 'seninle',\n",
       " 'şey',\n",
       " 'size',\n",
       " 'sizi',\n",
       " 'son',\n",
       " 'sonra',\n",
       " 'sorun',\n",
       " 'söyle',\n",
       " 'şu',\n",
       " 'tamam',\n",
       " 'tekrar',\n",
       " 'teşekkür',\n",
       " 'üç',\n",
       " 'var',\n",
       " 've',\n",
       " 'ya',\n",
       " 'yardım',\n",
       " 'yeni',\n",
       " 'yine',\n",
       " 'yok',\n",
       " 'yüzden',\n",
       " 'zaten',\n",
       " 'dikkat',\n",
       " 'onlar',\n",
       " 'özür',\n",
       " 'para',\n",
       " 'üzgünüm',\n",
       " 'dilerim',\n",
       " 'şeyi',\n",
       " 'şeyler',\n",
       " 'şimdi',\n",
       " 'siz',\n",
       " 'şunu',\n",
       " 'tabii',\n",
       " 'tam',\n",
       " 'emin',\n",
       " 'seni',\n",
       " 'fikrim',\n",
       " 'gidelim',\n",
       " 'bence',\n",
       " 'benim',\n",
       " 'biraz',\n",
       " 'bugün',\n",
       " 'bunun',\n",
       " 'çünkü',\n",
       " 'daha',\n",
       " 'dakika',\n",
       " 'değilim',\n",
       " 'gerek',\n",
       " 'git',\n",
       " 'içinde',\n",
       " 'küçük',\n",
       " 'mi',\n",
       " 'nasıl',\n",
       " 'gördün',\n",
       " 'görmek',\n",
       " 'ne',\n",
       " 'zaman',\n",
       " 'hem',\n",
       " 'hoşça',\n",
       " 'mü',\n",
       " 'kal',\n",
       " 'memnun',\n",
       " 'vardı',\n",
       " 'yani',\n",
       " 'yapıyorsun',\n",
       " 'merak',\n",
       " 'nereye',\n",
       " 'tüm',\n",
       " 'neyin',\n",
       " 'hakkında',\n",
       " 'mı',\n",
       " 'mu',\n",
       " 'ol',\n",
       " 'peki',\n",
       " 'saat',\n",
       " 'sen',\n",
       " 'tek',\n",
       " 'uzun',\n",
       " 'yoksa',\n",
       " 'sağ',\n",
       " 'tanıyor',\n",
       " 'birkaç',\n",
       " 'birlikte',\n",
       " 'devam',\n",
       " 'yeter',\n",
       " 'yolunda',\n",
       " 'eğer',\n",
       " 'hayır',\n",
       " 'hiç',\n",
       " 'ister',\n",
       " 'kendi',\n",
       " 'kimse',\n",
       " 'ver',\n",
       " 'adam',\n",
       " 'al',\n",
       " 'anne',\n",
       " 'başka',\n",
       " 'biliyor',\n",
       " 'bilmiyorum',\n",
       " 'bir',\n",
       " 'büyük',\n",
       " 'da',\n",
       " 'değil',\n",
       " 'demek',\n",
       " 'en',\n",
       " 'hemen',\n",
       " 'iki',\n",
       " 'kötü',\n",
       " 'neden',\n",
       " 'neler',\n",
       " 'oh',\n",
       " 'önemli',\n",
       " 'onun',\n",
       " 'selam',\n",
       " 'senin',\n",
       " 'teşekkürler',\n",
       " 'etme',\n",
       " 'eder',\n",
       " 'gidiyorsun',\n",
       " 'işin',\n",
       " 'kendine',\n",
       " 'miyim',\n",
       " 'oldum',\n",
       " 'yardımcı',\n",
       " 'dalga',\n",
       " 'dersin',\n",
       " 'diyorsun',\n",
       " 'düşünmüştüm',\n",
       " 'duyuyor',\n",
       " 'fikir',\n",
       " 'fikrin',\n",
       " 'geçiyorsun',\n",
       " 'gereken',\n",
       " 'girecek',\n",
       " 'göstermek',\n",
       " 'hazır',\n",
       " 'hepsi',\n",
       " 'iyilik',\n",
       " 'kes',\n",
       " 'kez',\n",
       " 'olursa',\n",
       " 'sakin',\n",
       " 'saniye',\n",
       " 'sence',\n",
       " 'seviyorum',\n",
       " 'sizin',\n",
       " 'sorabilir',\n",
       " 'söylemem',\n",
       " 'tane',\n",
       " 'yapabileceğim',\n",
       " 'yapabilirim',\n",
       " 'yazık']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file_list = os.listdir(image_path_folder)\n",
    "filename_without_ext_list = []\n",
    "for file in image_file_list:\n",
    "    # file and extention\n",
    "    file_without_ext = os.path.splitext(file)[0]\n",
    "    filename_without_ext_list.append(file_without_ext)\n",
    "filename_without_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_image_file = set(filename_without_ext_list)\n",
    "set_video_file = set(df_file_count[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an',\n",
       " 'anlama',\n",
       " 'doğum',\n",
       " 'gidiyor',\n",
       " 'günün',\n",
       " 'istediğim',\n",
       " 'istediğin',\n",
       " 'istediğiniz',\n",
       " 'kutlu',\n",
       " 'olmuş',\n",
       " 'soru',\n",
       " 'söylemek',\n",
       " 'zamanki',\n",
       " 'zor',\n",
       " 'şuna'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_video_file.difference(set_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
