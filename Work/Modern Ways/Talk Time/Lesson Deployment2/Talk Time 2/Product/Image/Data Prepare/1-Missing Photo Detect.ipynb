{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Photo Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 1000  # 28 native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_folder = f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/1000 Words/Images_Crop_Size\"\n",
    "path_folder = f\"/media/kurubal/SSD1/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Talk Time/Talk Time 2/Data/Deployment\"\n",
    "#file = \"Talk Time 2 Video List.xlsx\"\n",
    "#sheet = \"Sheet1\"  # Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2Gram</th>\n",
       "      <th>3Gram</th>\n",
       "      <th>4Gram</th>\n",
       "      <th>5Gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama bu</td>\n",
       "      <td>böyle bir şey</td>\n",
       "      <td>başka bir şey yok</td>\n",
       "      <td>bu da ne demek oluyor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu ne</td>\n",
       "      <td>bir kez daha</td>\n",
       "      <td>bir fikrin var mı</td>\n",
       "      <td>başka bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biraz daha</td>\n",
       "      <td>dalga mı geçiyorsun</td>\n",
       "      <td>ne var ne yok</td>\n",
       "      <td>o kadar da kötü değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu kadar</td>\n",
       "      <td>ne yazık ki</td>\n",
       "      <td>ben de seni seviyorum</td>\n",
       "      <td>daha iyi bir fikrim var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hazır mısın</td>\n",
       "      <td>önemli bir şey</td>\n",
       "      <td>bir şey sorabilir miyim</td>\n",
       "      <td>sana bir şey sorabilir miyim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ne zaman</td>\n",
       "      <td>hiçbir şey yok</td>\n",
       "      <td>bir şey mi var</td>\n",
       "      <td>yapabileceğim bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bir tane</td>\n",
       "      <td>öyle bir şey</td>\n",
       "      <td>burada ne işin var</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ne diyorsun</td>\n",
       "      <td>bir fikrim var</td>\n",
       "      <td>ne olduğunu biliyor musun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ne olacak</td>\n",
       "      <td>bir şey daha</td>\n",
       "      <td>önemli bir şey değil</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bir gün</td>\n",
       "      <td>bir şey mi</td>\n",
       "      <td>ben de öyle düşünmüştüm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>öyle değil</td>\n",
       "      <td>iyi bir fikir</td>\n",
       "      <td>sizin için ne yapabilirim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bu mu</td>\n",
       "      <td>ne olursa olsun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hepsi bu</td>\n",
       "      <td>beni duyuyor musun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bu benim</td>\n",
       "      <td>ama yine de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>böyle bir</td>\n",
       "      <td>daha iyi bir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>her şeyi</td>\n",
       "      <td>daha önce hiç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yardım et</td>\n",
       "      <td>bir tane daha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sakin ol</td>\n",
       "      <td>bir daha asla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ne dersin</td>\n",
       "      <td>bu kadar mı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bir saniye</td>\n",
       "      <td>başka bir şey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ne oluyor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en iyi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hadi ama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ne demek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iyi misin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bu gece</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2Gram                3Gram                      4Gram  \\\n",
       "0        ama bu        böyle bir şey          başka bir şey yok   \n",
       "1         bu ne         bir kez daha          bir fikrin var mı   \n",
       "2    biraz daha  dalga mı geçiyorsun              ne var ne yok   \n",
       "3      bu kadar          ne yazık ki      ben de seni seviyorum   \n",
       "4   hazır mısın       önemli bir şey    bir şey sorabilir miyim   \n",
       "5      ne zaman       hiçbir şey yok             bir şey mi var   \n",
       "6      bir tane         öyle bir şey         burada ne işin var   \n",
       "7   ne diyorsun       bir fikrim var  ne olduğunu biliyor musun   \n",
       "8     ne olacak         bir şey daha       önemli bir şey değil   \n",
       "9       bir gün           bir şey mi    ben de öyle düşünmüştüm   \n",
       "10   öyle değil        iyi bir fikir  sizin için ne yapabilirim   \n",
       "11        bu mu      ne olursa olsun                        NaN   \n",
       "12     hepsi bu   beni duyuyor musun                        NaN   \n",
       "13     bu benim          ama yine de                        NaN   \n",
       "14    böyle bir         daha iyi bir                        NaN   \n",
       "15     her şeyi        daha önce hiç                        NaN   \n",
       "16    yardım et        bir tane daha                        NaN   \n",
       "17     sakin ol        bir daha asla                        NaN   \n",
       "18    ne dersin          bu kadar mı                        NaN   \n",
       "19   bir saniye        başka bir şey                        NaN   \n",
       "20    ne oluyor                  NaN                        NaN   \n",
       "21       en iyi                  NaN                        NaN   \n",
       "22     hadi ama                  NaN                        NaN   \n",
       "23     ne demek                  NaN                        NaN   \n",
       "24    iyi misin                  NaN                        NaN   \n",
       "25      bu gece                  NaN                        NaN   \n",
       "\n",
       "                           5Gram  \n",
       "0          bu da ne demek oluyor  \n",
       "1           başka bir şey var mı  \n",
       "2          o kadar da kötü değil  \n",
       "3        daha iyi bir fikrim var  \n",
       "4   sana bir şey sorabilir miyim  \n",
       "5   yapabileceğim bir şey var mı  \n",
       "6                            NaN  \n",
       "7                            NaN  \n",
       "8                            NaN  \n",
       "9                            NaN  \n",
       "10                           NaN  \n",
       "11                           NaN  \n",
       "12                           NaN  \n",
       "13                           NaN  \n",
       "14                           NaN  \n",
       "15                           NaN  \n",
       "16                           NaN  \n",
       "17                           NaN  \n",
       "18                           NaN  \n",
       "19                           NaN  \n",
       "20                           NaN  \n",
       "21                           NaN  \n",
       "22                           NaN  \n",
       "23                           NaN  \n",
       "24                           NaN  \n",
       "25                           NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_video_file = pd.read_excel(f\"{path_folder}/{file}\")\n",
    "#df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_video_file_list = glob.glob(f\"{path_folder}/Talk Time 2 * Video List.xlsx\")\n",
    "ngram_video_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_file = pd.DataFrame()\n",
    "ngram_num = 1\n",
    "for file in ngram_video_file_list:\n",
    "    df_var = pd.read_excel(f\"{file}\")\n",
    "    df_var = df_var.iloc[:,[0]]\n",
    "    old_name = df_var.columns[0]\n",
    "    df_var = df_var.rename(columns={f\"{old_name}\":f\"ngram{ngram_num}\"})\n",
    "    df_video_file = pd.concat([df_video_file,df_var], axis=1)\n",
    "    ngram_num +=1 \n",
    "df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ne</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>şey</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daha</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>kez</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kötü</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>misin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>şeyi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  word_count\n",
       "0     bir          25\n",
       "1      ne          15\n",
       "2     şey          14\n",
       "3      bu           9\n",
       "4    daha           8\n",
       "..    ...         ...\n",
       "74    kez           1\n",
       "75     ki           1\n",
       "76   kötü           1\n",
       "77  misin           1\n",
       "78   şeyi           1\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file_count = word_count_result(df_video_file,df_video_file.columns)\n",
    "df_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ama',\n",
       " 'artık',\n",
       " 'asla',\n",
       " 'aslında',\n",
       " 'aynı',\n",
       " 'baba',\n",
       " 'bak',\n",
       " 'bakalım',\n",
       " 'bana',\n",
       " 'belki',\n",
       " 'ben',\n",
       " 'beni',\n",
       " 'benimle',\n",
       " 'bile',\n",
       " 'biliyorsun',\n",
       " 'biliyorum',\n",
       " 'diye',\n",
       " 'acele',\n",
       " 'biri',\n",
       " 'biz',\n",
       " 'bize',\n",
       " 'bizi',\n",
       " 'bizim',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bunu',\n",
       " 'burada',\n",
       " 'buraya',\n",
       " 'bütün',\n",
       " 'gerçek',\n",
       " 'böyle',\n",
       " 'çok',\n",
       " 'de',\n",
       " 'doğru',\n",
       " 'dostum',\n",
       " 'dur',\n",
       " 'ederim',\n",
       " 'efendim',\n",
       " 'et',\n",
       " 'evet',\n",
       " 'fazla',\n",
       " 'gece',\n",
       " 'gel',\n",
       " 'geldi',\n",
       " 'geliyor',\n",
       " 'gerçekten',\n",
       " 'geri',\n",
       " 'gibi',\n",
       " 'misin',\n",
       " 'ana',\n",
       " 'göre',\n",
       " 'gün',\n",
       " 'güzel',\n",
       " 'hadi',\n",
       " 'hala',\n",
       " 'harika',\n",
       " 'haydi',\n",
       " 'her',\n",
       " 'herkes',\n",
       " 'hey',\n",
       " 'hiçbir',\n",
       " 'için',\n",
       " 'ile',\n",
       " 'ilk',\n",
       " 'iş',\n",
       " 'istiyorsun',\n",
       " 'istiyorum',\n",
       " 'iyi',\n",
       " 'izin',\n",
       " 'kadar',\n",
       " 'mısın',\n",
       " 'işte',\n",
       " 'ki',\n",
       " 'kız',\n",
       " 'lazım',\n",
       " 'lütfen',\n",
       " 'merhaba',\n",
       " 'musun',\n",
       " 'anda',\n",
       " 'basit',\n",
       " 'nerede',\n",
       " 'o',\n",
       " 'olabilir',\n",
       " 'olacak',\n",
       " 'olan',\n",
       " 'olarak',\n",
       " 'oldu',\n",
       " 'olduğunu',\n",
       " 'olmak',\n",
       " 'olmaz',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'oluyor',\n",
       " 'ona',\n",
       " 'önce',\n",
       " 'onları',\n",
       " 'onu',\n",
       " 'onunla',\n",
       " 'orada',\n",
       " 'öyle',\n",
       " 'pekala',\n",
       " 'sadece',\n",
       " 'sana',\n",
       " 'sanırım',\n",
       " 'şekilde',\n",
       " 'seninle',\n",
       " 'şey',\n",
       " 'size',\n",
       " 'sizi',\n",
       " 'son',\n",
       " 'sonra',\n",
       " 'sorun',\n",
       " 'söyle',\n",
       " 'şu',\n",
       " 'tamam',\n",
       " 'tekrar',\n",
       " 'teşekkür',\n",
       " 'üç',\n",
       " 'var',\n",
       " 've',\n",
       " 'ya',\n",
       " 'yardım',\n",
       " 'yeni',\n",
       " 'yine',\n",
       " 'yok',\n",
       " 'yüzden',\n",
       " 'zaten',\n",
       " 'dikkat',\n",
       " 'onlar',\n",
       " 'özür',\n",
       " 'para',\n",
       " 'üzgünüm',\n",
       " 'dilerim',\n",
       " 'şeyi',\n",
       " 'şeyler',\n",
       " 'şimdi',\n",
       " 'siz',\n",
       " 'şunu',\n",
       " 'tabii',\n",
       " 'tam',\n",
       " 'emin',\n",
       " 'seni',\n",
       " 'fikrim',\n",
       " 'gidelim',\n",
       " 'bence',\n",
       " 'benim',\n",
       " 'biraz',\n",
       " 'bugün',\n",
       " 'bunun',\n",
       " 'çünkü',\n",
       " 'daha',\n",
       " 'dakika',\n",
       " 'değilim',\n",
       " 'gerek',\n",
       " 'git',\n",
       " 'içinde',\n",
       " 'küçük',\n",
       " 'mi',\n",
       " 'nasıl',\n",
       " 'gördün',\n",
       " 'görmek',\n",
       " 'ne',\n",
       " 'zaman',\n",
       " 'hem',\n",
       " 'hoşça',\n",
       " 'mü',\n",
       " 'kal',\n",
       " 'memnun',\n",
       " 'vardı',\n",
       " 'yani',\n",
       " 'yapıyorsun',\n",
       " 'merak',\n",
       " 'nereye',\n",
       " 'tüm',\n",
       " 'neyin',\n",
       " 'hakkında',\n",
       " 'mı',\n",
       " 'mu',\n",
       " 'ol',\n",
       " 'peki',\n",
       " 'saat',\n",
       " 'sen',\n",
       " 'tek',\n",
       " 'uzun',\n",
       " 'yoksa',\n",
       " 'sağ',\n",
       " 'tanıyor',\n",
       " 'birkaç',\n",
       " 'birlikte',\n",
       " 'devam',\n",
       " 'yeter',\n",
       " 'yolunda',\n",
       " 'eğer',\n",
       " 'hayır',\n",
       " 'hiç',\n",
       " 'ister',\n",
       " 'kendi',\n",
       " 'kimse',\n",
       " 'ver',\n",
       " 'adam',\n",
       " 'al',\n",
       " 'anne',\n",
       " 'başka',\n",
       " 'biliyor',\n",
       " 'bilmiyorum',\n",
       " 'bir',\n",
       " 'büyük',\n",
       " 'da',\n",
       " 'değil',\n",
       " 'demek',\n",
       " 'en',\n",
       " 'hemen',\n",
       " 'iki',\n",
       " 'kötü',\n",
       " 'neden',\n",
       " 'neler',\n",
       " 'oh',\n",
       " 'önemli',\n",
       " 'onun',\n",
       " 'selam',\n",
       " 'senin',\n",
       " 'teşekkürler',\n",
       " 'etme',\n",
       " 'eder',\n",
       " 'gidiyorsun',\n",
       " 'işin',\n",
       " 'kendine',\n",
       " 'miyim',\n",
       " 'oldum',\n",
       " 'yardımcı']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file_list = os.listdir(image_path_folder)\n",
    "filename_without_ext_list = []\n",
    "for file in image_file_list:\n",
    "    # file and extention\n",
    "    file_without_ext = os.path.splitext(file)[0]\n",
    "    filename_without_ext_list.append(file_without_ext)\n",
    "filename_without_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_image_file = set(filename_without_ext_list)\n",
    "set_video_file = set(df_file_count[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dalga',\n",
       " 'dersin',\n",
       " 'diyorsun',\n",
       " 'duyuyor',\n",
       " 'düşünmüştüm',\n",
       " 'fikir',\n",
       " 'fikrin',\n",
       " 'geçiyorsun',\n",
       " 'hazır',\n",
       " 'hepsi',\n",
       " 'kez',\n",
       " 'olursa',\n",
       " 'sakin',\n",
       " 'saniye',\n",
       " 'seviyorum',\n",
       " 'sizin',\n",
       " 'sorabilir',\n",
       " 'tane',\n",
       " 'yapabileceğim',\n",
       " 'yapabilirim',\n",
       " 'yazık'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_video_file.difference(set_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Jun  4 2021, 12:28:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
