{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Word Group Repeat With Youtube Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 200  # 28 native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_col_value_join_comma(df, df_columns_list):\n",
    "    '''\n",
    "    df_col_value_join_comma(df_test, [\"video_id\",\"start_time\",\"end_time\"])\\n\n",
    "    function used for selected column value join with comma in one row\n",
    "    '''\n",
    "    column_value_list = []\n",
    "    for column in df_columns_list:\n",
    "        list_var = df[f\"{column}\"].to_list()\n",
    "        list_var_string = [str(x) for x in list_var] \n",
    "        list_var_join = \",\".join(list_var_string)\n",
    "        column_value_list.append(list_var_join)\n",
    "\n",
    "    df_result = pd.DataFrame([[column_value_list[0],column_value_list[1],column_value_list[2]]], columns=df_columns_list)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Talk Time/Result/3-Adjust Word Group Repeat With Youtube Link\"\n",
    "\n",
    "#Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_file = \"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Turkish/Deployment2/Result/Deploy2 Result Manuel/Turkish/Twogram_Threegram_Selected.xlsx\"\n",
    "sheet = \"twogram_threegram_selected\"  # Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_word_group_time_loc = pd.read_excel(f\"{path_folder_file}\", sheet_name=f\"{sheet}\")\n",
    "df_word_group_time_loc = pd.read_excel(f\"Twogram Threegram Youtube Link Selected_Manuel.xlsx\")   \n",
    "df_word_group_time_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = df_word_group_time_loc.iloc[:,0].unique()\n",
    "len(search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other option \n",
    "# mUf7VNqChac =>  black screen\n",
    "# 0_CDMstFg7M => 10sn\n",
    "# bj1JRuyYeco => 20sn\n",
    "# cElhIDdGz7M => screensaver\n",
    "default_video_id = \"Q-8I-uMUMYA\"\n",
    "df_link_default = pd.DataFrame(data=[[\"repeat\",5,7,\"repeat_again\",f\"{default_video_id}\",f\"https://www.youtube.com/watch?v={default_video_id}&t=0s\"]], columns=[\"search_string\",\"start_time\",\"end_time\",\"sentence\",\"video_id\",\"video_url\"])\n",
    "df_link_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All word group result convert to join result in one row\n",
    "#df_result_repeat = pd.DataFrame()\n",
    "#for word_group in search_list:\n",
    "#    # for repeat 1\n",
    "#    df_word_group_search_repeat1 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group]\n",
    "#    # for repeat 2\n",
    "#    try:\n",
    "#        df_word_group_search_repeat2 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group].sample(1)\n",
    "#    except:\n",
    "#        df_word_group_search_repeat2 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group].tail(1)\n",
    "#    df_word_group_search_repeat2.reset_index(drop=True, inplace=True)   \n",
    "#    # repeat block\n",
    "#    for i in range(len(df_word_group_search_repeat1)):        \n",
    "#        df_result_repeat = pd.concat([df_result_repeat,df_word_group_search_repeat1.iloc[[i,]]], axis=0)\n",
    "#\n",
    "#    try:\n",
    "#        df_link_default_var = df_link_default\n",
    "#        word_time_diff_var = df_word_group_search_repeat2.loc[0 ,\"end_time\"] - df_word_group_search_repeat2.loc[0 ,\"start_time\"]\n",
    "#        if word_time_diff_var < 4:\n",
    "#            word_time_diff_var2 = 3\n",
    "#        else:\n",
    "#            word_time_diff_var2 = word_time_diff_var+1.0\n",
    "#\n",
    "#        df_link_default_var.loc[0,\"end_time\"] = df_link_default_var.loc[0,\"start_time\"] + word_time_diff_var2\n",
    "#    except:\n",
    "#        pass\n",
    "#\n",
    "#    for j in range(3):\n",
    "#        df_result_repeat = pd.concat([df_result_repeat,df_word_group_search_repeat2], axis=0)\n",
    "#        df_result_repeat = pd.concat([df_result_repeat,df_link_default_var], axis=0)\n",
    "#\n",
    "#df_result_repeat.reset_index(drop=True, inplace=True)\n",
    "#df_result_repeat_join = df_col_value_join_comma(df_result_repeat, [\"video_id\",\"start_time\",\"end_time\"])\n",
    "#\n",
    "#df_result_repeat.to_excel(f\"{lang_folder.capitalize()}_{word_end}_Word_Talk_Time2.xlsx\", index=False)\n",
    "#df_result_repeat_join.to_excel(f\"{lang_folder.capitalize()}_{word_end}_Word_Talk_Time_Join2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df_result_repeat[\"end_time\"].sum()-df_result_repeat[\"start_time\"].sum())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word group result convert to join result in one row\n",
    "df_all_join_result = pd.DataFrame()\n",
    "seq_num = 0  # option\n",
    "for word_group in search_list:\n",
    "    df_result_repeat = pd.DataFrame()\n",
    "    # for repeat 1\n",
    "    df_word_group_search_repeat1 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group]\n",
    "    # for repeat 2\n",
    "    try:\n",
    "        df_word_group_search_repeat2 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group].sample(1)\n",
    "    except:\n",
    "        df_word_group_search_repeat2 = df_word_group_time_loc[df_word_group_time_loc[\"search_string\"] == word_group].tail(1)\n",
    "    df_word_group_search_repeat2.reset_index(drop=True, inplace=True)   \n",
    "    # repeat block\n",
    "    for i in range(len(df_word_group_search_repeat1)):        \n",
    "        df_result_repeat = pd.concat([df_result_repeat,df_word_group_search_repeat1.iloc[[i,]]], axis=0)\n",
    "\n",
    "    try:\n",
    "        df_link_default_var = df_link_default\n",
    "        word_time_diff_var = df_word_group_search_repeat2.loc[0 ,\"end_time\"] - df_word_group_search_repeat2.loc[0 ,\"start_time\"]\n",
    "        if word_time_diff_var < 4:\n",
    "            word_time_diff_var2 = 3\n",
    "        else:\n",
    "            word_time_diff_var2 = word_time_diff_var+1.0\n",
    "\n",
    "        df_link_default_var.loc[0,\"end_time\"] = df_link_default_var.loc[0,\"start_time\"] + word_time_diff_var2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for j in range(3):\n",
    "        df_result_repeat = pd.concat([df_result_repeat,df_word_group_search_repeat2], axis=0)\n",
    "        df_result_repeat = pd.concat([df_result_repeat,df_link_default_var], axis=0)\n",
    "        df_result_repeat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_result_repeat_var = df_col_value_join_comma(df_result_repeat, [\"video_id\",\"start_time\",\"end_time\"]) \n",
    "    df_result_repeat_var.loc[0,[\"search_string\"]] = f\"{word_group}\"  # option for search string\n",
    "    df_result_repeat_var.loc[0,[\"count\"]] = df_result_repeat.loc[0,\"count\"] # option for count num     \n",
    "    df_all_join_result = pd.concat([df_all_join_result,df_result_repeat_var], axis=0)\n",
    "\n",
    "df_all_join_result.reset_index(drop=True, inplace=True)\n",
    "df_all_join_result.to_excel(f\"{lang_folder.capitalize()}_{word_end}_Word_Youtube_Talk_Time_Join.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_join_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{word_end}_Word_Youtube_Talk_Time_Join.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Twogram Threegram Youtube Link Selected.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby([\"search_string\"])[[\"search_string\"]].count()\n",
    "df_count.rename(columns={\"search_string\":\"count\"}, inplace=True)\n",
    "df_count.sort_values(by=\"count\", ascending=False, inplace=True)\n",
    "df_count.reset_index(inplace=True)\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_merge = pd.merge(df, df_count, how=\"inner\",on= \"search_string\")\n",
    "df_count_merge.sort_values(by=[\"count\",\"search_string\"], ascending=False, inplace=True)\n",
    "df_count_merge.reset_index(drop=True, inplace=True)\n",
    "df_count_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_merge[\"search_string\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_merge[df_count_merge[\"count\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_merge.to_excel(\"Twogram Threegram Youtube Link Selected_Count.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_manuel = pd.read_excel(f\"Twogram Threegram Youtube Link Selected_Count_Manuel.xlsx\")\n",
    "df_word_group_time_loc_manuel.sort_values(by=[\"count\",\"search_string\"],inplace=True, ascending=False)\n",
    "df_word_group_time_loc_manuel.reset_index(drop=True, inplace=True)\n",
    "df_word_group_time_loc_manuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_group_time_loc_manuel.to_excel(\"Twogram Threegram Youtube Link Selected_Manuel.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
