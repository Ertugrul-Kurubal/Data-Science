{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Photo Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 20000  # 28 native word end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Image Audio Video/Data/20000 Words/Images_Crop_Size\"\n",
    "path_folder = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Talk Time/Talk Time 5/Data/Deployment\"\n",
    "file = \"Talk Time 5 Video List.xlsx\"\n",
    "sheet = \"Sheet1\"  # Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2Gram</th>\n",
       "      <th>3Gram</th>\n",
       "      <th>4Gram</th>\n",
       "      <th>5Gram</th>\n",
       "      <th>6Gram</th>\n",
       "      <th>7Gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ve bu</td>\n",
       "      <td>ya da bir</td>\n",
       "      <td>ya da başka bir</td>\n",
       "      <td>istediğin başka bir şey var</td>\n",
       "      <td>eklemek istediğin bir şey var mı</td>\n",
       "      <td>söylemek istediğin başka bir şey var mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bir soru</td>\n",
       "      <td>herhangi bir şey</td>\n",
       "      <td>bu çok büyük bir</td>\n",
       "      <td>bu benim için çok önemli</td>\n",
       "      <td>söylemek istediğin başka bir şey var</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daha sonra</td>\n",
       "      <td>bir iki üç</td>\n",
       "      <td>kısa bir süre sonra</td>\n",
       "      <td>bu da demek oluyor ki</td>\n",
       "      <td>bir şey yok bir şey yok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bu konuda</td>\n",
       "      <td>çok önemli bir</td>\n",
       "      <td>iyi bir şey değil</td>\n",
       "      <td>ya da başka bir şey</td>\n",
       "      <td>eklemek istediğiniz bir şey var mı</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bir şekilde</td>\n",
       "      <td>diye bir şey</td>\n",
       "      <td>diye bir şey yok</td>\n",
       "      <td>istediğiniz bir şey var mı</td>\n",
       "      <td>için elimden gelen her şeyi yapacağım</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>gerçekten çok</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>evet evet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>evet biliyorum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sen ve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>adın ne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             2Gram             3Gram                4Gram  \\\n",
       "0            ve bu         ya da bir      ya da başka bir   \n",
       "1         bir soru  herhangi bir şey     bu çok büyük bir   \n",
       "2       daha sonra        bir iki üç  kısa bir süre sonra   \n",
       "3        bu konuda    çok önemli bir    iyi bir şey değil   \n",
       "4      bir şekilde      diye bir şey     diye bir şey yok   \n",
       "..             ...               ...                  ...   \n",
       "95   gerçekten çok               NaN                  NaN   \n",
       "96       evet evet               NaN                  NaN   \n",
       "97  evet biliyorum               NaN                  NaN   \n",
       "98          sen ve               NaN                  NaN   \n",
       "99         adın ne               NaN                  NaN   \n",
       "\n",
       "                          5Gram                                  6Gram  \\\n",
       "0   istediğin başka bir şey var       eklemek istediğin bir şey var mı   \n",
       "1      bu benim için çok önemli   söylemek istediğin başka bir şey var   \n",
       "2         bu da demek oluyor ki                bir şey yok bir şey yok   \n",
       "3           ya da başka bir şey     eklemek istediğiniz bir şey var mı   \n",
       "4    istediğiniz bir şey var mı  için elimden gelen her şeyi yapacağım   \n",
       "..                          ...                                    ...   \n",
       "95                          NaN                                    NaN   \n",
       "96                          NaN                                    NaN   \n",
       "97                          NaN                                    NaN   \n",
       "98                          NaN                                    NaN   \n",
       "99                          NaN                                    NaN   \n",
       "\n",
       "                                      7Gram  \n",
       "0   söylemek istediğin başka bir şey var mı  \n",
       "1                                       NaN  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "..                                      ...  \n",
       "95                                      NaN  \n",
       "96                                      NaN  \n",
       "97                                      NaN  \n",
       "98                                      NaN  \n",
       "99                                      NaN  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_file = pd.read_excel(f\"{path_folder}/{file}\")\n",
    "df_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>şey</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>çok</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>hepsi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>hem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>hatırlıyor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>göstermek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>şuna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  word_count\n",
       "0           bir         127\n",
       "1           şey          75\n",
       "2            bu          37\n",
       "3           çok          33\n",
       "4           var          32\n",
       "..          ...         ...\n",
       "187       hepsi           1\n",
       "188         hem           1\n",
       "189  hatırlıyor           1\n",
       "190   göstermek           1\n",
       "191        şuna           1\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file_count = word_count_result(df_video_file,df_video_file.columns)\n",
    "df_file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ama',\n",
       " 'artık',\n",
       " 'asla',\n",
       " 'aslında',\n",
       " 'aynı',\n",
       " 'baba',\n",
       " 'bak',\n",
       " 'bakalım',\n",
       " 'bana',\n",
       " 'belki',\n",
       " 'ben',\n",
       " 'beni',\n",
       " 'benimle',\n",
       " 'bile',\n",
       " 'biliyorsun',\n",
       " 'biliyorum',\n",
       " 'diye',\n",
       " 'acele',\n",
       " 'biri',\n",
       " 'biz',\n",
       " 'bize',\n",
       " 'bizi',\n",
       " 'bizim',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bunu',\n",
       " 'burada',\n",
       " 'buraya',\n",
       " 'bütün',\n",
       " 'gerçek',\n",
       " 'böyle',\n",
       " 'çok',\n",
       " 'de',\n",
       " 'doğru',\n",
       " 'dostum',\n",
       " 'dur',\n",
       " 'ederim',\n",
       " 'efendim',\n",
       " 'et',\n",
       " 'evet',\n",
       " 'fazla',\n",
       " 'gece',\n",
       " 'gel',\n",
       " 'geldi',\n",
       " 'geliyor',\n",
       " 'gerçekten',\n",
       " 'geri',\n",
       " 'gibi',\n",
       " 'misin',\n",
       " 'ana',\n",
       " 'göre',\n",
       " 'gün',\n",
       " 'güzel',\n",
       " 'hadi',\n",
       " 'hala',\n",
       " 'harika',\n",
       " 'haydi',\n",
       " 'her',\n",
       " 'herkes',\n",
       " 'hey',\n",
       " 'hiçbir',\n",
       " 'için',\n",
       " 'ile',\n",
       " 'ilk',\n",
       " 'iş',\n",
       " 'istiyorsun',\n",
       " 'istiyorum',\n",
       " 'iyi',\n",
       " 'izin',\n",
       " 'kadar',\n",
       " 'mısın',\n",
       " 'işte',\n",
       " 'ki',\n",
       " 'kız',\n",
       " 'lazım',\n",
       " 'lütfen',\n",
       " 'merhaba',\n",
       " 'musun',\n",
       " 'anda',\n",
       " 'basit',\n",
       " 'nerede',\n",
       " 'o',\n",
       " 'olabilir',\n",
       " 'olacak',\n",
       " 'olan',\n",
       " 'olarak',\n",
       " 'oldu',\n",
       " 'olduğunu',\n",
       " 'olmak',\n",
       " 'olmaz',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'oluyor',\n",
       " 'ona',\n",
       " 'önce',\n",
       " 'onları',\n",
       " 'onu',\n",
       " 'onunla',\n",
       " 'orada',\n",
       " 'öyle',\n",
       " 'pekala',\n",
       " 'sadece',\n",
       " 'sana',\n",
       " 'sanırım',\n",
       " 'şekilde',\n",
       " 'seninle',\n",
       " 'şey',\n",
       " 'size',\n",
       " 'sizi',\n",
       " 'son',\n",
       " 'sonra',\n",
       " 'sorun',\n",
       " 'söyle',\n",
       " 'şu',\n",
       " 'tamam',\n",
       " 'tekrar',\n",
       " 'teşekkür',\n",
       " 'üç',\n",
       " 'var',\n",
       " 've',\n",
       " 'ya',\n",
       " 'yardım',\n",
       " 'yeni',\n",
       " 'yine',\n",
       " 'yok',\n",
       " 'yüzden',\n",
       " 'zaten',\n",
       " 'dikkat',\n",
       " 'onlar',\n",
       " 'özür',\n",
       " 'para',\n",
       " 'üzgünüm',\n",
       " 'dilerim',\n",
       " 'şeyi',\n",
       " 'şeyler',\n",
       " 'şimdi',\n",
       " 'siz',\n",
       " 'şunu',\n",
       " 'tabii',\n",
       " 'tam',\n",
       " 'emin',\n",
       " 'seni',\n",
       " 'fikrim',\n",
       " 'gidelim',\n",
       " 'bence',\n",
       " 'benim',\n",
       " 'biraz',\n",
       " 'bugün',\n",
       " 'bunun',\n",
       " 'çünkü',\n",
       " 'daha',\n",
       " 'dakika',\n",
       " 'değilim',\n",
       " 'gerek',\n",
       " 'git',\n",
       " 'içinde',\n",
       " 'küçük',\n",
       " 'mi',\n",
       " 'nasıl',\n",
       " 'gördün',\n",
       " 'görmek',\n",
       " 'ne',\n",
       " 'zaman',\n",
       " 'hem',\n",
       " 'hoşça',\n",
       " 'mü',\n",
       " 'kal',\n",
       " 'memnun',\n",
       " 'vardı',\n",
       " 'yani',\n",
       " 'yapıyorsun',\n",
       " 'merak',\n",
       " 'nereye',\n",
       " 'tüm',\n",
       " 'neyin',\n",
       " 'hakkında',\n",
       " 'mı',\n",
       " 'mu',\n",
       " 'ol',\n",
       " 'peki',\n",
       " 'saat',\n",
       " 'sen',\n",
       " 'tek',\n",
       " 'uzun',\n",
       " 'yoksa',\n",
       " 'sağ',\n",
       " 'tanıyor',\n",
       " 'birkaç',\n",
       " 'birlikte',\n",
       " 'devam',\n",
       " 'yeter',\n",
       " 'yolunda',\n",
       " 'eğer',\n",
       " 'hayır',\n",
       " 'hiç',\n",
       " 'ister',\n",
       " 'kendi',\n",
       " 'kimse',\n",
       " 'ver',\n",
       " 'adam',\n",
       " 'al',\n",
       " 'anne',\n",
       " 'başka',\n",
       " 'biliyor',\n",
       " 'bilmiyorum',\n",
       " 'bir',\n",
       " 'büyük',\n",
       " 'da',\n",
       " 'değil',\n",
       " 'demek',\n",
       " 'en',\n",
       " 'hemen',\n",
       " 'iki',\n",
       " 'kötü',\n",
       " 'neden',\n",
       " 'neler',\n",
       " 'oh',\n",
       " 'önemli',\n",
       " 'onun',\n",
       " 'selam',\n",
       " 'senin',\n",
       " 'teşekkürler',\n",
       " 'etme',\n",
       " 'eder',\n",
       " 'gidiyorsun',\n",
       " 'işin',\n",
       " 'kendine',\n",
       " 'miyim',\n",
       " 'oldum',\n",
       " 'yardımcı',\n",
       " 'dalga',\n",
       " 'dersin',\n",
       " 'diyorsun',\n",
       " 'düşünmüştüm',\n",
       " 'duyuyor',\n",
       " 'fikir',\n",
       " 'fikrin',\n",
       " 'geçiyorsun',\n",
       " 'gereken',\n",
       " 'girecek',\n",
       " 'göstermek',\n",
       " 'hazır',\n",
       " 'hepsi',\n",
       " 'iyilik',\n",
       " 'kes',\n",
       " 'kez',\n",
       " 'olursa',\n",
       " 'sakin',\n",
       " 'saniye',\n",
       " 'sence',\n",
       " 'seviyorum',\n",
       " 'sizin',\n",
       " 'sorabilir',\n",
       " 'söylemem',\n",
       " 'tane',\n",
       " 'yapabileceğim',\n",
       " 'yapabilirim',\n",
       " 'yazık',\n",
       " 'an',\n",
       " 'anlama',\n",
       " 'doğum',\n",
       " 'gidiyor',\n",
       " 'günün',\n",
       " 'istediğim',\n",
       " 'istediğin',\n",
       " 'istediğiniz',\n",
       " 'kutlu',\n",
       " 'olmuş',\n",
       " 'soru',\n",
       " 'söylemek',\n",
       " 'şuna',\n",
       " 'zamanki',\n",
       " 'zor']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file_list = os.listdir(image_path_folder)\n",
    "filename_without_ext_list = []\n",
    "for file in image_file_list:\n",
    "    # file and extention\n",
    "    file_without_ext = os.path.splitext(file)[0]\n",
    "    filename_without_ext_list.append(file_without_ext)\n",
    "filename_without_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_image_file = set(filename_without_ext_list)\n",
    "set_video_file = set(df_file_count[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adın',\n",
       " 'alabilir',\n",
       " 'altı',\n",
       " 'andan',\n",
       " 'anlıyor',\n",
       " 'arada',\n",
       " 'azından',\n",
       " 'be',\n",
       " 'beri',\n",
       " 'beş',\n",
       " 'demedim',\n",
       " 'duyabiliyor',\n",
       " 'dört',\n",
       " 'ediyor',\n",
       " 'eklemek',\n",
       " 'elimden',\n",
       " 'etmek',\n",
       " 'geldiniz',\n",
       " 'geldiğini',\n",
       " 'geldiğiniz',\n",
       " 'gelen',\n",
       " 'gitti',\n",
       " 'hatırlıyor',\n",
       " 'herhangi',\n",
       " 'hoş',\n",
       " 'hoşuna',\n",
       " 'ifade',\n",
       " 'ihtiyacımız',\n",
       " 'ilgili',\n",
       " 'istediğimi',\n",
       " 'itibaren',\n",
       " 'işi',\n",
       " 'komik',\n",
       " 'konuda',\n",
       " 'korkacak',\n",
       " 'kısa',\n",
       " 'misiniz',\n",
       " 'musunuz',\n",
       " 'mıydı',\n",
       " 'nedir',\n",
       " 'nereden',\n",
       " 'olduğu',\n",
       " 'olsa',\n",
       " 'pek',\n",
       " 'sekiz',\n",
       " 'sormak',\n",
       " 'söyleyebilir',\n",
       " 'söz',\n",
       " 'süre',\n",
       " 'sürü',\n",
       " 'taraftan',\n",
       " 'ufak',\n",
       " 'vay',\n",
       " 'veriyorum',\n",
       " 'yapacak',\n",
       " 'yapacağım',\n",
       " 'yapacağız',\n",
       " 'yapıyorsunuz',\n",
       " 'yedi',\n",
       " 'yer',\n",
       " 'yoktur',\n",
       " 'zamana',\n",
       " 'zamandan',\n",
       " 'çocuk'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_video_file.difference(set_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
