{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Gram In N Gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 200  # 28 native word end index\n",
    "\n",
    "# word all usage in twogram\n",
    "word_use_num_min = 1  # word usage in selected twograms \n",
    "word_use_num_max = 2\n",
    "\n",
    "# # adding native word to shared word\n",
    "# twogram_start = 0  # 0 native word start index\n",
    "# twogram_end = 200  # 28 native word end index\n",
    "\n",
    "# sentence check\n",
    "twogram_sentence_check = False  # True, False\n",
    "threegram_sentence_check = False\n",
    "fourgram_sentence_check = False\n",
    "fivegram_sentence_check = False\n",
    "\n",
    "# n gram sample\n",
    "threegram_sample = 6\n",
    "fourgram_sample = 4\n",
    "fivegram_sample = 2\n",
    "\n",
    "# n gram select\n",
    "twogram_select_start = 0\n",
    "twogram_select_end = 10000\n",
    "\n",
    "threegram_select_start = 0\n",
    "threegram_select_end = 10000\n",
    "\n",
    "fourgram_select_start = 0\n",
    "fourgram_select_end = 10000\n",
    "\n",
    "fivegram_select_start = 0\n",
    "fivegram_select_end = 10000\n",
    "\n",
    "# prefix suffix file\n",
    "prefix_suffix = False  # True, False: True for adding prefix suffix word\n",
    "native_word = True # True for adding native word\n",
    "\n",
    "# adding output file extention\n",
    "if prefix_suffix & native_word:\n",
    "    file_ext = \"5\"\n",
    "elif (not prefix_suffix) & native_word:\n",
    "    file_ext = \"6\"\n",
    "else:\n",
    "    file_ext = \"7\"              \n",
    "    \n",
    "# 5 => for only native word with prefix suffix.\n",
    "# 6 => for only native word without prefix suffix.\n",
    "\n",
    "print(f\"{file_ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/\\\n",
    "Deployment2/Result/5-N Gram In N Gram Analysis/{lang_folder.capitalize()}\"\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(df):\n",
    "    for i in df.columns:\n",
    "        new_name = i.strip()\n",
    "        df.rename(columns={f\"{i}\":f\"{new_name}\"}, inplace=True)\n",
    "        df[f\"{new_name}\"] = df[f\"{new_name}\"].apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option\n",
    "if prefix_suffix:\n",
    "    df_word = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/Web Scrapping/Result/{lang_folder.capitalize()}/{lang_folder.capitalize()}/{lang_folder.capitalize()}_{word_end}_Word_Prefix_Suffix_Custom_Result_Manuel.xlsx\")\n",
    "    df_word = df_word.loc[:,[\"word\",\"frequency\"]]\n",
    "    df_word = pd.concat([df_word,df_word_select], axis=0)\n",
    "    df_word.drop_duplicates(inplace=True)    \n",
    "    df_word.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_word.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    df_word = df_word_select\n",
    "\n",
    "if native_word:\n",
    "    df_word\n",
    "else:\n",
    "    df_word = df_word.head(0)\n",
    "\n",
    "df_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_list = [\"sex\",\"seks\",\"seksi\",\"sexy\",\"sexe\",\"seksüel\",\"sexuell\",\"gey\",\"gay\",\"lezbiyen\",\"lesbienne\",\"eşcinsel\",\"mastürbasyon\",\"masturbation\",\"erotik\",\"érotique\", \\\n",
    "\"bikini\",\"penis\",\"vagina\",\"vajina\",\"fetish\",\"fetiş\",\"fetishy\",\"erotic\",\"erotik\",\"sexdom\",\"kondom\",\"condom\",\"dildo\",\"fetisj\",\"hétérosexuel\",\"féticher\",\"fétiche\",\"homosexuel\"\\\n",
    "\"ereksiyon\",\"erectie\",\"erection\",\"érection\",\"homoseksüel\",\"prezervatif\",\"préservatif\",\"ass\",\"fetisch\",\"fetiche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_select = df_word[\"word\"].values.tolist()\n",
    "word_select_set = set(word_select)\n",
    "disable_word_set = set(disable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_select_set.difference(disable_word_set))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if twogram_sentence_check:\n",
    "    df_twogram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Two_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_twogram_sent.rename(columns={\"two_gram\":\"twogram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_twogram = df_twogram_sent.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "else:\n",
    "    df_twogram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Twogram_Merge.csv\")  \n",
    "    df_twogram = df_twogram.loc[:,[\"twogram\",\"frequency\"]]\n",
    "    #df_twogram_select = df_twogram.iloc[twogram_start:twogram_end,]\n",
    "\n",
    "df_twogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list2  = df_twogram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist2 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist2 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list2):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list2.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist2.append(d_list2)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list2) # string_word liste\n",
    "\n",
    "result_list2 = list(resultlist2)\n",
    "df_result2 = pd.DataFrame(result_list2, columns=[0])  # add columns parameter for empty result\n",
    "df_result2 = df_result2.rename(columns = {0: \"twogram\"})\n",
    "df_merge2 = pd.merge(df_result2, df_twogram, how=\"left\", on=\"twogram\")\n",
    "df_merge_result2 = df_merge2.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result2.drop_duplicates(inplace=True)\n",
    "df_merge_result2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# all word should be used at least once\n",
    "#df_twogram_select = df_merge_result2.iloc[twogram_start:twogram_end,]\n",
    "\n",
    "df_merge_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word usage in twogram condition\n",
    "word_num_dict = {}\n",
    "for i in word_list:\n",
    "    word_num_dict[f\"{i}\"] = 0\n",
    "\n",
    "result_list_select = []\n",
    "var_list = []\n",
    "for i in range(len(df_merge_result2)):\n",
    "    twogram = df_merge_result2.loc[i,\"twogram\"]\n",
    "    frequency = df_merge_result2.loc[i,\"frequency\"]\n",
    "    words = word_tokenize(twogram)   \n",
    "    temp_list = [word for word in words]\n",
    "    temp_list = temp_list + var_list\n",
    "    # word count for max\n",
    "    dict_list_count = Counter(temp_list)\n",
    "    count_list = list(dict_list_count.values())\n",
    "    # word count for min\n",
    "    count_list2 = list(word_num_dict.values())\n",
    "\n",
    "    if any([True if i>word_use_num_max else False for i in count_list]) or not(any([True if j<word_use_num_min else False for j in count_list2])):\n",
    "        pass\n",
    "    else:\n",
    "        var_list = temp_list\n",
    "        result_list_select.append([twogram,frequency]) \n",
    "\n",
    "        for item2 in dict_list_count.items(): \n",
    "            word_num_dict[item2[0]] = item2[1]        \n",
    "\n",
    "print(f\"Max condition: {any([True if i>word_use_num_max else False for i in count_list2])} \\nMin condition: {any([True if j<word_use_num_min else False for j in count_list2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_select = pd.DataFrame(result_list_select, columns=[\"twogram\",\"frequency\"])\n",
    "df_twogram_select.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "df_twogram_select.reset_index(drop=True, inplace=True)\n",
    "df_twogram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threegram_sentence_check:\n",
    "    df_threegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Three_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_threegram_sent.rename(columns={\"three_gram\":\"threegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_threegram = df_threegram_sent.loc[:,[\"threegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_threegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Threegram_Merge.csv\")  \n",
    "    df_threegram = df_threegram.loc[:,[\"threegram\",\"frequency\"]]\n",
    "\n",
    "df_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list3  = df_threegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist3 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist3 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list3):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list3.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist3.append(d_list3)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list3) # string_word liste\n",
    "\n",
    "result_list3 = list(resultlist3)\n",
    "df_result3 = pd.DataFrame(result_list3, columns=[0])  # add columns parameter for empty result\n",
    "df_result3 = df_result3.rename(columns = {0: \"threegram\"})\n",
    "df_merge3 = pd.merge(df_result3, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_merge_result3 = df_merge3.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result3.drop_duplicates(inplace=True)\n",
    "df_merge_result3.reset_index(drop=True, inplace=True)\n",
    "df_threegram_select = df_merge_result3\n",
    "df_threegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fourgram_sentence_check:\n",
    "    df_fourgram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Four_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fourgram_sent.rename(columns={\"four_gram\":\"fourgram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fourgram = df_fourgram_sent.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fourgram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fourgram_Merge.csv\")  \n",
    "    df_fourgram = df_fourgram.loc[:,[\"fourgram\",\"frequency\"]]\n",
    "\n",
    "df_fourgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list4  = df_fourgram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist4 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist4 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list4):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list4.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist4.append(d_list4)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list4) # string_word liste\n",
    "\n",
    "result_list4 = list(resultlist4)\n",
    "df_result4 = pd.DataFrame(result_list4, columns=[0])  # add columns parameter for empty result\n",
    "df_result4 = df_result4.rename(columns = {0: \"fourgram\"})\n",
    "df_merge4 = pd.merge(df_result4, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_merge_result4 = df_merge4.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result4.drop_duplicates(inplace=True)\n",
    "df_merge_result4.reset_index(drop=True, inplace=True)\n",
    "df_fourgram_select = df_merge_result4\n",
    "df_fourgram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fivegram_sentence_check:\n",
    "    df_fivegram_sent = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/N Gram And Sentence/Five_Gram_And_Sentence.csv\")  # ext. sentence and ngram\n",
    "    df_fivegram_sent.rename(columns={\"five_gram\":\"fivegram\"}, inplace=True)  # ext. Not: Two_Gram_And_Sentence.csv convert to Two_Gram_And_Sentence_All.csv\n",
    "    df_fivegram = df_fivegram_sent.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "else:\n",
    "    df_fivegram = pd.read_csv(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.capitalize()}/Result/N Gram/Merge/Fivegram_Merge.csv\")  \n",
    "    df_fivegram = df_fivegram.loc[:,[\"fivegram\",\"frequency\"]]\n",
    "\n",
    "df_fivegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list5  = df_fivegram.iloc[:,0].values.tolist()\n",
    "\n",
    "resultlist5 = []\n",
    "manager = multiprocessing.Manager()\n",
    "resultlist5 = manager.list()\n",
    "\n",
    "def word_in_wordgroup(d_list5):\n",
    "    mergelist = []\n",
    "    try:\n",
    "        word = d_list5.split()\n",
    "    except:\n",
    "        word = []\n",
    "        #pass  disabled for non split value\n",
    "    var1 = range(len(word))\n",
    "    for j in var1:\n",
    "        if word[j] in word_list:\n",
    "            mergelist.append(word[j])\n",
    "            if len(mergelist) == len(word):\n",
    "                    resultlist5.append(d_list5)\n",
    "                        \n",
    "if __name__ == '__main__':\n",
    "    # with Pool(16) as p:\n",
    "    with Pool(nprocs) as p: # Pool number CPU sayısına eşit olursa tüm CPU lar çalışır\n",
    "        p.map(word_in_wordgroup, d_list5) # string_word liste\n",
    "\n",
    "result_list5 = list(resultlist5)\n",
    "df_result5 = pd.DataFrame(result_list5, columns=[0])  # add columns parameter for empty result\n",
    "df_result5 = df_result5.rename(columns = {0: \"fivegram\"})\n",
    "df_merge5 = pd.merge(df_result5, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_merge_result5 = df_merge5.sort_values(by=\"frequency\", ascending=False)\n",
    "df_merge_result5.drop_duplicates(inplace=True)\n",
    "df_merge_result5.reset_index(drop=True, inplace=True)\n",
    "df_fivegram_select = df_merge_result5\n",
    "df_fivegram_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_concat = pd.concat([df_twogram_select, df_threegram_select, df_fourgram_select, df_fivegram_select], axis=1)\n",
    "df_ngram_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"threegram\",threegram_sample)\n",
    "df_two_in_four = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fourgram\",fourgram_sample)\n",
    "df_two_in_five = word_in_wordgroup_simple(df_ngram_concat, \"twogram\",\"fivegram\",fivegram_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twogram_order_join_threegram = df_two_in_three.groupby([\"twogram\"])[\"threegram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fourgram = df_two_in_four.groupby([\"twogram\"])[\"fourgram\"].apply(\", \".join).reset_index()\n",
    "df_twogram_order_join_fivegram = df_two_in_five.groupby([\"twogram\"])[\"fivegram\"].apply(\", \".join).reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_twogram_order_join_threegram, df_twogram_order_join_fourgram, df_twogram_order_join_fivegram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = reduce(lambda  left,right: pd.merge(left,right, on=['twogram'], how='outer'), dfs)\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge = pd.merge(df_ngram_sample_join_merge, df_twogram_select, how=\"right\", on=\"twogram\")\n",
    "df_ngram_sample_join_merge.drop_duplicates(inplace=True)\n",
    "df_ngram_sample_join_merge.rename(columns={\"frequency\":\"two_freq\"}, inplace=True)\n",
    "df_ngram_sample_join_merge.sort_values(by=\"two_freq\", ascending=False, inplace=True)\n",
    "df_ngram_sample_join_merge.reset_index(drop=True, inplace=True)\n",
    "df_ngram_sample_join_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_join_merge.to_excel(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Join_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Frequency For Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_three_freq = pd.merge(df_two_in_three, df_threegram, how=\"left\", on=\"threegram\")\n",
    "df_two_in_three_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_three_freq.rename(columns={\"frequency\":\"three_freq\"}, inplace=True)\n",
    "df_two_in_three_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_three_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_four_freq = pd.merge(df_two_in_four, df_fourgram, how=\"left\", on=\"fourgram\")\n",
    "df_two_in_four_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_four_freq.rename(columns={\"frequency\":\"four_freq\"}, inplace=True)\n",
    "df_two_in_four_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_four_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two_in_five_freq = pd.merge(df_two_in_five, df_fivegram, how=\"left\", on=\"fivegram\")\n",
    "df_two_in_five_freq.drop_duplicates(inplace=True)\n",
    "df_two_in_five_freq.rename(columns={\"frequency\":\"five_freq\"}, inplace=True)\n",
    "df_two_in_five_freq.drop([\"twogram\"], axis=1, inplace=True)\n",
    "df_two_in_five_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat = pd.concat([df_twogram_select,df_two_in_three_freq, df_two_in_four_freq, df_two_in_five_freq], axis=1)\n",
    "df_ngram_sample_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_sample_concat.to_excel(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_With_{word_end}_Word_Frequency_Result.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Result And Select Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram_threegram_unique = df_ngram_sample_concat[[\"threegram\",\"three_freq\"]].drop_duplicates()\n",
    "df_ngram_fourgram_unique = df_ngram_sample_concat[[\"fourgram\",\"four_freq\"]].drop_duplicates()\n",
    "df_ngram_fivegram_unique = df_ngram_sample_concat[[\"fivegram\",\"five_freq\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_result_freq = df_twogram_select[\"frequency\"].sum()\n",
    "threegram_result_freq = df_ngram_threegram_unique[\"three_freq\"].sum()\n",
    "fourgram_result_freq = df_ngram_fourgram_unique[\"four_freq\"].sum()\n",
    "fivegram_result_freq = df_ngram_fivegram_unique[\"five_freq\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twogram_select_freq = df_twogram.iloc[twogram_select_start:twogram_select_end,][\"frequency\"].sum()\n",
    "threegram_select_freq = df_threegram.iloc[threegram_select_start:threegram_select_end,][\"frequency\"].sum()\n",
    "fourgram_select_freq = df_fourgram.iloc[fourgram_select_start:fourgram_select_end,][\"frequency\"].sum()\n",
    "fivegram_select_freq = df_fivegram.iloc[fivegram_select_start:fivegram_select_end,][\"frequency\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(twogram_result_freq/twogram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(threegram_result_freq/threegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fourgram_result_freq/fourgram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fivegram_result_freq/fivegram_select_freq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Move And Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = glob.glob(f\"{lang_folder.capitalize()}_{len(df_twogram_select)}_Twogram_In_{threegram_sample}_Threegram_{fourgram_sample}_\\\n",
    "Fourgram_{fivegram_sample}_Fivegram_Sample_*_Result.xlsx\")\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output_file:\n",
    "    source = k # source directory\n",
    "    destination = path\n",
    "    shutil.copy2(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output_file:\n",
    "    try:\n",
    "        os.remove(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "#import multiprocessing as mp\n",
    "from multiprocessing import Process, Manager, Pool, Queue\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "nprocs = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPU cores: {nprocs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language pair\n",
    "lang_folder = \"Turkish\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> target language for learner\n",
    "#lang_pair = \"Intersect\"  # Arabic, English, French, German, Turkish, Spanish, Portuguese, Dutch, Italian ==> native language\n",
    "\n",
    "# adding native word to shared word\n",
    "word_start = 0  # 0 native word start index\n",
    "word_end = 200  # 28 native word end index\n",
    "\n",
    "# word all usage in twogram\n",
    "word_use_num_min = 1  # word usage in selected twograms \n",
    "word_use_num_max = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_usage_result(word_list, df_target, target_column, word_usage_min, word_usage_max): # word_usage_result(word_list, df_target, target_column, target_opt_column, word_usage_min, word_usage_max)\n",
    "    '''\n",
    "    word_usage_result(word_list, df_ngram_pair, \"threegram\", \"frequency\", 1, 5) \\n\n",
    "    word_list is a list, df_target is a dateframe, target_column is df_target dataframe target column, \\n\n",
    "    target_opt_column is df_target dataframe opt_target column, \\n\n",
    "    word_usage_min and word_usage_max word usage condition.\n",
    "    '''    \n",
    "    word_num_dict = {}\n",
    "    for i in word_list:\n",
    "        word_num_dict[f\"{i}\"] = 0\n",
    "    \n",
    "    result_list_select = []\n",
    "    var_list = []\n",
    "    for i in range(len(df_target)):\n",
    "        target_value = df_target.loc[i,f\"{target_column}\"]\n",
    "        #opt_value = df_target.loc[i,f\"{target_opt_column}\"]\n",
    "        words = word_tokenize(target_value)   \n",
    "        temp_list = [word for word in words]\n",
    "        temp_list = temp_list + var_list\n",
    "        # word count for max\n",
    "        dict_list_count = Counter(temp_list)\n",
    "        count_list = list(dict_list_count.values())\n",
    "        # word count for min\n",
    "        count_list2 = list(word_num_dict.values())\n",
    "    \n",
    "        if any([True if i>word_usage_max else False for i in count_list]) or not(any([True if j<word_usage_min else False for j in count_list2])):\n",
    "            pass\n",
    "        else:\n",
    "            var_list = temp_list\n",
    "            result_list_select.append([target_value])\n",
    "            #result_list_select.append([target_value,opt_value])  \n",
    "    \n",
    "            for item2 in dict_list_count.items(): \n",
    "                word_num_dict[item2[0]] = item2[1]        \n",
    "    df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\"])\n",
    "    #df_result = pd.DataFrame(result_list_select, columns=[f\"{target_column}\",f\"{target_opt_column}\"])\n",
    "    #df_result.sort_values(by=\"frequency\", ascending=False, inplace=True)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_result(df,column_list): # df is dataframe, column_list is list value\n",
    "    '''\n",
    "    word_count_bool(df, column_list): df columns word count for word frequency\\n\n",
    "    df is dataframe, column_list is list value\\n\n",
    "    word_count_bool(df, [\"word\",\"twogram\"]):\n",
    "    '''\n",
    "    list_all = []\n",
    "    for i in df.loc[:,[x for x in column_list]].columns:\n",
    "        var_list = df[f\"{i}\"].dropna().tolist()\n",
    "        for j in var_list:\n",
    "            list_all.append(j)\n",
    "    text = \" \".join(list_all)\n",
    "    word_list = re.findall(r\"\\w+\",text, re.UNICODE)\n",
    "    df_word_list = pd.DataFrame(word_list, columns=[\"word\"])\n",
    "    #df_word_list.rename(columns={0:\"word\"}, inplace=True)\n",
    "    df_word_count = pd.DataFrame(df_word_list.value_counts())\n",
    "    df_word_count.reset_index(inplace=True)\n",
    "    df_word_count.rename(columns={0:\"word_count\"}, inplace=True)\n",
    "    \n",
    "    return  df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_wordgroup_simple(df, source_column, target_column, word_sample_num):\n",
    "\n",
    "    '''word_in_wordgroup(df, \"word\", \"twogram\"):\n",
    "       df is dataframe, source_column and target_column are \n",
    "       dataframe column string name. source_column convert list\n",
    "       values that are in target column.\n",
    "    '''\n",
    "    \n",
    "    df_select = df[[f\"{target_column}\"]].dropna()\n",
    "    df_result = pd.DataFrame()\n",
    "    for i in df[f\"{source_column}\"].dropna():\n",
    "        try:\n",
    "            word_in_word_cluster = df_select[df_select[f\"{target_column}\"].str.contains(fr\"(?:\\s|^){i}(?:\\s|$)\", na=True)].head(word_sample_num)    \n",
    "        except:\n",
    "            pass        \n",
    "        word_in_word_cluster.insert(0,f\"{source_column}\",i)\n",
    "        df_result = pd.concat([df_result,word_in_word_cluster], axis=0)\n",
    "    df_result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bir</td>\n",
       "      <td>18835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bu</td>\n",
       "      <td>11062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ne</td>\n",
       "      <td>8025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ve</td>\n",
       "      <td>7766036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>için</td>\n",
       "      <td>5484109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987922</th>\n",
       "      <td>karneleme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987923</th>\n",
       "      <td>karnaya</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987924</th>\n",
       "      <td>dörtlümüzün</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987925</th>\n",
       "      <td>karnavalınız</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987926</th>\n",
       "      <td>hurmanın</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987927 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  frequency\n",
       "0                bir   18835735\n",
       "1                 bu   11062659\n",
       "2                 ne    8025880\n",
       "3                 ve    7766036\n",
       "4               için    5484109\n",
       "...              ...        ...\n",
       "987922     karneleme          5\n",
       "987923       karnaya          5\n",
       "987924   dörtlümüzün          5\n",
       "987925  karnavalınız          5\n",
       "987926      hurmanın          5\n",
       "\n",
       "[987927 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_all = pd.read_excel(f\"/media/kurubal/SSD/Data Scientist/Work/Modern Ways/Project/{lang_folder.lower().capitalize()}/Deployment/Data/Word/Word_Merge_Preprocess.xlsx\")\n",
    "df_word_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_select = df_word_all.iloc[word_start:word_end,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word_select[\"word\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asla olmaz</td>\n",
       "      <td>ama neden böyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aynı şekilde</td>\n",
       "      <td>ama o benim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aynı şeyi</td>\n",
       "      <td>ama şimdi olmaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>başka biri</td>\n",
       "      <td>artık herkes biliyor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>başka kimse</td>\n",
       "      <td>aynı şekilde devam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bir de şu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bir daha asla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>peki ne için</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>daha da fazla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bu çok güzel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          twogram             threegram\n",
       "0      asla olmaz       ama neden böyle\n",
       "1    aynı şekilde           ama o benim\n",
       "2       aynı şeyi       ama şimdi olmaz\n",
       "3      başka biri  artık herkes biliyor\n",
       "4     başka kimse    aynı şekilde devam\n",
       "..            ...                   ...\n",
       "343           NaN             bir de şu\n",
       "344           NaN         bir daha asla\n",
       "345           NaN          peki ne için\n",
       "346           NaN         daha da fazla\n",
       "347           NaN          bu çok güzel\n",
       "\n",
       "[348 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_three = pd.read_excel(\"/home/kurubal/Downloads/Twogram Threegram.xlsx\")\n",
    "df_two_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bu</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>çok</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ne</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daha</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>seni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>siz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>demek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>söyle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>kazanmak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count\n",
       "0          bu          61\n",
       "1         çok          38\n",
       "2           o          32\n",
       "3          ne          31\n",
       "4        daha          26\n",
       "..        ...         ...\n",
       "152      seni           1\n",
       "153       siz           1\n",
       "154     demek           1\n",
       "155     söyle           1\n",
       "156  kazanmak           1\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_result(df_two_three,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_three[\"twogram\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_three[\"threegram\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twogram</th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asla olmaz</td>\n",
       "      <td>hayır asla olmaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aynı şekilde</td>\n",
       "      <td>aynı şekilde devam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aynı şekilde</td>\n",
       "      <td>aynı şekilde mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aynı şeyi</td>\n",
       "      <td>aynı şeyi ben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aynı şeyi</td>\n",
       "      <td>aynı şeyi mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tamam mı</td>\n",
       "      <td>değil tamam mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tamam mı</td>\n",
       "      <td>istiyorum tamam mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tamam mı</td>\n",
       "      <td>ol tamam mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tamam mı</td>\n",
       "      <td>yok tamam mı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ya da</td>\n",
       "      <td>ya da başka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          twogram           threegram\n",
       "0      asla olmaz    hayır asla olmaz\n",
       "1    aynı şekilde  aynı şekilde devam\n",
       "2    aynı şekilde     aynı şekilde mi\n",
       "3       aynı şeyi       aynı şeyi ben\n",
       "4       aynı şeyi        aynı şeyi mi\n",
       "..            ...                 ...\n",
       "271      tamam mı      değil tamam mı\n",
       "272      tamam mı  istiyorum tamam mı\n",
       "273      tamam mı         ol tamam mı\n",
       "274      tamam mı        yok tamam mı\n",
       "275         ya da         ya da başka\n",
       "\n",
       "[276 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_in_three = word_in_wordgroup_simple(df_two_three, \"twogram\",\"threegram\",threegram_sample)\n",
    "df_two_in_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_twogram = set(df_two_three[\"twogram\"].dropna().to_list())\n",
    "set_twogram_in_threegram = set(df_two_in_three[\"twogram\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'para için'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_all_twogram.difference(set_twogram_in_threegram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerek yok değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benimle geliyor musun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ve sen de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadece biraz daha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bana yardım et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>hayır sorun yok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>neden biliyor musun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>biliyorsun değil mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>hey buraya gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>doğru mu bilmiyorum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 threegram\n",
       "0          gerek yok değil\n",
       "1    benimle geliyor musun\n",
       "2                ve sen de\n",
       "3        sadece biraz daha\n",
       "4           bana yardım et\n",
       "..                     ...\n",
       "258        hayır sorun yok\n",
       "259    neden biliyor musun\n",
       "260    biliyorsun değil mi\n",
       "261         hey buraya gel\n",
       "262    doğru mu bilmiyorum\n",
       "\n",
       "[263 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_threegram_cover_twogram = set(df_two_in_three[\"threegram\"].to_list())\n",
    "df_selected_threegram = pd.DataFrame(set_threegram_cover_twogram,columns=[\"threegram\"])\n",
    "df_selected_threegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_threegram.to_excel(\"Threegram_Selected.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bu</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>çok</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>değil</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mi</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yok</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>bize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>seni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>siz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>bilmiyorum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>geldi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  word_count\n",
       "0            bu          30\n",
       "1           çok          17\n",
       "2         değil          17\n",
       "3            mi          17\n",
       "4           yok          16\n",
       "..          ...         ...\n",
       "147        bize           1\n",
       "148        seni           1\n",
       "149         siz           1\n",
       "150  bilmiyorum           1\n",
       "151       geldi           1\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_result(df_selected_threegram,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threegram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerek yok değil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benimle geliyor musun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ve sen de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadece biraz daha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bana yardım et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>bunu herkes biliyor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tam ona göre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>önemli olan da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>şimdi bana bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>hiç sorun değil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 threegram\n",
       "0          gerek yok değil\n",
       "1    benimle geliyor musun\n",
       "2                ve sen de\n",
       "3        sadece biraz daha\n",
       "4           bana yardım et\n",
       "..                     ...\n",
       "107    bunu herkes biliyor\n",
       "108           tam ona göre\n",
       "109         önemli olan da\n",
       "110         şimdi bana bak\n",
       "111        hiç sorun değil\n",
       "\n",
       "[112 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_threegram_word_usage_select = word_usage_result(word_list, df_selected_threegram, \"threegram\", word_use_num_min, word_use_num_max)\n",
    "df_threegram_word_usage_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ama</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daha</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tam</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kadar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>seni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>efendim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>siz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>doğru</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>kimse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  word_count\n",
       "0        ama           4\n",
       "1       daha           4\n",
       "2         de           4\n",
       "3        tam           4\n",
       "4      kadar           4\n",
       "..       ...         ...\n",
       "126     seni           1\n",
       "127  efendim           1\n",
       "128      siz           1\n",
       "129    doğru           1\n",
       "130    kimse           1\n",
       "\n",
       "[131 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_result(df_threegram_word_usage_select,[\"threegram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651d507d70892fab0fc6529d935cd476f6e2eb1791525b76da6cc8da34bc0503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
