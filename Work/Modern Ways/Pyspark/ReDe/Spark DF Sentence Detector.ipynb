{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "665560ad",
      "metadata": {
        "id": "665560ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/kurubal/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pyspark.ml import PipelineModel\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('tagsets')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.help.upenn_tagset('NNP')\n",
        "nltk.help.upenn_tagset('NN')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2fa793",
      "metadata": {
        "id": "ca2fa793"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37702a67",
      "metadata": {
        "id": "37702a67"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  with open(\"tr1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text_data = file.read()\n",
        "except:\n",
        "  print(\"There is not such a file  or path is incorrect\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82d3016",
      "metadata": {
        "id": "f82d3016"
      },
      "outputs": [],
      "source": [
        "text_data_clean_brackets = re.sub('[\\(\\[\\{].*?[\\)\\]\\}]', '', text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725ca812",
      "metadata": {
        "id": "725ca812"
      },
      "outputs": [],
      "source": [
        "custom_char = [\"-\",\"#\",\":\",\"~\",\"$\",\"*\",\"/\",\"+\"]\n",
        "for i in custom_char:\n",
        "    text_data_clean_brackets = text_data_clean_brackets.replace(i, '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb701474",
      "metadata": {
        "id": "fb701474"
      },
      "outputs": [],
      "source": [
        "text = re.sub(r\"\\'\", \"\", string=text_data_clean_brackets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z9LQEn0TMRj1",
      "metadata": {
        "id": "Z9LQEn0TMRj1"
      },
      "source": [
        "# START"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Y8oAjwGLMn2u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8oAjwGLMn2u",
        "outputId": "6c8434b3-ea53-469f-9128-e0567eb923d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 64 kB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 61.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1wgPalVmM9Ag",
      "metadata": {
        "id": "1wgPalVmM9Ag"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "_obzqlfb7ICO",
      "metadata": {
        "id": "_obzqlfb7ICO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "builder = SparkSession.builder\\\n",
        "        .appName(\"Spark NLP Licensed\")\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .config(\"spark.driver.memory\", \"24G\")\\\n",
        "        .config(\"spark.driver.maxResultSize\", \"2048GB\")\\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\")\n",
        "\n",
        "spark = builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "iUEILhczM6R6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "iUEILhczM6R6",
        "outputId": "16f227a3-6756-4e22-d6e8-f251e9a3b91f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://146697cdc196:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f208e466790>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ryQdAHB7RDyf",
      "metadata": {
        "id": "ryQdAHB7RDyf"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "for i in {0..10}\n",
        "do\n",
        " wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_$i.txt -P oncology_notes\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IhJy9bO-TeGo",
      "metadata": {
        "id": "IhJy9bO-TeGo"
      },
      "source": [
        "## Reading the divided text file as a spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uac0GB_ON1wL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uac0GB_ON1wL",
        "outputId": "26dd62a4-e9b0-43e1-e27c-07e911e0bd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|                path|                text|\n",
            "+--------------------+--------------------+\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "|file:/content/onc...|Sample Type / Med...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "textFiles = spark.sparkContext.wholeTextFiles(\"oncology_notes/*\")\n",
        "\n",
        "df = textFiles.toDF(schema=['path','text'])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af-_bZCN9oz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3af-_bZCN9oz",
        "outputId": "877b2f3c-1c09-45ef-caed-49dd3d4e4ef2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(text='Sample Type / Medical Specialty:\\nHematology - Oncology\\nSample Name:\\nDischarge Summary - Mesothelioma - 1\\nDescription:\\nMesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.\\n(Medical Transcription Sample Report)\\nPRINCIPAL DIAGNOSIS:\\nMesothelioma.\\nSECONDARY DIAGNOSES:\\nPleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.\\nPROCEDURES\\n1. On August 24, 2007, decortication of the lung with pleural biopsy and transpleural fluoroscopy.\\n2. On August 20, 2007, thoracentesis.\\n3. On August 31, 2007, Port-A-Cath placement.\\nHISTORY AND PHYSICAL:\\nThe patient is a 41-year-old Vietnamese female with a nonproductive cough that started last week. She has had right-sided chest pain radiating to her back with fever starting yesterday. She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center. Chest x-ray revealed right-sided pleural effusion.\\nPAST MEDICAL HISTORY\\n1. Pericardectomy.\\n2. Pericarditis.\\n2. Atrial fibrillation.\\n4. RNCA with intracranial thrombolytic treatment.\\n5 PTA of MCA.\\n6. Mesenteric venous thrombosis.\\n7. Pericardial window.\\n8. Cholecystectomy.\\n9. Left thoracentesis.\\nFAMILY HISTORY:\\nNo family history of coronary artery disease, CVA, diabetes, CHF or MI. The patient has one family member, a sister, with history of cancer.\\nSOCIAL HISTORY:\\nShe is married. Employed with the US Post Office. She is a mother of three. Denies tobacco, alcohol or illicit drug use.\\nMEDICATIONS\\n1. Coumadin 1 mg daily. Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.\\n2. Amiodarone 100 mg p.o. daily.\\nREVIEW OF SYSTEMS:\\nComplete review of systems negative except as in pulmonary as noted above. The patient also reports occasional numbness and tingling of her left arm.\\nPHYSICAL EXAMINATION\\nVITAL SIGNS: Blood pressure 123/95, heart rate 83, respirations 20, temperature 97, and oxygen saturation 97%.\\nGENERAL: Positive nonproductive cough and pain with coughing.\\nHEENT: Pupils are equal and reactive to light and accommodation. Tympanic membranes are clear.\\nNECK: Supple. No lymphadenopathy. No masses.\\nRESPIRATORY: Pleural friction rub is noted.\\nGI: Soft, nondistended, and nontender. Positive bowel sounds. No organomegaly.\\nEXTREMITIES: No edema, no clubbing, no cyanosis, no tenderness. Full range of motion. Normal pulses in all extremities.\\nSKIN: No breakdown or lesions. No ulcers.\\nNEUROLOGIC: Grossly intact. No focal deficits. Awake, alert, and oriented to person, place, and time.\\nLABORATORY DATA:\\nLabs are pending.\\nHOSPITAL COURSE:\\nThe patient was admitted for a right-sided pleural effusion for thoracentesis on Monday by Dr. X. Her Coumadin was placed on hold. A repeat echocardiogram was checked. She was started on prophylaxis for DVT with Lovenox 40 mg subcutaneously. Her history dated back to March 2005 when she first sought medical attention for evidence of pericarditis, which was treated with pericardial window in an outside hospital, at that time she was also found to have mesenteric pain and thrombosis, is now anticoagulated. Her pericardial fluid was accumulated and she was seen by Dr. Y. At that time, she was recommended for pericardectomy, which was performed by Dr. Z. Review of her CT scan from March 2006 prior to her pericardectomy, already shows bilateral plural effusions. The patient improved clinically after the pericardectomy with resolution of her symptoms. Recently, she was readmitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. CT of the chest also revealed a large mediastinal lymph node. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed epithelioid malignant mesothelioma. The patient was then stained with a PET CT, which showed extensive uptake in the chest, bilateral pleural pericardial effusions, and lymphadenopathy. She also had acidic fluid, pectoral and intramammary lymph nodes and uptake in L4 with SUV of 4. This was consistent with stage III disease. Her repeat echocardiogram showed an ejection fraction of 45% to 49%. She was transferred to Oncology service and started on chemotherapy on September 1, 2007 with cisplatin 75 mg/centimeter squared equaling 109 mg IV piggyback over 2 hours on September 1, 2007, Alimta 500 mg/ centimeter squared equaling 730 mg IV piggyback over 10 minutes. This was all initiated after a Port-A-Cath was placed. The chemotherapy was well tolerated and the patient was discharged the following day after discontinuing IV fluid and IV. Her Port-A-Cath was packed with heparin according to protocol.\\nDISCHARGE MEDICATIONS:\\nZofran, Phenergan, Coumadin, and Lovenox, and Vicodin\\nDISCHARGE INSTRUCTIONS:\\nShe was instructed to followup with Dr. XYZ in the office to check her INR on Tuesday. She was instructed to call if she had any other questions or concerns in the interim.\\n')]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.select(\"text\").head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4KNoovgUGfD",
      "metadata": {
        "id": "a4KNoovgUGfD"
      },
      "source": [
        "## Repartitioning by Dataframe\n",
        "\n",
        "Selecting the number of repartition depends on your sources. Increasing so high doesn't mean make faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XfhhCRIzULtx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfhhCRIzULtx",
        "outputId": "9b26f311-5dac-4ed9-b870-feb30bd3e9d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LO4bmTj3UGDR",
      "metadata": {
        "id": "LO4bmTj3UGDR"
      },
      "outputs": [],
      "source": [
        "df = df.repartition(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s-mPXU8WUTFl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-mPXU8WUTFl",
        "outputId": "74a468b3-c627-4d53-95fd-dca729720dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "38fcb741",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38fcb741",
        "outputId": "17ba3742-f445-4f05-a926-324eb6599f3c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documenter = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "sentencerDL = SentenceDetectorDLModel\\\n",
        "    .pretrained(\"sentence_detector_dl\", \"xx\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentences\")\n",
        "\n",
        "model = PipelineModel(stages=[documenter, sentencerDL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae56cd03",
      "metadata": {
        "id": "ae56cd03"
      },
      "outputs": [],
      "source": [
        "result = model.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PWnbG_GZkUfZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWnbG_GZkUfZ",
        "outputId": "0fc3fbde-c6d8-4a4f-8fbe-19917e216c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                path|                text|            document|           sentences|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 35...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 51...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 26...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 56...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 44...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 52...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 23...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 39...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 35...|[{document, 0, 54...|\n",
            "|file:/content/onc...|Sample Type / Med...|[{document, 0, 32...|[{document, 0, 54...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "peBvGFAAkfUz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "peBvGFAAkfUz",
        "outputId": "a6dcde11-82d1-4a77-eea6-c90fe0a6f742"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_3.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_0.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_1.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_2.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_4.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_6.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_8.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_9.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_5.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>file:/content/oncology_notes/mt_oncology_7.txt</td>\n",
              "      <td>[Sample Type / Medical Specialty:\\nHematology ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             path                                             result\n",
              "0  file:/content/oncology_notes/mt_oncology_3.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "1  file:/content/oncology_notes/mt_oncology_0.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "2  file:/content/oncology_notes/mt_oncology_1.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "3  file:/content/oncology_notes/mt_oncology_2.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "4  file:/content/oncology_notes/mt_oncology_4.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "5  file:/content/oncology_notes/mt_oncology_6.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "6  file:/content/oncology_notes/mt_oncology_8.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "7  file:/content/oncology_notes/mt_oncology_9.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "8  file:/content/oncology_notes/mt_oncology_5.txt  [Sample Type / Medical Specialty:\\nHematology ...\n",
              "9  file:/content/oncology_notes/mt_oncology_7.txt  [Sample Type / Medical Specialty:\\nHematology ..."
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_res = result.select(\"path\",\"sentences.result\").toPandas()\n",
        "pd_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oEhP-WQlk5Q6",
      "metadata": {
        "id": "oEhP-WQlk5Q6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\", 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q-KJSe89lCqd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-KJSe89lCqd",
        "outputId": "ba4d6c4d-cec9-42e2-8c6b-b6951208c663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Sample Type / Medical Specialty:\\nHematology - Oncology',\n",
              " 'Sample Name:\\nParathyroid Adenoma Excision',\n",
              " 'Description:\\nExcision of right superior parathyroid adenoma, seen on sestamibi parathyroid scan and an ultrasound.',\n",
              " '(Medical Transcription Sample Report)',\n",
              " 'PREOPERATIVE DIAGNOSIS:\\nRight superior parathyroid adenoma.',\n",
              " 'POSTOPERATIVE DIAGNOSIS:\\nRight superior parathyroid adenoma.',\n",
              " 'PROCEDURE:\\nExcision of right superior parathyroid adenoma.',\n",
              " 'ANESTHESIA:\\nLocal with 1% Xylocaine and anesthesia standby with sedation.',\n",
              " 'CLINICAL HISTORY:\\nThis 80-year-old woman has had some mild dementia.',\n",
              " 'She was begun on Aricept but could not tolerate that because of strange thoughts and hallucinations.',\n",
              " 'She was found to be hypercalcemic.',\n",
              " 'Intact PTH was mildly elevated.',\n",
              " 'A sestamibi parathyroid scan and an ultrasound showed evidence of a right superior parathyroid adenoma.',\n",
              " 'FINDINGS AND PROCEDURE:\\nThe patient was placed on the operating table in the supine position.',\n",
              " \"A time out was taken so that the anesthesia personnel, nursing personnel, surgical team, and patient could confirm the patient's identity, operative site and operative plan.\",\n",
              " 'The electronic medical record was reviewed as was the ultrasound.',\n",
              " 'The patient was sedated.',\n",
              " 'A small roll was placed behind the shoulders to moderately hyperextend the neck.',\n",
              " 'The head was supported in a foam head cradle.',\n",
              " 'The neck and chest were prepped with chlorhexidine and isolated with sterile drapes.',\n",
              " 'After infiltration with 1% Xylocaine with epinephrine along the planned incision, a transverse incision was made in the skin crease a couple of centimeters above the clavicular heads and carried down through the skin, subcutaneous tissue, and platysma.',\n",
              " 'The larger anterior neck veins were divided between 4-0 silk ligatures.',\n",
              " 'Superior and inferior flaps were developed in the subplatysmal plane using electrocautery and blunt dissection.',\n",
              " 'The sternohyoid muscles were separated in the midline, and the right sternohyoid muscle was retracted laterally.',\n",
              " 'The right sternothyroid muscle was divided transversely with the cautery.',\n",
              " 'The right middle thyroid vein was divided between 4-0 silk ligatures.',\n",
              " 'The right thyroid lobe was rotated leftward.',\n",
              " 'Posterior to the mid portion of the left thyroid lobe, a right superior parathyroid adenoma of moderate size was identified.',\n",
              " 'This was freed up and its pedicle was ligated with small Hemoclips and divided and the gland was removed.',\n",
              " 'It was sent for weight and frozen section.',\n",
              " 'It weighed 960 mg and on frozen section was consistent with a parathyroid adenoma.',\n",
              " 'Prior to the procedure, a peripheral blood sample had been obtained and placed in a purple top tube labeled \"pre-excision.\" It was our intention to monitor intraoperative intact parathyroid hormone 10 minutes after removal of this parathyroid adenoma.',\n",
              " 'However, we could not obtain 3 cc of blood from either the left foot or the left arm after multiple attempts, and therefore, we decided that the chance of cure of hyperparathyroidism by removal of this parathyroid adenoma was high enough and the improvement in that chance of cure marginal enough that we would terminate the procedure without monitoring PTH.',\n",
              " 'The neck was irrigated with saline and hemostasis found to be satisfactory.',\n",
              " 'The sternohyoid muscles were reapproximated with interrupted 4-0 Vicryl.',\n",
              " 'The platysma was closed with interrupted 4-0 Vicryl, and the skin was closed with subcuticular 5-0 Monocryl and Dermabond.',\n",
              " 'The patient was awakened and taken to the recovery area in satisfactory condition having tolerated the procedure well.']"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd_res.loc[0].result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62a8d74",
      "metadata": {
        "id": "b62a8d74"
      },
      "outputs": [],
      "source": [
        "sent_list = []\n",
        "for anno in sd_model.fullAnnotate(text)[0][\"sentences\"]:\n",
        "     sent_list.append(anno.result)\n",
        "#print(sent_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b804c65",
      "metadata": {
        "id": "4b804c65"
      },
      "outputs": [],
      "source": [
        "sentence_lower =  []\n",
        "for i in sent_list:\n",
        "    sentence_lower.append(i.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2fc5fe",
      "metadata": {
        "id": "ab2fc5fe"
      },
      "outputs": [],
      "source": [
        "sent_token_df = pd.DataFrame(sentence_lower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7da32c7",
      "metadata": {
        "id": "e7da32c7"
      },
      "outputs": [],
      "source": [
        "sent_token_df = sent_token_df.rename(columns={0:\"sentence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be26b3a",
      "metadata": {
        "id": "7be26b3a"
      },
      "outputs": [],
      "source": [
        "sent_token_df.sentence = sent_token_df.sentence.apply(lambda x: re.sub(pattern=\"[^\\w\\s]\", repl=\"\", string=x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecaa86f8",
      "metadata": {
        "id": "ecaa86f8"
      },
      "outputs": [],
      "source": [
        "def space(sentence):\n",
        "    word_var = word_tokenize(sentence)\n",
        "    sent_var = \" \".join(word_var)\n",
        "    return sent_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f40edd",
      "metadata": {
        "id": "73f40edd"
      },
      "outputs": [],
      "source": [
        "sent_token_df.sentence = sent_token_df.sentence.apply(lambda x : space(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cfa16fe",
      "metadata": {
        "id": "3cfa16fe"
      },
      "outputs": [],
      "source": [
        "sent_token_df.drop(sent_token_df[sent_token_df.sentence == \"\"].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1edb9b4",
      "metadata": {
        "id": "d1edb9b4"
      },
      "outputs": [],
      "source": [
        "sent_count= sent_token_df.sentence.value_counts().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e512171",
      "metadata": {
        "id": "3e512171"
      },
      "outputs": [],
      "source": [
        "sent_count_df = pd.DataFrame(sent_count).reset_index()\n",
        "sent_count_df.rename(columns={\"index\":\"sentence\", \"sentence\":\"frequency\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bd5bdd",
      "metadata": {
        "id": "d3bd5bdd"
      },
      "outputs": [],
      "source": [
        "total_frequency = sent_count_df.frequency.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a592e8cd",
      "metadata": {
        "id": "a592e8cd"
      },
      "outputs": [],
      "source": [
        "sent_count_df[\"ratio\"] = (sent_count_df.frequency/total_frequency)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7422e49",
      "metadata": {
        "id": "b7422e49"
      },
      "outputs": [],
      "source": [
        "sent_count_df[\"cumul_ratio\"] = np.cumsum(sent_count_df[\"ratio\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbc0a3cd",
      "metadata": {
        "id": "fbc0a3cd"
      },
      "outputs": [],
      "source": [
        "def sentence_lenght(sentence):\n",
        "    word_var2 = word_tokenize(sentence)\n",
        "    if len(word_var2) <= 10:\n",
        "        sent_var2 = \" \".join(word_var2)\n",
        "        return sent_var2\n",
        "    else:\n",
        "        return \"sentence is bigger than ten word\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f52991e",
      "metadata": {
        "id": "9f52991e"
      },
      "outputs": [],
      "source": [
        "sent_count_df.sentence = sent_count_df.sentence.apply(sentence_lenght)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349519d9",
      "metadata": {
        "id": "349519d9"
      },
      "outputs": [],
      "source": [
        "sent_count_df.drop(sent_count_df[sent_count_df.sentence == \"sentence is bigger than ten word\"].index,axis=0, inplace=True)\n",
        "sent_count_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddba6aaa",
      "metadata": {
        "id": "ddba6aaa"
      },
      "outputs": [],
      "source": [
        "sent_count_df.to_csv(\"Sentence_Tokenize1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39fbcd3",
      "metadata": {
        "id": "b39fbcd3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46b8e75",
      "metadata": {
        "id": "b46b8e75"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb2e52c",
      "metadata": {
        "id": "abb2e52c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8078ea",
      "metadata": {
        "id": "0b8078ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b98579",
      "metadata": {
        "id": "87b98579"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DF Sentence Detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
